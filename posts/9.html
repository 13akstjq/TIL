<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>TIL</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://13akstjq.github.io/TIL//posts/9" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="TIL" data-gatsby-head="true"/><meta property="og:title" content="TIL" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/TIL/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://TIL.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://13akstjq.github.io/TIL//posts/9" data-gatsby-head="true"/><meta name="twitter:title" content="TIL" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/TIL/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | TIL" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/TIL/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/TIL/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/TIL/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/TIL/favicons/favicon-96x96.png"/><link rel="icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/TIL/favicons/browserconfig.xml"/><link rel="preload" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/TIL/_next/static/css/7978fe7362f7d4c9.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/7978fe7362f7d4c9.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/TIL/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/TIL/_next/static/chunks/webpack-21ffe88bdca56cba.js" defer=""></script><script src="/TIL/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/TIL/_next/static/chunks/main-a5eeabb286676ce6.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/TIL/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/TIL/_next/static/chunks/463-925361deb4cec4b1.js" defer=""></script><script src="/TIL/_next/static/chunks/873-2eda6d845ad1e69e.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/posts/%5Bpage%5D-350e448526ad5efa.js" defer=""></script><script src="/TIL/_next/static/2X_5azw6MGdlttKMlGdWA/_buildManifest.js" defer=""></script><script src="/TIL/_next/static/2X_5azw6MGdlttKMlGdWA/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/TIL">TIL</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/TIL/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="Python으로 머신러닝에서 불균형 데이터 다루는 방법" href="/TIL/post/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Python으로 머신러닝에서 불균형 데이터 다루는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Python으로 머신러닝에서 불균형 데이터 다루는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">Python으로 머신러닝에서 불균형 데이터 다루는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">33<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="취미로 만든 파이썬 버전 관리 시스템 I Coded Pit 소개 " href="/TIL/post/2024-07-09-ICodedPitAVersionControlSysteminPythonforFun"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="취미로 만든 파이썬 버전 관리 시스템 I Coded Pit 소개 " loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-ICodedPitAVersionControlSysteminPythonforFun_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="취미로 만든 파이썬 버전 관리 시스템 I Coded Pit 소개 " loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">취미로 만든 파이썬 버전 관리 시스템 I Coded Pit 소개 </strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="TensorFlow Transform 프로덕션에서 매끄러운 데이터 준비를 위한 필수 가이드" href="/TIL/post/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="TensorFlow Transform 프로덕션에서 매끄러운 데이터 준비를 위한 필수 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="TensorFlow Transform 프로덕션에서 매끄러운 데이터 준비를 위한 필수 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">TensorFlow Transform 프로덕션에서 매끄러운 데이터 준비를 위한 필수 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="모델 성능 시각화 Python 코드로 혼동 행렬 그리는 방법 가이드" href="/TIL/post/2024-07-09-VisualizingModelPerformanceAGuidetoPlottingConfusionMatricesinPythonCode"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="모델 성능 시각화 Python 코드로 혼동 행렬 그리는 방법 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-VisualizingModelPerformanceAGuidetoPlottingConfusionMatricesinPythonCode_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="모델 성능 시각화 Python 코드로 혼동 행렬 그리는 방법 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">모델 성능 시각화 Python 코드로 혼동 행렬 그리는 방법 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="PyBroker를 사용한 포트폴리오 최적화 방법" href="/TIL/post/2024-07-09-PortfolioOptimizationwithPyBroker"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="PyBroker를 사용한 포트폴리오 최적화 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-PortfolioOptimizationwithPyBroker_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="PyBroker를 사용한 포트폴리오 최적화 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">PyBroker를 사용한 포트폴리오 최적화 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LangChain 심층 분석  Part 4 최신 LLM 스터디 다이어리" href="/TIL/post/2024-07-09-LLMStudyDiaryComprehensiveReviewofLangChainPart4"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LangChain 심층 분석  Part 4 최신 LLM 스터디 다이어리" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-LLMStudyDiaryComprehensiveReviewofLangChainPart4_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LangChain 심층 분석  Part 4 최신 LLM 스터디 다이어리" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">LangChain 심층 분석  Part 4 최신 LLM 스터디 다이어리</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="FastAPI 애플리케이션에서 Server-Sent EventSSE 사용 방법" href="/TIL/post/2024-07-09-Server-SentEventSSEinFastAPIApplications"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="FastAPI 애플리케이션에서 Server-Sent EventSSE 사용 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-Server-SentEventSSEinFastAPIApplications_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="FastAPI 애플리케이션에서 Server-Sent EventSSE 사용 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">FastAPI 애플리케이션에서 Server-Sent EventSSE 사용 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="1억 행 파이썬 처리 도전  10분에서 4초로 줄이는 방법" href="/TIL/post/2024-07-09-PythonOneBillionRowChallengeFrom10Minutesto4Seconds"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="1억 행 파이썬 처리 도전  10분에서 4초로 줄이는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-PythonOneBillionRowChallengeFrom10Minutesto4Seconds_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="1억 행 파이썬 처리 도전  10분에서 4초로 줄이는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">1억 행 파이썬 처리 도전  10분에서 4초로 줄이는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="구버전 AWS Lambda 런타임 자동 업데이트 방법" href="/TIL/post/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="구버전 AWS Lambda 런타임 자동 업데이트 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="구버전 AWS Lambda 런타임 자동 업데이트 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">구버전 AWS Lambda 런타임 자동 업데이트 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="FastAPI 실습 간단한 할 일 목록 애플리케이션 만들기 방법" href="/TIL/post/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="FastAPI 실습 간단한 할 일 목록 애플리케이션 만들기 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="FastAPI 실습 간단한 할 일 목록 애플리케이션 만들기 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">FastAPI 실습 간단한 할 일 목록 애플리케이션 만들기 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 9, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/TIL/posts/1">1</a><a class="link" href="/TIL/posts/2">2</a><a class="link" href="/TIL/posts/3">3</a><a class="link" href="/TIL/posts/4">4</a><a class="link" href="/TIL/posts/5">5</a><a class="link" href="/TIL/posts/6">6</a><a class="link" href="/TIL/posts/7">7</a><a class="link" href="/TIL/posts/8">8</a><a class="link posts_-active__YVJEi" href="/TIL/posts/9">9</a><a class="link" href="/TIL/posts/10">10</a><a class="link" href="/TIL/posts/11">11</a><a class="link" href="/TIL/posts/12">12</a><a class="link" href="/TIL/posts/13">13</a><a class="link" href="/TIL/posts/14">14</a><a class="link" href="/TIL/posts/15">15</a><a class="link" href="/TIL/posts/16">16</a><a class="link" href="/TIL/posts/17">17</a><a class="link" href="/TIL/posts/18">18</a><a class="link" href="/TIL/posts/19">19</a></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Python으로 머신러닝에서 불균형 데이터 다루는 방법","description":"","date":"2024-07-09 14:33","slug":"2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython","content":"\n기계 학습의 분류 문제를 다룰 때 고려해야 할 중요한 요소 중 하나는 레이블을 정의하는 클래스의 균형입니다.\n\n세 개의 클래스로 이루어진 상황을 상상해보세요. 초기 분석을 수행하여 정확도를 계산하면 93%를 얻을 수 있습니다. 그런 다음 더 깊게 들여다보는데, 데이터의 80%가 한 클래스에 속한다는 것을 알 수 있습니다. 이것이 좋은 징후인가요?\n\n음, 그렇지 않습니다. 이 문서에서는 그 이유를 설명하고 있습니다.\n\n# 초보자를 위한 Jupyter 노트북 설정하기\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기계 학습 초보자라면, ML 문제를 해결하기 위해 두 가지 소프트웨어를 사용할 수 있다는 것을 모를 수 있습니다:\n\n- Anaconda\n- Google Colaboratory\n\nAnaconda는 데이터 분석 및 기계 학습으로 예측을 하는 데 필요한 모든 라이브러리를 제공하는 데이터 과학 플랫폼입니다. 또한 데이터 과학자들이 데이터를 분석하는 데 사용하는 Jupyter Notebooks를 제공합니다. 따라서 Anaconda를 설치하면 필요한 모든 것을 갖추게 됩니다.\n\n반면에 Google Colaboratory는 설정이 필요 없는 호스팅된 Jupyter Notebook 서비스로, 무료로 컴퓨팅 리소스 및 필요한 모든 라이브러리에 대한 액세스를 제공합니다. 따라서 PC에 아무것도 설치하지 않고 데이터를 분석하려면 이 솔루션을 선택할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마침내, 이 글에서 찾을 수 있는 모든 코드를 포함하는 공개 저장소를 만들었습니다. 이 저장소는 하나의 Jupyter Notebook에 있어 데이터 과학자들이 데이터를 분석하는 방식을 확인하고자 할 때 참고할 수 있습니다.\n\n# 머신 러닝에서 불균형 데이터 소개\n\n이 섹션은 머신 러닝에서 클래스 불균형 문제를 소개하고, 불균형 클래스가 흔한 시나리오를 다룹니다. 그러나 계속하기 전에, \"불균형\" 또는 \"균형이 맞지 않는\" 용어를 무시하고 사용할 수 있다는 점을 얘기합시다.\n\n# 불균형 데이터 정의 및 모델 성능에 미치는 영향\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n상상해봐요. 당신이 100명의 학생들을 가르치는 수학 선생님인 상황을 상상해보세요. 이 학생들 중 90명은 수학을 잘하는 학생(Group A), 그리고 10명은 어려워하는 학생들(Group B)이라고 부를 수 있겠네요. 이 수업 구성은 기계 학습 세상에서 \"불균형 데이터\"로 알려져 있어요.\n\n기계 학습에서 데이터는 컴퓨터에 예측이나 결정을 내리도록 가르치는 데 사용되는 교과서와 같아요. 불균형 데이터가 있다는 것은 컴퓨터가 배워야 하는 것들에 대한 예제 수에 큰 차이가 있다는 것을 의미해요. 우리의 수업 비유에 따르면, 과반이 되는 A 그룹보다 소수인 B 그룹의 학생 수가 적어요.\n\n이제 우리의 기계 학습 모델의 성능은 불균형 데이터에 영향을 받아요. 예를 들어, 여기에는 몇 가지 영향들이 있어요:\n\n- 편향된 학습. 대부분의 학생들이 수학을 잘하는 이 불균형한 수업에서 컴퓨터를 가르치면, 약간 편향될 수 있어요. 마치 컴퓨터가 수학 천재들에게 둘러싸인 듯하니, 모두가 수학 천재인 것으로 생각할 수 있어요. 기계 학습 용어로는 모델이 과반수 클래스 쪽으로 편향될 수 있어요. 그것은 일반적인 것(Group A)을 예측하는 데 능숙해지지만 드문 것(Group B)을 이해하는 데 어려움을 겪을 수 있어요. 당신이 학생들의 투표를 사용하여 수학 가르치기에 얼마나 능숙한지를 평가한다면, 90%의 학생이 수학을 잘하는 것이기 때문에 편향된 결과를 받을 수 있어요. 그런데 이 90% 중 대부분이 사설 수업을 듣고 있다면 당신은 알 수 없어요.\n- 잘못된 정확도. 컴퓨터의 성능을 평가하려면 컴퓨터가 수학을 잘하는 학생이나 어려워하는 학생을 올바르게 식별한 횟수를 확인하여야 해요. A 그룹이 많기 때문에 컴퓨터는 대부분의 학생을 올바르게 맞출 수 있을 거예요. 그래서 정확도가 높아 보인다면 컴퓨터가 훌륭한 일을 하는 것처럼 보일 수 있어요. 그러나 B 그룹이 적기 때문에 실제로는 B 그룹에는 엉망진창일 수 있어요. 기계 학습에서 이 높은 정확도는 컴퓨터가 소수 클래스에서 얼마나 잘 수행되고 있는지 알려주지 않아서 잘못된 정보일 수 있어요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n간단히 말해서, 불균형 데이터는 컴퓨터에 학습시키려는 서로 다른 사례들에 대해 불균형한 예제 수가 있다는 것을 의미하며, 특히 드물게 발생하는 경우를 처리할 때 머신러닝 모델의 성능에 심각한 영향을 미칠 수 있습니다.\n\n어쨌든, 데이터가 불균형할 것으로 예상되는 경우도 있습니다.\n\n이것들에 대해 설명하기 전에 먼저 어떤 경우에 불균형 데이터가 일반적인지 살펴보겠습니다.\n\n# 불균형 데이터가 흔한 시나리오\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현실적인 시나리오에서는 데이터가 불균형적인 경우가 많이 발생합니다. 만약 그렇지 않다면, 오류가 있는 것을 의미합니다.\n\n예를 들어 의학 분야를 생각해보겠습니다. 대규모 인구 중에서 희귀 질병을 찾으려고 할 때, 데이터는 불균형해야 합니다. 그렇지 않으면 우리가 찾고 있는 질병이 희귀하지 않다는 것을 의미합니다.\n\n사기 탐지의 경우도 마찬가지입니다. 금융 기관의 데이터 과학자로서 신용 카드에서 사기 거래를 분석하고 있을 때, 불균형한 데이터를 발견해야 합니다. 그렇지 않으면 사기 거래가 비-사기 거래만큼 자주 발생한다는 것을 의미합니다.\n\n# 불균형 문제 이해하기\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 Python 코드와 함께 실제 상황에 대해 알아볼까요? 이를 통해 다음을 보여줄 수 있습니다:\n\n- 그래픽을 기반으로 한 주요 및 소수 클래스 간의 차이.\n- 불균형한 데이터에 영향을 받는 평가 지표들.\n- 불균형한 데이터에 영향을 받지 않는 평가 지표들.\n\n# 주요 및 소수 클래스 간의 차이\n\n수학 선생님인 당신이라고 가정해보겠습니다. 이번에는 1000명의 학생으로 이루어진 대규모 강의를 하고 있습니다. 머신러닝을 사용하여 어떠한 분류를 수행하기 전에, 데이터가 불균형인지 확인하기로 결정했습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하나의 방법은 분포를 시각화하는 것입니다. 예를 들어, 다음과 같이:\n\n```js\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n```js\n# 재현 가능성을 위해 랜덤 시드 설정\nnp.random.seed(42)\n# 다수 클래스 (Class 0)를 위한 데이터 생성\nmajority_class = np.random.normal(0, 1, 900)\n# 소수 클래스 (Class 1)를 위한 데이터 생성\nminority_class = np.random.normal(3, 1, 100)\n# 다수 클래스와 소수 클래스 데이터 결합\ndata = np.concatenate((majority_class, minority_class))\n# 클래스 레이블 생성\nlabels = np.concatenate((np.zeros(900), np.ones(100)))\n# 클래스 분포 플로팅\nplt.figure(figsize=(8, 6))\nplt.hist(data[labels == 0], bins=20, color='blue', alpha=0.6, label='다수 클래스 (Class 0)')\nplt.hist(data[labels == 1], bins=20, color='red', alpha=0.6, label='소수 클래스 (Class 1)')\nplt.xlabel('특성 값')\nplt.ylabel('빈도수')\nplt.title('불균형 데이터셋의 클래스 분포')\nplt.legend()\nplt.show()\n```\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 Python 예제에서는 두 개의 클래스를 만들었습니다:\n\n- 주요 클래스 (클래스 0). 이 클래스는 데이터 포인트의 대다수를 나타냅니다. 평균이 0이고 표준 편차가 1인 정규 분포에서 900개의 데이터 포인트를 생성했습니다. 실제 시나리오에서는 매우 흔하거나 전형적인 것을 나타낼 수 있습니다.\n- 소수 클래스 (클래스 1). 이 클래스는 데이터 포인트의 소수를 나타냅니다. 평균이 3이고 표준 편차가 1인 정규 분포에서 100개의 데이터 포인트를 생성했습니다. 이 클래스는 의도적으로 흔하지 않게 만들어져 불균형 데이터셋을 시뮬레이션합니다. 실제로는 드문 사건이나 이상을 나타낼 수 있습니다.\n\n다음으로, 이 두 클래스를 해당 레이블 (주요 클래스에 대한 0 및 소수 클래스에 대한 1)과 함께 단일 데이터셋으로 결합합니다. 마지막으로, 히스토그램을 사용하여 클래스 분포를 시각화합니다. 히스토그램에서:\n\n- 파란 막대는 주요 클래스 (클래스 0)를 나타내며, 좌측에 더 크고 더 빈번한 막대입니다.\n- 빨간 막대는 소수 클래스 (클래스 1)를 나타내며, 우측에 더 작고 덜 빈번한 막대입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 시각화는 불균형 데이터셋에서 주요 및 소수 클래스 간의 차이를 명확하게 보여줍니다. 주요 클래스는 소수 클래스보다 훨씬 많은 데이터 포인트를 가지고 있으며, 이는 불균형 데이터의 일반적인 특성입니다.\n\n클래스 불균형을 다루는 또 다른 방법은 분포를 통해 직접적으로 빈도를 살펴보는 것입니다. 예를 들어, 다음과 같이 할 수 있습니다:\n\n```js\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n```js\n# 재현성을 위해 임의의 시드 설정\nnp.random.seed(42)\n# 주요 클래스 (클래스 0)에 대한 데이터 생성\nmajority_class = np.random.normal(0, 1, 900)\n# 소수 클래스 (클래스 1)에 대한 데이터 생성\nminority_class = np.random.normal(3, 1, 100)\n# 주요 및 소수 클래스 데이터 결합\ndata = np.concatenate((majority_class, minority_class))\n# 클래스에 대한 레이블 생성\nlabels = np.concatenate((np.zeros(900), np.ones(100))\n# 각 클래스의 빈도 카운트\nclass_counts = [len(labels[labels == 0]), len(labels[labels == 1])]\n# 막대 그래프를 사용하여 클래스 빈도 플로팅\nplt.figure(figsize=(8, 6))\nplt.bar(['주요 클래스 (클래스 0)', '소수 클래스 (클래스 1)'], class_counts, color=['blue', 'red'])\nplt.xlabel('클래스')\nplt.ylabel('빈도')\nplt.title('불균형 데이터셋의 클래스 빈도')\nplt.show()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같이 테이블 태그를 마크다운 형식으로 변경해주세요.\n\n![image](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_1.png)\n\n그러니까, 이 경우에는 클래스에 속하는 데이터의 모든 발생을 계산하는 내장 메소드 len()을 사용할 수 있습니다.\n\n# 이상 데이터로 영향을 받는 일반 평가 지표\n\n이상 데이터에 영향을 받는 모든 평가 지표를 설명하려면 먼저 다음을 정의해야 합니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- True positive (TP). 분류기가 조건이나 특성의 존재를 올바르게 예측한 값\n- True negative (TN). 분류기가 조건이나 특성의 부재를 올바르게 예측한 값\n- False positive (FP). 분류기가 특정 조건이나 속성이 존재하는 것으로 잘못 예측한 값\n- False negative (FN). 분류기가 특정 조건이나 속성이 존재하지 않는 것으로 잘못 예측한 값\n\n다음은 불균형 데이터가 영향을 미치는 일반적인 평가 지표입니다:\n\n- 정확도. 데이터 세트에서 올바르게 예측된 인스턴스의 비율을 측정합니다.\n\n![이미지](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_2.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬에서 정확도 지표를 계산하는 방법에 대한 예제를 만들어보겠습니다:\n\n```python\nfrom sklearn.metrics import accuracy_score\n```\n\n```python\n# 실제 레이블\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n# 모델이 예측한 레이블\npredicted_labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(\"정확도:\", accuracy)\n```\n\n결과는:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n정확도: 0.5;\n```\n\n정확도는 불균형한 데이터를 다룰 때 혼란을 줄 수 있습니다.\n\n실제로 95%가 A 클래스에 속하고 5%만 B 클래스에 속하는 데이터 세트가 있다고 가정해 봅시다. 모델이 모든 인스턴스를 A 클래스로 예측한다면 95%의 정확도를 달성할 것입니다. 하지만 이는 반드시 모델이 좋다는 것을 의미하지는 않습니다. 이는 단지 클래스 불균형을 악용한 것뿐입니다. 다시 말해, 이 메트릭은 소수 클래스 (B 클래스)를 얼마나 잘 식별하는지를 고려하지 않습니다.\n\n- 정밀도. 이것은 모든 예측된 긍정 인스턴스 중 올바르게 예측된 긍정 인스턴스의 비율을 측정합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![How to Handle Imbalanced Data for Machine Learning in Python](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_3.png)\n\n한 예제를 통해 Python에서 정밀도 지표를 계산하는 방법을 살펴보겠습니다:\n\n```python\nfrom sklearn.metrics import precision_score\n```\n\n```python\n# True labels\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n# Predicted labels by a model\npredicted_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nprecision = precision_score(true_labels, predicted_labels)\nprint(\"Precision:\", precision)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n결과는 다음과 같습니다:\n\n```js\n정밀도: 0.5;\n```\n\n불균형 데이터 세트에서는 정밀도가 매우 오해를 일으킬 수 있습니다.\n\n실제로, 모델이 하나의 인스턴스만을 긍정적(클래스 B)으로 분류하고 그게 맞는 경우, 정밀도는 100%가 될 것입니다. 그러나 이는 모델이 소수 클래스에서의 성능을 나타내는 것이 아닐 수 있습니다. 왜냐하면 많은 긍정적 인스턴스를 놓칠 수 있기 때문입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 재현율 (또는 민감도). 재현율은 또한 민감도 또는 진양성율로 알려져 있으며, 올바르게 예측된 긍정적 인스턴스의 비율을 측정합니다:\n\n![Example](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_4.png)\n\n파이썬을 사용하여 재현율 지표를 계산하는 예제를 만들어 보겠습니다:\n\n```js\nfrom sklearn.metrics import recall_score\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 실제 레이블\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n# 모델이 예측한 레이블\npredicted_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nrecall = recall_score(true_labels, predicted_labels)\nprint(\"재현율:\", recall)\n```\n\n결과는:\n\n```js\n재현율: 1.0;\n```\n\n재현율은 불균형한 데이터셋에서도 잘못된 정보를 줄 수 있습니다. 특히 모든 긍정적인 인스턴스를 포착하는 것이 중요할 때에는요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 모델이 더 많은 양의 양성 인스턴스가 있는 상황에서 한 인스턴스만을 양성(Class B)으로 예측할 경우, 재현율이 매우 낮을 수 있습니다. 이는 모델이 소수 클래스의 중요한 부분을 놓치고 있음을 나타낼 수 있습니다. 이는 이 메트릭이 false positives를 고려하지 않기 때문에 발생합니다.\n\n- F1 스코어. F1 스코어는 정밀도와 재현율의 조화평균입니다. 정밀도와 재현율 사이의 균형을 제공합니다:\n\n![image](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_5.png)\n\n파이썬을 사용하여 F1 스코어 메트릭을 계산하는 예제를 만들어봅시다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfrom sklearn.metrics import f1_score\n```\n\n```js\n# True labels\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n# Predicted labels by a model\npredicted_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n# Calculate and print F1-score\nf1 = f1_score(true_labels, predicted_labels)\nprint(\"F1-Score:\", f1)\n```\n\n결과는:\n\n```js\nF1-Score: 0.6666666666666666\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 메트릭은 정밀도와 재현율을 사용하여 생성되었기 때문에 데이터 불균형에 영향을 받을 수 있습니다.\n\n하나의 클래스가 지배적이고 (다수 클래스인 경우), 그 모델이 해당 클래스를 편향으로 처리하는 경우, F1 점수는 소수 클래스의 낮은 재현율에도 높은 정밀도 때문에 상대적으로 높을 수 있습니다. 이는 모델의 전체 효과를 잘못 나타낼 수 있습니다.\n\n# 데이터 불균형에 영향을 받지 않는 가장 많이 사용되는 평가 지표\n\n이제 클래스 불균형에 영향을 받지 않는 평가 지표 중 가장 많이 사용되는 두 가지를 설명하겠습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 혼동 행렬. 혼동 행렬은 분류 알고리즘의 성능을 요약하는 표입니다. 이는 True Positives (TP), True Negatives (TN), False Positives (FP) 및 False Negatives (FN)의 자세한 분석을 제공합니다. 특히, 주 대각선(왼쪽 위에서 오른쪽 아래)은 TP와 TN을 보여주며, 보조 대각선(왼쪽 아래에서 오른쪽 위)은 FP와 FN을 나타냅니다. 따라서, 머신 러닝 모델이 데이터를 올바르게 분류할 경우, 혼동 행렬의 주 대각선은 가장 높은 값을, 보조 대각선은 가장 낮은 값을 보고해야 합니다.\n\n파이썬에서 예제를 보여드리겠습니다:\n\n```python\nfrom sklearn.metrics import confusion_matrix\n```\n\n```python\n# True and predicted labels\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\npredicted_labels = [0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n# Create confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels)\n# Print confusion matrix\nprint(\"Confusion Matrix:\")\nprint(cm)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 저희가 얻은 것은:\n\n```js\n혼동 행렬:\n[[5 0]\n [1 4]]\n```\n\n이 혼동 행렬은 주 대각선에 결과가 가장 많기 때문에(10개 중 9개) 좋은 분류기를 나타냅니다. 이는 분류기가 5개의 TP와 4개의 TN을 예측했다는 것을 의미합니다.\n\n그에 비해, 보조 대각선은 낮은 결과를 보여줍니다(10개 중 1개). 이는 분류기가 1개의 FP와 0개의 FN을 예측했음을 의미합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러므로 이것은 좋은 분류기로 이어집니다.\n\n따라서 혼동 행렬은 모델 성능의 자세한 분석을 제공하여 각 클래스에 대해 올바르게 또는 잘못 분류된 인스턴스의 수를 몇 초 안에 알 수 있도록합니다.\n\n- AUC/ROC 커브. ROC는 \"Receiver Operating Characteristic\"의 약자로, 참 긍정률 (TPR)을 다른 임계값에서 거짓 긍정률 (FPR)에 대비하여 그래픽 방식으로 그리는 분류기를 평가하는 방법입니다.\n\n우리는 다음과 같이 정의합니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- TPR을 민감도로(우리가 말했듯이 recall로도 불릴 수 있음).\n- FPR을 1-특이도로 정의합니다.\n\n특이도는 분류기가 모든 부정적인 샘플을 찾는 능력을 의미합니다:\n\n![이미지](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_6.png)\n\nAUC는 ROC 곡선 아래 영역을 나타내며 \"곡선 아래 영역\"을 의미합니다. 이는 0에서 1사이의 전체적인 성능 지표로, 1은 분류기가 레이블의 100%를 실제 값으로 예측한다는 것을 의미하며, 서로 다른 분류기들을 비교할 때 더 적합합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 이진 분류 문제를 공부한다고 가정해봅시다. 파이썬에서 AUC 곡선을 그리는 방법은 다음과 같습니다:\n\n```python\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\n```\n\n```python\n# 무작위로 이진 분류 데이터세트 생성\nX, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n# 데이터세트를 학습 및 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# 학습 데이터에서 로지스틱 회귀 모델 학습\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n# 테스트 데이터에 대해 확률 예측\nprobs = model.predict_proba(X_test)\n# ROC 곡선 및 AUC 점수 계산\nfpr, tpr, thresholds = roc_curve(y_test, probs[:, 1])\nauc_score = roc_auc_score(y_test, probs[:, 1])\n# ROC 곡선 그리기\nplt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_score))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc='lower right')\nplt.show()\n```\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_7.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 코드로는 다음을 할 수 있어요:\n\n- make_classification 메서드로 분류 데이터셋을 생성했어요.\n- 데이터셋을 훈련 세트와 테스트 세트로 나눴어요.\n- Logistic Regression 분류기로 훈련 세트를 fit했어요.\n- predict_proba() 메서드로 테스트 데이터에 대한 예측을 만들었어요.\n- ROC 곡선과 AUC 점수를 계산했어요.\n- AUC 곡선을 그렸어요.\n\n# 불균형 데이터 다루는 기술\n\n이 섹션에서는 불균형 데이터를 다루는 몇 가지 기술을 다루겠어요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다시 말해, 우리는 불균형 데이터를 다루는 방법에 대해 이야기할 것입니다.\n\n## 리샘플링\n\n불균형 데이터셋을 처리하는 데 널리 사용되는 방법론은 리샘플링입니다. 이 방법론은 두 가지 다른 프로세스로 나눌 수 있습니다:\n\n- 오버샘플링. 소수 클래스에 더 많은 예제를 추가하는 것을 의미합니다.\n- 언더샘플링. 다수 클래스에서 샘플을 제거하는 것을 의미합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 가지 방법에 대해 설명해 보겠습니다.\n\n## Oversampling\n\nOversampling은 소수 클래스의 인스턴스 수를 늘려 클래스 분포를 균형있게 만드는 재표본화 기술입니다. 주로 기존 인스턴스를 복제하거나 소수 클래스와 유사한 합성 데이터 포인트를 생성함으로써 수행됩니다. 목표는 모델이 훈련 중에 두 클래스의 더 균형 잡힌 표현을 볼 수 있도록 하는 것입니다.\n\n장점:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 모델 성능 향상. Oversampling은 소수 클래스의 특성을 더 잘 학습할 수 있도록 도와주어 전체적인 분류 성능을 향상시킬 수 있습니다, 특히 소수 클래스에 대해서 더욱 효과적입니다.\n- 정보 보존. 언더샘플링과는 달리, 오버샘플링은 과반 클래스의 모든 인스턴스를 보존하여 정보의 손실이 없도록 합니다.\n\n단점:\n\n- 과적합의 위험. 중복되거나 합성된 인스턴스는 적절하게 제어되지 않으면, 특히 합성 데이터가 기존 데이터와 너무 유사한 경우에는 과적합을 유발할 수 있습니다.\n- 훈련 시간 증가. 오버샘플링으로 인한 더 큰 데이터셋은 머신러닝 알고리즘의 학습 시간이 더 오래 걸릴 수 있습니다.\n\nPython에서 불균형한 데이터셋에 대한 오버샘플링 기술을 어떻게 활용할 수 있는지 알아보겠습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter\n```\n\n```js\n# 3개 클래스를 가지는 불균형 데이터셋 생성\nX, y = make_classification(\n    n_samples=1000,\n    n_features=20,\n    n_classes=3,\n    n_clusters_per_class=1,\n    weights=[0.1, 0.3, 0.6],  # 클래스 불균형\n    random_state=42\n)\n# 초기 클래스들의 히스토그램 출력\nplt.figure(figsize=(10, 6))\nplt.hist(y, bins=range(4), align='left', rwidth=0.8, color='blue', alpha=0.7)\nplt.title(\"초기 클래스들의 히스토그램\")\nplt.xlabel(\"클래스\")\nplt.ylabel(\"인스턴스 개수\")\nplt.xticks(range(3), ['클래스 0', '클래스 1', '클래스 2'])\nplt.show()\n# RandomOverSampler를 사용하여 오버샘플링 적용\noversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\nX_resampled, y_resampled = oversampler.fit_resample(X, y)\n# 재샘플링된 클래스들의 히스토그램 출력\nplt.figure(figsize=(10, 6))\nplt.hist(y_resampled, bins=range(4), align='left', rwidth=0.8, color='orange', alpha=0.7)\nplt.title(\"재샘플링된 클래스들의 히스토그램 (오버샘플링)\")\nplt.xlabel(\"클래스\")\nplt.ylabel(\"인스턴스 개수\")\nplt.xticks(range(3), ['클래스 0', '클래스 1', '클래스 2'])\nplt.show()\n```\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_8.png\" /\u003e\n\n## 언더샘플링\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n언더샘플링은 머신 러닝에서 사용되는 샘플링 기술 중 하나로, 주요 클래스의 인스턴스 수를 줄여 클래스 분포를 균형있게 만드는 것에 초점을 맞춥니다. 주로 주요 클래스에서 인스턴스를 무작위로 제거해 두 클래스가 보다 균형 잡힌 표현이 되도록 하는 방식입니다. 여기에는 언더샘플링의 장단점이 있습니다.\n\n장점:\n\n- 과적합 위험이 감소합니다. 언더샘플링은 오버샘플링과 비교하여 과적합 위험을 줄입니다. 주요 클래스의 인스턴스 수를 줄이면 모델이 학습 데이터를 외워버리는 경향이 줄어들고 새로운, 보이지 않는 데이터에 대해 더 잘 일반화할 수 있습니다.\n- 빠른 학습 시간입니다. 언더샘플링을 거친 후 데이터셋에는 더 이상 적은 인스턴스가 있기 때문에 머신 러닝 알고리즘의 학습 시간을 줄일 수 있습니다. 보통 데이터가 적을수록 학습 시간이 더 빨라집니다.\n\n단점:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 정보 손실. 언더샘플링은 주요 클래스에서 인스턴스를 버림으로써 귀중한 정보 손실을 야기할 수 있습니다. 만일 버려진 인스턴스에 주요 클래스의 전반적인 이해에 기여하는 중요한 특성이 있다면 문제가 될 수 있습니다.\n- 편향된 모델의 위험. 주요 클래스에서 인스턴스를 제거하면 편향된 모델을 유발할 수 있으며, 이는 실제 주요 클래스의 분포를 정확하게 포착하지 못할 수 있습니다. 이러한 편향은 모델이 실제 세계 상황에 일반화하는 능력에 영향을 줄 수 있습니다.\n- 주요 클래스에서의 성능 저하 가능성. 언더샘플링은 주요 클래스에서 성능이 나쁜 모델을 유발할 수 있습니다. 왜냐하면 학습할 정보가 적기 때문입니다. 이는 주요 클래스의 인스턴스를 잘못 분류할 수 있게 됩니다.\n- 샘플링 비율에 민감함. 언더샘플링 정도는 모델의 성능에 중대한 영향을 미칠 수 있습니다. 샘플링 비율이 과도하면 주요 클래스의 중요한 정보가 손실될 수 있고, 너무 보수적이면 클래스 불균형 문제가 계속 남을 수 있습니다.\n\n아래는 파이썬에서 불균형 데이터셋에 대해 언더샘플링 기술을 활용하는 방법입니다:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\n```\n\n```python\n# 3개 클래스를 갖는 불균형 데이터셋 생성\nX, y = make_classification(\n    n_samples=1000,\n    n_features=20,\n    n_classes=3,\n    n_clusters_per_class=1,\n    weights=[0.1, 0.3, 0.6],  # 클래스 불균형\n    random_state=42\n)\n# 초기 클래스 히스토그램 출력\nplt.figure(figsize=(10, 6))\nplt.hist(y, bins=range(4), align='left', rwidth=0.8, color='blue', alpha=0.7)\nplt.title(\"Initial Classes의 히스토그램\")\nplt.xlabel(\"클래스\")\nplt.ylabel(\"인스턴스 수\")\nplt.xticks(range(3), ['클래스 0', '클래스 1', '클래스 2'])\nplt.show()\n# RandomUnderSampler를 사용하여 언더샘플링 적용\nundersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\nX_resampled, y_resampled = undersampler.fit_resample(X, y)\n# 재샘플링 클래스의 히스토그램 출력\nplt.figure(figsize=(10, 6))\nplt.hist(y_resampled, bins=range(4), align='left', rwidth=0.8, color='orange', alpha=0.7)\nplt.title(\"Resampled Classes (언더샘플링)의 히스토그램\")\nplt.xlabel(\"클래스\")\nplt.ylabel(\"인스턴스 수\")\nplt.xticks(range(3), ['클래스 0', '클래스 1', '클래스 2'])\nplt.show()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Markdown 형식으로 표를 변경한 것입니다.\n\n![image](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_9.png)\n\n## 성능 비교\n\n다음은 Python 예제를 만들어보겠습니다.\n\n- 균형이 맞지 않은 데이터 세트를 만듭니다.\n- 언더샘플링 및 오버샘플링을 진행합니다.\n- 언더샘플링 및 오버샘플링된 데이터 세트에 대해 훈련 및 검증 세트를 만들고, KNN 분류기로 학습합니다.\n- 언더샘플링 및 오버샘플링된 데이터 세트의 정확도를 비교합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import accuracy_score\n```\n\n```js\n# 3개의 클래스를 가진 불균형 데이터셋 생성\nX, y = make_classification(\n    n_samples=1000,\n    n_features=20,\n    n_classes=3,\n    n_clusters_per_class=1,\n    weights=[0.1, 0.3, 0.6],  # 클래스 불균형\n    random_state=42\n)\n# 원본 데이터셋을 학습 및 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# RandomOverSampler를 사용하여 오버샘플링 적용\noversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\nX_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n# RandomUnderSampler를 사용하여 언더샘플링 적용\nundersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\nX_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)\n# 원본 학습 세트에 KNN 분류기 피팅\nknn_original = KNeighborsClassifier(n_neighbors=5)\nknn_original.fit(X_train, y_train)\n# 오버샘플링된 학습 세트에 KNN 분류기 피팅\nknn_oversampled = KNeighborsClassifier(n_neighbors=5)\nknn_oversampled.fit(X_train_oversampled, y_train_oversampled)\n# 언더샘플링된 학습 세트에 KNN 분류기 피팅\nknn_undersampled = KNeighborsClassifier(n_neighbors=5)\nknn_undersampled.fit(X_train_undersampled, y_train_undersampled)\n# 학습 세트에 대한 예측 수행\ny_train_pred_original = knn_original.predict(X_train)\ny_train_pred_oversampled = knn_oversampled.predict(X_train_oversampled)\ny_train_pred_undersampled = knn_undersampled.predict(X_train_undersampled)\n# 테스트 세트에 대한 예측 수행\ny_test_pred_original = knn_original.predict(X_test)\ny_test_pred_oversampled = knn_oversampled.predict(X_test)\ny_test_pred_undersampled = knn_undersampled.predict(X_test)\n# 학습 세트의 정확도 계산 및 출력\nprint(\"원본 학습 세트 정확도:\", accuracy_score(y_train, y_train_pred_original))\nprint(\"오버샘플링된 학습 세트 정확도:\", accuracy_score(y_train_oversampled, y_train_pred_oversampled))\nprint(\"언더샘플링된 학습 세트 정확도:\", accuracy_score(y_train_undersampled, y_train_pred_undersampled))\n# 테스트 세트의 정확도 계산 및 출력\nprint(\"\\n원본 테스트 세트 정확도:\", accuracy_score(y_test, y_test_pred_original))\nprint(\"오버샘플링된 테스트 세트 정확도:\", accuracy_score(y_test, y_test_pred_oversampled))\nprint(\"언더샘플링된 테스트 세트 정확도:\", accuracy_score(y_test, y_test_pred_undersampled))\n```\n\n결과:\n\n```js\n원본 학습 세트 정확도: 0.9125\n오버샘플링된 학습 세트 정확도: 0.9514767932489452\n언더샘플링된 학습 세트 정확도: 0.85\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n원본 테스트 세트 정확도: 0.885\n오버샘플링된 테스트 세트 정확도: 0.79\n언더샘플링된 테스트 세트 정확도: 0.805\n```\n\n정확도 지표 비교를 통해 이러한 방법론의 특징을 확인할 수 있습니다:\n\n- 오버샘플링 기술은 KNN 모델이 오버피팅되고 있는 것을 시사하며, 이는 오버샘플링 그 자체 때문입니다.\n- 언더샘플링 기술은 KNN 모델이 편향될 수 있음을 시사하며, 이는 언더샘플링 그 자체 때문입니다.\n- 리샘플링 없이 모델을 학습시킨 것은 데이터의 불균형으로 정확도가 잘못 이끌 수 있음을 보여줍니다.\n\n따라서 이 경우, 가능한 해결책은 오버샘플링을 사용하고 KNN의 하이퍼파라미터를 조정하여 오버피팅을 피할 수 있는지 확인해 보는 것입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 앙상블\n\n불균형 데이터를 다루는 또 다른 방법은 앙상블 학습을 사용하는 것입니다. 특히, 랜덤 포레스트(Random Forest, RF)는 여러 의사 결정 트리 모델의 앙상블인데, 주 클래스에 편향되지 않는 내재적 능력으로 널리 사용되는 머신 러닝 모델입니다.\n\n그 이유는 다음과 같습니다:\n\n- Bootstrap 샘플링. RF 모델은 무작위 샘플링을 사용하여 작동합니다. 즉, 다양한 의사 결정 트리 모델을 훈련하는 동안, 선택된 데이터는 전체 데이터 세트의 무작위 하위 집합을 사용하고, 데이터는 대체됩니다. 이는 평균적으로 각 의사 결정 트리가 원래 데이터의 약 2/3에 대해 훈련됩니다. 결과적으로 소수 클래스의 일부 인스턴스가 의사 결정 트리를 작성하는 데 사용된 하위 집합에 포함될 가능성이 높습니다. 샘플 선택의 이 랜덤성은 주요 및 소수 클래스의 영향을 균형있게 조정하는 데 도움이 됩니다.\n- 무작위 특성 선택. 데이터를 무작위화하는 것 외에도, 랜덤 포레스트는 각 트리의 각 노드에 대해 무작위로 특성을 선택합니다. 즉, 분할할 때 고려할 특성의 무작위 하위 집합을 선택합니다. 이 특성의 무작위성은 대부분 주 클래스를 대표하는 특성에 대한 잠재적인 편향을 줄입니다.\n- 오류 수정 메커니즘. 랜덤 포레스트는 그 자체의 앙상블 성격을 통해 오류 수정 메커니즘을 사용합니다. 앙상블에서 한 의사 결정 트리가 소수 클래스 인스턴스에서 오류를 발생시키면, 앙상블의 다른 트리들은 해당 인스턴스에 대해 정확한 예측을 함으로써 보상할 수 있습니다. 앙상블 기반의 오류 수정은 주요 클래스의 우세함을 완화하는 데 도움이 됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전에 만든 데이터세트를 고려해 봅시다. 랜덤 포레스트 분류기를 사용하여 적합한 결과를 살펴봅시다:\n\n```js\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n```\n\n```js\n# 3개의 클래스로 불균형 데이터세트 생성\nX, y = make_classification(\n    n_samples=1000,\n    n_features=20,\n    n_classes=3,\n    n_clusters_per_class=1,\n    weights=[0.1, 0.3, 0.6],  # 클래스 불균형\n    random_state=42\n)\n# 데이터세트를 훈련 세트와 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# 훈련 세트에 랜덤 포레스트 분류기를 적합\nrf_classifier = RandomForestClassifier(random_state=42)\nrf_classifier.fit(X_train, y_train)\n# 훈련 세트와 테스트 세트에 대한 예측 생성\ny_train_pred = rf_classifier.predict(X_train)\ny_test_pred = rf_classifier.predict(X_test)\n# 훈련 세트의 정확도 계산 및 출력\ntrain_accuracy = accuracy_score(y_train, y_train_pred)\nprint(\"훈련 세트 정확도:\", train_accuracy)\n# 테스트 세트의 정확도 계산 및 출력\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(\"테스트 세트 정확도:\", test_accuracy)\n```\n\n그리고 우리는 다음과 같은 결과를 얻습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n학습 세트 정확도: 1.0\n테스트 세트 정확도: 0.97\n```\n\n이 경우에는 랜덤 포레스트를 사용했기 때문에 데이터 세트를 다시 샘플링할 필요가 없었습니다. 그래도 결과는 모델이 과적합될 가능성을 시사합니다. 이는 랜덤 포레스트 특성 때문일 수 있으므로 하이퍼파라미터 튜닝을 위해 추가적인 조사가 필요할 것입니다.\n\n어쨌든, 이 경우에는 하이퍼파라미터 튜닝 후 RF 모델을 사용하는 것이 KNN을 사용하고 데이터 세트를 언더샘플링하거나 오버샘플링하는 것보다 좋은 선택일 수 있습니다.\n\n# 결론\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 기계 학습(Machine Learning)에서 불균형 데이터를 다루는 방법에 대해 논의했습니다.\n\n특히, 희귀한 사건을 연구하기 때문에 데이터가 불균형할 것으로 예상되는 상황이 있습니다.\n\n반면에 데이터가 불균형해서는 안 되는 경우, 리샘플링(resampling)과 앙상블링(ensembling)과 같은 ML 모델을 다루는 방법에 대한 몇 가지 방법론을 소개했습니다.\n\n원문은 2024년 3월 7일 https://semaphoreci.com 에서 게시되었습니다.\n","ogImage":{"url":"/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png","tag":["Tech"],"readingTime":33},{"title":"취미로 만든 파이썬 버전 관리 시스템 I Coded Pit 소개 ","description":"","date":"2024-07-09 14:31","slug":"2024-07-09-ICodedPitAVersionControlSysteminPythonforFun","content":"\n\u003cimg src=\"/TIL/assets/img/2024-07-09-ICodedPitAVersionControlSysteminPythonforFun_0.png\" /\u003e\n\n안녕하세요! Git이라는 신비한 도구를 모든 개발자가 지켜왔다는데, 그 실제 동작 원리가 궁금한 적이 있으신가요? 저도 그랬어요. Sanket Singh의 \"I coded Git in 1.5 hours | Make your own Version Control System 😎\"라는 YouTube 비디오에서 영감을 받아, 조금씩 코딩하는 모험을 떠났어요. 파이썬으로 제가 직접 버전 관리 시스템을 만들어보는 건 어떨까요?\n\n여기 ⛏️Pit이 나왔습니다! 귀엽고 놀랍도록 기능적인 버전 관리 시스템(VCS)이에요. 코딩을 즐기고 도전해보고 싶다는 이유로 만들었죠. 'Pit'이라는 이름은 깊고 어두운 구멍 연상시킬 수 있겠지만, 이 프로젝트는 사실 VCS의 매력적인 세계를 탐험하는 데 집중한 거예요. 게다가, 리포지토리를 초기화할 때 \"난 Pit을 파고 있어\"라고 말하는 건 정말 재미있는 일이에요.\n\nPit을 알아보기 전에 Git을 먼저 살펴볼까요? 2005년 Linus Torvalds가 만든 Git은 소스 코드의 변경 사항을 추적하는 분산 버전 관리 시스템으로, 여러 개발자가 협업할 수 있도록 하고 작업을 덮어쓰지 않게 합니다. 강력하고 유연하며 진지한 코딩 활동을 위해 필수적이에요.\n이론은 넘어가고 Pit이 완성된 후 어떻게 작동하는지 확인해보겠습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-07-09-ICodedPitAVersionControlSysteminPythonforFun_1](/TIL/assets/img/2024-07-09-ICodedPitAVersionControlSysteminPythonforFun_1.png)\n\n안녕하세요! 이 두 부분으로 구성된 기사에서 Pit이 어떻게 작동하는지 알아보겠습니다. 환경을 설정하고 VCS의 핵심 구성 요소를 만드는 것부터 시작해서 변경 내용을 커밋하고 로그를 확인하는 고급 기능까지 살펴볼 거에요. 그러니 당신의 삽(아니, 키보드!)을 쥐고 함께 파는 것을 시작해봐요!\n\n# Pit을 파다 — 버전 컨트롤 시스템 설정하기\n\nPit은 명령줄 인터페이스를 통해 기본적인 버전 관리 기능을 제공하도록 설계되었습니다. 사용자는 새 저장소를 초기화하고 파일을 스테이징 영역에 추가하며 변경 사항을 커밋하고 커밋 로그를 확인하거나 저장소의 상태를 확인할 수 있어요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 프로젝트 구조\n\n구현 세부 정보에 대해 파헤치기 전에 Pit 프로젝트의 구조를 살펴보겠습니다:\n\n```js\nproject/\n├── .pit/                 # 메인 저장소 디렉토리 (자동 생성됨)\n│   ├── objects/          # 객체(파일) 스냅샷을 저장하는 디렉토리\n│   ├── HEAD              # 현재 커밋을 참조하는 파일\n│   ├── index             # 스테이징 영역(스테이징된 파일의 목록)을 저장하는 파일\n├── pit.py                # Pit의 메인 Python 스크립트\n├── pit.cmd               # 명령 처리기\n├── 기타 파일들           # 프로젝트에 있는 기타 파일들\n```\n\nPit의 핵심은 Pit 클래스로, 핵심 기능을 캡슐화하고 Python의 pathlib 라이브러리를 통해 파일 시스템과 상호 작용합니다. 이 구조를 통해 Pit은 초기화된 디렉토리(초기화 명령)부터 커밋 스냅샷을 저장하는 일 등 저장소 데이터를 효과적으로 관리할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport os\nimport sys\nfrom pathlib import Path\nimport hashlib\nfrom datetime import datetime\nimport json\nfrom pprint import pp\n\nclass Pit:\n    def __init__(self, repo_path=\".\") -\u003e None:\n        self.repo_path = Path(repo_path, \".pit\")\n        self.objects_path = self.repo_path / \"objects\"\n        self.head_path = self.repo_path / \"HEAD\"\n        self.index_path = self.repo_path / \"index\"\n```\n\n# Implementing init Command\n\npit init\n\n## Project Initialization with Pit\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPit을 사용하기 위해서는 새 저장소를 초기화해야 합니다. 이 과정은 프로젝트 내에서 버전 관리를 관리하기 위한 필요한 디렉터리 구조와 파일을 설정합니다.\n\n## 저장소 구조 설정\n\n파이썬의 Pit 클래스는 start 메서드를 통해 이 초기화를 처리합니다. 다음은 포함된 단계를 살펴봅시다:\n\n저장소 존재 여부 확인: start 메서드는 먼저 지정된 또는 현재 디렉토리(repo_path)에 .pit 디렉터리가 이미 존재하는지 확인합니다. 이미 존재한다면 저장소가 이미 존재한다는 메시지를 인쇄하고 프로그램을 종료합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\ndef start(self):\n    if self.repo_path.exists():\n        print(\"⛏️  이미 작업공간이 존재합니다!\")\n        sys.exit(1)\n```\n\n저장소 디렉토리 생성: 저장소가 존재하지 않는 경우, Pit은 경로를 이용하여 주요 .pit 디렉토리 및 하위 디렉토리 (objects, HEAD, index)를 생성합니다. 여기서 objects 디렉토리는 파일 내용의 스냅샷을 보관하고, HEAD 파일은 현재 커밋을 추적하며, index 파일은 변경 사항을 위한 스테이징 영역 역할을 합니다.\n\n```python\ndef start(self):\n    # ...\n    self.repo_path.mkdir(exist_ok=True)\n    self.objects_path.mkdir(exist_ok=True)\n    self.head_path.touch(exist_ok=True)\n    if not self.index_path.exists():\n        with self.index_path.open(\"w\") as index_file:\n            index_file.write(\"[]\")\n    print(\"⛏️  할일들을 처리중...\")\n```\n\ninit 명령어를 구현함으로써, Pit은 프로젝트 이력과 변경 사항을 관리하기 위한 기초를 마련합니다. 이 체계적인 접근은 업무 분리를 명확히 하고, 파일 추가 (add), 변경 내용 커밋 (commit), 커밋 로그 보기 (log)와 같은 후속 작업을 위해 저장소를 준비합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# add 명령어 구현\n\npit add `파일명`\n\n## Pit을 사용하여 스테이징 변경하기\n\n리포지토리를 초기화한 후에 Pit을 사용하는 다음 단계는 변경 사항을 스테이징하는 것입니다. 특히, 파일을 스테이징 영역에 추가하는 것입니다. 이를 통해 사용자는 프로젝트 파일의 버전을 제어하고 조직적으로 관리하기 위해 수정 사항을 다음 커밋을 위해 준비할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 스테이징 영역에 파일 추가하기\n\nPit 클래스의 add 메서드는 이 과정을 용이하게 도와줍니다. 이러한 과정을 살펴보겠습니다:\n\n파일 데이터 읽기: add 메서드는 read_file 도우미 메서드를 사용하여 file_path로 지정된 파일의 내용을 읽어옵니다.\n\n```js\ndef add(self, file_path):\n    file_data = self.read_file(file_path)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파일 내용 해싱: 다음으로, Pit은 파일 내용의 SHA-1 해시를 계산하여 파일을 고유하게 식별합니다. 이 해시는 체크섬으로 작용하여 무결성을 보장하고 파일 버전을 빠르게 찾을 수 있도록 합니다.\n\n```js\ndef add(self, file_path):\n    # ...\n    file_hash = self.hash_object(file_data)\n```\n\n오류 처리: 지정된 파일이 존재하지 않을 경우 (FileNotFoundError), Pit은 오류 메시지를 인쇄하고 정상적으로 종료합니다.\n\n```js\ndef add(self, file_path):\n    # ...\n    if not file_data:\n        print(f\"⛏️  Error: {file_path}를 찾을 수 없습니다!\")\n        sys.exit(1)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기존 파일 확인: Pit은 객체 디렉토리에 동일한 해시를 가진 파일이 이미 있는지 확인합니다. 이미 존재한다면 해당 파일이 이미 저장소에 추가되었음을 나타냅니다.\n\n```python\ndef add(self, file_path):\n    # ...\n    if self.check_hash_exists(file_hash):\n        print(f\"⛏️  오류: {file_path}이(가) 이미 존재합니다!\")\n        sys.exit(1)\n```\n\n파일 스테이징: 새 파일이며 검사를 통과하면 Pit은 파일 내용을 해시된 이름으로 객체 디렉토리에 저장합니다. 인덱스 파일을 업데이트하여 다음 커밋을 위해 파일 경로와 해시를 포함시킵니다.\n\n```python\ndef add(self, file_path):\n    # ...\n    object_path = self.objects_path / file_hash\n    self.write_file(object_path, file_data)\n    self.update_staging_area(file_path, file_hash)\n    print(f\"⛏️  {file_path}를 스테이징 영역에 추가했습니다\")\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# commit 명령어 구현하기\n\npit commit \"메시지\"\n\n## Pit를 사용하여 프로젝트 스냅샷 캡처하기\n\nadd 명령어로 변경 사항을 스테이징한 후, Pit을 사용하여 버전 관리하는 다음 단계는 이러한 변경 사항을 커밋하는 것입니다. 커밋은 프로젝트의 현재 상태에 대한 스냅샷을 생성하고, 저장소의 히스토리에 기록합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 변경 내용 커밋하기\n\nPit 클래스의 commit 메서드는 이 프로세스를 용이하게 합니다. 이에 관련된 단계를 살펴봅시다:\n\nStaged 파일 읽기: commit 메서드는 as_list 도우미 메서드를 사용하여 인덱스 파일에서 Staged 파일의 목록을 검색하는 작업으로 시작합니다.\n\n```js\ndef commit(self, message):\n    index = self.as_list(self.read_file(self.index_path))\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현재 HEAD 가져오기: 그런 다음 get_current_head 메서드를 사용하여 HEAD 파일에서 현재 커밋 (HEAD)의 해시를 검색합니다.\n\n```js\ndef commit(self, message):\n    # ...\n    parent_commit = self.get_current_head()\n```\n\n커밋 데이터 생성: Pit은 부모 커밋 해시 (있는 경우), 커밋 메시지, 타임스탬프 및 스테이징된 파일 목록을 포함한 커밋 데이터를 구성합니다. 이 데이터는 JSON 형식으로 직렬화됩니다.\n\n```js\ndef commit(self, message):\n    # ...\n    commit_data = json.dumps({\n        \"parent\": parent_commit,\n        \"message\": message,\n        \"date\": datetime.now().isoformat(),\n        \"files\": index\n    })\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n커밋 데이터 해싱: 직렬화된 커밋 데이터에 대해 SHA-1 해시가 계산되어 저장소 내에서 커밋을 고유하게 식별합니다.\n\n```python\ndef commit(self, message):\n    # ...\n    commit_hash = self.hash_object(str(commit_data))\n```\n\n커밋 객체 저장: Pit은 커밋 데이터를 해시 된 이름으로 objects 디렉토리에 기록하여 프로젝트 상태를 영구적으로 기록합니다.\n\n```python\ndef commit(self, message):\n    # ...\n    commit_path = self.objects_path / commit_hash\n    self.write_file(commit_path, str(commit_data))\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nHEAD 및 인덱스 업데이트: HEAD 파일이 새로운 커밋 해시를 가리키도록 업데이트되어 저장소의 최신 상태를 나타냅니다. 인덱스 파일이 지워져, 향후 변경을 위한 스테이징 영역이 재설정됩니다.\n\n```python\ndef commit(self, message):\n    # ...\n    self.write_file(self.head_path, commit_hash)\n    self.write_file(self.index_path, \"[]\")\n```\n\n작업 완료 메시지: 마지막으로, Pit은 성공적으로 커밋되었음을 나타내는 확인 메시지를 출력하고 참조용으로 커밋 해시를 표시합니다.\n\n```python\ndef commit(self, message):\n    # ...\n    print(f\"⛏️  {commit_hash}로 커밋되었습니다.\")\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 로그 명령어 구현\n\npit log\n\n## Pit로 프로젝트 이력 탐색하기\n\n커밋 명령어로 변경 사항을 커밋한 후, Pit은 로그 명령어를 통해 사용자가 저장소의 이력을 탐색할 수 있습니다. 이 명령어는 커밋들의 연대순 목록을 표시하여 프로젝트의 진화와 시간이 지남에 따른 변경 사항 순서를 제공합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 커밋 로그 보기\n\nPit 클래스의 log 메서드는 이 프로세스를 용이하게합니다. 함께 차례대로 진행해 보겠습니다:\n\n현재 HEAD 가져오기: log 메서드는 get_current_head 메서드를 사용하여 HEAD 파일에서 현재 커밋의 해시를 검색하여 시작됩니다.\n\n```js\ndef log(self):\n    current_commit_hash = self.get_current_head()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n커밋 반복: Pit은 루프를 사용하여 현재 HEAD부터 시작하여 커밋 기록을 반복합니다. 초기 커밋 (부모가 없는 곳)에 도달할 때까지 커밋 데이터를 가져와 표시합니다.\n\n```python\ndef log(self):\n    # ...\n    while current_commit_hash:\n        commit_data = self.read_file(self.objects_path / current_commit_hash)\n        commit_data = json.loads(commit_data)\n```\n\n커밋 정보 표시: 각 커밋에 대해 Pit은 커밋 해시, 커밋 메시지 및 기타 세부 정보 (예: 타임스탬프, 부모 커밋 등)와 같은 관련 정보를 출력합니다.\n\n```python\ndef log(self):\n    # ...\n        # ...\n        print(f\"⛏️  Commit: {current_commit_hash}\")\n        pp(commit_data)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n### 커밋 기록 탐색: `Pit`은 `current_commit_hash`를 부모 커밋의 해시로 업데이트하여 초기 커밋부터 최신 커밋까지 저장소의 기록을 탐색할 수 있습니다.\n\n```python\ndef log(self):\n    # ...\n        # ...\n        current_commit_hash = commit_data.get('parent')\n```\n\n### 커밋이 없는 경우 처리: 만약 커밋이 없다면 (HEAD가 없는 경우), `Pit`은 아직 커밋이 없다는 메시지를 출력합니다.\n\n```python\ndef log(self):\n    # ...\n    if not current_commit_hash:\n        print(\"⛏️  아직 커밋이 없습니다!\")\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 클래스에서 중요한 메소드였습니다. 사용자를 안내해주는 도우미 메소드인 show_usage()도 있습니다.\n\nPit의 show_usage 함수는 사용자가 유효한 명령을 지정하지 않거나 잘못된 인수를 제공하여 도구를 호출했을 때 사용법 지침과 명령 옵션을 표시하는 유틸리티로 작용합니다. 이 함수를 통해 사용자는 명령 줄 인터페이스(CLI)를 통해 Pit와 효과적으로 상호 작용하는 방법을 이해할 수 있습니다.\n\n```js\ndef show_usage():\n    print(\"⛏️  Pit - 간단한 버전 관리 시스템\")\n    print(\"사용법: pit \u003ccommand\u003e [\u003cargs\u003e]\")\n    print(\"명령어:\")\n    print(\"  init        빈 pit 저장소 생성\")\n    print(\"  add         파일을 스테이징 영역에 추가\")\n    print(\"  commit      변경 사항을 저장소에 기록\")\n    print(\"  log         커밋 로그보기\")\n```\n\n# 명령 줄 인터페이스(CLI) 작업 관리\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n피트(Pit)의 주요 기능인 main 함수는 명령줄 인터페이스(CLI)를 통해 버전 관리 작업을 실행하는 진입점으로 기능합니다. 이 함수는 사용자, 다양한 피트(init, add, commit, log) 명령어, 그리고 피트 클래스의 기본 기능 간의 상호 작용을 조정합니다. 이 함수는 클래스 외부에 있어야 합니다.\n\nmain 함수는 사용자가 전달한 명령줄 인자를 처리하고, 이에 해당하는 동작을 피트 클래스 내에서 정의된 메소드에 위임합니다. 코드를 살펴봅시다:\n\n```js\nif __name__ == \"__main__\"\n    def main():\n        pit = Pit()\n        if len(sys.argv) \u003c 2:\n            show_usage()\n            sys.exit(1)\n        command = sys.argv[1]\n        if command == \"init\":\n            pit.start()\n        elif command == \"add\":\n            if len(sys.argv) \u003c 3:\n                print(\"Usage: pit add \u003cfile_path\u003e\")\n                sys.exit(1)\n            file_path = sys.argv[2]\n            if file_path == \"*\":\n                for file in Path(\".\").rglob(\"*\"):\n                    if file.is_file():\n                        pit.add(file)\n            else:\n                pit.add(file_path)\n         elif command == \"commit\":\n            if len(sys.argv) \u003c 3:\n                print(\"Usage: pit commit \u003cmessage\u003e\")\n                sys.exit(1)\n            message = sys.argv[2]\n            pit.commit(message)\n        elif command == \"log\":\n            pit.log()\n        else:\n            show_usage()\n            sys.exit(1)\n```\n\n## 배치 스크립트\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 배치 스크립트 (pit.cmd)는 Python 모듈(pit)과 상호 작용하는 간단한 방법을 제공합니다. 이 모듈은 버전 관리 기능을 구현하며, Python의 직접적인 모듈 실행 능력(-m 플래그)을 활용하여 명령줄 인수를 원활하게 전달함으로써 윈도우 명령 프롬프트에서 pit 모듈을 유연하고 직관적으로 사용할 수 있습니다.\n\n```js\n@echo OFF\npython -m pit %*\n```\n\n# 결론\n\n이 pit과의 여정 첫 부분에서 우리는 Python 기반 버전 관리 시스템의 기본 설정 및 초기 작업을 탐색했습니다. 우리는 pit init을 사용하여 새 저장소를 초기화하여 프로젝트 히스토리를 관리하는 데 필요한 디렉토리 구조를 설정했습니다. 이후에는 pit add로 스테이징 영역에 파일을 추가하고, pit commit으로 변경 사항을 커밋하며, pit log를 통해 커밋 히스토리를 살펴보았습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 기초적인 명령어들을 통해, 우리는 변경 사항을 추적하고 버전을 관리하며 협업과 프로젝트 관리에 체계적인 방법을 제공하는 피트를 위한 기반을 마련했습니다. 첫 번째 파트에서는 Python 프로젝트 내에서 피트를 효과적으로 활용하기 위한 필수 도구들을 갖추었습니다.\n\n곧 공개될 Part 2를 기대해 주세요. 거기에서는 피트를 이해하고 적용하는 능력을 향상시켜 우리의 개발 워크플로우를 더욱 강화할 것입니다.\n","ogImage":{"url":"/assets/img/2024-07-09-ICodedPitAVersionControlSysteminPythonforFun_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-ICodedPitAVersionControlSysteminPythonforFun_0.png","tag":["Tech"],"readingTime":17},{"title":"TensorFlow Transform 프로덕션에서 매끄러운 데이터 준비를 위한 필수 가이드","description":"","date":"2024-07-09 14:29","slug":"2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction","content":"\n## 제품 환경을 위한 데이터 파이프라인 확장을 위한 TensorFlow Transform 활용\n\n![이미지](/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_0.png)\n\n데이터 전처리는 머신 러닝 파이프라인에서 중요한 단계 중 하나입니다. TensorFlow Transform은 거대한 데이터셋 위에서 분산 환경에서 이를 달성하는 데 도움이 됩니다.\n\n데이터 변환에 대해 더 알아보기 전에, 제품 파이프라인 프로세스의 첫 번째 단계인 데이터 유효성 검사에 대해 다룬 제 글 \"TFX 방식으로 제품 파이프라인에서 데이터 유효성 검사하기\"가 있습니다. 더 나은 이해를 위해 이 글을 확인해보세요!\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 데모에서는 환경을 구성하는 것이 훨씬 쉽고 빠르기 때문에 이를 위해 Colab을 사용했습니다. 탐색 단계에 있다면 중요한 부분에 집중할 수 있도록 도와줄 Colab을 추천드립니다.\n\nML 파이프라인 작업은 데이터 수집 및 검증으로 시작하여 변환을 거칩니다. 변환된 데이터는 학습 및 배포됩니다. 이전 글에서 검증 부분을 다루었고, 이제는 변환 부분을 다룰 예정입니다. Tensorflow에서 파이프라인에 대한 더 나은 이해를 위해 아래 글을 확인해보세요.\n\n이전에 말한 대로 Colab을 사용할 것입니다. 그래서 tfx 라이브러리를 설치하면 됩니다.\n\n```js\n! pip install tfx\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_1.png\" /\u003e\n\n그 다음은 imports가 옵니다.\n\n```js\n# 라이브러리 가져오기\n\nimport tensorflow as tf\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import ExampleValidator\nfrom tfx.components import SchemaGen\nfrom tfx.v1.components import ImportSchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Transform\n\nfrom tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\nfrom google.protobuf.json_format import MessageToDict\n\nimport os\n```\n\n저희는 데이터 유효성 검사 기사에서와 같이 Kaggle에서 제공하는 타이타닉 우주선 데이터셋을 사용할 것입니다. 이 데이터셋은 상업적 및 비상업적 용도로 무료로 사용할 수 있습니다. 여기에서 데이터셋에 접근할 수 있습니다. 데이터셋에 대한 설명이 아래 그림에 표시되어 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_2.png\" /\u003e\n\n데이터 변환 부분을 시작하기 위해서는 파이프라인 구성 요소를 배치할 폴더를 생성하는 것이 좋습니다(그렇지 않으면 기본 디렉터리에 배치됩니다). 저는 파이프라인 구성 요소를 위한 하나와 훈련 데이터를 위한 다른 하나의 폴더를 만들었습니다.\n\n```js\n# 파이프라인 폴더 경로\n# 생성된 모든 구성 요소는 여기에 저장됩니다\n_pipeline_root = '/content/tfx/pipeline/'\n\n# 훈련 데이터 경로\n# 여러 훈련 데이터 파일을 포함할 수도 있습니다\n_data_root = '/content/tfx/data/'\n```\n\n그 다음으로, InteractiveContext를 만들고 파이프라인 디렉터리 경로를 전달합니다. 이 과정은 또한 파이프라인 프로세스의 메타데이터를 저장하기 위한 sqlite 데이터베이스를 생성합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nInteractiveContext은 각 단계를 탐색하는 데 사용됩니다. 각 단계에서 생성된 아티팩트를 확인할 수 있습니다. 프로덕션 환경에서는 Apache Beam과 같은 파이프라인 생성 프레임워크를 사용하면 이 전체 프로세스가 개입없이 자동으로 실행될 것입니다.\n\n```js\n# InteractiveContext 초기화\n# 이는 메타데이터를 저장하기 위해 sqlite db를 생성합니다\n\ncontext = InteractiveContext(pipeline_root=_pipeline_root)\n```\n\n다음으로 데이터 수집부터 시작합니다. 데이터가 csv 파일로 저장되어 있다면 CsvExampleGen을 사용하여 데이터 파일이 저장된 디렉터리 경로를 전달할 수 있습니다.\n\n```js\n# 입력 CSV 파일\nexample_gen = CsvExampleGen(input_base=_data_root)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nTFX는 현재 csv, tf.Record, BigQuery 및 일부 사용자 정의 실행기를 지원합니다. 자세한 내용은 아래 링크에서 확인할 수 있어요.\n\n`ExampleGen` 구성 요소를 실행하려면 `context.run`을 사용하세요.\n\n```js\n# 구성 요소 실행하기\n\ncontext.run(example_gen)\n```\n\n구성 요소를 실행한 후, 아래와 같은 출력이 생성됩니다. 실행 ID, 구성 요소 세부 정보 및 구성 요소의 출력이 저장된 위치가 표시됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_3.png\" /\u003e\n\n확장하면 이 상세 정보를 볼 수 있어야 합니다.\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_4.png\" /\u003e\n\n디렉토리 구조는 아래 이미지와 같습니다. 이 모든 아티팩트들은 TFX에 의해 자동으로 생성되었습니다. 또한 자동으로 버전이 지정되며 세부 정보는 metadata.sqlite에 저장됩니다. 해당 sqlite 파일은 데이터 출처 또는 데이터 계보를 유지하는 데 도움이 됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같이 코드를 사용하여 이러한 자료를 프로그램적으로 탐색해 보세요.\n\n```js\n# 생성된 자료 확인\nartifact = example_gen.outputs['examples'].get()[0]\n\n# 분할 이름과 URI 표시\nprint(f'split names: {artifact.split_names}')\nprint(f'artifact uri: {artifact.uri}')\n```\n\n출력은 파일 이름과 URI가 될 것입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_6.png)\n\n이제 train uri를 복사하여 파일 내부의 세부 정보를 살펴보겠습니다. 파일은 zip 파일로 저장되어 있으며 TFRecordDataset 형식으로 저장되어 있습니다.\n\n```js\n# 훈련 예제를 나타내는 출력 아티팩트의 URI를 가져옵니다\ntrain_uri = os.path.join(artifact.uri, 'Split-train')\n\n# 이 디렉토리에 있는 파일 목록(모든 압축된 TFRecord 파일)을 가져옵니다\ntfrecord_filenames = [os.path.join(train_uri, name)\n                      for name in os.listdir(train_uri)]\n\n# 이 파일들을 읽을 `TFRecordDataset`을 생성합니다\ndataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n```\n\n아래 코드는 Tensorflow에서 가져온 것이며, TFRecordDataset에서 레코드를 가져와 결과를 반환하여 검사할 수 있는 표준 코드입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 도우미 함수로 개별 예제 가져오기\n\ndef get_records(dataset, num_records):\n'''주어진 데이터 세트에서 레코드를 추출합니다.\n매개변수:\ndataset (TFRecordDataset): ExampleGen에 의해 저장된 데이터 세트\nnum_records (int): 미리보기할 레코드 수\n'''\n\n    # 빈 리스트를 초기화합니다.\n    records = []\n\n    # 가져올 레코드 수를 지정하는 `take()` 메서드 사용\n    for tfrecord in dataset.take(num_records):\n\n        # 텐서의 넘파이 속성을 가져옵니다.\n        serialized_example = tfrecord.numpy()\n\n        # 직렬화된 데이터를 읽기 위해 `tf.train.Example()`을 초기화합니다.\n        example = tf.train.Example()\n\n        # 예제 데이터를 읽습니다 (결과는 프로토콜 버퍼 메시지입니다).\n        example.ParseFromString(serialized_example)\n\n        # 프로토콜 버퍼 메시지를 Python 사전으로 변환합니다.\n        example_dict = (MessageToDict(example))\n\n        # 레코드 목록에 추가합니다.\n        records.append(example_dict)\n\n    return records\n\n# 데이터 세트에서 3개의 레코드 가져오기\n\nsample_records = get_records(dataset, 3)\n\n# 결과 출력\n\npp.pprint(sample_records)\n\n3개의 레코드를 요청했고, 출력은 다음과 같습니다. 각 레코드와 해당 메타데이터가 사전 형식으로 저장됩니다.\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_7.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로, 다음 단계로 진행하여 StatisticsGen을 사용하여 데이터의 통계를 생성하는 과정으로 이동합니다. example_gen 객체에서 출력을 인수로 전달합니다.\n\nstatistics.run을 사용하여 구성 요소를 실행합니다. 이때 statistics_gen을 인수로 전달합니다.\n\n```js\n# example_gen 객체를 사용하여 StatisticsGen으로 데이터 집합 통계 생성\n\nstatistics_gen = StatisticsGen(\n    examples=example_gen.outputs['examples'])\n\n# 구성 요소 실행\ncontext.run(statistics_gen)\n```\n\n결과를 확인하려면 context.show를 사용할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 출력 통계 보기\n\ncontext.show(statistics_gen.outputs['statistics'])\n```\n\nTFDV (TensorFlow Data Validation) 기사에서 설명한 통계 생성과 매우 유사하다는 것을 알 수 있습니다. 그 이유는 TFX가 이러한 작업을 수행하기 위해 내부적으로 TFDV를 사용하기 때문입니다. TFDV에 익숙해지면 이러한 프로세스를 더 잘 이해하는 데 도움이 될 것입니다.\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_8.png\" /\u003e\n\n다음 단계는 스키마를 생성하는 것입니다. 이 작업은 statistics_gen 객체를 전달하여 SchemaGen을 사용하여 수행됩니다. 구성 요소를 실행하고 context.show를 사용하여 시각화하세요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 통계_gen 객체를 사용하여 SchemaGen을 사용하여 스키마 생성\n\nschema_gen = SchemaGen(\n    statistics=statistics_gen.outputs['statistics'],\n    )\n\n# 컴포넌트 실행\ncontext.run(schema_gen)\n\n# 스키마 시각화\n\ncontext.show(schema_gen.outputs['schema'])\n```\n\n출력 결과에는 데이터의 기본 스키마에 관한 세부 정보가 표시됩니다. TFDV와 마찬가지로입니다.\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_9.png\" /\u003e\n\n여기에 제시된 스키마를 수정해야 하는 경우 tfdv를 사용하여 수정하고 스키마 파일을 생성할 수 있습니다. ImportSchemaGen을 사용하여 새 파일을 tfx에 사용하도록 요청할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 스키마 파일을 수동으로 추가\nschema_gen = ImportSchemaGen(schema_file=\"path_to_schema_file/schema.pbtxt\")\n```\n\n다음으로, ExampleValidator를 사용하여 예제를 유효성 검사합니다. statistics_gen 및 schema_gen을 인수로 전달합니다.\n\n```js\n# ExampleValidator를 사용하여 예제 유효성을 검사\n# statistics_gen 및 schema_gen 객체를 전달합니다\n\nexample_validator = ExampleValidator(\n    statistics=statistics_gen.outputs['statistics'],\n    schema=schema_gen.outputs['schema'])\n\n# 구성 요소를 실행합니다.\ncontext.run(example_validator)\n```\n\n모든 것이 잘되었음을 나타내는 이상적인 출력입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_10](/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_10.png)\n\nAt this point, our directory structure looks like the image above. We can see that for every step in the process, the corresponding artifacts are created.\n\n![TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_11](/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_11.png)\n\nLet us move on to the actual transformation part. We will now create the `constants.py` file to add all the constants required for the process.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 이 프로젝트에 사용할 모든 상수를 포함하는 파일 생성\n\n\\_constants_module_file = 'constants.py'\n\n모든 상수를 생성하고 constants.py 파일에 쓸 것입니다. “%%writefile '\\_constants_module_file'”을 참조하세요. 이 몤령어는 코드를 실행시키지 않고 대신 주어진 셀의 모든 코드를 지정된 파일로 작성합니다.\n\n%%writefile {\\_constants_module_file}\n\n# 문자열 데이터 유형을 인덱스로 변환할 기능\n\nCATEGORICAL_FEATURE_KEYS = ['CryoSleep', 'Destination', 'HomePlanet', 'VIP']\n\n# 지속적인 것으로 표시된 숫자 기능\n\nNUMERIC_FEATURE_KEYS = ['Age', 'FoodCourt', 'RoomService', 'ShoppingMall', 'Spa', 'VRDeck']\n\n# 버킷에 그룹화할 수 있는 기능\n\nBUCKET_FEATURE_KEYS = ['Age']\n\n# 각 버킷 기능을 인코딩하는 데 사용하는 버킷 수\n\nFEATURE_BUCKET_COUNT = {'Age': 4}\n\n# 모델이 예측할 기능\n\nLABEL_KEY = 'Transported'\n\n# 기능 이름을 바꾸기 위한 유틸리티 함수\n\ndef transformed_name(key):\nreturn key + '\\_xf'\n\n실제 데이터를 변환하는 코드를 포함하는 transform.py 파일을 생성합시다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 프로젝트를 위한 전처리 코드가 포함된 파일을 생성합니다.\n\n_transform_module_file = 'transform.py'\n```\n\n여기서는 tensorflow_transform 라이브러리를 사용할 것입니다. 변환 과정에 대한 코드는 preprocessing_fn 함수 안에 작성될 것입니다. 변환 과정에서 tfx가 내부적으로 이를 찾을 수 있도록 동일한 이름을 사용해야 합니다.\n\n```js\n%%writefile {_transform_module_file}\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nimport constants\n\n# 상수 모듈의 내용을 언패킹합니다.\n_NUMERIC_FEATURE_KEYS = constants.NUMERIC_FEATURE_KEYS\n_CATEGORICAL_FEATURE_KEYS = constants.CATEGORICAL_FEATURE_KEYS\n_BUCKET_FEATURE_KEYS = constants.BUCKET_FEATURE_KEYS\n_FEATURE_BUCKET_COUNT = constants.FEATURE_BUCKET_COUNT\n_LABEL_KEY = constants.LABEL_KEY\n_transformed_name = constants.transformed_name\n\n\n# 변환을 정의합니다.\ndef preprocessing_fn(inputs):\n\n    outputs = {}\n\n    # 이러한 기능들을 [0,1] 범위로 스케일링합니다.\n    for key in _NUMERIC_FEATURE_KEYS:\n        outputs[_transformed_name(key)] = tft.scale_to_0_1(\n            inputs[key])\n\n    # 이러한 기능들을 버킷으로 나눕니다.\n    for key in _BUCKET_FEATURE_KEYS:\n        outputs[_transformed_name(key)] = tft.bucketize(\n            inputs[key], _FEATURE_BUCKET_COUNT[key])\n\n    # 문자열을 어휘 사전의 인덱스로 변환합니다.\n    for key in _CATEGORICAL_FEATURE_KEYS:\n        outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(inputs[key])\n\n    # 라벨 문자열을 인덱스로 변환합니다.\n    outputs[_transformed_name(_LABEL_KEY)] = tft.compute_and_apply_vocabulary(inputs[_LABEL_KEY])\n\n    return outputs\n```\n\n이 데모에서는 몇 가지 표준 스케일링 및 인코딩 함수를 사용했습니다. transform 라이브러리에는 실제로 다양한 함수가 포함되어 있습니다. 여기에서 살펴보세요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 변환 과정을 보겠습니다. Transform 객체를 생성하고 example_gen 및 schema_gen 객체와 함께 우리가 만든 transform.py 파일의 경로를 전달합니다.\n\n```js\n# TF 경고 메시지 무시\ntf.get_logger().setLevel('ERROR')\n\n# example_gen 및 schema_gen 객체로 Transform 구성 요소 인스턴스화\n# transform 파일의 경로를 전달\n\ntransform = Transform(\n    examples=example_gen.outputs['examples'],\n    schema=schema_gen.outputs['schema'],\n    module_file=os.path.abspath(_transform_module_file))\n\n# 구성 요소 실행\ncontext.run(transform)\n```\n\n실행하고 변환 부분이 완료되었습니다!\n\n아래 이미지에 나타난 변환된 데이터를 살펴보세요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![TensorFlow Transform](/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_12.png)\n\n# 그냥 scikit-learn 라이브러리나 pandas를 사용하는 것은 왜 아닌가요?\n\n지금 이게 여러분의 질문인가요?\n\n이 프로세스는 데이터 전처리를 원하는 개인을 위한 것이 아닙니다. 모델 훈련을 시작하고 싶은 사람들을 위한 것이 아닙니다. 이것은 대규모 데이터 (분산 처리를 요구하는 데이터)와 끊어질 여지가 없는 자동화된 프로덕션 파이프라인에 적용되어야 합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n변환을 적용한 후에 폴더 구조가 다음과 같이 보입니다\n\n![folder structure](/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_13.png)\n\n여기에는 변환 전후의 세부 내용이 포함되어 있습니다. 또한 변환 그래프도 만들어졌습니다.\n\n우리는 tft.scale_to_0_1을 사용하여 숫자 특성을 스케일링했습니다. 이러한 함수는 전체 데이터를 분석해야 하는 세부 정보를 계산해야 합니다(예: 특성 내 평균, 최소값 및 최대값). 여러 기계에 분산된 데이터를 분석하여 이러한 세부 정보를 얻는 것은 성능이 많이 필요합니다(특히 여러 번 수행해야 하는 경우). 이러한 세부 사항은 한 번 계산되고 변환 그래프에 유지됩니다. 함수가 이러한 세부 정보를 필요로 할 때마다, 그것은 바로 변환 그래프에서 검색됩니다. 또한 학습 단계에서 생성된 변환을 직접 서빙 데이터에 적용하여 전처리 단계에서 일관성을 보장하는 데 도움이 됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nTensorflow Transform 라이브러리를 사용하는 또 다른 주요 장점은 모든 단계가 아티팩트로 기록되어 데이터 계보가 유지된다는 것입니다. 또한 데이터가 변경될 때 자동으로 데이터 버전 관리가 수행됩니다. 이로 인해 제품 환경에서의 실험, 배포 및 롤백이 쉬워집니다.\n\n여기까지 입니다. 궁금한 점이 있으시면 댓글 섹션에 남겨주세요.\n\n본문에 사용된 노트북 및 데이터 파일은 이 링크를 통해 내 GitHub 저장소에서 다운로드할 수 있습니다.\n\n# 다음은 무엇일까요?\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이프라인 구성 요소를 더 잘 이해하기 위해 아래 글을 읽어보세요.\n\n제 글을 읽어주셔서 감사합니다. 마음에 드셨다면 몇 개의 박수로 격려해 주시고, 만약 다른 쪽에 계신다면 의견란에 개선할 점을 알려주세요. 안녕히 가세요.\n\n특별히 언급하지 않는 한, 모든 이미지는 저자가 찍은 것입니다.\n","ogImage":{"url":"/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-TensorFlowTransformEnsuringSeamlessDataPreparationinProduction_0.png","tag":["Tech"],"readingTime":18},{"title":"모델 성능 시각화 Python 코드로 혼동 행렬 그리는 방법 가이드","description":"","date":"2024-07-09 14:27","slug":"2024-07-09-VisualizingModelPerformanceAGuidetoPlottingConfusionMatricesinPythonCode","content":"\n\u003cimg src=\"/TIL/assets/img/2024-07-09-VisualizingModelPerformanceAGuidetoPlottingConfusionMatricesinPythonCode_0.png\" /\u003e\n\n안녕하세요! 이 기사에서는 머신러닝 모델을 평가하는데 있어서 혼동 행렬의 중요성에 대해 살펴보겠습니다. 혼동 행렬이 무엇이며, 어떻게 작동하는지, 그리고 분류 모델의 성능을 평가하는 데 왜 중요한지에 대한 자세한 설명을 제공할 것입니다. 게다가, 우리는 혼동 행렬을 그리는 Python 함수를 살펴보고, 결과를 효과적으로 해석하는 방법에 대한 통찰을 제공할 것입니다.\n\n## 혼동 행렬 소개\n\n혼동 행렬은 분류 알고리즘의 성능을 평가하는 데 사용되는 표입니다. 예측된 레이블을 실제 레이블과 비교하여 모델이 얼마나 잘 수행되고 있는지 명확하게 보여줍니다. 이 행렬은 모델이 어떤 종류의 오류를 범하고 있는지 이해하는 데 특히 유용하며, 개선할 부분을 식별하는 데 도움이 됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 혼동 행렬의 구조\n\n이진 분류 문제의 혼동 행렬은 일반적으로 다음과 같은 모습을 갖습니다:\n\n![Confusion Matrix](/TIL/assets/img/2024-07-09-VisualizingModelPerformanceAGuidetoPlottingConfusionMatricesinPythonCode_1.png)\n\n다중 클래스 분류 문제의 경우, 행렬은 더 많은 클래스를 수용하도록 확장됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 정확도: 정확도 점수 이상의 자세한 정확도 정보를 제공합니다.\n- 오류 분석: 오류 유형(거짓 양성 및 거짓 음성)을 식별하는 데 도움이 됩니다.\n- 모델 개선: 오분류를 이해함으로써 모델을 개선하는 데 유용한 통찰을 제공합니다.\n\n## Python으로 혼동 행렬 플로팅\n\n```js\nimport itertools\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_confusion_matrix(cm, class_labels=None, normalize=False, figsize=(10, 10)):\n    \"\"\"\n    레이블 및 백분율로 혼동 행렬을 플로팅합니다.\n\n    Args:\n        cm (numpy.ndarray): 혼동 행렬.\n        class_labels (list, optional): 클래스에 대한 사용자 정의 레이블. 기본값은 None입니다.\n        normalize (bool, optional): 백분율을 위해 혼동 행렬을 정규화할지 여부. 기본값은 False입니다.\n        figsize (tuple, optional): 도표의 크기. 기본값은 (10, 10)입니다.\n\n    Returns:\n        None\n    \"\"\"\n    n_classes = cm.shape[0]\n\n    # 플로팅을 위한 도표 및 축 생성\n    fig, ax = plt.subplots(figsize=figsize)\n\n    # 혼동 행렬 시각화를 위한 컬러맵 생성\n    cax = ax.matshow(cm, cmap=plt.cm.Blues)  # 다른 컬러맵을 사용할 수 있습니다\n\n    # 플롯에 컬러바 추가\n    fig.colorbar(cax)\n\n    # 축 레이블 (선택사항)\n    if class_labels is not None:\n        labels = class_labels\n    else:\n        labels = np.arange(cm.shape[0])\n\n    # 축 레이블 및 제목 설정\n    ax.set(\n        title=\"혼동 행렬\",\n        xlabel=\"예측된 레이블\",\n        ylabel=\"실제 레이블\",\n        xticks=np.arange(n_classes),\n        yticks=np.arange(n_classes),\n        xticklabels=labels,\n        yticklabels=labels,\n    )\n\n    # 가독성을 높이기 위해 x축 레이블 회전\n    ax.xaxis.set_label_position(\"bottom\")\n    ax.xaxis.tick_bottom()\n\n    # 레이블 크기 조정\n    plt.setp(ax.xaxis.get_majorticklabels(), size=20)\n    plt.setp(ax.yaxis.get_majorticklabels(), size=20)\n    ax.title.set_size(20)\n\n    # 텍스트 색상 임계값 계산\n    threshold = (cm.max() + cm.min()) / 2.\n\n    # 필요한 경우 혼동 행렬 정규화\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    # 혼동 행렬의 각 요소를 순회하고 텍스트 주석 추가\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        # 값 및 백분율 표시 (선택사항)\n        text = f\"{cm[i, j]:.2f}\" if normalize else f\"{cm[i, j]}\"\n\n        # 임계값에 기반한 텍스트 색상 설정\n        color = \"white\" if cm[i, j] \u003e threshold else \"black\"\n\n        # 중앙 정렬 및 적절한 크기로 텍스트 주석 추가\n        ax.text(\n            j,\n            i,\n            text,\n            ha=\"center\",\n            va=\"center\",\n            color=color,\n            fontsize=15,\n        )\n\n    # 혼동 행렬 플롯 표시\n    plt.show()\n```\n\nPlot Confusion Matrix 함수 사용 방법\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 혼동 행렬 생성: 플로팅하기 전에 모델의 예측과 실제 레이블을 이용해 혼동 행렬을 생성해야 합니다. 이를 위해 sklearn.metrics.confusion_matrix를 사용할 수 있습니다.\n\n```js\nfrom sklearn.metrics import confusion_matrix\n\ny_pred = model.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\n```\n\n2. 혼동 행렬 플로팅: 생성된 행렬로 plot_confusion_matrix 함수를 호출하세요.\n\n```js\nplot_confusion_matrix(cm, (class_labels = [\"Class 0\", \"Class 1\"]), (normalize = True));\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n혼동 행렬은 분류 모델의 성능을 평가하는 강력한 도구입니다. 이들은 모델이 얼마나 잘 수행되고 있는지에 대한 포괄적인 관점을 제공하며 개선이 필요한 부분을 강조합니다. 혼동 행렬을 시각화함으로써, 모델의 동작에 대한 더 깊은 통찰력을 얻고 미래 개선을 위한 정보를 파악할 수 있습니다.\n\n본 문서에서는 혼동 행렬을 플로팅하는 Python 함수를 제공하고 사용 방법을 설명했습니다. 이 함수를 워크플로에 통합함으로써, 모델의 예측을 효과적으로 분석하고 해석할 수 있어 더 나은 정확도의 머신 러닝 모델에 이르게 될 것입니다.\n","ogImage":{"url":"/assets/img/2024-07-09-VisualizingModelPerformanceAGuidetoPlottingConfusionMatricesinPythonCode_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-VisualizingModelPerformanceAGuidetoPlottingConfusionMatricesinPythonCode_0.png","tag":["Tech"],"readingTime":5},{"title":"PyBroker를 사용한 포트폴리오 최적화 방법","description":"","date":"2024-07-09 14:26","slug":"2024-07-09-PortfolioOptimizationwithPyBroker","content":"\n\u003cimg src=\"/TIL/assets/img/2024-07-09-PortfolioOptimizationwithPyBroker_0.png\" /\u003e\n\n포트폴리오 최적화는 포트폴리오 내 자산을 특정 목표를 충족시키기 위해 할당하는 방법입니다. 예를 들어, 이는 리스크를 최소화하고 수익을 극대화하는 목표로 자산 포트폴리오를 구성하는 데 사용할 수 있습니다.\n\n포트폴리오 최적화는 정기적으로 주식 포트폴리오를 리밸런싱하는 유용한 기술일 수 있습니다. 이 접근 방식을 통해 우리는 포트폴리오의 원하는 목표를 달성하기 위해 가장 최적의 방법으로 주식을 매수하고 매도할 수 있습니다.\n\n이 글에서는 Python과 PyBroker를 사용하여 매월 초에 포트폴리오를 리밸런싱하는 거래 전략을 시뮬레이션하는 방법을 살펴볼 것입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 설정\n\n거래 전략을 시뮬레이션하기 위해서는 Python에서 백테스팅 프레임워크를 사용할 수 있습니다. 우리는 트레이딩 전략을 개발하기 위한 오픈소스 Python 프레임워크인 PyBroker을 사용할 것입니다. PyBroker을 사용하기 위해 아래의 명령어를 터미널에 입력하여 라이브러리를 설치할 수 있습니다:\n\n```js\npip install -U lib-pybroker\n```\n\n그 다음으로, 우리가 PyBroker에서 구현할 전략을 위해 포트폴리오 최적화를 수행할 수 있는 Riskfolio-Lib을 설치해봅시다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```shell\npip install -U riskfolio-lib\n```\n\n위의 패키지를 설치한 후, 필요한 라이브러리를 import하여 새 노트북을 만들어봅시다:\n\n```shell\nimport pandas as pd\nimport pybroker as pyb\nimport riskfolio as rp\nfrom datetime import datetime\nfrom pybroker import ExecContext, Strategy, YFinance\n```\n\n또한 PyBroker에서 데이터 캐싱을 활성화할 수도 있습니다. 이렇게 하면 Yahoo Finance로부터 다운로드된 히스토리컬 데이터가 캐싱되어 전략을 테스트할 수 있습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\npyb.enable_data_source_cache(\"rebalancing\");\n```\n\n## Positions Rebalancing\n\n우리는 PyBroker를 사용하여 매달 처음에 길이만 있는 포트폴리오를 동일한 포지션 사이징을 사용하여 리밸런싱(rebalancing)하는 간단한 전략을 작성해 보겠습니다. 말하자면, 매월 초에 우리 전략은 포트폴리오의 각 주식이 대략적으로 동일한 할당을 갖도록 충분한 주식을 매수하거나 매도할 것입니다.\n\n먼저, 주식의 목표 할당에 도달하기 위해 주식의 충분한 주식을 매수하거나 매도할 수 있는 함수를 구현하는 것으로 시작합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\ndef set_target_shares(\n    ctxs: dict[str, ExecContext],  # 종목 심볼 -\u003e 실행 컨텍스트\n    targets: dict[str, float]      # 종목 심볼 -\u003e 목표 가중치\n):\n    for symbol, target in targets.items():\n        ctx = ctxs[symbol]\n        # 목표 가중치를 사용하여 목표 주식수 계산\n        target_shares = ctx.calc_target_shares(target)\n        pos = ctx.long_pos()\n        # 현재 해당 종목의 매수 포지션이 없는 경우 매수\n        if pos is None:\n            ctx.buy_shares = target_shares\n        # 아니면, 목표치에 도달할 만큼 주식을 매수\n        elif pos.shares \u003c target_shares:\n            ctx.buy_shares = target_shares - pos.shares\n        # 현재 할당이 목표 수준을 초과하는 경우, 충분한 주식 매도\n        elif pos.shares \u003e target_shares:\n            ctx.sell_shares = pos.shares - target_shares\n```\n\n현재 할당이 목표 수준을 초과하면 해당 자산의 필요 주식을 판매하고, 현재 할당이 목표 수준 미만이면 해당 자산의 필요 주식을 구매하는 함수입니다.\n\n다음으로 매월 초에 각 주식을 동일 비중으로 타겟팅하는 리밸런싱 함수를 작성합니다:\n\n```python\ndef rebalance(ctxs: dict[str, ExecContext]):\n    if start_of_month(ctxs):\n        target = 1 / len(ctxs)  # 동일 가중치\n        set_target_shares(ctxs, {symbol: target for symbol in ctxs.keys()})\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼 이제 새로운 달의 시작을 감지하는 도우미 함수를 구현해 봅시다:\n\n```js\ndef start_of_month(ctxs: dict[str, ExecContext]) -\u003e bool:\n    dt = tuple(ctxs.values())[0].dt\n    if dt.month != pyb.param('current_month'):\n        pyb.param('current_month', dt.month)\n        return True\n    return False\n```\n\n이제 이러한 함수들을 사용하여 다섯 가지 주식 포트폴리오를 위한 리밸런싱 전략을 백테스트할 수 있습니다.\n\n```js\nstrategy = Strategy(YFinance(), (start_date = \"1/1/2018\"), (end_date = \"1/1/2023\"));\nstrategy.add_execution(None, [\"TSLA\", \"NFLX\", \"AAPL\", \"NVDA\", \"AMZN\"]);\nstrategy.set_after_exec(rebalance);\nresult = strategy.backtest();\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n백테스트를 실행한 후에는 주문 목록을 확인할 수 있습니다:\n\n```js\nresult.orders;\n```\n\n```js\n     type symbol date        shares  limit_price  fill_price  fees\nid\n1    buy  NFLX   2018-01-03  99      NaN          203.86      0.0\n2    buy  AAPL   2018-01-03  464     NaN           43.31      0.0\n3    buy  TSLA   2018-01-03  935     NaN           21.36      0.0\n4    buy  AMZN   2018-01-03  336     NaN           59.84      0.0\n5    buy  NVDA   2018-01-03  376     NaN           52.18      0.0\n... ... ... ... ... ... ... ...\n292  sell NFLX   2022-12-02   15     NaN         315.99       0.0\n293  sell NVDA   2022-12-02   97     NaN         166.89       0.0\n294  buy  AAPL   2022-12-02   27     NaN         146.82       0.0\n295  buy  TSLA   2022-12-02   70     NaN         193.68       0.0\n296  buy  AMZN   2022-12-02   41     NaN          94.57       0.0\n```\n\n그리고 우리의 전략을 평가하기 위한 성능 지표를 확인할 수 있습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nresult.metrics_df;\n```\n\n```js\ntrade_count                 207.000000\ninitial_market_value     100000.000000\nend_market_value         320498.810000\ntotal_pnl                305804.840000\ntotal_return_pct            305.804840\nmax_drawdown            -332039.770000\nmax_drawdown_pct            -52.068777\n```\n\n## 포트폴리오 최적화 사용\n\n포트폴리오에서 각 주식을 동일한 포지션 크기로 할당하는 대신, 포트폴리오 최적화를 사용하여 각 주식의 할당을 결정해 보겠습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRiskfolio-Lib을 사용하여 포트폴리오에서 각 주식에 할당해야 하는 금액을 최소화하여 리스크를 계산할 수 있어요. 이것은 각 주식과 연관된 과거 리스크를 측정함으로써 할 수 있어요.\n\n조건부 가치위험(CVaR)은 각 주식의 위험을 평가하는 한 가지 방법이에요. 특정 확률 수준 이상의 최악의 시나리오에서 예상 손실을 제공해요. 예를 들어, CVaR은 95% 신뢰 수준을 고려할 때 시나리오 중 최악의 5%에서의 평균 손실을 추정할 수 있어요.\n\n아래에서는 작년의 수익률을 사용하여 CVaR을 최소화하고 포트폴리오에 할당하기 위해 RiskFolio-Lib을 사용했어요.\n\n```js\npyb.param('lookback', 252)  # 작년의 수익률 사용 -\u003e 252 바.\n\ndef calculate_returns(ctxs: dict[str, ExecContext], lookback: int):\n    prices = {}\n    for ctx in ctxs.values():\n        prices[ctx.symbol] = ctx.adj_close[-lookback:]\n    df = pd.DataFrame(prices)\n    return df.pct_change().dropna()\n\ndef optimization(ctxs: dict[str, ExecContext]):\n    if start_of_month(ctxs):\n        Y = calculate_returns(ctxs, lookback)\n        port = rp.Portfolio(returns=Y)\n        port.assets_stats(method_mu='hist', method_cov='hist', d=0.94)\n        # CVaR을 최소화한 후 목표 가중치 얻기.\n        w = port.optimization(\n            model='Classic',\n            rm='CVaR',\n            obj='MinRisk',\n            rf=0,      # 무위험 이자율.\n            l=0,       # 리스크 회피 계수.\n            hist=True  # 과거 시나리오 사용.\n        )\n        targets = {\n            symbol: w.T[symbol].values[0]\n            for symbol in ctxs.keys()\n        }\n        set_target_shares(ctxs, targets)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRiskfolio-Lib의 공식 문서에서 더 많은 정보와 예제를 찾을 수 있어요. 이제 전략의 백테스팅으로 넘어가 볼까요?\n\n```js\nstrategy.set_after_exec(optimization);\nresult = strategy.backtest((warmup = pyb.param(\"lookback\")));\n```\n\n여기서는 새 전략의 성과 지표를 확인해 봅시다:\n\n```js\ntrade_count                     100.000000\ninitial_market_value         100000.000000\nend_market_value             201318.070000\ntotal_pnl                    139465.420000\ntotal_return_pct                139.465420\nmax_drawdown                -106042.150000\nmax_drawdown_pct                -35.190829\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n흥미로운 내용이에요! 이 전략을 사용한 수익률이 평균 포지션 사이즈와 비교했을 때 적은 것을 볼 수 있어요 (139% vs 305%), 그런데 최대 손실액은 낮았다는 것도 알 수 있어요 (35% vs 52%). CVaR을 최소화하는 것이 포트폴리오의 전체 수익률을 크게 줄였다는 점을 고려해봤을 때, 이에 따라 포트폴리오의 하락폭도 크게 감소했어요!\n\n그리고 이 글로 마무리 지을게요! 이제 여러분도 포트폴리오 최적화를 자신만의 거래 전략에 사용하는데 충분히 장비가 되었을 거에요. 또한 https://www.pybroker.com에서 PyBroker 사용에 대한 더 많은 튜토리얼을 찾아볼 수 있어요. 모든 코드는 Github 저장소에서 확인할 수 있어요.\n\n읽어 주셔서 감사합니다!\n","ogImage":{"url":"/assets/img/2024-07-09-PortfolioOptimizationwithPyBroker_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-PortfolioOptimizationwithPyBroker_0.png","tag":["Tech"],"readingTime":10},{"title":"LangChain 심층 분석  Part 4 최신 LLM 스터디 다이어리","description":"","date":"2024-07-09 09:23","slug":"2024-07-09-LLMStudyDiaryComprehensiveReviewofLangChainPart4","content":"\n오늘은 Greg Kamradt의 \"The LangChain Cookbook - 7 Core Concepts\"의 나머지 챕터들을 끝까지 리뷰하겠습니다!\n\n- Indexes - 문서를 LLM이 작업하기 쉽도록 구조화하는 것\n\n- 문서 로더\n\n원본 코드의 이 부분은 변경 없이 작동했습니다. 그러나 다양한 문서 로더에 대한 참조 링크가 깨져 있어서 해당 로더를 검색했습니다. 현재 지원되는 문서 로더 목록은 아래와 같습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# URL 및 웹페이지\n\nunstructured 모듈을 설치해야 합니다.\n\n```js\n!pip install unstructured\n```\n\n만약 이 모듈이 설치되어 있다면, 원래 코드가 작동될 것입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같은 표를 Markdown 형식으로 변경해주세요.\n\n| Header One | Header Two |\n| ---------- | ---------- |\n| Item One   | Item Two   |\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nfaiss를 설치해야 합니다. CPU만 사용하는 경우 다음과 같이 설치할 수 있습니다:\n\n```js\n!pip install faiss-cpu\n```\n\n(Nvidia GPU를 사용하는 머신의 경우, 다음 명령을 사용할 수 있습니다: !pip install faiss-gpu)\n\n다음으로, OpenAIEmbeddings의 import 문을 블로그 포스트 Part 2에서 한 것처럼 변경하겠습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n#langchain.embeddings에서는 OpenAIEmbeddings를 사용합니다.\nfrom langchain_openai import OpenAIEmbeddings\n```\n\n저는 `get_relevant_documents` 대신 `invoke`를 사용했습니다.\n\n```js\n# docs = retriever.get_relevant_documents(\"저자가 건설하고 싶어했던 것의 종류는 무엇인가요?\")\ndocs = retriever.invoke(\"저자가 건설하고 싶어했던 것의 종류는 무엇인가요?\")\n```\n\n이 두 가지 변경으로 원래 코드가 작동하게 되었고, 벡터 저장소를 사용하여 LLM에서 응답을 받을 수 있었습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# VectorStores\n\n이것도 아래와 같이 OpenAIEmbeddings 클래스의 import 소스를 변경함으로써 쉽게 작동합니다.\n\n```js\n#from langchain.embeddings import OpenAIEmbeddings\nfrom langchain_openai import OpenAIEmbeddings\n```\n\n# Memory\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n원래 코드는 그대로 작동합니다. Langchain의 다양한 메모리 유형 목록에 대한 링크가 깨져 있어 찾아보았습니다. 아래에서 확인할 수 있습니다.\n\n# 체인\n\nSimpleSequentialChain 및 LLMChain이 사용되지 않게 되어 전체적으로 많은 변경을 해야 했습니다. 아래 정보에 따르면 LLMChain 대신 RunnableSequence를 사용하라고 나와 있어서 이 안내에 따르기로 결정했습니다.\n\n두 개 이상의 RunnableSequence를 결합하는 방법을 찾지 못해 당황했습니다. LangChain 문서를 살펴본 결과 아래와 같이 \"다중 체인\"이라는 문서를 발견했습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기에 작성된 샘플을 참고하여, StrOutputParser를 통해 두 ChatPromptTemplate을 결합해보려고 했고, Cookbook처럼 작동하는 체인을 생성할 수 있었습니다.\n\n```js\nfrom operator import itemgetter\n\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\nprompt1 = ChatPromptTemplate.from_template(\n\"\"\"사용자가 제안한 지역의 고전 요리를 생각해 내는 것이 당신의 일입니다.\n% 사용자 위치\n{user_location}\n\n당신의 응답:\n\"\"\"\n)\n\nprompt2 = ChatPromptTemplate.from_template(\n\"\"\"한 끼 식사가 주어지면, 그 요리를 집에서 어떻게 만들 수 있는 간단한 레시피를 제시해 주세요.\n% 요리\n{user_meal}\n\n당신의 응답:\n\"\"\"\n)\n\nmodel = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)\n\nchain1 = prompt1 | model | StrOutputParser()\nchain2 = {\"user_meal\": chain1} | prompt2 | model | StrOutputParser()\n\nchain2.invoke({\"user_location\": \"Paris\"})\n```\n\nChatPromptTemplate를 모델과 StrOutputParser에 연결하여 객체를 생성했습니다. Prompt1을 모델에 입력하고 출력 AIMessage를 StrOutputParser를 통해 문자열로 변환했습니다. 이 체인1의 출력에서 \"user_meal\": \"chain1 출력\"과 같은 PromptTemplate의 입력을 만들고, prompt2에 연결하여 모델 → StrOutputParser로 연결합니다. 완성된 체인에 \"Paris\"를 user_location으로 입력했을 때 결과는 다음과 같습니다:\n\n‘집에서 Coq au Vin을 만들려면, 큰 냄비에 베이컨을 볶아주세요. 베이컨을 꺼내고 베이컨 기름에 닭 조각을 볶아주세요. 다진 양파와 버섯을 넣고 레드 와인과 치킨 육수를 부어주세요. 약 1시간 정도 닭이 익고 소스가 농도가 될 때까지 강한 불에서 조리해주세요. 베이글이나 감자 퓨레 위에 또는 후식으로 인기 많은 Crusty Bread와 함께 뜨거운 상태로 제공하세요. 집에서 만든 Coq au Vin을 즐기세요!’\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nchain1의 출력물은 \"Coq au Vin\"입니다. 그 입력을 사용하여 chain2는 \"Coq au Vin\"을 어떻게 만드는지 설명합니다. Coq au Vin은 나에게는 전혀 익숙하지 않았던 요리였지만, 빨갛게 푹 구운 수탉 요리인 것 같습니다... 그 요리 이름이 전혀 익숙하지 않아서 사용자 위치로 오사카를 입력해보았더니:\n\n```js\nchain2.invoke({ user_location: \"Osaka\" });\n```\n\n아래와 같이 오떼노미야키를 만드는 방법을 안내해주었습니다. 이를 통해 드디어 제대로 작동하고 있다는 느낌이 들었습니다.\n\n'집에서 오떼노미야키를 만들려면, 그릇에 밀가루 1컵, 갈아 만든 야무 1컵, 달걀 2개, 다진 양배추 1컵을 섞어주세요. 돼지고기, 새우 또는 채소와 같은 자신의 선택한 토핑을 추가하세요. 팬이나 비스듬한 팬을 예열하고 형태를 부여하여 배터를 담구면을 붓세요. 각 면이 황금색이 될 때까지 며칠씩 조리하세요. 오떼노미야키를 달콤하고 매콤한 소스, 마요네즈, 윗부분에 가는 안주 살짝 뿌려서 내세요. 만들어진 오떼노미야키를 즐기세요!'\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 요약 체인\n\nCookbook의 코드 부분은 변경 없이 작동했기 때문에 넘어갈게요.\n\n# 에이전트\n\n먼저, google-search-results 모듈을 설치해야 했어요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n!pip install google-search-results\n```\n\n아래 링크에서 SERP_API_KEY를 얻었습니다.\n\n키를 SERP_API_KEY 환경 변수에 저장했습니다.\n\n```js\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\nserp_api_key=os.getenv('SERP_API_KEY', 'your_api_key')\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가장 큰 변화는 initialize_agent 함수가 사용되지 않게 되어서 Agent를 호출하는 방법을 근본적으로 변경해야 했다는 것이었습니다.\n\n```js\nfrom langchain.agents import load_tools\n# from langchain.agents import initialize_agent\nfrom langchain.llms import OpenAI\nimport json\nfrom langchain import hub\nfrom langchain.agents import AgentExecutor, create_react_agent\n\nllm = OpenAI(temperature=0, openai_api_key=openai_api_key)\ntoolkit = load_tools([\"serpapi\"], llm=llm, serpapi_api_key=serp_api_key)\n# agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)\nprompt = hub.pull(\"hwchase17/react\")\nagent = create_react_agent(model, toolkit, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=toolkit, verbose=True)\nagent_executor.invoke({\"input\":\"what was the first album of the\"\n                    \" band that Natalie Bergman is a part of?\"})\n```\n\n원래 코드는 \"zero-shot-react-description\"이라는 메모리가 없는 ReAct 프레임워크 에이전트의 인스턴스를 생성했기 때문에, 아래 정보를 참고하여 코드를 다시 작성했습니다.\n\nReAct라는 용어는 익숙하지 않았지만 아래 설명대로 보면, 추론과 행동을 연결하고 이를 통해 얻은 피드백을 사용하여 다음 추론 단계로 넘어가는 에이전트 구성 방식인 것 같습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 샘플에 사용된 프롬프트는 LangSmith에서 공개된 프롬프트이며, 해당 프롬프트의 내용을 아래에서 확인할 수 있었습니다.\n\n이 에이전트를 상세 모드로 실행할 때 아래와 같은 추론 프로세스가 실행되고 있다는 것을 확인할 수 있었습니다.\n\n![이미지](/TIL/assets/img/2024-07-09-LLMStudyDiaryComprehensiveReviewofLangChainPart4_0.png)\n\n최종 답변은 다음과 같았습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n{'input': '나탈리 베르그먼이 소속된 밴드의 첫 앨범은 무엇인가요?',\n'output': 'Wild Belle'}\n```\n\n원래 질문은 \"나탈리 베르그먼이 속한 밴드의 첫 앨범은 무엇인가요?\"였습니다. 다시 말해서 \"나탈리 베르그먼이 속한 밴드의 첫 앨범의 이름을 알려주세요\"였습니다. 그러나 최종 답변은 그녀가 속한 밴드의 이름이 나왔습니다. 로그를 보니, 에이전트가 문제를 이해하지 못한 것으로 보입니다.\n\n카름 레이 안사생님은 유튜브 비디오에서 에이전트 기술이 아직 발전 중이라고 언급했습니다. 그러나 Langchain을 사용할 때 이러한 추론이 어떻게 진행되는지 로그를 확인하는 것이 유용할 수 있을 것 같으므로, 앞으로 다양한 에이전트를 살펴보는 기회를 더 만들고 싶습니다.\n\n이를 통해 카름 레이 안사생님의 \"The LangChain Cookbook — 7 Core Concepts\"의 모든 레시피를 마지막 레시피를 포함하여 제가 작업하며 성공적으로 수행했습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n때로는 너무 많은 것이 더 이상 사용되지 않아서 포기해야 한다고 생각했던 적이 있었지만, 모든 샘플이 성공적으로 작동되었어요.\n\n이 과정에서 살펴보지 못한 관련된 여러 가지 사항들이 있어서, 그것들을 모두 조사하고 다른 샘플들을 탐구하여 가능하다면 다른 노트에서 소개하고 싶어요.\n\n독서해 주셔서 감사합니다!\n\n네 목차 블로그 시리즈 끝까지 읽어 주셔서 감사합니다. 이 게시물들이 유익하고 통찰력있었기를 바랍니다. 여러분의 지속적인 관심은 저에게 AI 및 언어 기술에 대한 지식을 공유하는 동기가 되었어요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현재 시리즈를 마침하지만, AI 및 언어 기술에 대한 여정은 아직 끝나지 않았습니다. 이 블로그에 대한 질문이나 OpenAI API, LLM 또는 LangChain과 관련된 개발 프로젝트에 관심이 있다면 저에게 연락해 주세요.\n\nGoldrush Computing에서는 일본어 원어민을 보유한 일본 기업으로서의 전문성을 자랑합니다. 우리는 일본어와 문화에 맞춘 프롬프트 및 RAG 시스템을 개발하는 것에 특화되어 있습니다. 일본 시장용 AI 솔루션을 최적화하거나 일본어 애플리케이션을 개발하려는 경우, 저희는 도와드릴 준비가 되어 있습니다. 일본에 특화된 AI 최적화가 필요한 협업이나 프로젝트가 있다면 망설이지 말고 연락해 주세요.\n\n아래 이메일 주소로 직접 연락해 주세요!\n\n```js\nmizutori@goldrushcomputing.com\n```\n","ogImage":{"url":"/assets/img/2024-07-09-LLMStudyDiaryComprehensiveReviewofLangChainPart4_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-LLMStudyDiaryComprehensiveReviewofLangChainPart4_0.png","tag":["Tech"],"readingTime":11},{"title":"FastAPI 애플리케이션에서 Server-Sent EventSSE 사용 방법","description":"","date":"2024-07-09 09:22","slug":"2024-07-09-Server-SentEventSSEinFastAPIApplications","content":"\n서버 전송 이벤트(Server-Sent Events, SSE)는 서버가 싱글 HTTP 연결을 통해 웹 클라이언트에 실시간 업데이트를 푸시할 수 있는 서버 푸시 기술입니다. 대시보드, 알림 또는 실시간 분석과 같이 실시간 업데이트가 필요한 애플리케이션에 특히 유용합니다.\n\n![SSE](/TIL/assets/img/2024-07-09-Server-SentEventSSEinFastAPIApplications_0.png)\n\n## SSE 소개\n\n- SSE는 서버가 초기 클라이언트 연결을 설정하자마자 브라우저 클라이언트로 데이터 전송을 시작할 수 있는 표준입니다.\n- 웹소켓과 달리 SSE는 양방향 통신이 아닌 단방향이며, 서버에서 클라이언트로 데이터가 흐릅니다.\n- 이로써 SSE는 서버가 클라이언트로 업데이트를 푸시해야 하는 경우에 더 간단한 대안이 됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 왜 SSE를 사용해야 하나요?\n\nSSE는 다음과 같은 시나리오에서 유용합니다:\n\n- 실시간 업데이트: 실시간 업데이트를 클라이언트에 푸시해야 하는 애플리케이션들, 예를 들어 실시간 스포츠 점수, 주식 시장 업데이트, 또는 채팅 애플리케이션 등.\n- 서버 모니터링 및 대시보드: 실시간 모니터링 대시보드는 SSE를 활용하여 클라이언트가 서버를 계속 폴링할 필요 없이 메트릭 및 상태를 업데이트할 수 있습니다.\n- 알림: 서버에서 보내는 알림을 SSE로 효율적으로 관리할 수 있어서, 클라이언트 측에서 지속적으로 폴링할 필요가 줄어듭니다.\n- 스트리밍 데이터: 대용량 데이터 세트나 로그를 실시간으로 스트리밍하는 것을 SSE로 간단하게 구현할 수 있습니다.\n\n# FastAPI에서 SSE 구현하기\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFastAPI은 속도와 사용 편의성으로 유명하며, sse-starlette 라이브러리와 통합하여 SSE를 구현하는 데 잘 작동합니다. 다음은 설정 방법입니다.\n\n# 예제 구현\n\n## 단계 1: 필요한 라이브러리 설치\n\n먼저, FastAPI와 sse-starlette를 설치하세요:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\npip install fastapi sse-starlette\n```\n\n## Step 2: FastAPI 애플리케이션 생성\n\n```js\nfrom fastapi import FastAPI\nfrom sse_starlette.sse import EventSourceResponse\nimport asyncio\n\napp = FastAPI()\nasync def event_generator():\n    while True:\n        await asyncio.sleep(1)\n        yield {\"data\": \"This is a server-sent event!\"}\n@app.get(\"/events\")\nasync def sse_endpoint():\n    return EventSourceResponse(event_generator())\n```\n\n이 예시에서 event_generator는 매 초마다 새 이벤트를 생성하는 비동기 생성자입니다. sse_endpoint 엔드포인트는 EventSourceResponse를 사용하여 SSE 연결을 처리합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## FastAPI에서 SSE 사용 사례\n\n- 대시보드용 실시간 업데이트:\n\n  - SSE는 모니터링 시스템이나 실시간 분석 대시보드와 같은 실시간 메트릭을 표시하는 애플리케이션에 복잡한 WebSocket 관리 없이 업데이트를 푸시하는 간단한 방법을 제공합니다.\n\n- 실시간 알림:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 사용자에게 이벤트 알림이 필요한 애플리케이션(메신저 앱이나 알림 시스템과 같은)은 SSE를 사용하여 이러한 업데이트를 신속하게 전달할 수 있습니다.\n\n- 스트리밍 로그:\n\n- SSE는 실시간 로그나 기타 스트리밍 데이터를 표시해야 하는 애플리케이션에 잘 맞는 가벼운 솔루션입니다.\n\n## SSE의 장점:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 간편함: SSE는 웹소켓에 비해 구현과 관리가 간단합니다.\n- 자동 재연결: 브라우저가 자동으로 재연결을 처리하여 SSE가 실시간 업데이트에 강력합니다.\n- HTTP 호환성: SSE는 표준 HTTP/2 연결을 통해 작동하므로 기존 인프라와 작업하기 쉽습니다.\n\n## SSE 대안:\n\n- 웹소켓:\n\n- 양방향 통신: 양방향 통신이 필요한 경우 웹소켓을 선호합니다.\n- 낮은 지연 시간: 웹소켓은 SSE보다 낮은 지연 시간을 제공하여 온라인 게임과 같이 매우 상호작용적인 애플리케이션에 적합합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Long Polling:\n\n- 호환성: Long polling은 오래된 브라우저와 호환되며 WebSockets이나 SSE를 지원하지 않는 경우에 사용할 수 있습니다.\n- 오버헤드: 반복된 요청으로 인해 SSE나 WebSockets에 비해 더 많은 오버헤드를 도입합니다.\n\n# SSE의 현실 세계에서의 사용 사례\n\n서버-전송 이벤트 (SSE)는 실시간 업데이트를 필요로하는 현실 세계 애플리케이션에서 널리 사용되고 있습니다. 여기에 몇 가지 주목할 만한 예시가 있습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 라이브 스포츠 스코어\n- 주식 시장 및 금융 데이터\n- 소셜 미디어 플랫폼 등등..\n\n우리는 ESPN이나 BBC Sports와 같이 제공되는 라이브 스포츠 스코어 업데이트 애플리케이션의 예시를 더 자세히 살펴보겠습니다.\n\n진행 중인 축구 경기에 대한 실시간 업데이트를 제공하는 라이브 스포츠 스코어 애플리케이션을 상상해보세요. 이 애플리케이션은 골 득점 및 경기 통계와 같은 업데이트를 제공해야 합니다. 이곳이 [GitHub 링크](GitHub Link).\n\n## SSE 구현\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 서버 측 구현:\n\n아래 파일은 경기 개요를 포함하고 있습니다.\n\n```js\n// scores.py\n\n[\n  {\n    time: \"00:01\",\n    scores: \"1:0\",\n    event: \"Goal! Team A scores!\",\n  },\n  {\n    time: \"00:05\",\n    scores: \"1:1\",\n    event: \"Goal! Team B scores!\",\n  },\n  {\n    time: \"00:10\",\n    scores: \"2:1\",\n    event: \"Goal! Team A scores again!\",\n  },\n];\n```\n\n- 서버는 경기 데이터의 실시간 피드를 유지하며 SSE를 사용하여 연결된 클라이언트에게 전송합니다.\n- 어떤 이벤트(골, 교체 등)가 발생할 때마다, 서버는 이 업데이트를 모든 연결된 클라이언트에게 푸시합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# main.py\n\nfrom fastapi import FastAPI\nfrom sse_starlette.sse import EventSourceResponse\nimport asyncio\nimport json\n\napp = FastAPI()\n\nasync def event_generator():\nwith open(\"scores.json\", \"r\") as file:\nscores = json.load(file)\nfor score in scores:\nawait asyncio.sleep(5)  \n yield f\"Match Summary: {json.dumps(score)}\\n\\n\"\n\n@app.get(\"/live-scores\")\nasync def live_scores_endpoint():\nreturn EventSourceResponse(event_generator())\n\n# Adding CORS middleware\n\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\nCORSMiddleware,\nallow_origins=[\"*\"],\nallow_credentials=True,\nallow_methods=[\"*\"],\nallow_headers=[\"*\"],\n)\n\nClient-Side Implementation:\n\n- 웹 응용 프로그램인 클라이언트는 서버와 SSE 연결을 설정하고 업데이트를 수신합니다.\n\n```html\n\u003c!-- index.html --\u003e\n\n\u003c!DOCTYPE html\u003e\n\u003chtml\u003e\n  \u003chead\u003e\n    \u003ctitle\u003eLive Sports Scores\u003c/title\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003ch1\u003eLive Football Scores\u003c/h1\u003e\n    \u003cdiv id=\"score-updates\"\u003e\u003c/div\u003e\n\n    \u003cscript\u003e\n      const eventSource = new EventSource(\"http://127.0.0.1:8000/live-scores\");\n\n      eventSource.onmessage = function (event) {\n        const newElement = document.createElement(\"div\");\n        newElement.innerHTML = event.data;\n        document.getElementById(\"score-updates\").appendChild(newElement);\n      };\n\n      eventSource.onerror = function (event) {\n        console.error(\"EventSource failed:\", event);\n        eventSource.close();\n      };\n    \u003c/script\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 참고\n\n- https://fastapi.tiangolo.com/\n- https://pypi.org/project/sse-starlette/\n\n# 결론\n\nsse-starlette를 사용하면 FastAPI 애플리케이션에 SSE를 통합하는 것이 간편하고 효율적입니다. 실시간 대시보드, 알림 시스템 또는 데이터 스트리밍 애플리케이션을 개발 중이든, SSE는 견고하고 간편한 해결책을 제공합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n읽어 주셔서 감사합니다! 만일 어떠한 오류를 발견하시거나 개선 제안이 있으시다면 아래 댓글에 공유해 주세요.\n\n이 글이 마음에 들었다면 👏 버튼을 눌러 다른 사람들이 발견할 수 있도록 도와주세요. GitHub에서 제 프로필을 팔로우하고 LinkedIn에서 저와 연결해도 괜찮아요.\n","ogImage":{"url":"/assets/img/2024-07-09-Server-SentEventSSEinFastAPIApplications_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-Server-SentEventSSEinFastAPIApplications_0.png","tag":["Tech"],"readingTime":9},{"title":"1억 행 파이썬 처리 도전  10분에서 4초로 줄이는 방법","description":"","date":"2024-07-09 09:21","slug":"2024-07-09-PythonOneBillionRowChallengeFrom10Minutesto4Seconds","content":"\n![Python One Billion Row Challenge](/TIL/assets/img/2024-07-09-PythonOneBillionRowChallengeFrom10Minutesto4Seconds_0.png)\n\n요즘에는 프로그래밍 언어가 10억 행의 데이터를 통합하는 속도에 대한 문제가 주목을 받고 있습니다. 성능이 가장 우수하지 않은 Python은 당연히 특히 현재 최상위 성능을 발휘하는 Java 구현이 단 몇 초(1.535초)만에 처리 가능하다는 점에서 거의 기회가 없습니다!\n\n도전의 근본적인 규칙은 외부 라이브러리를 사용하지 않는 것입니다. 오늘의 목표는 규칙을 준수한 후에 외부 라이브러리와 더 적합한 파일 형식을 사용했을 때 결과가 어떻게 나오는지 살펴보는 것입니다.\n\n모든 스크립트를 5회 실행하여 결과를 평균화했습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하드웨어로는 12개 CPU 코어와 36 GB RAM이 장착된 16인치 M1 Pro MacBook Pro를 사용하고 있습니다. 코드를 실행할 경우 결과가 다를 수 있지만, 구현 사이에는 비슷한 백분율 차이를 볼 수 있을 것입니다.\n\n## 코드\n\n- GitHub 저장소 — Python으로 10억 행 도전\n\n# 10억 행 도전이란 무엇인가요?\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n1 Billion Row Challenge (1BRC)의 아이디어는 간단합니다 - .txt 파일을 통해 10억 행의 데이터를 처리하는 것입니다.\n","ogImage":{"url":"/assets/img/2024-07-09-PythonOneBillionRowChallengeFrom10Minutesto4Seconds_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-PythonOneBillionRowChallengeFrom10Minutesto4Seconds_0.png","tag":["Tech"],"readingTime":2},{"title":"구버전 AWS Lambda 런타임 자동 업데이트 방법","description":"","date":"2024-07-09 09:20","slug":"2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates","content":"\n## Python for devops v1.2 - 구버전/지원 중단된 런타임을 사용 중인 AWS 람다 함수의 업그레이드를 위한 Python 스크립트 작성하기.\n\n![이미지](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_0.png)\n\n저의 블로그 시리즈 Python for DevOps의 두 번째 블로그 포스트입니다. 여기서는 실제 데브옵스 사용 사례를 탐구하면서 Python 스크립트를 작성해봅니다.\n\nPython for devops 첫 번째 부분 - SQS 큐 암호화 자동화\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 시나리오\n\n보안 팀으로부터 수백 개의 Lambda 함수가 Python 3.8 및 Node.js 14x와 같은 지원되지 않는 런타임을 실행 중이라는 불만을 받았다고 가정해 봅시다. AWS는 Lambda 함수의 오래된 런타임을 자동으로 업데이트하지 않습니다.\n\n이 모든 Lambda 함수를 수동으로 업데이트하는 것은 고통스러울 수 있습니다. 책임감 있는 Devops 엔지니어로서, 이러한 수동 작업을 피하고 이러한 작업을 자동화하기 위한 재사용 가능한 Python 스크립트를 작성하고 싶어 합니다.\n\n# 블로그 포스트에서 다룰 내용은 무엇인가요?\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 블로그 포스트에서는 람다 런타임 업데이트를 자동화하는 방법을 가르쳐 드리겠습니다. 우리의 스크립트는 원하는 Python 버전을 인수로 받아 이전 버전을 사용 중인 람다를 나열한 후 런타임을 원하는 버전으로 업그레이드할 것입니다.\n\n## 따를 단계들\n\n- Lambda를 위한 boto3 클라이언트 생성.\n- AWS 계정의 해당 지역 내 모든 람다 함수를 나열.\n- 람다 함수의 런타임 가져오기.\n- 람다 런타임이 원하는 버전보다 낮은지 유효성 검사.\n- 람다 런타임을 원하는 버전으로 업그레이드.\n- 스크립트를 작성하는 동안 최선의 실천 방법을 준수할 것입니다.\n\n# 선행 조건:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 지역 머신에서 AWS 자격 증명을 구성하려면 aws configure 명령을 실행하세요. 최근 블로그 게시물의 지침을 따라 주세요.\n- AWS CLI 명령을 실행하여 이전 버전의 Python 런타임에서 실행되는 몇 가지 샘플 람다 함수를 만드세요.\n\n# Python 스크립트 개발을 진행하기 전에 사전 설정을 해봅시다 — 데모 람다 함수 생성.\n\n## 1. 배포 패키지 준비\n\n- 람다 함수 코드를 위한 디렉터리를 만드세요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nmkdir my-lambda-function\ncd my-lambda-function\n```\n\n- 람다 함수 코드를 생성하세요 (예: lambda_function.py)\n\n```js\ndef lambda_handler(event, context):\n    return \"Hello, World!\"\n```\n\n- 디렉토리 내용을 압축하세요\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```bash\nzip -r deployment-package.zip .\n```\n\n## 2. Create a Lambda Execution Role\n\n- Create a trust policy (e.g., trust-policy.json)\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- IAM 역할을 생성하세요\n\n```js\naws iam create-role --role-name MyLambdaExecutionRole --assume-role-policy-document file://trust-policy.json\n```\n\n![연결된 이미지](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_1.png)\n\n- 역할에 AWSLambdaBasicExecutionRole 정책을 연결하세요\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\naws iam attach-role-policy --role-name MyLambdaExecutionRole --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n\n## 3. 람다 함수 배포하기\n\n- 람다 함수를 만드는 AWS CLI 명령어는 다음과 같이 보일 것입니다.\n\naws lambda create-function \\\n --function-name MyPython38Function \\\n --runtime python3.8 \\\n --role arn:aws:iam::YOUR_ACCOUNT_ID:role/YOUR_LAMBDA_EXECUTION_ROLE \\\n --handler lambda_function.lambda_handler \\\n --zip-file fileb://path/to/your/deployment/package.zip\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이제 IAM 역할과 배포 패키지를 사용하여 3개의 람다 함수를 배포할 예정입니다.\n\n```js\naws lambda create-function \\\n    --function-name medium-blog-lambda1 \\\n    --runtime python3.8 \\\n    --role arn:aws:iam::366130468123:role/MyLambdaExecutionRole \\\n    --handler lambda_function.lambda_handler \\\n    --zip-file fileb://my-lambda-function/deployment-package.zip \\\n    --timeout 15 \\\n    --memory-size 128\n```\n\n아래와 같이 3개의 람다 함수가 생성됩니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_2.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 파이썬 스크립트 작성을 시작할 준비가 끝났어요.\n\n파이썬 코드를 작성하기 전에, 최고의 방법을 따라 파이썬 환경을 설정해보겠어요.\n\n## 파이썬 가상 환경 만들기\n\n```js\n# 가상 파이썬 환경 만들기\npython3 -m venv medium_blog\n\n# 가상 환경 활성화하기\nsource medium_blog/bin/activate\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- requirements.txt 파일을 생성하고 해당 파일에 의존성을 넣어주세요.\n\nboto3는 Python 라이브러리로, Python을 사용하여 AWS 리소스와 통신할 수 있게 해줍니다.\n\n# requirements.txt\n\nboto3\n\n- 의존성을 설치해주세요\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\npip install -r requirements.txt\n```\n\n# 이제 설정을 완료했으니, 파이썬 스크립트를 작성해 볼까요?\n\n우리는 코드를 작은 부분, 즉 함수로 나누어 각 함수가 한 가지 작업을 수행하도록 할 수 있어요.\n\n참고: 블로그 포스트의 전체 코드는 제 공개 GitHub에 올릴 예정이에요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 1. Python 모듈을 가져와 boto3를 사용하여 람다 클라이언트를 만듭니다\n\n![lambda client](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_3.png)\n\n## 2. 모든 람다를 나열하는 함수 — 람다 함수 목록을 반환합니다.\n\n![list lambdas](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_4.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기능은 lambda_client를 사용하여 Lambda 함수 목록을 가져와 반환합니다.\n\nlist_functions()[“Functions”] 대신 list_functions().get(“Functions”, None)을 사용하여 응답에 “Functions” 키가 없을 때 KeyError를 방지할 수 있습니다. 이렇게 하면 코드가 기본값인 None을 반환하므로 더 견고하고 런타임 오류를 방지할 수 있습니다.\n\n## 3. 람다 런타임 가져오기.\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_5.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 함수는 lambda_json_list에 있는 딕셔너리에서 FunctionName과 Runtime을 추출하고(Runtime 값이 없는 경우에는 컨테이너 기반 람다 함수의 경우), 이름과 런타임을 포함하는 튜플의 목록을 반환합니다.\n\n4. 원하는 런타임과 런타임을 비교하고 런타임이 원하는 것보다 낮으면 True를 반환합니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_6.png)\n\n버전 클래스는 packaging.version 모듈에서 사용되며 버전 문자열을 구문 분석하고 비교하는 데 사용됩니다. 이 함수에서는 현재 런타임 버전이 지정된 버전보다 이전 버전인지 확인합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 5. 비교 함수가 True 값을 반환하면 람다 런타임을 업데이트합니다.\n\n![Lambda Runtime Update](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_7.png)\n\n이 함수는 람다 함수를 새로운 런타임으로 업데이트합니다.\n\n예외 처리를 위해 try/except 블록을 사용했습니다. 이를 통해 예기치 않은 오류를 관리하고 대응할 수 있습니다. try 블록 내에서 위험한 작업을 시도하고 그에 따른 예외를 except에서 처리하여 프로그램이 오류로 인해 충돌하지 않고 우아하게 회복될 수 있도록 합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 6. 조각들을 함께 모으기\n\n![이미지](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_8.png)\n\n## 7. 스크립트 실행하기\n\n![이미지](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_9.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 코드 스니펫을 모두 `update_lambda_runtimes.py` 파일에 붙여넣고 아래 명령어를 실행하여 스크립트를 실행합니다.\n\n```js\npython update_lambda_runtimes.py\n```\n\n`__name__`이 `'__main__'`인 상태에서 스크립트를 실행할 때만 `run()` 함수가 실행되도록 하여 스크립트를 실행합니다.\n\n스크립트의 유용성을 높이기 위해 명령줄 인수를 받을 수 있도록 활성화해야 합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Automatic Outdated AWS Lambda Runtime Updates](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_10.png)\n\n이 함수는 Python에서 argparse 모듈을 사용하여 명령줄 인자 파서를 만듭니다. 스크립트 실행 시 제공해야 할 인수인 python_version (단축 형식 -a)을 기대합니다.\n\n## 명령줄 인수를 사용하여 스크립트 실행\n\n![Automatic Outdated AWS Lambda Runtime Updates Example](/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_11.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\npython update_lambda_runtimes.py --python-version python3.9\n```\n\n블로그 게시물의 전체 코드는 제 공개 GitHub 리포지토리에서 찾을 수 있습니다. 다음 링크를 사용하여 액세스하세요.\n\n## 무엇을 더 해야 할까요?\n\n- 로깅 사용하기.\n- 코드 문서화 및 타입 힌트 사용하기.\n- NodeJS, Go 등 다른 런타임을 포함하는 스크립트 확장하기.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저와 LinkedIn에서 연락하세요: [https://www.linkedin.com/in/akhilesh-mishra-0ab886124/](https://www.linkedin.com/in/akhilesh-mishra-0ab886124/)\n","ogImage":{"url":"/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-AutomateOutdatedAWSLambdaRuntimeUpdates_0.png","tag":["Tech"],"readingTime":12},{"title":"FastAPI 실습 간단한 할 일 목록 애플리케이션 만들기 방법","description":"","date":"2024-07-09 09:18","slug":"2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication","content":"\n# 먼저, FastAPI에 대한 간결한 소개부터 시작해보겠습니다.\n\nFastAPI는 Python으로 API를 구축하기 위한 현대적인 웹 프레임워크입니다. Sebastián Ramírez가 만들었으며, 빠르고 사용하기 쉽며 기능이 풍부하여 인기를 얻고 있습니다.\n\nFastAPI는 여러 이유로 눈에 띕니다:\n\n- 속도: 사용 가능한 Python 프레임워크 중 가장 빠릅니다.\n- 사용 편의성: Python의 타입 힌트 덕분에 코드 작성이 직관적이고 명확합니다.\n- 대화형 문서: Swagger UI 및 ReDoc와 같은 도구를 사용하여 대화형 API 문서를 자동으로 생성합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFastAPI은 웹 부분에 Starlette(Starlette은 Python에서 비동기 웹 서비스를 구축하기에 이상적인 가벼운 ASGI 프레임워크/도구)를 기반으로 하고 데이터 유효성 검증을 위해 Pydantic을 사용하여 빠르고 신뢰성이 높습니다.\n\n이 글에서는 FastAPI가 인기 있는 이유, 주요 특징, 그리고 직접 API를 구축하기 위해 FastAPI를 시작하는 방법을 살펴보겠습니다. 경험 많은 개발자든 API 개발에 처음 도전하는 개발자든 FastAPI를 사용하면 효율적이고 확장 가능한 웹 애플리케이션을 손쉽게 만들 수 있습니다.\n\n# Flask와 Django와 비교한 FastAPI의 핵심 기능 및 이점\n\nFlask와 Django와 비교했을 때, FastAPI는 다음과 같은 특징으로 두각을 나타냅니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 성능 우수성: FastAPI는 Starlette과 Pydantic을 활용하여 빠른 속도에서 Node.js와 Go와 경쟁하며 효율적인 성능을 제공합니다.\n- 사용 편의성 및 개발 속도: FastAPI의 간단한 구문과 자동 문서화(Swagger UI, ReDoc)는 개발을 가속화시켜 오류를 줄입니다.\n- 데이터 유효성 검사 및 보안: 통합된 Pydantic은 견고한 데이터 유효성을 보장하여 API 신뢰성을 향상시킵니다. FastAPI는 인증 및 권한 부여를 위한 내장 도구로 보안을 간소화합니다.\n- 비동기 지원 및 확장성: 비동기 프로그래밍에 대한 일류 지원은 병렬 요청 처리를 가능하게 하며 높은 수요 애플리케이션의 확장성에 중요합니다.\n\nFastAPI는 이러한 분야에서 뛰어나므로 Python 기반 API 프레임워크에서 속도, 확장성 및 개발의 편의성을 필요로 하는 개발자에게 플라스크와 장고 대비 매력적인 선택지입니다.\n\n# FastAPI로 시작하기\n\nFastAPI로 시작하는 것은 간단하며 몇 가지 주요 단계를 거치면 됩니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 설치:\n\n- FastAPI를 pip를 사용하여 설치하세요:\n\n```js\npip install fastapi\n```\n\n2- 개발 서버 실행:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 빠른 ASGI 서버 인 Uvicorn을 사용하여 FastAPI 애플리케이션을 실행하세요:\n\n```js\nuvicorn your_module_name:app --reload\n```\n\n- your_module_name을 FastAPI 앱이 정의된 Python 파일로 바꿔주세요.\n- --reload 옵션을 사용하여 자동으로 다시로드되도록 설정할 수 있습니다. 코드에 변경 사항이 감지되면 서버가 자동으로 재시작되어 개발이 더 빠르고 편리해집니다.\n\n3- 첫 번째 FastAPI 애플리케이션 만들기:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Python 파일(main.py)에 FastAPI 애플리케이션을 정의하세요:\n\n```python\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n```\n\n- 이 예제에서 @app.get(\"/\")은 루트 URL(\"/\")에서 GET 요청에 응답하는 라우트를 정의합니다.\n\n![이미지](/TIL/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_0.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n4- 대화식 API 문서 탐색:\n\n- FastAPI는 자동으로 대화식 API 문서를 생성합니다. 브라우저에서 http://localhost:8000/docs 에 방문하여 Swagger UI를 탐색해보세요.\n\n![FastAPI Swagger UI](/TIL/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_1.png)\n\n- 또는, http://localhost:8000/redoc 에 방문하여 ReDoc 문서를 확인할 수도 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/TIL/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_2.png)\n\n5- Expand Your Application:\n\n- Build upon your basic application by adding more routes, handling query parameters, path parameters, request bodies, and integrating with databases or other services.\n\n# Real-World Use Case: Simple To-Do List API\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n간단한 To-Do 리스트 API를 만들면 FastAPI의 핵심 기능과 이점을 이해하는 데 훌륭한 방법입니다. 이 API를 사용하면 사용자가 할 일 항목을 추가, 보기, 업데이트 및 삭제하는 기본 작업을 수행하여 작업을 관리할 수 있습니다.\n\n1- 모델 정의:\n\nFastAPI에서 Pydantic을 사용하여 모델을 정의하면 API 요청 및 응답의 데이터 구조를 유효성 검사할 수 있습니다. 다음은 간단한 To-Do 리스트 API의 모델을 정의하는 방법에 대한 코드입니다:\n\n```js\n# Pydantic 및 typing 모듈에서 필요한 구성 요소 가져오기\nfrom pydantic import BaseModel\nfrom typing import List\n\n# 단일 TodoItem을 위한 Pydantic 모델 정의\nclass TodoItem(BaseModel):\n    id: int  # TodoItem의 정수 ID\n    title: str  # 예상되는 문자열인 TodoItem의 제목\n    description: str  # 예상되는 문자열인 TodoItem의 설명\n    completed: bool = False  # TodoItem이 완료되었는지를 나타내는 부울 플래그, 기본값은 False\n\n# TodoList를 나타내는 또 다른 Pydantic 모델 정의\nclass TodoList(BaseModel):\n    todos: List[TodoItem] = []  # 기본적으로 비어 있도록 초기화된 TodoItem 객체 목록\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 모델을 정의하는 것은 API가 처리하는 데이터를 일관되게 유지하고 유효성을 검증하여 FastAPI 애플리케이션에서 데이터 관리와 오류 처리를 간소화합니다.\n\n루트 구현:\n\nFastAPI에서 루트는 API의 엔드포인트를 정의하고 들어오는 요청을 처리하는 방법을 지정합니다. 루트를 구현하는 것은 간단한 할 일 목록 API를 구축하는 중요한 단계입니다.\n\n```python\nfrom fastapi import FastAPI, HTTPException\nfrom typing import Optional\n\n# FastAPI 인스턴스 생성\napp = FastAPI()\n# 할 일 항목을 임시 보관하는 (인메모리 리스트)\ntodos = []\n# 모든 할 일 항목을 검색하는 엔드포인트\n@app.get(\"/todos/\", response_model=TodoList)\nasync def read_todos():\n    return {\"todos\": todos}\n\n# 새 할 일 항목 생성하는 엔드포인트\n@app.post(\"/todos/\")\nasync def create_todo(title: str, description: str):\n    # 고유 ID 생성 (실제 애플리케이션에서는 데이터베이스 또는 UUID 사용을 고려)\n    todo = {\"id\": len(todos) + 1, \"title\": title, \"description\": description, \"completed\": False}\n    todos.append(todo)\n    return todo\n\n# 특정 할 일 항목 업데이트하는 엔드포인트\n@app.put(\"/todos/{todo_id}/\", response_model=TodoItem)\nasync def update_todo(todo_id: int, title: Optional[str] = None, description: Optional[str] = None):\n    for todo in todos:\n        if todo[\"id\"] == todo_id:\n            todo[\"title\"] = title if title else todo[\"title\"]\n            todo[\"description\"] = description if description else todo[\"description\"]\n            return todo\n    raise HTTPException(status_code=404, detail=\"할 일을 찾을 수 없습니다\")\n\n# 특정 할 일 항목 삭제하는 엔드포인트\n@app.delete(\"/todos/{todo_id}/\")\nasync def delete_todo(todo_id: int):\n    for idx, todo in enumerate(todos):\n        if todo[\"id\"] == todo_id:\n            del todos[idx]\n            return {\"message\": \"할 일이 삭제되었습니다\"}\n    raise HTTPException(status_code=404, detail=\"할 일을 찾을 수 없습니다\")\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 설명:\n\n- GET 라우트 (/todos/): 모든 할 일 항목을 검색하여 리스트 형식으로 반환합니다.\n\n![이미지](/TIL/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_3.png)\n\n- POST 라우트 (/todos/): 고유한 ID, 제목 및 설명을 갖는 새로운 할 일 항목을 만들고 목록에 추가합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/TIL/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_4.png)\n\n- PUT Route (/todos/'todo_id'/): 기존에 있는 ID로 식별된 to-do 항목을 업데이트합니다. 부분적 업데이트가 가능합니다 (제목 또는 설명만 업데이트할 수 있음).\n\n![image](/TIL/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_5.png)\n\n- DELETE Route (/todos/'todo_id'/): 목록에서 ID로 식별된 to-do 항목을 삭제합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_6.png\" /\u003e\n\n이러한 경로들은 클라이언트가 할 일 항목에 대해 모든 CRUD 작업(생성, 읽기, 업데이트, 삭제)을 수행할 수 있도록 합니다. 이를 통해 FastAPI가 다양한 유형의 HTTP 요청과 응답을 처리하는 방법을 보여줍니다.\n\n# 결론\n\nFastAPI를 사용하여 간단한 할 일 목록 API를 작성하면 강력한 기능과 이점에 대해 실용적으로 소개 받을 수 있습니다. 모델 정의, 경로 구현, CRUD 작업 처리 단계를 따르면 FastAPI의 사용 편의성, 성능 및 자동 문서화 기능에 대한 실전 경험을 얻을 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFastAPI의 직관적인 디자인과 강력한 기능으로 초심자든 숙련된 개발자든 모두 현대적이고 고성능의 웹 API를 만드는데 우수한 선택이 될 것입니다. 이 연습을 통해 FastAPI의 핵심 개념을 이해하는데 도움을 받을 뿐만 아니라 미래에 더 복잡하고 확장 가능한 애플리케이션을 구축하는 기술도 갖추게 될 것입니다.\n\nFastAPI를 활용하여 빠르고 효율적으로 API를 개발할 수 있어, 애플리케이션이 강력하면서 유지보수가 쉬운 것을 보장할 수 있습니다. 즐거운 코딩되세요!\n","ogImage":{"url":"/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-Hands-OnwithFastAPICreatingaSimpleTo-DoListApplication_0.png","tag":["Tech"],"readingTime":10}],"page":"9","totalPageCount":19,"totalPageGroupCount":1,"lastPageGroup":19,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"9"},"buildId":"2X_5azw6MGdlttKMlGdWA","assetPrefix":"/TIL","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>