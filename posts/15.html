<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>TIL</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://13akstjq.github.io/TIL//posts/15" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="TIL" data-gatsby-head="true"/><meta property="og:title" content="TIL" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/TIL/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://TIL.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://13akstjq.github.io/TIL//posts/15" data-gatsby-head="true"/><meta name="twitter:title" content="TIL" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/TIL/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | TIL" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/TIL/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/TIL/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/TIL/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/TIL/favicons/favicon-96x96.png"/><link rel="icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/TIL/favicons/browserconfig.xml"/><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-eb138c3217d71553.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-de1dc5579188f9be.js" defer=""></script><script src="/_next/static/xx51Gh_JNHDTBdDwrgykD/_buildManifest.js" defer=""></script><script src="/_next/static/xx51Gh_JNHDTBdDwrgykD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">TIL</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="데이터 시각화 상사를 놀라게 할 Python으로 인터랙티브 그래프 만드는 3가지 비밀 팁" href="/post/2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 시각화 상사를 놀라게 할 Python으로 인터랙티브 그래프 만드는 3가지 비밀 팁" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 시각화 상사를 놀라게 할 Python으로 인터랙티브 그래프 만드는 3가지 비밀 팁" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">데이터 시각화 상사를 놀라게 할 Python으로 인터랙티브 그래프 만드는 3가지 비밀 팁</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="시계열 데이터에서 기본 모델 적용하는 방법" href="/post/2024-07-12-HowToBaselineModelsinTimeSeries"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="시계열 데이터에서 기본 모델 적용하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-12-HowToBaselineModelsinTimeSeries_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="시계열 데이터에서 기본 모델 적용하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">시계열 데이터에서 기본 모델 적용하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법" href="/post/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Phidata를 사용하여 AI 어시스턴트 구축하는 방법" href="/post/2024-07-12-UsePhidatatobuildAIAssistants"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Phidata를 사용하여 AI 어시스턴트 구축하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/no-image.jpg"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Phidata를 사용하여 AI 어시스턴트 구축하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">Phidata를 사용하여 AI 어시스턴트 구축하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">21<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="MLOps - 쉽게 배우는 2024년 Mlflow Pipelines 기초" href="/post/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="MLOps - 쉽게 배우는 2024년 Mlflow Pipelines 기초" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="MLOps - 쉽게 배우는 2024년 Mlflow Pipelines 기초" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">MLOps - 쉽게 배우는 2024년 Mlflow Pipelines 기초</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="초보자를 위한 P-해킹 시작 가이드" href="/post/2024-07-12-P-HackingforBeginners"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="초보자를 위한 P-해킹 시작 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-12-P-HackingforBeginners_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="초보자를 위한 P-해킹 시작 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">초보자를 위한 P-해킹 시작 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="유튜브 영상을 요약하는 서버리스 API 배포하는 방법" href="/post/2024-07-12-HowtoDeployaServerlessAPIThatSummarizesYouTubeVideos"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="유튜브 영상을 요약하는 서버리스 API 배포하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-12-HowtoDeployaServerlessAPIThatSummarizesYouTubeVideos_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="유튜브 영상을 요약하는 서버리스 API 배포하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">유튜브 영상을 요약하는 서버리스 API 배포하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="암호화폐를 이용한 파이썬 리스크 포트폴리오 관리 방법" href="/post/2024-07-12-RiskPortfolioManagementinPythonwithCryptos"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="암호화폐를 이용한 파이썬 리스크 포트폴리오 관리 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-12-RiskPortfolioManagementinPythonwithCryptos_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="암호화폐를 이용한 파이썬 리스크 포트폴리오 관리 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">암호화폐를 이용한 파이썬 리스크 포트폴리오 관리 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="TimeGPT vs TiDE 제로샷 추론이 예측의 미래인가, 단순한 과대광고인가" href="/post/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="TimeGPT vs TiDE 제로샷 추론이 예측의 미래인가, 단순한 과대광고인가" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="TimeGPT vs TiDE 제로샷 추론이 예측의 미래인가, 단순한 과대광고인가" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">TimeGPT vs TiDE 제로샷 추론이 예측의 미래인가, 단순한 과대광고인가</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">19<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="새로운 R 및 Python IDE, Posit Positron 시작하기 사용법 가이드" href="/post/2024-07-12-GettingStartedWithPositPositronthenewIDEforRandPython"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="새로운 R 및 Python IDE, Posit Positron 시작하기 사용법 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/TIL/assets/img/2024-07-12-GettingStartedWithPositPositronthenewIDEforRandPython_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="새로운 R 및 Python IDE, Posit Positron 시작하기 사용법 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><span class="writer">TIL</span></div><strong class="PostList_title__loLkl">새로운 R 및 Python IDE, Posit Positron 시작하기 사용법 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jul 12, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link posts_-active__YVJEi" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"데이터 시각화 상사를 놀라게 할 Python으로 인터랙티브 그래프 만드는 3가지 비밀 팁","description":"","date":"2024-07-12 19:54","slug":"2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss","content":"\n\n\u003cimg src=\"/TIL/assets/img/2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss_0.png\" /\u003e\n\n해당 글과 함께, 그래프를 인터랙티브하게 만들어 보여줌으로써 Python의 가능성을 향상시킬 것이고, 당신의 상사를 감명시킬 것입니다. 이 팁들의 목표는 더 나은 인상을 주고 사용자/고객 경험을 향상하는 데 있습니다. 효과가 있습니다!\n\n요약하자면, 3가지 목표는 다음과 같습니다:\n\n- 1. 상호작용 (팁 #1, #2 및 #3)\n- 2. 멋진 그래프 (팁 #3)\n- 3. 상사를 감명시키기 (팁 #1, #2 및 #3)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3년간 데이터 과학자로 근무하고 2년간 헤지펀드 매니저로 일한 경험을 토대로 고객들 앞에서 얻은 세 가지 조언이에요. 다른 아이디어가 있으면 댓글로 자유롭게 공유해 주세요.\n\n이 글에서는 1번과 2번 팁을 다룰 거예요.\n\n시작해 보죠.\n\n## 0. 준비 사항\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시작하기 전에 Python3 버전과 다음 패키지들이 설치되어 있는지 확인해 주세요:\n\n- Pandas\n- Plotly\n- Pandas DataReader\n\n위의 패키지들이 설치되어 있는지 확인했다면, Pandas DataReader를 사용하여 시장 데이터를 가져올 것입니다. 이 경우, Tesla의 데이터를 가져올 것입니다.\n\n만약 위의 패키지 중 어떤 것이 이미 설치되어 있지 않다면, 아래와 같이 pip 명령어를 사용할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\npip install pandas-datareader\npip install DateTime\n\n\n더 많은 알고리즘 트레이딩 및 시장 데이터 획득에 대해 더 읽고 싶다면, 이 훌륭한 기사를 강력히 추천합니다.\n\n읽기 귀찮다면, 아래 코드 라인을 찾을 수 있습니다:\n\n테슬라에서 데이터를 업로드한 후, 다음과 같은 출력물 및 사용될 데이터세트는 다음과 같습니다:\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss_1.png\" /\u003e\n\n이제 전제 조건이 해결되었으니, 첫 번째 팁부터 시작할 수 있어요.\n\n## 팁 1: 범위 슬라이더 추가\n\n나누고 싶은 첫 번째 팁은 범위 슬라이드 셀렉터입니다. 한 줄의 코드로 이미 그래프에 상당한 상호작용성을 불러올 수 있다는 사실에 믿음이 가시나요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같이 코드를 입력해보세요:\n\n\n정적 그래프 대신 사용자가 특정 시간 범위를 선택하고 확대할 수 있습니다.\n\n아래 예시에서는 재정 그래프를 기준으로 하겠지만, 시계열과 같은 데이터를 사용하면 언제든지 사용할 수 있습니다.\n\n예를 들어, 마케팅에서는 시간에 따른 판매량을 플로팅하거나, 의료 공학에서 회복 진행 상황을 플로팅하는 데 사용할 수 있습니다. 다양한 분야를 모두 다룰 순 없지만, 응용 가능성에 대한 제 언급에 대해 이해하셨을 것입니다.\n\n아래 코드를 입력해보죠:\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아이디어가 인상적이지 않니?\n\n위 그래프를 살펴보면 그래프에 범위 슬라이드 셀렉터가 추가되었음을 알 수 있어요. 이를 통해 사용자/클라이언트가 그래프의 특정 부분을 쉽게 확대 또는 축소할 수 있을 거예요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다른 예시로 여러 주식을 여러 개 가져올 수 있는 경우가 있습니다. 그리고 이러한 주식을 동일한 척도에 맞추어 인덱싱할 수도 있습니다 (출처 1). 아래는 결과입니다: \n\n![image](/TIL/assets/img/2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss_3.png)\n\n## 팁 2: 대화형 버튼 추가하기\n\n두 번째 팁은 대화형 필터링 버튼을 공유하고 싶습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나, 이것에 대해 들어보신 적이 없을 것 같아요.\n\n하지만, 제가 발견하고 나서, 제 삶은 급부상했어요.\n\n상호 작용 필터링은 고객/사용자가 직관적으로 데이터를 필터링하거나 강조하려는 특정 시간이나 그래프 부분에 직접 확대하는 것을 도와줍니다.\n\n![그래프 이미지](/TIL/assets/img/2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss_4.png)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다시 말씀드리지만 이 도표는 금융 데이터용으로 만들어졌지만 시계열 데이터의 모든 유형을 보여줄 수 있습니다.\n\n위의 그래프를 만들기 위해 그래프에 추가해야 할 솔 코드의 라인은 다음과 같습니다:\n\n```js\nfig.update_layout(\n    xaxis=dict(rangeselector=dict(\n        buttons=list([\n                dict(count=1, label=\"1 개월\", step=\"month\", stepmode=\"backward\"),\n                dict(count=6,label=\"6 개월\", step=\"month\", stepmode=\"backward\"),\n                dict(count=1,label=\"연간 데이터\", step=\"year\",stepmode=\"backward\"),\n                dict(count=1,label=\"1 년 데이터\",step=\"year\",stepmode=\"backward\"),\n                dict(step=\"all\",label=\"전체 데이터\")\n            ]))))\n```\n\n조밀하게 보일 수 있지만 한 번 입력하면 이제 그래프에 모두 재사용할 수 있어 즐겁게 복사하여 붙여넣기만 하면 됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 번 코드 블록을 가지고 있으면 변경할 수 있는 변수는 다음과 같습니다:\n\n![이미지](/TIL/assets/img/2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss_5.png)\n\n심지어 첫 번째 팁과 함께 혼합하여 청중을 황홀하게 만들 수도 있어요.\n\n아래 이미지에서는 원하는 기간에 맞게 이름을 맞추었고, 레인지 선택기와 결합된 최종 결과가 이와 유사하게 표시됩니다:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![image](https://miro.medium.com/v2/resize:fit:1200/1*KXVXwd9Y9XOvuauDPta1wQ.gif)\n\n다음과 같은 코드 한 줄로 HTML로 내보낼 수도 있어요. 이렇게 하면 해당 파일을 고객이나 친구에게 보낼 수 있어요.\n\n```js\nfig.write_html(\"/Users/Desktop/MyGraph.html\")\n```\n\nA부터 Z까지 직접 만드는 방법이 궁금하시면 다음 스텝별 영상을 따라해보세요. 실시간으로 확인하실 수 있어요:\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n질문이 있거나 데이터 시각화의 특정 부분을 다루길 원하시는 경우, 언제든지 Q\u0026A에 댓글을 남겨주세요.\n\n좋은 코딩 되세요\n\n사지드 레살니\n\n# 출처:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLearn Algo Trading in One Day(Module 3):\n\n[Python for Algorithmic Trading](https://www.udemy.com/course/python-for-algorithmic-trading)","ogImage":{"url":"/TIL/assets/img/2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-DataVisualisation3SecretTipsonPythontoMakeInteractiveGraphsandImpressYourBoss_0.png","tag":["Tech"],"readingTime":8},{"title":"시계열 데이터에서 기본 모델 적용하는 방법","description":"","date":"2024-07-12 19:52","slug":"2024-07-12-HowToBaselineModelsinTimeSeries","content":"\n\n\n![이미지](/TIL/assets/img/2024-07-12-HowToBaselineModelsinTimeSeries_0.png)\n\n데이터 수집을 완료했습니다. 사업 케이스를 개요하고 후보 모델(예: 랜덤 포레스트)을 결정했으며, 개발 환경을 설정하고 키보드에 손을 대었습니다. 이제 시계열 모델을 구축하고 훈련할 준비가 되었습니다.\n\n잠깐만요 - 바로 시작하지 마세요. 랜덤 포레스트 모델의 훈련 및 테스트를 시작하기 전에 먼저 베이스라인 모델을 훈련해야 합니다.\n\n# 베이스라인 모델이란 무엇인가요?\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기준 모델은 최종적으로 더 복잡한 머신 러닝 모델을 구축하기 위한 기준이 되는 간단한 모델입니다.\n\n데이터 과학자들이 기준 모델을 만드는 이유는:\n\n- 기준 모델을 통해 더 복잡한 모델의 성능을 어느 정도 예측할 수 있습니다.\n- 기준 모델의 성능이 좋지 않을 경우, 데이터 품질에 문제가 있을 수 있음을 나타낼 수 있습니다.\n- 기준 모델이 최종 모델보다 더 나은 성능을 보일 경우, 해당 알고리즘, 특성, 하이퍼파라미터 또는 다른 데이터 전처리에 문제가 있을 수 있습니다.\n- 기준 모델과 복잡한 모델이 비슷하게 성능을 보인다면, 복잡한 모델이 더 세밀한 조정이 필요하다는 것을 나타낼 수 있습니다. 또한, 더 복잡한 모델이 필요하지 않을 수도 있고, 보다 간단한 모델이 충분할 수도 있습니다.\n\n보통 기준 모델은 이동 평균 모델과 같은 통계 모델이거나, 대상 모델의 간단한 버전일 수 있습니다. 예를 들어, Random Forest 모델을 학습할 예정이라면 먼저 기준으로 Decision Tree 모델을 학습시킬 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 시계열 데이터의 기준 모델\n\n시계열 데이터에 대해 기준 모델로 인기 있는 옵션이 몇 가지 있습니다. 이 중에서 함께 공유하고 싶어요. 이 두 가지 모두 데이터의 시간순서를 전제로 하고 데이터의 패턴에 따라 예측을 수행하기 때문에 잘 작동합니다.\n\n## 단순 예측\n\n단순 예측은 가장 간단한 방법입니다 — 다음 값은 이전 값과 동일하다고 가정합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n날씨를 예측해보려는 모델을 구축 중이라고 가정해 봅시다. 이미 'Date'와 'TemperatureF' 두 개의 열이 적어도 포함된 데이터프레임 df를 불러왔다고 상정할게요. 이를 Python으로 구현하기 위해 먼저 타임스탬프와 타겟 변수를 분리하고 학습 및 테스트 세트로 분할하세요.\n\n```python\nimport numpy as np \n\n# 분할 인덱스 정의\nsplit_time = 1000\n\n# 타겟 배열과 시간/날짜 배열 분리\nseries = np.array(df['TemperatureF'])\ntime = np.array(df['Date'])\n\n# 학습 및 테스트 세트 나누기\ntime_train = time[:split_time]\ntime_test = time[split_time:]\n\nseries_train = series[:split_time]\nseries_test = series[split_time:]\n```\n\n이제 데이터를 준비했으므로, 순진한 예측을 계산할 수 있어요.\n\n```python\n# 순진한 예측은 단순히 시리즈를 1만큼 이동합니다\nnaive_fcst = series[split_time - 1: -1]\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n결과를 시각화하고 테스트 세트에서 나이브 예측이 어떻게 수행되는지 확인하기 위해 plotly 그래프 개체를 사용할 수 있습니다:\n\n```js\nimport plotly.graph_objects as go\n\nfig = go.Figure([\n        go.Scatter(x=time_test, y=series_test, text='true', name='true'),\n        go.Scatter(x=time_test, y=naive_fcst, text='pred', name='pred'),\n    ])\n\nfig.show()\n```\n\n여기 제 결과물입니다:\n\n\u003cimg src=\"/TIL/assets/img/2024-07-12-HowToBaselineModelsinTimeSeries_1.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막 단계는 후에 벤치마킹에 사용할 메트릭을 계산하는 것입니다. 선택할 메트릭은 특정 문제에 따라 다를 것이지만 MSE 및 RMSE를 계산하는 방법은 다음과 같습니다:\n\n```js\nfrom sklearn.metrics import mean_squared_error\n\nmse = mean_squared_error(series_test,naive_fcst)\nrmse = mean_squared_error(series_test,naive_fcst,squared=False)\n\nprint(“MSE:”, mse)\nprint(“RMSE:”, rmse)\n```\n\n## 이동 평균 예측\n\n이동평균(MA) 베이스라인 모델은 다음 데이터 포인트를 바로 이전 n개의 데이터 포인트의 평균으로 예측합니다. n의 값은 사용자에 달려있어요—일반적인 이동평균에는 30일 이동평균, 60일, 90일, 180일 등이 있습니다. 또한 사용 사례 및 분야에 따라 달라집니다. 주식 시장에서는 종종 21, 50, 100 및 200을 사용합니다. 게다가, 최종 모델로 30일을 예측할 것이라는 것을 알고 있다면 30일 이동평균을 사용하여 베이스라인을 테스트하는 것이 좋습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n특정 문제와 목표 결과에 대해 일반적으로 사용되는 이동 평균을 조사해보는 것이 중요합니다.\n\n이를 Python으로 구현하려면, 이전과 동일한 데이터 구조(시간 및 시리즈)를 유지한 채 다음을 수행하십시오.\n\n먼저, 전체 데이터셋에 대한 예측을 생성하십시오.\n\n```python\n# 리스트 초기화\nforecast = []\nwindow_size = 30\n\n# 윈도우 크기를 기반으로 이동 평균 계산\nfor time in range(len(series) - window_size):\n    forecast.append(series[time:time + window_size].mean())\n\n# 넘파이 배열로 변환\nforecast = np.array(forecast)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로 이동 평균 예측에서 테스트 세트를 분리하세요. 원래의 테스트 세트와 일치시키기 위해 window_size만큼 예측 배열을 이동할 겁니다.\n\n```js\nmoving_avg = forecast[split_time - window_size:]\n```\n\n이전과 같이 결과를 시각화해서 표시해주세요.\n\n```js\nfig = go.Figure([\n        go.Scatter(x=time_test, y=series_test, text='true', name='true'),\n        go.Scatter(x=time_test, y=moving_avg, text='pred', name='pred'),\n    ])\n\nfig.show()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이렇게 보이도록 표 태그를 마크다운 형식으로 변경해보세요. \n\n![Moving Average Chart](/TIL/assets/img/2024-07-12-HowToBaselineModelsinTimeSeries_2.png)\n\n에러 메트릭을 얻으려면, 이전과 같은 과정을 따르되 moving_avg 배열을 사용하면 됩니다.\n\n```python\nmse = mean_squared_error(series_test, moving_avg)\nrmse = mean_squared_error(series_test, moving_avg, squared=False)\n\nprint(\"MSE:\", mse)\nprint(\"RMSE:\", rmse)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 주의 사항 + 결론\n\n\"예측\"이라는 단어를 사용했지만, 사실 미래를 예측한 것은 아니에요. 저는 train test split을 했기 때문에 테스트 세트에서 예측을 할 때 이미 날짜별 이전 값을 가지고 있었거든요. 만약 앞으로 30일을 예측하려고 한다면, 진정한 naive 예측은 다음 30일이 마지막 날이나 마지막 데이터 포인트와 똑같다고 가정할 것이에요. 이는 수평선 예측으로 이어질 거에요. 이와 마찬가지로 이동평균에도 적용돼요. 그래서 이러한 기술들은 실제로 오랜 기간을 예측하기에는 최적적이지 않아요. 그러나 이러한 기법들은 여전히 기준을 설정하고 최종 모델에서 괜찮은 성능이 어떤 것인지를 평가하는 데 유용해요.\n\n기준 모델은 코드의 타당성을 점검하고 최종 모델이 데이터셋에서 신뢰성 있게 예측할 수 있는 능력을 추정하는 좋은 방법을 제공해요. 데이터 오류를 탐지하고 최종 모델 선택 과정에 도움이 되는 요소일 수 있어요. 다음에 시계열 데이터를 다룰 때는 꼭 먼저 기준선을 설정해보세요.","ogImage":{"url":"/TIL/assets/img/2024-07-12-HowToBaselineModelsinTimeSeries_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-HowToBaselineModelsinTimeSeries_0.png","tag":["Tech"],"readingTime":7},{"title":"Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법","description":"","date":"2024-07-12 19:50","slug":"2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown","content":"\n\n# 요약\n\n**문맥:** 제로샷 러닝(Zero-shot learning, ZSL)은 머신 러닝에서 cutting-edge한 방법론으로, 모델이 사전 노출 없이 새로운 객체를 인식할 수 있게 하여 인간 추론 능력을 모방합니다.\n\n**문제:** 기존 모델은 각 클래스에 대해 방대한 레이블 데이터가 필요하며, 이는 종종 실용적이지 않으며 확장 가능성을 제한합니다.\n\n**접근:** 본 보고서는 합성 데이터셋을 활용한 ZSL의 실용적 구현을 탐구하며, 특성 엔지니어링, 모델 훈련, 하이퍼파라미터 최적화 및 평가 지표에 대해 자세히 다룹니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n결과: 모델은 99.5%라는 높은 정확도를 달성하여, 혼동 행렬, 예측 분포도, 교차 검증 결과를 통해 보이지 않은 데이터를 분류하는 데 우수한 성능을 나타냈습니다.\n\n결론: 제로샷 학습은 전통적인 지도 학습의 제약을 극복하는 데 강력한 도구로 작용하며, 강력한 일반화 능력과 다양한 실제 응용 가능성을 보여줍니다.\n\n키워드: 제로샷 학습, 머신러닝 모델, 합성 데이터셋, 피처 엔지니어링, 하이퍼파라미터 최적화.\n\n# 소개\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n박물관에 들어가 새로운 동물을 그린 그림을 보게 된다면 어떤 기술들을 가지고 있는지를 살펴보면서, 비늘, 날개, 그리고 뱀 모양의 몸 등의 특징을 보고, 이것이 바로 용이라는 것을 유추할 수 있습니다. 용을 한번도 본 적이 없더라도 설명을 토대로 추론하고 인식하는 인간의 능력은 바로 인공 지능의 Zero-shot learning (ZSL)이 목표로 하는 것입니다. 데이터가 풍부하지만 항상 레이블이 되어있지 않은 세계에서, ZSL은 기계가 학습하는 방식의 한계를 뛰어넘어, 그동안 본 적 없는 물체를 식별하고 분류할 수 있도록 가능하게 합니다.\n\n![그림](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png)\n\n# Zero-Shot Learning의 이해\n\nZero-shot learning은 기계 학습에서 혁신적인 방법으로, 모델이 직접적으로 그러한 특정 클래스에 대해 훈련을 받지 않아도 새로운 객체 클래스를 인식하도록 설계됩니다. 기존의 기계 학습 모델은 인식해야 하는 각 카테고리에 대해 많은 레이블이 달린 데이터가 필요합니다. 그러나 ZSL은 속성, 텍스트 설명 또는 임베딩과 같은 의미 정보를 활용하여 새롭고 보지 못한 클래스에 대해 합리적인 추측을 할 수 있도록합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 제로샷 러닝은 어떻게 작동하나요?\n\n- 특성 추출: 모델은 훈련 단계에서 알려진 클래스에서 특성을 추출합니다. 이는 주로 이미지 인식 작업에는 사전 훈련된 합성곱 신경망(CNNs) 또는 텍스트에는 트랜스포머 모델을 사용하여 수행됩니다.\n- 의미 임베딩: 보여지거나 보이지 않는 각 클래스는 의미 벡터와 연관됩니다. 이러한 벡터는 속성(예: 호랑이를 줄무늬가 있는 동물, 네 다리가 있고 날카로운 이빨을 가진 동물로 설명)에서 파생되거나 Word2Vec 또는 GloVe와 같은 단어 임베딩을 통해 처리된 텍스트 설명에서 얻을 수 있습니다.\n- 매핑 함수: ZSL의 핵심은 시각적 특성을 의미 임베딩에 연결하는 매핑 함수에 있습니다. 모델이 새로운 이미지나 텍스트를 만나면 추출된 특성을 가장 가까운 의미 벡터에 매핑하여 보이지 않는 클래스를 인식하고 분류할 수 있게 합니다.\n\n# 제로샷 러닝의 적용 분야\n\n- 이미지 인식: ZSL은 야생 동물 모니터링과 같은 분야에서 설명적 속성을 기반으로 새로운 종을 식별하는 데 도움을 줄 수 있습니다. 예를 들어, 일반 동물에 대해 훈련된 모델은 해당 특성을 이해하여 새로 발견된 종을 인식할 수 있습니다.\n- 자연어 처리(NLP): 설명에서 맥락적 정보를 사용하여, ZSL은 모델이 명시적으로 훈련받지 않은 주제에 대한 텍스트 분류나 감정 분석과 같은 작업을 처리할 수 있게 합니다.\n- 추천 시스템: ZSL은 훈련 데이터에 없는 항목을 제안하여 사용자 경험과 참여를 향상시키는 방식으로 추천 시스템을 개선합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 도전과 향후 방향\n\n제로샷 학습은 엄청난 잠재력을 제공하지만 도전도 있습니다:\n\n- 의미적 간극: 시각적 특징과 의미적 표현 간의 불일치는 잘못된 매핑으로 이어질 수 있습니다. 이 간극을 줄이는 것은 정확도 향상에 중요합니다.\n- 속성 종속성: ZSL의 효과성은 의미적 특성이나 설명의 품질과 포괄성에 크게 의존합니다.\n- 확장성: 많은 클래스를 인식하는 것은 계산적인 도전으로 남아 있으며, 효율적인 알고리즘과 견고한 매핑 함수가 필요합니다.\n\n연구자들은 이러한 도전에 대한 해결책을 적극적으로 탐구하고 있습니다. 개선된 임베딩 기술, 제로샷 및 퓨샷 학습을 결합한 하이브리드 모델, 그리고 보다 견고한 매핑 함수는 개발 중인 전략 중 일부입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 실용 예시\n\n아래에는 합성 데이터셋을 활용한 제로샷 러닝을 보여주는 포괄적인 파이썬 코드 블록이 있습니다. 예시에는 특성 기술, 특성 엔지니어링, 하이퍼파라미터 최적화, 교차 검증, 모델 예측, 메트릭, 플롯 및 결과 해석이 포함되어 있습니다. 이 코드는 scikit-learn, numpy, pandas, matplotlib 및 seaborn 라이브러리를 사용합니다.\n\n```python\n# 필요한 라이브러리 가져오기\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 합성 데이터셋 생성\ndef create_synthetic_data():\n    np.random.seed(42)\n    n_samples = 1000\n    features = np.random.rand(n_samples, 5)\n    labels = (np.sum(features, axis=1) \u003e 2.5).astype(int)\n    \n    # DataFrame으로 변환\n    df = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(1, 6)])\n    df['label'] = labels\n    \n    # 제로샷 러닝을 위한 의미 정보 추가\n    semantic_info = {\n        0: 'low_sum',\n        1: 'high_sum'\n    }\n    \n    df['semantic_label'] = df['label'].map(semantic_info)\n    return df\n\n# 합성 데이터셋 생성\ndf = create_synthetic_data()\n\n# 특성 엔지니어링: 특성 표준화\nscaler = StandardScaler()\nX = scaler.fit_transform(df.drop(['label', 'semantic_label'], axis=1))\ny = df['label']\n\n# 데이터를 학습 및 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 제로샷 러닝 설정\nsemantic_labels = df['semantic_label'].unique()\nsemantic_embeddings = {\n    'low_sum': np.array([0.2, 0.2, 0.2, 0.2, 0.2]),\n    'high_sum': np.array([0.8, 0.8, 0.8, 0.8, 0.8])\n}\n\n# GridSearchCV를 사용한 하이퍼파라미터 최적화\nparam_grid = {\n    'C': [0.1, 1, 10],\n    'solver': ['liblinear']\n}\n\nmodel = LogisticRegression()\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\n# Grid search에서 최적의 모델\nbest_model = grid_search.best_estimator_\n\n# 예측\ny_pred = best_model.predict(X_test)\n\n# 평가 메트릭\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"정확도:\", accuracy)\nprint(\"분류 보고서:\\n\", classification_report(y_test, y_pred))\n\n# 혼동 행렬\nconf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('예측 라벨')\nplt.ylabel('실제 라벨')\nplt.title('혼동 행렬')\nplt.show()\n\n# 결과 시각화\nplt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap='viridis', marker='o')\nplt.title('제로샷 러닝 예측')\nplt.xlabel('특성 1')\nplt.ylabel('특성 2')\nplt.show()\n\n# 결과 해석\n# 합성 데이터를 사용하여 제로샷 러닝 모델의 성능을 확인할 수 있습니다.\n# 혼동 행렬 및 분류 보고서를 통해 정확도 및 분류 성능을 파악할 수 있습니다.\n\n# 교차 검증 결과\nresults = pd.DataFrame(grid_search.cv_results_)\nresults.plot(kind='bar', x='param_C', y='mean_test_score', yerr='std_test_score', capsize=4)\nplt.xlabel('C (정규화 매개변수)')\nplt.ylabel('평균 테스트 점수')\nplt.title('교차 검증 결과')\nplt.show()\n\n# 마무리\n# 제로샷 러닝은 의미 정보를 기반으로 보이지 않는 클래스를 예측할 수 있는 모델을 만듭니다.\n# 합성 예시는 제로샷 러닝 모델이 제공된 속성을 기반으로 일반화할 수 있는 능력을 보여줍니다.\n```\n\n이 코드는 합성 데이터셋을 활용하여 제로샷 러닝의 실용적인 예시를 제공하며, 데이터 생성부터 평가 및 결과 시각화까지의 전체 머신 러닝 파이프라인을 다룹니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 결과 해석\n\n혼동 행렬: 혼동 행렬은 분류 모델의 성능을 시각적으로 보여줍니다. 제공된 혼동 행렬에서:\n\n- 모형은 0 클래스의 경우 89개 및 1 클래스의 경우 110건을 정확하게 분류했습니다.\n- 1 클래스의 하나의 사례가 0 클래스로 분류되는 잘못된 분류가 있었습니다.\n- 0 클래스가 1 클래스로 잘못 분류된 경우는 없었습니다.\n\n이는 모델의 예측 정확도가 높음을 나타냅니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![image](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_1.png)\n\n정확도: 0.995 모델은 99.5%의 정확도를 달성했습니다. 이는 예측 중 99.5%가 정확했음을 나타냅니다. 이 뛰어난 정확도 점수는 모델이 이 데이터셋에서 매우 잘 수행한다는 것을 시사합니다.\n\n분류 보고서: 분류 보고서는 각 클래스에 대한 정밀도, 재현율 및 f1-점수를 포함한 상세한 지표를 제공합니다:\n\n- 정밀도: 두 클래스 모두에 대한 정밀도가 매우 높습니다 (클래스 0의 경우 0.99, 클래스 1의 경우 1.00), 이는 모델이 매우 낮은 오검출률을 가지고 있다는 것을 나타냅니다.\n- 재현율: 두 클래스 모두에 대한 재현율도 매우 높습니다 (클래스 0의 경우 1.00, 클래스 1의 경우 0.99), 이는 모델이 매우 낮은 오물체률을 가지고 있다는 것을 나타냅니다.\n- f1-점수: 정밀도와 재현율의 조화 평균인 f1-점수는 클래스 0의 경우 0.99, 클래스 1의 경우 1.00으로, 두 클래스에 대한 균형 잡힌 정확한 모델 성능을 시사합니다.\n- 지원: 지원 값(클래스 0의 경우 89, 클래스 1의 경우 111)은 테스트 데이터셋의 각 클래스에 대한 실제 인스턴스를 나타냅니다.\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제로샷 러닝 예측 산점도: 산점도는 제로샷 러닝 예측을 시각화합니다. 각 포인트는 테스트 인스턴스를 나타내며, 다른 색상은 예측된 클래스를 나타냅니다. 포인트들의 명확한 군집화는 모델이 특징에 기반하여 두 클래스를 구별하는 능력을 나타냅니다.\n\n![Zero-Shot Learning Predictions Scatter Plot](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_2.png)\n\n교차 검증 결과: 막대 차트는 정규화 매개변수 CCC의 다른 값에 대한 교차 검증에서의 평균 테스트 점수를 보여줍니다:\n\n- 모델은 모든 테스트된 CCC 값에 대해 일관된 우수한 성능을 보이며, 평균 테스트 점수는 1.0에 가깝습니다.\n- 오차 막대는 최소 테스트 점수의 표준 편차를 나타내며, 모델의 성능이 안정적이고 CCC의 선택에 지나치게 민감하지 않음을 시사합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![Zero-Shot Learning Approach](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_3.png)\n\n최종 생각:\n\n- 모델은 뛰어난 성능을 보여주며 높은 정확도, 정밀도, 재현율 및 F1 점수를 가지고 있습니다.\n- 혼동 행렬과 산점도는 모델의 능력을 추가로 확인하여 테스트 인스턴스를 최소 오류로 올바르게 분류합니다.\n- 교차 검증 결과는 견고한 모델이 다양한 하이퍼파라미터 설정에서 잘 수행되는 것을 나타냅니다.\n\n이 zero-shot 학습 접근 방식은 합성 데이터셋을 사용하더라도 훌륭한 결과를 보여주며 의미 정보를 기반으로 보이지 않는 클래스를 정확하게 일반화하고 예측할 수 있는 모델의 능력을 강조합니다.\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n제로샷 학습은 머신 러닝에서 큰 발전을 의미하며 직접적인 경험 없이 새로운 개념을 일반화하고 인식하는 인간의 능력을 반영합니다. 우리가 제로샷 학습 기술을 계속 발전시키고 향상시킬수록, 더 유연하고 확장 가능하며 동적인 현실 세계 환경에서 작동할 수 있는 AI 시스템을 만들기에 더 근접해집니다. AI의 미래는 배우고 적응하는 능력에 있으며, 제로샷 학습은 이 방향으로의 중요한 한걸음입니다.\n\n여러분의 의견을 듣고 싶습니다! 제로샷 학습이 귀하의 산업에서 AI의 미래를 어떻게 변화시킬 것으로 보십니까? 아래 댓글에 의견과 경험을 공유해주시고, 이 혁신적인 기술의 끝없는 가능성에 대한 대화를 이끌어봅시다!\n\n# 참고문헌","ogImage":{"url":"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png","tag":["Tech"],"readingTime":11},{"title":"Phidata를 사용하여 AI 어시스턴트 구축하는 방법","description":"","date":"2024-07-12 19:48","slug":"2024-07-12-UsePhidatatobuildAIAssistants","content":"\n\n지금까지 기능 호출을 사용하는 심플한 AI 시스템을 만드는 것은 다소 까다로웠습니다. 일반적으로 사용되는 대형 언어 모델 (LLM)의 특정 API 명세에 대한 심층적인 지식이 필요했으며 코딩 기술 수준도 일정 수준 이상이어야 했습니다.\n\nPhidata는 이러한 복잡성을 해결하고 기능 호출을 사용하여 손쉽게 AI 어시스턴트를 구축할 수 있는 툴킷을 제공함으로써 전체 프로세스를 간단히 만들고 있습니다.\n\n기능 호출을 통해 LLM은 함수를 호출하여 작업을 수행하고 응답에 따라 다음 단계를 지능적으로 선택할 수 있습니다. 이는 인간이 문제를 해결하는 방식과 유사합니다.\n\n## Phidata는 누구인가요?\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPhidata는 2023년에 Ashpreet Bedi에 의해 설립되었어요. 그는 Airbnb와 Facebook에서 10년간 데이터 엔지니어링 및 ML 인프라를 구축한 뒤 Phidata를 만들었죠. Phidata의 초기 비전은 AI 엔지니어링과 데브옵스 사이의 간극을 줄이는 것이었습니다.\n\n## Phidata에 접속하려면?\n\nPhidata는 무료로 이용할 수 있어요. 아래의 문서 웹사이트 링크로 이동해보세요.\n\n또한, 그들의 GitHub 리포도 확인해보세요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 할 일\n\n이 기사에서 여러 예시를 사용하여 Phidata를 사용하여 유용한 작업을 수행할 수 있는 어시스턴트를 구축하는 방법을 보여드릴 거에요.\n\n현재 Phidata는 OpenAI와 Ollama를 포함한 여러 LLM을 지원하고 있어요. 테스트 케이스에서는 먼저 Mistral LLM을 사용한 Ollama를 사용한 후 openhermes로 전환한 다음 OpenAI GPT-4를 사용할 거예요. Ollama에 익숙하지 않다면, 접속 및 사용에 대한 글을 작성했어요. 아래를 클릭하여 읽어보세요.\n\n코드를 따라하려면 Mistral 및 openhermes 모델을 Ollama를 통해 다운로드했는지 확인하세요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저 시스템에 영향을 주지 않고 코딩 및 실험을 할 수 있는 별도의 개발 환경을 설정해야 합니다. 저는 conda를 사용하여 개발 환경을 설정하지만 여러분이 편한 방법을 사용하셔도 괜찮습니다.\n\n```js\n# 테스트 환경 생성\nconda create -n phidata python=3.11 -y\n```\n\n환경이 생성되면 activate 명령을 사용하여 해당 환경으로 전환한 후 필요한 모든 라이브러리를 설치할 수 있습니다.\n\n```js\n# 이제 해당 환경을 활성화합니다\nconda activate phidata\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 필수 라이브러리 설치\npip install -U phidata\npip install ollama duckduckgo-search openai pydantic\n\n# 저는 Windows의 WSL에서 실행 중이며 종종 Notebook을 실행할 때\n# chardet과 관련된 오류가 발생합니다.\n# 따라서 다음 설치 명령어를 사용하여 문제를 해결할 수 있습니다.\npip install chardet\n```\n\n```js\n# Jupyter 설치\nconda install jupyter -y\n```\n\n이제 명령 프롬프트에서 'jupyter notebook'을 입력하세요. 브라우저에서 Jupyter Notebook이 열릴 것입니다. 자동으로 열리지 않는다면 'jupyter notebook' 명령어를 실행한 후 화면 가장 아래에 URL이 표시될 것입니다. 해당 URL을 복사하여 브라우저에 붙여넣으면 Jupyter Notebook을 시작할 수 있습니다.\n\n당신의 URL은 제 것과 다를 수 있지만 다음과 유사한 형식이어야 합니다:-\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nhttp://127.0.0.1:8888/tree?token=3b9f7bd07b6966b41b68e2350721b2d0b6f388d248cc69da\n```\n\n안녕하세요, 코드를 시작해봅시다. 각 섹션으로 나누어 주석을 달아두겠습니다. 무슨 일이 일어나고 있는지 설명할게요.\n\nPhidata는 Assistant를 사용하여 AI 애플리케이션을 개발합니다. Assistant는 기능을 호출하여 작업을 수행하기 위해 LLM을 이용합니다. 내장 메모리, 지식 및 저장소를 사용하여 자율적인 AI 애플리케이션을 쉽게 구축할 수 있습니다.\n\n## 예시 1 — 간단한 요청/응답 Assistant\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\n# 이제 이게 가장 쉬운 방법입니다\n# 비서를 설정하고, 그 후에 요청을 해보세요\n#\nfrom phi.assistant import Assistant\nfrom phi.llm.ollama import Ollama\n\nassistant = Assistant(\n    llm=Ollama(model=\"mistral\"),\n    description=\"당신은 경험 많은 시인입니다\",\n)\nassistant.print_response(\"여름 목초지에 대한 짧은 시를 써주세요\", markdown=True)\n\n\u003e\u003e\n\n╭──────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────╮\n│ 메시지  │ 여름 목초지에 대한 짧은 시를 써주세요                                                               │\n├──────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────┤\n│ 응답    │                                                                                                      │\n│ (3.5초) │  # 여름의 목초지                                                                                          │\n│          │                                                                                                      │\n│          │  황금빛에 녹아 있는,                                                                                │\n│          │  여름 목초지가 피어나 있고,                                                                          │\n│          │  진주와 금빛으로 된 이불에 싸여 있어,                                                               │\n│          │  자연의 비밀들이 과감하게 드러나 있습니다.                                                       │\n│          │                                                                                                      │\n│          │  햇빛이 반짝이는 도드람 속을 춤추며 지나가,                                                │\n│          │  잎들이 속삭이며, 자장가처럼 부드럽게 속삭이며,                                        │\n│          │  나비들이 따뜻한 공기 속에서 물줄기를 그리고,                                          │\n│          │  비교할 수 없는 모습의 심포니가 펼쳐집니다.                                                │\n│          │                                                                                                      │\n│          │  국화와 미국쑥은 손에 손을 잡고,                                                         │\n│          │  데이지는 온화한 하늘 아래에서 핀다,                                                       │\n│          │  꿀벌들은 달콤한 기쁨을 찾아 떠 돕니다,                                               │\n│          │  고요함이 불을 지피는 이 안식처에서.                                                    │\n│          │                                                                                                      │\n│          │  하늘의 푸른 천장 아래서,                                                              │\n│          │  여름 목초지는 평화로운 음조를 뽑습니다.                                             │\n│          │  생명과 사랑의 판,                                                                        │\n│          │  아름다움의 끝없는 이야기가 펼쳐집니다.                                                 │\n│          │  ``                                                                                                  │\n│          │                                                                                                      │\n╰──────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────╯\r\n```\n\n## 예시 2 — 인터넷 검색하기\n\nLLM과 도구 호출을 사용할 때 몇 가지 문제가 발생하는 것으로 보입니다. Mistral 모델을 사용할 때 일부 문제가 발생했습니다. Openhermes로 LLM 모델을 변경하면 Phidata가 더 잘 대처하는 것으로 보여, 계속하기 전에 Ollama와 함께 openhermes를 먼저 실행하십시오.\n\n```python\n# phidata에는 여러 도구가 있습니다\n# duckduckgo는 인터넷 기반 연구를 할 때 매우 유용합니다\n#\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.llm.ollama import Ollama\n\nassistant = Assistant(\n  tools=[DuckDuckGo()], \n  llm=Ollama(model=\"openhermes\"),\n  description=\"당신은 경험이 많은 연구자입니다\",\n  show_tool_calls=True)\n\nassistant.print_response(\"AI에서 가장 최신 트렌드인 이야기 찾기? 소스를 포함하여 최상위 이야기 요약.\")\n\n\u003e\u003e\n\n╭──────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────╮\n│ 메시지  │ AI에서 가장 최신 트렌드인 이야기 찾기? 소스를 포함하여 최상위 이야기 요약.                                  │\n├──────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────┤\n│ 응답    │                                                                                                      │\n│ (7.8초) │ 실행 중:                                                                                                 │\n│          │  - duckduckgo_news(쿼리=AI에서 가장 최신 트렌드인 이야기, 최대 결과=1)                                 │\n│          │  - duckduckgo_news(쿼리=AI에서 최상위 이야기, 최대 결과=3)                                         │\n│          │                                                                                                      │\n│          │ AI에서 가장 최신 트렌드와 최상위 이야기를 기반으로, 다음은 그 이야기들과 출처를 요약한 것입니다:│\n│          │                                                                                                      │\n│          │ 1. \"Walmart의 생성 AI 검색의 빠른 성공으로 Google이 걱정해야 할 이유\": Walmart은                    │\n│          │ 웹사이트 검색에 생성 AI를 효과적으로 통합하여 맞춤형 쇼핑 경험을 더해가고 있습니다.                  │\n│          │ 이로 인해 Google의 검색 시장에 미치는 잠재적 영향에 대한 우려가 제기되고 있습니다. (출처:           │\n│          │ CNBC on MSN.com)                                                                                     │\n│          │ 2. \"모두가 SoundHound AI에 대해 이야기하고 있는데, 그것이 다음 백만장자 메이커 기술 주식인가?\": SoundHound AI는||\n│          │ 투자자, 언론 및 월스트리트로부터 상당한 관심을 받고 있으며, 음성 기반 AI 어시스턴트에 대한 관심이             ||\n│          │ 커지면서 더욱 주목을 받고 있습니다. (출처: The Motley Fool on MSN.com)                                    ||\n│          │ 3. \"AI로 이야기하는 책들이 나왔습니다. 인간들은 일자리를 잃을까요? 이 스타트업은 해결책을 갖고 있습니다\": AI 소프트웨어||\n│          │ 가 점차적으로 오디오북과 뉴스 기사를 이야기하는 데 사용되면서, 인간 이야기꾼들의 미래에 대한 우려가 올라옵니다.  ||\n│          │ 한 스타트업은 인간 보코이버를 대체하기 위한 AI 모델을 훈련시켜 아닌 보코오버를 강화시키기 위한 해결책을 제공합니다.   ||\n│          │ (출처: MSN)                                                                                        ||\n│          │ 4. \"Nvidia 주식이 상승하고 있습니다. 그 칩들이 메타의 새 AI 모델을 구동하고 있습니다\": Nvidia 주식이 상승하는 이유는  ||\n│          │ 메타 플랫폼의 최신 인공지능 훈련을 지원하고 있기 때문입니다                                                 ||\n╰──────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────╯\r\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 예제 3 — 외부 함수 호출\n\n이전 프로젝트에서 전 세계의 모든 지명 위치의 온도를 가져오기 위해 파이썬 함수를 작성했어요. 그것을 Phidata와 어떻게 통합할 수 있는지 알아봅시다. 제 함수는 OpenWeatherMap API를 사용해요. 무료로 API 키를 등록하고 얻을 수 있어요. 아래 링크를 클릭해보세요.\n\n```js\n# 우리가 작성한 Python 함수를\n# Phidata에 아주 쉽게 통합할 수 있어요\n#\nfrom phi.llm.ollama import Ollama\nfrom phi.tools import Toolkit\nfrom phi.assistant import Assistant\n\nimport requests\n\nclass GetTemp(Toolkit):\n    def __init__(self):\n        super().__init__()\n\n    def get_temp(self,location:str)-\u003estr:\n        # 여기에 API 키를 입력해주세요\n        API_KEY = \"여기에_당신의_웨더맵_키를_입력하세요\"\n    \n        # url을 저장하는 base_url 변수\n        base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n    \n        # 요청 전체 URL\n        complete_url = base_url + \"appid=\" + API_KEY + \"\u0026q=\" + location\n    \n        # requests 모듈의 get 메서드\n        # 응답 객체를 반환합니다\n        response = requests.get(complete_url)\n        x = response.json()\n     \n        # \"cod\" 키의 값이 \"404\"와 같으면\n        # 위치가 발견된 것이고 그렇지 않으면\n        # 도시가 발견되지 않았어요\n        if x[\"cod\"] != \"404\":\n            y = x[\"main\"]\n            # 가독성을 위해 온도를 켈빈에서 섭씨로 변환\n            temp_celsius = y[\"temp\"] - 273.15\n            return str(temp_celsius)\n        else:\n            return None\n\nassistant = Assistant(\n    description=\"도구를 이용해 세계 온도 데이터를 얻는 유용한 Assistant에요\", \n    tools=[GetTemp().get_temp], \n    llm=Ollama(model=\"openhermes\"),\n)\n\nassistant.print_response(\"에든버러의 온도는?\")\nassistant.print_response(\"뉴욕의 온도는?\")\n\n\u003e\u003e\n\n╭──────────┬──────────────────────────────────────────────────────────────╮\n│ 메시지   │ 에든버러의 온도는?                                            │\n├──────────┼──────────────────────────────────────────────────────────────┤\n│ 응답     │ 에든버러의 온도는 현재 10.62도 입니다                           │\n│ (1.3초)  │                                                              │\n╰──────────┴──────────────────────────────────────────────────────────────╯\n╭──────────┬───────────────────────────────────────────────────────╮\n│ 메시지   │ 뉴욕의 온도는?                                              │\n├──────────┼───────────────────────────────────────────────────────┤\n│ 응답     │ 뉴욕의 온도는 현재 7.99도 입니다                             │\n│ (1.0초)  │                                                       │\n╰──────────┴───────────────────────────────────────────────────────╯\n```\n\n## 예제 4 — 파이썬 코드 작성과 실행\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이번 테스트에서는 Phidata에게 CSV 파일에서 간단한 탐색적 데이터 분석을 수행하는 Python 프로그램을 작성해 달라고 요청할 것입니다. 사용할 데이터는 IMDB 영화 통계 레코드 세트입니다. 이 데이터는 Phidata가 AWS S3 버킷에 저장하고 제공합니다. 데이터 세트에는 1000개의 레코드가 있으며 처음 몇 개는 다음과 같습니다.\n\nPhidata에게 데이터 세트의 모든 영화의 평균 상영 시간을 계산하는 Python 프로그램을 작성해 달라고 요청할 것입니다. 이를 위해 OpenAI GPT-4 LLM을 사용해야 하므로 API 키가 필요합니다. 이미 API 키를 보유하고 있지 않다면 platform.openai.com에 방문하여 획득하십시오. 참고: 이를 위해서는 결제 세부 정보를 입력해야 합니다. 시작합니다.\n\n```python\nfrom phi.assistant.python import PythonAssistant\nfrom phi.file.local.csv import CsvFile\nfrom phi.tools import Toolkit\nfrom phi.assistant import Assistant\nfrom phi.llm.openai import OpenAIChat\n\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"여러분의_OPENAI_API_KEY\"\n\n\npython_assistant = PythonAssistant(\n    files=[\n        CsvFile(\n            path=\"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n            description=\"IMDB의 영화 정보를 담고 있습니다.\",\n        )\n    ],\n    llm=OpenAIChat(model=\"gpt-4\"),\n    pip_install=True,\n    \n)\n\npython_assistant.print_response(\"영화들의 평균 상영 시간을 계산하세요. 최종 응답은 '영화의 평균 상영 시간은 \u003cavg_runtime\u003e 분입니다' 형식이어야 합니다. \u003cavg_runtime\u003e은 여러분이 계산한 값입니다.\", markdown=True)\n```\n\n이것이 출력입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n╭──────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────╮\n│          │ 영화의 평균 런타임을 분 단위로 계산하세요? 최종 응답은 '\u003cavg_runtime\u003e 분입니다' 형식으로 나와야 합니다. 여기서 \u003cavg_runtime은 계산된 값 입니다. │\n├──────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────┤\n│ Message  │ 제공된 \"IMDB-Movie-Data.csv\"에서 영화의 평균 런타임을 계산하려면 다음 단계를 따르세요:                 │\n│ (34.0s)  │                                                                                                      │\n│ Response │  1. 팬더스(Pandas)를 사용하여 CSV 파일에서 데이터를 로드합니다. 팬더스는 대용량 데이터를 처리하는 효율적인 라이브러리입니다.  │\n│          │  2. 'Runtime (Minutes)' 열의 평균을 계산합니다.                                                       │\n│          │  3. 데이터셋이 이미 온라인에서 사용 가능하기 때문에 데이터를 다운로드할 필요가 없습니다.                │\n│          │                                                                                                      │\n│          │ 이를 계산하기 위한 파이썬 코드는 다음과 같습니다:                                                        │\n│          │                                                                                                    │\n│          │                                                                                                  │\n│          │  import pandas as pd                                                                              │\n│          │                                                                                                    │\n│          │  def calculate_average_runtime():                                                                 │\n│          │      url = 'https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv'                  │\n│          │      data = pd.read_csv(url)                                                                      │\n│          │      avg_runtime = data['Runtime (Minutes)'].mean()                                                 │\n│          │      return avg_runtime                                                                           │\n│          │                                                                                                    │\n│          │  if __name__ == \"__main__\":                                                                       │\n│          │      print(f'영화의 평균 런타임은 {calculate_average_runtime()} 분입니다')                         │\n│          │                                                                                                    │\n│          │                                                                                                    │\n│          │ 코드를 저장하고 실행해 봅시다: 오류가 있는 것으로 보입니다. 프로그램은 평균 런타임을 반환하지 않고 출력합니다. 평균 런타임을 반환하도록 코드를 수정할 것입니다.  │\n│          │                                                                                                    │\n│          │ 수정된 파이썬 코드는 다음과 같습니다:                                                                   │\n│          │                                                                                                    │\n│          │                                                                                                    │\n│          │  import pandas as pd                                                                              │\n│          │                                                                                                    │\n│          │  def calculate_average_runtime():                                                                 │\n│          │      url = 'https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv'                  │\n│          │      data = pd.read_csv(url)                                                                      │\n│          │      avg_runtime = data['Runtime (Minutes)'].mean()                                                 │\n│          │      return avg_runtime                                                                           │\n│          │                                                                                                    │\n│          │  if __name__ == \"__main__\":                                                                       │\n│          │      avg_runtime = calculate_average_runtime()                                                      │\n│          │      print(f'영화의 평균 런타임은 {avg_runtime} 분입니다')                                         │\n│          │                                                                                                    │\n│          │                                                                                                    │\n│          │ 이제 스크립트 실행 시 avg_runtime이 반환될 것이며, save_to_file_and_run 함수에서 해당 변수를 요청할 수 있습니다. 수정하겠습니다. 영화의 평균 런타임은 ...분입니다 │\n╰──────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────╯\nINFO     Saved: /home/tom/average_runtime.py                                                                       \nINFO     Running /home/tom/average_runtime.py                                                                      \n영화의 평균 런타임은 113.172 분입니다\nINFO     Saved: /home/tom/average_runtime.py                                                                       \nINFO     Running /home/tom/average_runtime.py                                                                      \n영화의 평균 런타임은 113.172 분입니다\r\n```\n\n113.172 분의 답이 정확하다는 것을 확인할 수 있습니다(아래 참조).\n\n## 결론\n\nPhidata에 꽤 impressed했습니다. 여러 가지 작업을 효율적으로 수행할 수 있는 것 같습니다. 현재 local LLMs를 사용하는 부분이 조금 hit-and-miss 한 것이 유일한 문제입니다. 하지만 이것 또한 앞으로 몇 주 및 몇 달 사이에 개선될 것으로 기대합니다. 만약 누군가가 이미 시도해보고 새로운 용도를 발견했다면 댓글로 알려주세요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 컨텐츠가 마음에 드셨다면, 다음 게시물들도 흥미롭게 보실 수 있을 거예요.","ogImage":{"url":"/TIL/assets/no-image.jpg"},"coverImage":"/TIL/assets/no-image.jpg","tag":["Tech"],"readingTime":21},{"title":"MLOps - 쉽게 배우는 2024년 Mlflow Pipelines 기초","description":"","date":"2024-07-12 19:47","slug":"2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines","content":"\n\n\u003cimg src=\"/TIL/assets/img/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines_0.png\" /\u003e\n\n# 소개\n\n다양한 통계에 따르면 모델들을 개발하는데 50%와 90% 사이의 모델들이 제품화되지 못하는 경우가 많습니다. 이는 작업을 구조화하는 데 실패한 결과입니다. 학계나 Kaggle에서 습득한 기술이 수천 명의 사용자가 사용하는 머신러닝 기반 시스템을 구축할 수 있을 정도로 충분하지 않은 경우가 종종 있습니다.\n\n산업계에서 머신러닝 업무를 찾을 때 가장 필수적인 기술 중 하나는 MLflow와 같이 복잡한 파이프라인을 조정하는 도구를 사용하는 능력입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 글에서는 프로젝트를 여러 단계로 구조화하고 모든 단계를 체계적으로 관리하는 방법을 알아볼 것입니다.\n\n이 글의 스크립트를 실행하려면 Deepnote를 사용합니다: 협업 데이터 과학 프로젝트 및 프로토타입에 적합한 클라우드 기반 노트북입니다.\n\n## Mlflow이란?\n\nMLflow는 Databricks가 개발한 기계 학습의 완전한 라이프사이클 관리를 위한 오픈 소스 플랫폼입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMLflow은 훈련 중인 모델을 모니터링하고 아티팩트 스토어를 사용하며 모델을 제공하는 등 여러 가지 기능을 제공합니다. 오늘은 MLflow를 머신러닝 파이프라인의 오케스트레이터로 사용하는 방법을 살펴볼 것입니다. 왜냐하면 특히 인공지능 세계에서는 다양한 단계와 실험이 있기 때문에 깔끔하고 이해하기 쉽고 쉽게 재현할 수 있는 코드를 갖추는 것이 중요합니다.\n\n그런데 정확히 MLflow를 사용하여 관리해야 하는 단계는 무엇일까요? 이는 우리 작업의 문맥에 따라 달라집니다. 머신러닝 파이프라인은 우리가 일하는 환경과 최종 목표가 무엇인지에 따라 달라질 수 있습니다. 예를 들어, 캐글 과제를 해결하기 위한 파이프라인은 대부분 모델링에 시간을 소비하므로 간단합니다. 반면 산업에서는 데이터 및 코드 품질을 확인하는 단계가 여러 개일 수 있습니다.\n\n여기서는 매우 기본적인 파이프라인을 가정합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 가능한 한 각 단계를 독립적으로 개발하길 원합니다. 모델링을 맡은 사람들은 데이터 수집, 데이터 다운로드, 정리 등과 무관하게 그 구성요소만 개발하면 됩니다.\n\n우리는 (과장해서) 각 파이프라인 구성요소에 대한 팀이 있는 상황을 더 가정해 봅시다. 우리는 각 팀이 가장 잘 아는 도구와 언어로 작업할 수 있도록 하여 각 팀의 작업을 용이하게 하길 원합니다. 그래서 각 단계마다 독립적인 개발 환경을 원합니다. 예를 들어, 데이터 다운로드는 C++로 개발하고, 데이터 정리는 Julia로, 모델링은 Python으로, 그리고 추론은 Java로 개발할 수 있습니다. MLflow를 통해 가능합니다!\n\nMLflow를 설치하려면 pip를 사용할 수 있습니다.\n\n## MLflow 프로젝트 정의\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMLflow 프로젝트는 3가지 주요 부분으로 구성되어 있습니다:\n\n- 코드: 작업 중인 작업을 해결하기 위해 작성하는 코드\n- 환경: 환경을 정의해야 합니다. 코드 실행에 필요한 종속성은 무엇인가요?\n- MLflow 프로젝트 정의: 각 MLflow 프로젝트에는 사용자가 프로젝트와 상호 작용하는 방법과 무엇을 실행해야 하는지를 정의하는 MLproject라는 파일이 있습니다.\n\n이 글에서 각 파이프라인 구성 요소의 코드는 간편함을 위해 Python으로 작성할 것입니다. 그러나 이전에 언급했듯이 이것이 반드시 그렇다는 것은 아닙니다.\n\n환경을 어떻게 관리할까요? 재현 가능하고 격리된 개발 환경을 정의하려면 여러 도구를 사용할 수 있습니다. 주요 도구로는 docker와 conda가 있습니다. 이 예에서는 conda를 사용할 것인데, conda를 사용하면 의존성을 빠르고 쉽게 지정할 수 있지만, docker는 다소 어려운 학습 곡선을 가지고 있습니다. conda를 다운로드해야 한다면, 가벼운 버전인 miniconda를 추천합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n개발 환경을 정의하는 conda.yml 파일을 만들어 가상 환경을 생성할 수 있습니다.\n\n우리가 할 일은 conda.yml에서 pip 사용을 정의하고 나중에 wandb와 같은 추가 설치를 위해 pip를 사용하는 것입니다. (참고로 이 경우에는 wandb가 실제로 필요하지 않습니다.)\n\n\n# conda.yml\nname: download_data\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - requests\n  - pip\n  - mlflow\n  - hydra-core\n  - pip:\n    - wandb\n\n\n이제 conda.yml에 정의된 환경을 생성하기 위해 다음 명령을 CLI에서 실행할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nconda env create --file=conda.yaml\n```\n\n이제 활성화해 봅시다.\n\n```js\nconda activate download_data\n```\n\n이제 MLproject 파일을 정의해야 합니다. 이 파일에 유의해 주세요. yaml로 작성되어 있지만 확장자가 필요하지 않습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 파일에서는 먼저 단계의 이름과 사용할 콘다 환경을 정의합니다. 그런 다음 계산을 시작할 주요 Python 파일인 entry point를 지정해야 합니다. 그 후에는 파일을 시작하는 데 필요한 매개변수도 정의해야 합니다. 예를 들어, 다운로드 단계에서는 데이터를 다운로드할 URL을 전달할 것으로 예상합니다.\n\n마지막으로 mlflow가 실제로 시작해야 하는 명령을 표시합니다.\n\n\nname: download_data\nconda_env: conda.yml\n\nentry_points:\n  main:\n    parameters:\n      data_url:\n        description: 데이터 다운로드 URL\n        type: uri\n\n    command: \u003e-\n      python main.py --data_url {data_url} #중괄호에 입력 변수를 넣으세요\n\n\n이제 본격적으로 주 Python 코드 main.py를 작성할 준비가 됐습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬 코드에서는 MLproject로부터 예상되는 인수 \"data_url\"을 입력으로 받아야 합니다. 그런 다음 사용자가 이 인수를 cli에서 전달할 수 있도록 argparser를 사용할 수 있습니다.\n\n그런 다음 run() 함수를 실행하는데, 이 함수는 URL에서 CSV 파일을 읽어 로컬로 저장하는 일을 하는데, 이는 이 구성요소에서 기대되는 데이터의 간단한 다운로드를 수행합니다.\n\n여기에는 MIT 라이선스의 오픈 소스 데이터가 사용되었습니다. 구체적으로, GitHub의 다음 URL에서 찾을 수 있는 클래식 Titanic 데이터셋입니다: https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n\n이렇게 main.py 파일을 작성할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 mlflow를 사용하여 전체 구성 요소를 실행할 수 있습니다. mlflow에서 매개변수를 지정하려면 -P 플래그를 사용합니다.\n\n```js\nmlflow run . -P data_url=\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n```\n\n터미널 로그에서 처음에 Mlflow가 conda.yml을 사용하여 개발 환경을 재생성하려고 시도하고(첫 번째 시도에 시간이 걸릴 수 있음) 그런 다음 코드를 실행합니다. 결과적으로 데이터셋이 다운로드되는 것을 볼 수 있어야 합니다!\n\n![이미지](/TIL/assets/img/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines_2.png)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 구성 요소에서 파이프라인으로\n\n좋아요, 이제 한 구성 요소로 구성된 MLflow 프로젝트를 만드는 기초가 마련되었습니다. 하지만 전체 파이프라인을 어떻게 개발할까요? MLflow에서 파이프라인이란 다른 MLflow 프로젝트로 이뤄진 것으로 구성됩니다!\n\n![이미지](/TIL/assets/img/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines_3.png)\n\n루트 디렉토리에서 여러 구성 요소로 파이프라인을 생성하고 싶으므로 각 구성 요소용 서브디렉토리를 두 개 만들겠습니다. 다음 이미지에서 확인할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![Step 1](/TIL/assets/img/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines_4.png)\n\n간단하게 말하자면, 데이터 다운로드 및 데이터 정리 두 단계만 실행합니다. 물론, 실제 파이프라인은 훈련, 추론 등 훨씬 많은 단계로 구성됩니다.\n\n위 다이어그램에서 각 구성 요소/단계는 자체적으로 3개의 파일로 설명된 MLflow 프로젝트입니다. 전체 구조는 다음 이미지에서 확인할 수 있습니다.\n\n![Step 2](/TIL/assets/img/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines_5.png)\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 이 디렉토리에 있는 모든 파일을 어떻게 정의했는지 살펴봅시다.\n\n🟢 mlflow_pipeline/conda.yml\n\n이 파일은 이전과 다르지 않습니다. 개발 환경을 정의합니다.\n\n```yaml\n#conda.yaml\nname: mlflow_pipeline\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - pandas\n  - mlflow\n  - requests\n  - pip\n  - mlflow\n```  \n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n🟢 mlflow_pipeline/MLproject\n\n파이프라인의 모든 단계를 항상 실행할 필요는 없을 수도 있지만 때로는 일부 단계만 실행하고 싶을 때가 있습니다. 따라서 쉼표로 구분된 실행하려는 모든 단계를 정의하는 문자열을 입력으로 받습니다.\n\nMLflow를 실행할 때 다음과 같은 명령을 사용할 것입니다:\n\nmlflow run . P steps=”download,cleaning,training”\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\nname: mlflow_pipeline\nconda_env: conda.yml\n\nentry_points:\n  main:\n    parameters:\n      steps:\n        description: 쉼표로 구분된 수행할 단계\n        type: str\n\n      data_url:\n        descripton: 데이터의 URL\n        type: uri\n\n    command: \u003e-\n      python main.py --steps {steps} --data_url {data_url}\n\n\n🟢 mlflow_pipeline/main.py\n\n이 파일에서는 이제 단계를 처리할 것입니다. 입력을 파싱하면 문자열을 쉼표로 분할하여 모든 단계가 배열에 포함됩니다.\n\n각 단계에 대해 mlflow.run을 실행하며, 이번에는 cli를 사용하지 않고 직접 Python에서 실행합니다. 명령어는 매우 유사하지만 각 실행에는 구성 요소 경로와 entry point(항상 main)를 지정하고 필요한 경우 매개변수를 전달합니다.\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서부터 다른 구성 요소를 정의하는 방법은 이전에 했던 것과 매우 유사합니다. 다운로드 및 정리 단계를 계속 설명하겠습니다.\n⚠️ 모든 conda.yml은 동일하므로 여러 번 반복하는 것을 피하겠습니다.\n\n🟢 mlflow_pipeline/data_download/MLproject\n\n이전과 마찬가지로 data_download은 데이터를 다운로드하기 위한 input 매개변수, 즉 데이터의 URL을 예상하며, 나머지는 표준입니다.\n\n```js\nname: download_data\nconda_env: conda.yml\n\nentry_points:\n  main:\n    parameters:\n      data_url:\n        description: 데이터 다운로드 URL\n        type: str\n\n    command: \u003e-\n      python run.py --data_url {data_url}\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n🟢 mlflow_pipeline/data_download/run.py\n\nrun.py 파일에서는 MLproject에 정의된 URL 파일을 가져와 pandas 데이터프레임을 열고 .csv 확장자로 데이터셋을 로컬에 저장합니다.\n\n🟢 mlflow_pipeline/data_cleaning/MLproject\n\n이 경우, 데이터 클리닝은 매우 간단합니다. 파이프라인 구조화에 초점을 맞추고 복잡한 단계 생성에 대해서는 다루지 않습니다. 입력 매개변수를 예상하지 않으므로 run.py만 실행하면 됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\nname: data_cleaning\nconda_env: conda.yml\n\nentry_points:\n  main:\n    command: \u003e-\n      python run.py\n```\n\n🟢 mlflow_pipeline/data_cleaning/run.py\n\n실제 데이터 클리닝에서는 null 값이 포함된 모든 행을 삭제하고 새로운 데이터프레임을 CSV로 로컬 루트 폴더에 저장합니다.\n\n이제 우리가 실수를 하지 않았다면 적절한 매개변수를 지정하여 단일 mlflow 명령어로 전체 파이프라인을 실행할 수 있습니다. 그럼 단계와 데이터셋의 URL을 지정하세요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nmlflow run . -P steps=\"data_download,data_cleaning\" -P data_url=\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\" \n```\n\n모든 단계가 올바르게 수행될 것이며, 여러분의 디렉토리에 두 개의 새 CSV 파일이 생길 것입니다! 🚀\n\n![image](/TIL/assets/img/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines_6.png)\n\n# 결론\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 MLflow에서 프로젝트가 구성되는 방식과 파이프라인이 프로젝트 시퀀스에 의해 정의되는 방법을 살펴 보았습니다.\n\n파이프라인의 각 단계는 자체 환경에 의해 정의되기 때문에 독립적으로 개발할 수 있습니다. 각 단계의 개발에는 다른 언어와 도구를 사용할 수 있으며, MLflow는 오로지 Orchestration 역할만을 합니다. 이 기사가 여러분께 MLflow의 사용 방법에 대한 아이디어를 제공해 드렸기를 바랍니다.\n\nMLFlow는 머신러닝 실험을 추적하는 데 매우 유용하지만, 복잡성과 가파른 학습 곡선 때문에 MLOps에 새로운 작은 프로젝트나 팀들을 망설이게 할 수 있습니다. 그러나 실험 추적, 데이터 및 모델 버전 관리, 협업이 중요한 경우에는 매우 편리하며 중대규모 프로젝트에 이상적입니다.\n\nMLflow가 제공하는 기능들은 매우 다양합니다. 예를 들어, 모델의 성능을 모니터링하거나 생성한 아티팩트를 저장하는 데 사용할 수 있습니다. 앞으로 다른 도구들을 MLflow에 통합하여 그 잠재력을 최대한 활용하는 방법을 소개할 예정이니 기대해 주세요!\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 이 기사에 관심이 있다면 제 Medium 팔로우해주세요! 😁\n\n💼 Linkedin ️| 🐦 Twitter | 💻 Website","ogImage":{"url":"/TIL/assets/img/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-MLOpsAGentleIntroductiontoMlflowPipelines_0.png","tag":["Tech"],"readingTime":14},{"title":"초보자를 위한 P-해킹 시작 가이드","description":"","date":"2024-07-12 19:45","slug":"2024-07-12-P-HackingforBeginners","content":"\n\n생명 통계학의 모든 주제 중에서 학생들에게 설명하기 가장 어려운 것은 p-값의 개념입니다. 본질적으로 p-값은 영 가설을 기각하는 확률입니다. 간단히 말하면, 우리가 관찰하고 있는 것 사이에 연관성이 없을 때에도 두 가지 사이에 연관성이 있다고 말할 확률이죠. 이것은 우리가 보고 있는 것이 우연히 발생한 것일 확률이기도 합니다.\n\n내가 말했지만, 설명하기 어려울 거야.\n\n기본적으로 통계 분석을 할 때는 매우 낮은 p-값을 원합니다. 값이 낮을수록 좋습니다... 값이 낮을수록 두 가지 이상의 것이 연관성이 있는 것처럼 보일 확률이 줄어듭니다. 그리고 우리는 0.05의 p-값을 기준으로 삼습니다. 왜냐하면 5%의 확률로 잘못될 우리가 받아들일 수 있기 때문이죠.\n\n0.051이면 정말이지 말이 안 돼야지요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 그것이죠. 연구의 디자인을 조작하여 수행하는 통계 분석의 p-값을 0.05 미만으로 만들 수 있습니다. 그렇게 함으로써 결과가 \"통계적으로 유의하다\"로 판정될 수 있지만, 분석에서 보는 관련성의 강도는 바뀌지 않을 수도 있습니다. 예를 들어볼까요?\n\n## 감자 샐러드를 먹었지요? \n\n작은 파티에서 섭취한 음식으로 인한 식중독 발작을 조사하고 있습니다. 파티에 8명이 참석했고, 그들에게 무엇을 먹었는지 물어보았습니다. 감자 샐러드를 먹은 대부분의 사람들이 병에 걸린 것을 주목했습니다. 감자 샐러드를 먹고 병이든지의 연관성을 결정하기 위해 카이 제곱 독립성 검정을 수행하기로 결정했습니다. 다음은 결과입니다:\n\n- 감자 샐러드를 먹은 사람 5명 중 4명이 병에 걸렸습니다.\n- 감자 샐러드를 먹지 않은 사람 3명 중 1명이 병에 걸렸습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n꽤 명확하죠? 샐러드를 먹은 사람 중에 병에 걸릴 확률은 4/1인 반면, 샐러드를 먹지 않은 사람 중에 병에 걸릴 확률은 1/2입니다. 이 확률들의 비율(즉, \"오즈비\")은 8입니다. 샐러드를 먹은 사람들은 병에 걸릴 오즈가 8배 높습니다.\n\n하지만 여기 한 가지를 알려드릴게요. 이 오즈비의 p-값은 0.468로, 0.05 임계값을 크게 넘는 숫자에요. 이 결과는 통계적으로 유의하지 않습니다. 보고 있는 것이 우연히 발생한 것일 가능성이 높습니다. (다시 말해, 이것은 단순한 설명입니다. 만약 전문 용어로 설명을 원하신다면: \"p-값은 귀무가설이 참이라고 할 때, 관측된 결과나 그 이상을 관측할 확률을 측정합니다.\")\n\n다음은 R 코드입니다 (뒤에 코드 전체 및 이와 유사한 분석을 하는 Python 코드도 포함하겠습니다):\n\n```js\n# 필요한 라이브러리를 로드합니다\nlibrary(dplyr)\n\n# 카이제곱 검정을 수행하고 결과를 출력하는 도우미 함수\nanalyze_data \u003c- function(counts_multiplier) {\n  # 데이터 생성\n  exposure \u003c- rep(c(\"Ate\", \"Did Not Eat\"), each = 2)\n  status \u003c- rep(c(\"Ill\", \"Not Ill\"), times = 2)\n  count \u003c- c(4, 1, 1, 2) * counts_multiplier\n  data \u003c- data.frame(exposure, status, count)\n  \n  # 올바른 교차표를 만들기 위해 데이터 요약\n  summarized_data \u003c- data %\u003e%\n    group_by(exposure, status) %\u003e%\n    summarise(count = sum(count), .groups = 'drop')\n  \n  # chisq.test 함수에서 예상하는 행렬 형식으로 변환\n  contingency_table \u003c- xtabs(count ~ exposure + status, data = summarized_data)\n  \n  # 카이제곱 검정 수행\n  chi_test_result \u003c- chisq.test(contingency_table,simulate.p.value = T,correct = T)\n  \n  # 결과 출력\n  cat(\"배수\", counts_multiplier, \"배로 조정한 카이제곱 검정 결과:\\n\")\n  cat(\"카이제곱 통계량:\", chi_test_result$statistic, \", p-값:\", chi_test_result$p.value, \"\\n\")\n  print(contingency_table)\n  cat(\"\\n\")\n}\n\n# 다양한 count 배수에 대해 데이터 분석\nanalyze_data(1)  # 5개 케이스와 3개 컨트롤을 사용하여\nanalyze_data(2)  # 10개 케이스와 6개 컨트롤을 사용하여\nanalyze_data(3)  # 15개 케이스와 9개 컨트롤을 사용하여\nanalyze_data(4)  # 20개 케이스와 12개 컨트롤을 사용하여\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기 결과입니다:\n\n```js\n\u003e analyze_data(1)  # 5명의 사례와 3명의 대조군을 대상으로 함\n1배 분석 결과 카이제곱 테스트:\n카이제곱 통계량: 1.742222, p-값: 0.4682659\n             상태\n노출         병에 걸림 건강한 상태\n  먹음           4         1\n  안 먹음       1         2\n```\n\n(이안의 얀트스의 연속 보정(Yates' continuity correction)에 대해 궁금한 점이 있다면, 여기서 이와 같은 사용 사례를 읽어볼 수 있습니다: https://www.jstor.org/stable/2983604. 혹은 왜 피셔의 정확 테스트(Fisher's Exact Test)를 사용했는지 궁금하다면, 여기서 확인해보세요: https://online.stat.psu.edu/stat504/lesson/4/4.5. 이러한 것들은 이 게시물의 범위를 벗어난 복잡한 통계 개념들입니다.)\n\n\u003cimg src=\"/TIL/assets/img/2024-07-12-P-HackingforBeginners_0.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\np-값을 계산하기 위해 정규 분포가 아닌 카이 제곱 분포를 사용한다는 점을 유의하세요. 이들은 결국 카테고리별 사람 수이기 때문에 연속적인 숫자가 아닙니다. 위 분포에서 곡선 아래 약 47%가 X 축의 1.74 오른쪽에 있습니다. 이는 우리가 데이터에서 계산한 검정 통계량입니다. 샘플 크기가 이 계산에 어떤 영향을 미치는지 확인하면서 그래프를 다시 참조하세요.\n\n## p-값 부풀리기!\n\np-값을 낮추려면 무엇을 해야 할까요? 당연히 샘플 크기를 증가시키면 됩니다! 분석 중인 내용의 샘플 크기를 늘리면 p-값이 낮아지는 통계적 효과가 이미 알려져 있습니다. 테스트 통계량을 계산하는 데 사용하는 수학 때문에 샘플 크기는 데이터의 표준 오차 — 또는 데이터의 변동성 — 공식의 분모에 있습니다. 샘플이 커질수록 변동성이 줄어들고 우리의 관측이 더 정밀해집니다. 더 정밀하면 우리가 본 것이 우연히 발생한 것일 가능성이 더 적어집니다.\n\n그래서 10건의 사례와 6건의 대조군으로 샘플 크기를 증가시키겠습니다. 여기에 결과가 있습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n\u003e analyze_data(2)  # 10 cases and 6 controls 지정\n2배로 증가 시킨 Chi-square 테스트 결과:\nChi-square 통계량: 3.484444 , p-값: 0.1164418 \n             상태\n노출    아프다 아프지 않다\n  먹음      8       2\n  안 먹음   2       4\n```\n\n이제 p-값은 0.116입니다. 0.05에 가까워졌지만 아직은 그 정도는 아닙니다. 오즈 비는 8로 유지됩니다.\n\n초기 표본 크기를 세 배로 증가 시킨 15개 케이스와 9개 컨트롤의 경우 어떻게 될까요?\n\n```js\n\u003e analyze_data(3)  # 15 cases and 9 controls 지정\n3배로 증가 시킨 Chi-square 테스트 결과:\nChi-square 통계량: 5.226667 , p-값: 0.03898051 \n             상태\n노출    아프다 아프지 않다\n  먹음      12       3\n  안 먹음   3       6\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n와! p-값은 0.018(반올림)로 나왔어요. 정말 놀이로 초기 샘플 크기의 네 배를 늘려보겠어요:\n\n```js\n\u003e analyze_data(4)  # 20개의 사례와 12개의 대조군을 가지고\n4 배로 증가한 데이터를 바탕으로 카이제곱 테스트의 결과:\n카이제곱 통계량: 6.968889, p-값: 0.017991\n             상태\n노출           아픔 안아픔\n  먹은 음식       16       4\n  먹지 않은 음식   4       8\n```\n\n와우! p-값이 0.05 이하에 있어서 통계적으로 유의미해졌어요. 하지만 우리의 연관성 측정 방법인 오즈비는 변하지 않았어요. 여전히 8.0으로 유지돼요. 이게 무슨 뜻일까요?\n\n## “통계적으로 유의하지 않음” 대 “연관성 없음”\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n각 예시에서 보았듯이, 음식을 먹고 아플 가능성과의 연관성은 표본 크기에 상관없이 동일했습니다. 표본 크기를 변경함으로써 우리는 p-값을 낮추고 결과를 \"통계적으로 유의미하게\" 만들었습니다. 그러나 전염병 역학자로서, 나는 감자 샐러드를 원망하기만 하지 않을 겁니다. 다른 음식들과 함께 그 음식을 테스트하러 가고, 대규모 유통업체 문제가 아닌지 집고 조사할 것입니다. 집에서 직접 만든 감자 샐러드가 아닌 경우에는 슈퍼마켓에서 제품을 회수하고 리콜 프로세스를 시작할 것입니다.\n\np-값이 유의미한 수준에 도달할 때까지 기다리지 않을 겁니다. 왜냐하면 발병은 이미 발생한 것이기 때문입니다. 초기 8명만 파티에 참석했습니다. 파티에 가지 않은 더 많은 사람들을 찾아볼 수 없습니다. 그러나 만약 지역 사회의 더 많은 사람이 상업적인 출처인 감자 샐러드를 먹은 사실을 발견한다면 이론적으로 더 많은 사람들과 함께 더 큰 연구를 할 수 있습니다.\n\n유감스럽지만, 결과가 인상적인 연구들은 통계 분석 결과가 0.05보다 높거나 비슷해서 발표되지 않는 경우가 많습니다. 이는 연구자들도 결과에 대한 방법론적 치가와 p-값의 오해 때문입니다. 모든 p-값이 하는 일은 결과의 확신 정도를 알려주는 것뿐이며 결과가 참인지 아닌지는 말해주지 않습니다.\n\n결과의 통계적 유의성만큼 중요한 많은 다른 요소들이 연구에 영향을 미칩니다. 예를 들어, 데이터를 그룹별로 분리하는 것을 잊었는지, 심슨의 역설을 유발할 가능성이 있나요?\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n참여자를 선택하는 방식에서 베크슨 편향에 빠지지는 않았는지 확인했나요?\n\n원인과 결과 사이의 관련성을 제대로 설명하는 데 있어 데이터에 혼재변수와 같은 요인이 있었나요?\n\n## 더 나쁜 p-값 조작이 있다\n\n일부 불성실한 사람들은 표본 크기를 증가시키는 것 이상으로 데이터를 조작합니다. 다른 사람들과 마찬가지로, 통계적 유의성을 관련성의 강도와 동일시하거나, 논문이 특정 범위 내의 p-값을 갖고 있을 때만 게재되도록 받아내려고 합니다. 그들은 데이터를 잘라내어 연관성이 실제로 없는 상황에서 연관성이 갑자기 나타나게 만듭니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2020년 미국 연방 선거를 교란하려고 한 사람들이 법정에서 자신들의 주장을 뒷받침하기 위해 p-해킹을 사용했었다면서요.\n\n게다가 더 심각한 것은, 출판된 논문 가운데 취소된 연구들이 많이 존재합니다 (그리고 일부는 아직도 사전 인쇄 및 블로그 글의 야생에 살아 있습니다). 이들의 저자들이 합법적인 출판을 위해 사악한 p-해킹을 사용했거나, 치료법이 작동한다고 보이기 위해 가짜 결과를 제시한 경우도 있었으며, 또는 다른 이유를 주장하기 위해 사용한 경우도 있습니다.\n\n그러므로 p-값이나 그와 관련된 95% 신뢰구간에 모든 책임을 떠밀지 말아야 합니다. 표본 크기를 확인해보세요. 제안된 내용의 생물학적 타당성을 살펴보세요. 해당 연구가 다른 곳에서 재현되었는지 확인해보세요. 그리고 표본 추출 방법이나 데이터 집계 방식에서 생기는 편향을 확인하세요.\n\n하지만, 이 글로부터 아무것도 배우지 못했다면 이것만은 꼭 기억하세요: 상온에 보관되는 식품은 따뜻하게 하고, 냉장보관할 것이거나, 보관하지 말아야 합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 분석 예제에 대한 R 코드입니다: https://gist.github.com/RFNajera/c571c7b9d21be2dbabbad085af3333eb\n\nPython 코드는 여기에서 확인할 수 있습니다: https://gist.github.com/RFNajera/3762c8bc27f2e930c74d44869717d875\n\n저 같은 선생이 마음에 드셨다면 또한 Medium의 글도 마음에 드시나요? 멤버십 가입하여 저희 작품을 지원해보는 건 어떨까요? 자세한 정보는 여기를 클릭해주세요: https://medium.com/membership\n감사합니다!\n\nRené F. Najera, MPH, DrPH는 공중보건 의사, 역학학자, 아마추어 사진작가, 러닝/사이클링/수영 애호가, 남편, 아버지이자 \"모두에게 친근한 친구\"입니다. 그는 현재 공중보건 센터의 이사로 일하거나, 지역 타코 가게에서 타코를 즐기거나, 버지니아 북부의 대학에서 지역 및 국제 보건학 부서에서 부교수로 가르치거나, 세계 최고의 공중보건 학교에서 역학학 부서에서 조교수로 일하고 있을 수 있습니다. 이 블로그 글에 담긴 모든 의견은 Dr. Najera의 의견이며, 반드시 고용주, 친구, 가족 또는 지인들의 의견을 대변하는 것은 아닙니다.","ogImage":{"url":"/TIL/assets/img/2024-07-12-P-HackingforBeginners_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-P-HackingforBeginners_0.png","tag":["Tech"],"readingTime":10},{"title":"유튜브 영상을 요약하는 서버리스 API 배포하는 방법","description":"","date":"2024-07-12 19:43","slug":"2024-07-12-HowtoDeployaServerlessAPIThatSummarizesYouTubeVideos","content":"\n\n이 게시물에서는 Google Cloud의 서버리스 클라우드 함수를 자동화하는 방법을 배울 수 있습니다.\n\n이 어플리케이션은 항상 프로토타입을 만들고 싶었던 것을 수행할 것입니다: YouTube 비디오를 요약하는 것 📹.\n\n현재 사용 가능한 강력한 LLM(Large Language Models), 확장 가능한 클라우드 아키텍처 및 효율적인 개발자 도구를 활용하여 이 아이디어를 실현하는 것이 이제 가능합니다.\n\n그래서 이 프로젝트를 구축하는 데 다룰 내용은 다음과 같습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 클라우드 함수 간단 소개\n- 로컬에서 클라우드 함수 개발 및 테스트하는 방법\n- GCP에서 인프라 설계하고 클라우드 함수 배포하는 방법\n\n마지막으로, Python 코드만 사용하여 인프라 프로비저닝 및 클라우드 함수 배포할 것입니다. GCP UI를 조작하거나 다른 구문이 필요한 인프라 코드(IaC) 도구를 사용하지 않을 것입니다.\n\n한 번 살펴보세요.\n\nML 콘텐츠, 상세한 튜토리얼 및 산업에서 실용적인 팁에 관심이 있다면, 제 뉴스레터를 팔로우하세요. The Tech Buffet이라고 합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 클라우드 함수란 무엇인가요?\n\n클라우드 함수는 구글 클라우드 서비스로, 서버나 컨테이너를 관리할 필요가 없이 클라우드에서 코드를 실행할 수 있도록 하는 서비스입니다. 그리고 확장 가능하고 비용 효율적인 방식으로 작동합니다.\n\n이것이 바로 클라우드 함수가 서버리스라고 불리는 이유입니다.\n\n클라우드 함수를 사용하면 개발자 경험이 간단합니다. 로컬에서 코드를 작성하고 테스트한 후에 해당 코드를 구글 클라우드에 전송하여 배포하고 운영 인프라를 관리할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n구름 함수의 두 번째 훌륭한 기능은 비용입니다: 사용한 만큼만 지불하게 됩니다. 구체적으로 말하면 함수의 실행 시간에 대한 비용을 청구하며, 100밀리초 단위로 측정됩니다. 그리고 함수가 유휴 상태인 경우에는 아무런 비용도 발생하지 않습니다!\n\n구름 함수는 주로 다른 시스템(예: 구름 스토리지 또는 PubSub)에서 트리거되는 단기적 이벤트 기반 작업을 처리하는 데 설계되었습니다.\n\n예를 들어, 버킷에 파일이 저장될 때나 BigQuery에 행이 삽입될 때 트리거되는 구름 함수를 만들 수 있습니다.\n\n또한 알림을 보내거나 다른 시스템을 트리거하는 데 구름 함수가 사용되는 것을 자주 볼 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 로컬에서 클라우드 함수 개발 및 테스트하기\n\n이 작은 프로젝트에서 우리가 만들 클라우드 함수는 REST API로 작동합니다. YouTube URL로 구성된 사용자 입력을 받아 요약 내용을 반환할 것입니다.\n\nGCP에 배포하기 전에 먼저 이 함수를 로컬에서 빌드하고 테스트해 봅시다.\n\nYouTube 비디오를 요약하기 위해 다음 Python 라이브러리가 필요합니다:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- youtube-transcript-api: YouTube 비디오에서 자막을 추출하는 데 사용됩니다.\n- langchain 및 langchain-openai: OpenAI 언어 모델과 상호 작용하여 요약을 생성하는 데 사용됩니다.\n- python-dotenv: OpenAI 자격 증명을 환경 변수로로드하는 데 사용됩니다.\n- functions-framework: 이식 가능한 파이썬 함수를 작성하고 로컬에서 테스트하는 FaaS (Function as a Service) 프레임워크\n\n시작하기 가장 간단한 방법은 가상 환경을 만드는 것입니다:\n\n```js\npython -m venv ./venv\nsource venv/bin/activate\npip install -r function/requirements.txt\n```\n\n그런 다음, 함수의 코드는 function/main.py 파일에 정의됩니다:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비디오를 요약할 주요 기능을 여기에 소개합니다 (더 자세한 내용은 repo에서 나머지 코드를 확인하세요):\n\n→ 먼저 비디오 대본과 제목을 추출하고 LLM을 초기화한 후, 프롬프트를 작성하여 LLM에 요약을 보냅니다.\n\n```js\ndef summarize_youtube_video(url, additional_instructions):\n    transcript = get_youtube_video_transcript(url)\n    title = get_youtube_video_title(url)\n    llm = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n    prompt = get_prompt(title, transcript, additional_instructions)\n    summary = llm.predict(prompt)\n    data = {\n        \"url\": url,\n        \"title\": title,\n        \"summary\": summary,\n        \"transcript\": transcript,\n    }\n    return data\n```\n\n이 논리를 REST API로 래핑하기 위해 functions_framework 패키지를 사용할 것입니다. 이를 통해 HTTP 요청이 전송되면 호출되는 Cloud Function 핸들러(또는 entry point)를 정의할 수 있습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\n@functions_framework.http\ndef main(request: flask.Request):\n    if request.method == \"POST\":\n        url = request.form.get(\"url\")\n        additional_instructions = request.form.get(\"instructions\")\n        data = summarize_youtube_video(url, additional_instructions)\n        return flask.jsonify(data)\n    else:\n        return \"Method Not Allowed\", 400\n```\n\n전체 클라우드 함수 코드는 여기에서 확인할 수 있습니다.\n\n클라우드 함수를 로컬에서 테스트하려면 다음 명령을 실행하세요:\n\n```bash\nfunctions-framework --target=main --source=function/main.py --debug\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n해당 명령어를 실행하면 로컬 웹 서버가 시작됩니다. 그래서 Postman을 열어 몇 가지 요청을 보내 봅시다:\n\nTerraform과 Pulumi 간의 차이점에 대해 논의하는 비디오를 보내 봅시다:\n\nURL을 입력하고 전송 버튼을 클릭하여 양식 데이터를 채우면 다음 결과를 얻을 수 있습니다: summary, title, transcript (전체 텍스트), URL.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서 요약을 자세히 살펴보겠습니다:\n\n```js\nTerraform과 Pulumi는 DevOps 세계에서 자주 비교되는 두 가지 도구입니다. Terraform은 상태를 정의하는 일관성으로 유명한 반면 Pulumi는 Python 및 C#과 같은 명령형 프로그래밍 언어를 사용하여 보다 유연한 접근 방식을 제공합니다. 그러나 이는 팀으로 작업하거나 조직을 변경할 때 잠재적인 문제를 야기할 수도 있습니다.\\n\\n반면 Terraform은 HCL (Hashicorp Configuration Language)을 사용하여 상태를 더 제한적이고 일관된 방식으로 정의합니다. 이를 통해 더 쉬운 협업과 상태 파일을 보다 안전하게 관리할 수 있습니다. 게다가 Terraform은 SaaS 제품이 아니기 때문에 상태가 자동으로 원격 네트워크로 푸시되지 않습니다. 민감한 정보를 다룰 때 이는 고려할 사항일 수 있습니다.\\n\\n총론적으로 발표자는 단순성과 일관성을 이유로 Pulumi 대신 Terraform을 강력히 선호합니다. 또한 Terraform은 지원을 제공하고 모든 질문에 답변할 수 있는 거의 2,000명의 커뮤니티를 갖고 있다고 언급합니다. 마지막으로 발표자는 시청자들에게 Terraform을 가장 간단한 형태로 사용하고 복잡한 것을 피하라고 권장합니다.\n```\n\n이 튜토리얼을 재현하면 Postman 클라이언트와 함께 놀 수 있고, 다른 비디오를 시도하고 심지어 LLM에 사용자 정의 지침을 추가할 수 있습니다.\n\n다음 예시에서 LLM에게 프랑스어로 대답하도록 요청할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드 함수가 로컬에서 테스트되었습니다.\n\n이제 배포할 준비가 되었어요 👇.\n\n# 클라우드 함수를 위한 인프라 프로비저닝\n\n몇 년 전에 클라우드 함수를 배포해 달라고 요청하면, 저는 기쁜 마음으로 GCP 콘솔에 로그인하고 소스 코드를 버킷에 넣은 다음 UI에서 클라우드 함수를 생성하고 Google Secret Manager에 비밀 정보를 추가하고 앱에 연결하고 배포 버튼을 눌렀을 거예요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 우리가 소스 코드를 변경할 때마다 이러한 단계들을 수행한다면, 이것은:\n\n- 지루할 것이다\n- 오류 발생 가능성이 높을 것이다\n- 코드베이스 안에서 추적하기 어려울 것이다\n- 협업하기 어려울 것이다\n\n## 풀루미 🚀\n\n풀루미(Pulumi)는 이미 알고 있는 프로그래밍 언어를 사용하여 어떠한 아키텍처나 클라우드 공급자에도 인프라를 구축하고 배포하는 데 도움을 주는 SDK입니다(예: Python, TypeScript, Java 등).\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPulumi를 시작하려면 다음과 같이 설치하고 구성해야 합니다:\n\n## 👉 Pulumi 다운로드 및 구성 ⚙️\n\n- Mac을 사용 중이라면 Homebrew로 Pulumi를 설치할 수 있습니다\n\n```js\nbrew install pulumi/tap/pulumi\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 다른 OS를 사용 중이라면 대안들을 확인해보세요.\n\n```js\ngcloud config set project \u003cYOUR_GCP_PROJECT_ID\u003e\n```\n\n- Pulumi는 Google Cloud 리소스와 상호 작용하기 위해 기본 애플리케이션 자격 증명을 필요로 합니다. 따라서 인증 애플리케이션 기본 로그인 명령을 실행하여 해당 자격 증명을 얻어야 합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngcloud auth application-default login\n```\n\n- Pulumi이 GCP 계정으로 구성된 후 Pulumi 프로젝트를 만들 수 있습니다.\n폴더의 루트에 Pulumi.yaml이라는 YAML 파일을 만들고 다음 라인을 붙여넣습니다:\n\n```js\nname: youtube-summarizer\nruntime:\n  name: python\n  options:\n    virtualenv: venv\nbackend:\n  url: gs://pulumi-gcp-state/main\ndescription: A minimal Google Cloud Python Pulumi program\nconfig:\n  pulumi:tags:\n    value:\n      pulumi:template: \"\"\n```\n\n이 파일은 런타임(Python)을 정의하고, virtualenv 폴더를 가리키며, Pulumi가 인프라의 상태를 저장하는 백엔드 URL을 설정합니다. Pulumi는 다른 백엔드를 사용할 수 있으며, 이 예시에서는 Google Cloud Storage를 사용합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 명령을 실행하여 올바른 매개변수로 Pulumi를 구성하세요:\n\n```js\npulumi config set gcp:region \u003cGCP-REGION\u003e\npulumi config set gcp:project \u003cGCP-PROJECT-ID\u003e\n```\n\n첫 번째 명령을 실행하면 Pulumi가 스택의 이름을 선택하라는 메시지가 표시됩니다. 이 스택은 Pulumi 프로젝트가 배포될 환경입니다.\n\n저는 방금 'dev'를 선택했어요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n구성이 완료되면 다음 내용이 포함된 Pulumi.dev.yaml 파일이 생성됩니다:\n\n```js\nencryptionsalt: v1:GJeieppLoAs=:v1:tglu/3T2fbOmQs59:ahQNXFSYgfQsvRp1J4GB4e670KOffg==\nconfig:\n  gcp:project: playground-351113\n  gcp:region: europe-west1\n```\n\n## 👉 Pulumi를 사용하여 인프라 정의하기\n\nPulumi 코드로 인프라를 작성하기 전에 앱 아키텍처를 정의한 다음 보여드릴게요. 이것을 통해 필요한 서비스를 이해할 수 있을 거예요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다수의 구성 요소가 함께 작동합니다:\n\n- 클라우드 함수의 코드를 저장하는 버킷\n- OpenAI API 키를 저장하는 시크릿 매니저\n- 귀하를 대신하여 클라우드 함수 리소스 액세스를 부여하는 서비스 계정\n- 서비스 계정이 시크릿 매니저에 액세스할 수 있도록 하는 IAM 정책\n- Cloud Run에서 Cloud 함수를 호출할 수 있게 하는 IAM 호출자 역할(Cloud Functions의 2세대는 Cloud Run에서 관리됩니다)\n\n모든 이 서비스들은 __main__.py 파일에서 명령적인 방식으로 정의될 것입니다:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 번에 하나씩 살펴봐요:\n\n- 소스 코드가 담긴 버킷:\n\n```js\nimport os\nfrom pulumi import asset, export\nimport pulumi_gcp as gcp\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n#### 버킷 생성 및 코드 업로드\n\nbucket = gcp.storage.Bucket(\"bucket\", location=\"EU\")\n\narchive = gcp.storage.BucketObject(\n    \"python-zip\",\n    name=\"python-code.zip\",\n    bucket=bucket.name,\n    source=asset.AssetArchive({\".\": asset.FileArchive(\"./function\")}),\n)\n```\n\n- 비밀값과 그 값\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n#### 비밀 생성\n\nsecret = gcp.secretmanager.Secret(\n    \"openai-api-key\",\n    replication=gcp.secretmanager.SecretReplicationArgs(\n        auto=gcp.secretmanager.SecretReplicationAutoArgs(),\n    ),\n    secret_id=\"openai-secret\",\n)\nsecret_version = gcp.secretmanager.SecretVersion(\n    \"1\",\n    secret=secret.name,\n    secret_data=os.environ.get(\"OPENAI_API_KEY\"),\n)\n```\n\n- 서비스 계정\n\n```js\n#### 서비스 계정 생성\n\nservice_account = gcp.serviceaccount.Account(\n    \"service-account\",\n    account_id=\"service-account-id\",\n    display_name=\"Summarizer Service Account\",\n)\n\nservice_account_email = service_account.email.apply(\n    lambda email: f\"serviceAccount:{email}\"\n)\n```\n\n- 서비스 계정에 대한 IAM 정책을 비밀에 액세스하도록 설정하기\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nsecret_accessor = gcp.organizations.get_iam_policy(\n    bindings=[\n        gcp.organizations.GetIAMPolicyBindingArgs(\n            role=\"roles/secretmanager.secretAccessor\",\n            members=[service_account_email],\n        )\n    ]\n)\n\nsecret_iam_policy = gcp.secretmanager.SecretIamPolicy(\n    \"my-secret-iam-policy\",\n    secret_id=secret.id,\n    project=gcp.config.project,\n    policy_data=secret_accessor.policy_data,\n)\n```\n\n- 클라우드 기능\n\n```js\n#### 클라우드 기능 생성\n\ncloud_function = gcp.cloudfunctionsv2.Function(\n    resource_name=\"cloud-function\",\n    location=\"europe-west1\",\n    build_config=gcp.cloudfunctionsv2.FunctionBuildConfigArgs(\n        entry_point=\"main\",\n        runtime=\"python39\",\n        source=gcp.cloudfunctionsv2.FunctionBuildConfigSourceArgs(\n            storage_source=gcp.cloudfunctionsv2.FunctionBuildConfigSourceStorageSourceArgs(\n                bucket=bucket.name,\n                object=archive.name,\n            )\n        ),\n    ),\n    service_config=gcp.cloudfunctionsv2.FunctionServiceConfigArgs(\n        available_memory=\"256M\",\n        ingress_settings=\"ALLOW_ALL\",\n        timeout_seconds=60,\n        service_account_email=service_account.email,\n        secret_environment_variables=[\n            gcp.cloudfunctionsv2.FunctionServiceConfigSecretEnvironmentVariableArgs(\n                key=\"OPENAI_API_KEY\",\n                version=\"1\",\n                project_id=gcp.config.project,\n                secret=\"openai-secret\",\n            )\n        ],\n    ),\n)\n```\n\n- 클라우드 런 IAM 바인딩  \n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n#### Cloud Run에 인보커 역할 추가\n\nbinding = gcp.cloudrun.IamBinding(\n    \"binding\",\n    location=cloud_function.location,\n    service=cloud_function.name,\n    role=\"roles/run.invoker\",\n    members=[\"allUsers\"],\n)\n```\n\n- Pulumi의 출력: Cloud Function 엔드포인트 URL\n\n```js\nexport(\"python_endpoint\", cloud_function.service_config.apply(lambda sc: sc.uri))\n```\n\n이 변경 사항을 배포하려면, 아래 명령어를 실행하면 됩니다:\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\r\npulumi up\r\n```\r\n\r\n업데이트를 하기 전에 Pulumi는 먼저 미리보기를 보여주고 사용자가 확인을 하면 리소스가 생성됩니다.\n\n\u003cimg src=\"/TIL/assets/img/2024-07-12-HowtoDeployaServerlessAPIThatSummarizesYouTubeVideos_1.png\" /\u003e\n\n이 엔드포인트를 Postman에서 시도함으로써 API가 작동하는지 확인할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 👉 자원 정리하기\n\n클라우드 함수 프로토타입 작업이 완료되면 스택을 파괴하고 모든 리소스를 제거할 수 있어요.\n\n```js\npulumi destroy\n```\n\n# 결론\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGCP 서비스를 백엔드로 사용하는 서버리스 애플리케이션을 Pulumi와 같은 Infrastructure-as-code (IaC) 도구로 구축할 수 있어요.\n\n이는 유연성을 제공하고 자동화를 높이며, 클라우드 리소스를 UI에서 조작할 때 발생하는 오류를 줄여줘요.\n\nPulumi는 다양한 기능을 제공하며, 다른 클라우드 서비스와 원활하게 통합돼요. 자세한 내용은 문서를 확인해보세요.\n\n다음에 또 뵐게요! 👋","ogImage":{"url":"/TIL/assets/img/2024-07-12-HowtoDeployaServerlessAPIThatSummarizesYouTubeVideos_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-HowtoDeployaServerlessAPIThatSummarizesYouTubeVideos_0.png","tag":["Tech"],"readingTime":17},{"title":"암호화폐를 이용한 파이썬 리스크 포트폴리오 관리 방법","description":"","date":"2024-07-12 19:42","slug":"2024-07-12-RiskPortfolioManagementinPythonwithCryptos","content":"\n\n디지털 자산이 전례 없는 중요성을 얻는 시대에는 강력하고 효과적인 포트폴리오 관리 전략이 이전보다 중요합니다. 이 기사는 역사적 시장 데이터를 활용하고 첨단 금융 알고리즘을 적용하여 암호화폐 포트폴리오를 최적화하는 Python 스크립트에 대해 심층적으로 다룹니다. 강력한 ccxt 라이브러리를 통합하여 늘어난 암호화폐 거래소에서 역사적 가격 데이터를 가져옵니다. 이를 통해 심층적인 분석과 전략 실행이 가능해집니다. 스크립트의 기능은 이동 평균 교차 전략을 활용하여 최적의 거래 신호를 식별하는 데 도움이 됩니다. 더불어, 위험과 수익을 효율적으로 균형잡는 볼록 최적화 기법을 사용한 포트폴리오 최적화 모듈을 포함하고 있습니다. 이 포괄적인 가이드는 시장 데이터를 획득하고 처리하는 기술적 세부 사항을 보여주는데 그치지 않고, 전략 수립부터 포트폴리오 시각화에 이르기까지의 실용적인 응용에 대한 통찰력을 제공하여 트레이더와 투자자가 암호화폐의 다이내믹한 세계에서 정보에 기반한 결정을 내릴 수 있도록 돕습니다.\n\n# 포트폴리오 리스크 관리 사용의 장점\n\n- 위험 완화: 포트폴리오 리스크 관리는 위험을 식별, 평가 및 완화하여 포트폴리오가 중요한 손실에 대해 보호받도록 돕습니다.\n- 정보기반 결정: 역사적 데이터와 시장 동향을 분석함으로써 투자자는 자산 할당을 최적화하여 보다 정보에 기반한 결정을 내릴 수 있습니다.\n- 수익 향상: 효과적인 리스크 관리를 통해 투자자는 수익을 극대화하고 동시에 위험을 최소화하는 포트폴리오를 달성할 수 있습니다.\n- 다양성: 다양성을 홍보하여 어떤 단일 자산의 불리한 움직임에 대한 영향을 줄입니다.\n- 일관성: 일관된 투자 전략을 유지하여 시장 변동성에 기반한 충동적인 결정을 피합니다.\n- 준수: 규제 요구 사항과 지침을 준수하는 데 도움을 줌으로써 법적과 윤리적 기준을 준수합니다.\n\n# 포트폴리오 리스크 관리 사용의 단점\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 복잡성: 포트폴리오 위험 관리 전략을 구현하는 것은 복잡할 수 있으며, 재무 시장과 금융 상품에 대한 심층적인 이해가 필요합니다.\n- 비용: 위험 관리 도구와 소프트웨어에는 연관된 비용이 있으며, 모든 투자자가 감당할 수 없을 수도 있습니다.\n- 시간 소모: 지속적인 모니터링과 분석이 필요하기 때문에 시간이 많이 소요되며 자원이 많이 소모될 수 있습니다.\n- 과도한 조심: 위험 관리에 과도하게 초점을 맞출 경우, 과도한 보수적인 전략으로 이어질 수 있어 수익을 제한할 수 있습니다.\n- 역사적 데이터에 의존: 위험 관리는 종종 역사적 데이터에 의존하는데, 이는 미래 시장 상황을 정확하게 예측하지 못할 수 있습니다.\n\n# 포트폴리오 위험 관리의 장점\n\n- 안정성 향상: 위험을 효과적으로 관리함으로써 포트폴리오는 더 큰 안정성을 달성할 수 있어 극단적인 손실 가능성을 줄일 수 있습니다.\n- 자본 할당 개선: 더 나은 자본 할당이 가능하며, 자원이 가장 유망한 자산에 투자되도록 보장합니다.\n- 투자자 신뢰 증대: 투자자들이 위험 감소에 초점을 두고 투자를 관리하고 있다는 사실에 대한 신뢰감을 높여줍니다.\n- 전략적 유연성: 전략적 유연성을 제공하여 시장 변화에 따라 전략을 조정할 수 있도록 허용합니다.\n- 성과 모니터링 향상: 지속적인 성과 모니터링을 가능하게 하여 투자자가 필요에 따라 전략을 추적하고 조정할 수 있도록 도와줍니다.\n\n# 포트폴리오 위험 관리의 단점\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 자원 소모가 많음: 효율적으로 구현하고 유지하기 위해서는 상당한 시간, 자금 및 전문지식이 필요합니다.\n- 과도한 최적화 가능성: 리스크를 최소화하는 데 초점을 맞추다 보면 높은 수익 기회가 놓칠 수 있는 과도한 최적화의 위험이 있습니다.\n- 데이터 의존성: 정확하고 최신 데이터에 대한 높은 의존성으로 인해 획득과 유지가 어려울 수 있습니다.\n- 시장의 예측 불가능성: 견고한 리스크 관리 실천에도 불구하고 시장은 예측할 수 없으며 예기치 못한 사건이 포트폴리오에 여전히 영향을 줄 수 있습니다.\n- 소규모 투자자에 대한 적용 범위가 제한적: 복잡성과 비용 제한으로 인해 고급 리스크 관리의 혜택이 소규모 투자자에게 덜 접근하기 어려울 수 있습니다.\n\n![이미지](/TIL/assets/img/2024-07-12-RiskPortfolioManagementinPythonwithCryptos_0.png)\n\n```js\n바이낸스에서의 역사적 데이터 획득 중...\n\n최적화 결과:\nBTC/USDT: 1.0\nETH/USDT: -5.538816095795286e-23\n\n예상 포트폴리오 수익률: 0.0017\n최소 포트폴리오 분산: 0.0195\n```\n\n![이미지](/TIL/assets/img/2024-07-12-RiskPortfolioManagementinPythonwithCryptos_1.png)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n# 필요한 라이브러리 가져오기\nimport ccxt\nimport pandas as pd\nimport numpy as np\nimport cvxpy as cp\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n# ccxt에서 기록 데이터 가져오는 함수\ndef get_ccxt_data(exchange_name, symbols, timeframe, since):\n    exchange = getattr(ccxt, exchange_name)()\n    data = {}\n\n    for symbol in symbols:\n        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=since)\n        \n        if ohlcv:\n            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n            df['time'] = pd.to_datetime(df['timestamp'], unit='ms')\n            df.set_index('time', inplace=True)\n            df.drop(['timestamp', 'open', 'high', 'low', 'volume'], axis=1, inplace=True)\n            \n            # 일일 수익률 계산\n            df['return'] = df['close'].pct_change().fillna(0)\n            \n            # 데이터 사전에 저장\n            data[symbol] = df\n    \n    return data\n\n# 이동평균 교차 전략 적용하는 함수\ndef apply_sma_strategy(data, short_window=12, long_window=26):\n    for symbol, df in data.items():\n        df['SMA_50'] = df['close'].rolling(window=short_window).mean()\n        df['SMA_200'] = df['close'].rolling(window=long_window).mean()\n        df['signal'] = 0\n        df.loc[df.index[short_window:], 'signal'] = np.where(\n            df.loc[df.index[short_window:], 'SMA_50'] \u003e df.loc[df.index[short_window:], 'SMA_200'], 1, 0\n        )\n        df['position'] = df['signal'].shift(1).fillna(0)\n    return data\n\n# 전략에 따라 수익 조정하는 함수\ndef adjust_returns(data):\n    for symbol, df in data.items():\n        df['adjusted_return'] = df['return'] * df['position']\n    return data\n\n# 포트폴리오 최적화하는 함수\ndef optimize_portfolio(data):\n    symbols = list(data.keys())\n    n_assets = len(symbols)\n    \n    # 모든 자산 중 가장 작은 데이터 길이 찾기\n    min_length = min(len(data[symbol]) for symbol in symbols)\n    \n    # 수익 조정하고 정규화하기\n    returns = np.zeros((min_length, n_assets))\n    for i, symbol in enumerate(symbols):\n        # 데이터 길이 조정\n        df = data[symbol].iloc[:min_length]\n        returns[:, i] = df['adjusted_return'].values\n    \n    # 공분산 행렬과 기대수익률 계산\n    cov_matrix = np.cov(returns, rowvar=False)\n    expected_returns = np.mean(returns, axis=0)\n    \n    # 최적화 변수\n    weights = cp.Variable(n_assets)\n    risk = cp.quad_form(weights, cov_matrix)\n    objective = cp.Maximize(expected_returns @ weights - 0.5 * risk)\n    \n    # 제약 조건\n    constraints = [cp.sum(weights) == 1, weights \u003e= 0]\n    \n    # 최적화 문제 해결\n    prob = cp.Problem(objective, constraints)\n    prob.solve()\n    \n    # 최적화 결과 표시\n    print(\"\\n최적화 결과:\")\n    for i, symbol in enumerate(symbols):\n        print(f\"{symbol}: {weights.value[i]}\")\n    \n    # 포트폴리오의 최소 분산과 기대수익률 계산\n    min_variance = cp.sqrt(cp.quad_form(weights.value, cov_matrix)).value\n    expected_return_portfolio = expected_returns @ weights.value\n    \n    print(f\"\\n예상 포트폴리오 수익률: {expected_return_portfolio:.4f}\")\n    print(f\"최소 포트폴리오 분산: {min_variance:.4f}\")\n    \n    return symbols, weights.value\n\n# 결과 시각화하는 함수\ndef visualize_results(symbols, weights):\n    # 포트폴리오의 각 자산 가중치 그래프로 표시\n    plt.figure(figsize=(10, 6))\n    plt.bar(symbols, weights, color='blue')\n    plt.xlabel('자산')\n    plt.ylabel('가중치')\n    plt.title('최적화된 포트폴리오 내 자산 가중치')\n    plt.show()\n\n# 메인 스크립트 실행\nif __name__ == \"__main__\":\n    # 매개변수 정의\n    exchange_name = 'binance'  # 거래소 이름\n    symbols = [\"BTC/USDT\", \"ETH/USDT\"]  # 자산 심볼\n    timeframe = '1d'  # 시간프레임 (1일)\n    since = ccxt.binance().parse8601('2023-01-01T00:00:00Z')  # 시작 날짜\n    \n    # ccxt에서 기록 데이터 가져오기\n    print(f\"{exchange_name}에서 기록 데이터 가져오는 중...\")\n    data = get_ccxt_data(exchange_name, symbols, timeframe, since)\n    \n    if data:\n        # 이동평균 교차 전략 적용\n        data = apply_sma_strategy(data)\n        \n        # 전략에 따라 수익 조정\n        data = adjust_returns(data)\n        \n        # 포트폴리오 최적화\n        symbols, weights = optimize_portfolio(data)\n        \n        # 결과 시각화\n        visualize_results(symbols, weights)\n","ogImage":{"url":"/TIL/assets/img/2024-07-12-RiskPortfolioManagementinPythonwithCryptos_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-RiskPortfolioManagementinPythonwithCryptos_0.png","tag":["Tech"],"readingTime":8},{"title":"TimeGPT vs TiDE 제로샷 추론이 예측의 미래인가, 단순한 과대광고인가","description":"","date":"2024-07-12 19:39","slug":"2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype","content":"\n\n이 게시물은 Rafael Guedes와 공저한 것입니다.\n\n# 소개\n\n예측은 학술 연구 및 산업 응용 분야에서 인공지능(AI)의 핵심 영역 중 하나입니다. 실제로, 이는 모든 산업에 걸쳐 찾아볼 수 있는 가장 보편적인 도전 중 하나일 것입니다. 미래 매출량 및 시장 동향을 정확하게 예측하는 것은 기업이 계획 프로세스를 최적화하기 위해 꼭 필요합니다. 이는 이윤 기여를 향상시키고 낭비를 최소화하며 충분한 재고 수준을 보장하고 공급망 최적화 및 전체 의사 결정을 개선하는 것을 포함합니다.\n\n예측 모델을 개발하는 것은 복잡하고 다면적인 도전입니다. 이는 최첨단(STATE-OF-THE-ART, SOTA) 예측 방법론과 적용 대상인 특정 비즈니스 분야에 대한 깊은 이해를 요구합니다. 또한, 예측 엔진은 기관 내에서 폭넓은 프로세스를 지원하는 중요한 인프라 역할을 할 것입니다. 예를 들어:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 마케팅 팀은 모델을 활용하여 다가오는 기간에 대한 투자 할당에 관한 전략적 의사 결정을 진행합니다. 예를 들어, 다음 달이나 분기에 대한 투자 배정에 대한 결정을 내립니다.\n- 구매 팀은 공급 업체로부터의 매입 수량과 타이밍에 관한 정보에 기초하여 재고 수준을 최적화하고 낭비나 부족을 줄이기 위해 모델을 활용합니다.\n- 운영 팀은 예측을 활용하여 생산 라인을 최적화합니다. 예상 수요를 충족시키기 위해 자원과 인력을 효율적으로 투입하면서 운영 비용을 최소화합니다.\n- 재무 팀은 예산 및 리소스 할당을 위해 모델을 신뢰합니다. 예측 데이터를 활용하여 월별 금융 요구 사항을 예측하고 그에 맞게 자원을 할당합니다.\n- 고객 서비스 팀은 예측을 활용하여 고객 조회량을 예상하며, 고품질의 고객 서비스를 유지하고 대기 시간을 최소화하면서 적정 직원 수를 조정할 수 있습니다.\n\n최근 예측 분야의 발전은 텍스트 (예: ChatGPT), 텍스트-이미지 (예: Midjourney) 및 텍스트-음성 (예: Eleven Labs) 등 여러 도메인에서 기초 모델의 성공적인 개발에 의해 형성되었습니다. 이러한 모델들의 널리 퍼짐으로 인해 이전에 본적이 없던 데이터에 대한 예측을 생성하도록 설계된 TimeGPT [1]와 같은 모델들이 등장했습니다. 이러한 모델들은 텍스트, 이미지 및 음성 분야의 선례를 따르는 방법론과 아키텍처를 활용합니다. 일반적인 사전 훈련된 모델은 예측 작업에 대해 패러다임 변화를 가져올 것입니다. 조직에게 더 접근 가능하게 만들어줄 뿐만 아니라, 계산 복잡성을 줄이고 전반적으로 더 정확하게 만들 것입니다.\n\n이 글에서는 TimeGPT의 가능한 아키텍처에 대해 깊이 있는 설명을 제공합니다. 또한 모델이 제로샷 추론을 수행할 수 있도록 하는 주요 구성 요소를 다룹니다. 이론적 개요를 따라 특정 사용 사례와 데이터셋에 TimeGPT를 적용합니다. 구체적인 구현 세부사항을 다루고 모델 성능을 철저히 분석합니다. 마지막으로 TimeGPT와 TiDE [2]의 성능을 비교하여, 간단한 MLP인 TiDE가 예측 사용 사례에서 Transformer를 이기는 것을 보여줍니다.\n\n![](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_0.png)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n항상 코드는 저희의 GitHub에서 확인하실 수 있어요.\n\n# TimeGPT\n\nTimeGPT [1]는 시계열 예측을 위한 최초의 기초 모델로, 다양한 도메인을 범위로 일반화할 수 있는 능력으로 특징화되어 있어요. 훈련 단계에서 사용된 데이터 이외의 데이터셋에서도 정확한 예측을 할 수 있어요. 시계열 예측을 위한 기초 모델에 대한 연구 분야는 최근에 크게 성장하고 있어요. 카네기 멜론 대학교(CMU)의 연구자들이 개발한 \"MOMENT\"[3], Google의 \"TimesFM\"[4], Morgan Stanley와 ServiceNow의 공동 연구인 \"Lag-Llama\"[5], 그리고 Salesforce의 \"Moirai\"[6]와 같은 주목할 만한 최근 작업이 있어요. 앞으로 다른 시계열 예측을 위한 기초 모델들에 대해서도 다룰 계획이에요.\n\nTimeGPT는 제로샷 추론 설정에서 우수한 성능을 발휘하기 위해 전이 학습을 활용하고 있어요. 경제, 인구 통계, 의료, 날씨, IoT 센서 데이터, 에너지, 웹 트래픽, 판매, 운송 및 은행 업무 등 다양한 도메인의 대중적으로 제공되는 데이터셋에서 1000억 개의 데이터 포인트를 사용해 훈련되었어요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다양한 도메인의 폭넓은 다양성 덕분에 이 모델은 여러 계절성, 다양한 길이의 주기, 그리고 변화하는 추세와 같은 복잡한 패턴을 잡을 수 있어요. 게다가 데이터셋은 다양한 노이즈 수준, 이상값, 드리프트, 그리고 기타 다양한 특징을 보여줘요. 일부는 규칙적인 패턴이 있는 깨끗한 데이터로 이루어져 있고, 다른 일부는 시간이 흐름에 따라 추세와 패턴이 변동될 수 있는 예상치 못한 사건과 행동을 포함하고 있어요. 이러한 도전들은 모델이 배울 수 있는 많은 시나리오를 제공하여 모델의 견고성과 일반화 능력을 향상시켜요.\n\n![이미지](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_1.png)\n\n## 아키텍처\n\nTimeGPT는 시계열 예측을 위해 특별히 설계된 Transformer 기반 모델로, 인코더-디코더 아키텍처 내부에 self-attention 메커니즘을 통합하고 있어요. self-attention 메커니즘을 활용하여 시계열 내에서 서로 다른 지점의 중요성을 동적으로 가중할 수 있어요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델은 입력으로 과거 값(y)과 외생 공변럇(x)의 창을 받습니다. 공변럇에는 추가 시계열 데이터 및/또는 특정 이벤트를 나타내는 이진 변수가 포함될 수 있습니다. 이러한 입력은 지역 위치 임베딩을 통해 순차 정보로 보강됩니다. 이를 통해 모델은 시간 의존성을 인식할 수 있습니다. 저자들이 명시적으로 언급하지는 않았지만, 모든 입력이 위치 인코딩 후 연결된다고 가정하며, 이는 인코더에 공급되는 최종 입력을 생성합니다.\n\n![image](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_2.png)\n\n위치 인코딩은 또한 저자들에 의해 정의되지 않았습니다. 우리는 이들이 기초 변환자 아키텍처 논문의 삼각 함수를 사용한다고 가정합니다. 이러한 함수는 다양한 주파수로 특징 지어지지만 입력 데이터와 동일한 차원을 유지합니다.\n\n![image](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_3.png)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위치 인코딩과 함께 보강된 입력 벡터는 인코더에 소개됩니다. 인코더 내에서 다중 헤드 어텐션 레이어는 입력 시퀀스 내의 다양한 요소에 가중치를 평가하고 할당하여 그들의 상대적 중요성을 반영합니다. 이 representatino은 이후 완전 연결된 피드 포워드 네트워크에 의해 처리됩니다. 이것은 시퀀스 내 요소들 간의 더 복잡한 관계를 포착하는 representatino을 생성하는 것을 가능하게 합니다. 그런 다음 출력은 아키텍처의 디코더 부분으로 전달됩니다.\n\n![이미지](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_4.png)\n\n인코더의 출력을 처리하는 것 외에도 디코더는 자기 회귀적인 프로세스에서 작동합니다. 이전에 생성된 출력을 통합하여 다음 시간 단계(i+1)의 예측을 생성하기 전에 작동합니다. 이것은 인코더에 의해 생성된 숨겨진 상태들과 이전에 생성된 출력 간의 복잡한 관계를 포착하기 위해 주의 메커니즘을 활용합니다. 이 접근 방식은 디코더가 인코더의 representatino에 포착된 문맥적 및 순차적 정보를 자체 반복적인 예측과 함께 효과적으로 종합할 수 있도록 합니다.\n\n![이미지](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_5.png)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막으로, 선형 레이어는 디코더의 출력을 예측 지향의 길이와 동일한 값 벡터로 매핑하는 역할을 합니다.\n\n![이미지](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_6.png)\n\nTimeGPT는 잠재적 결과물의 확률 분포를 생성할 수 있습니다. 다시 말해, 예측 간격의 추정입니다. 저자들은 기존 오류를 기반으로 하는 조화 예측을 사용하여 예측 간격을 추정했습니다. 전통적인 방법과 달리, 조화 예측은 분포 가정이 필요하지 않으며 다음과 같은 방법으로 수행할 수 있습니다:\n\n- M개의 교육 및 보정 세트 생성;\n- 각 보정 세트를 모델로 예측;\n- 각 예측 시점 h에 대해 모델의 예측 값과 보정 세트 내 실제 결과 간의 절대 잔차 값이 계산됩니다. 이러한 계산된 잔차는 비준수 점수라고 불립니다.\n- 각 예측 시점 h의 비준수 점수의 분포에서 특정 백분위수를 선택합니다. 선택한 백분위수는 예측 간격의 커버리지 수준을 결정하며, 더 높은 백분위수는 더 넓은 간격을 의미합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예측 간격은 예측 값 ± 최종 비준수 점수로 제공됩니다.\n\n![이미지](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_7.png) \n\n# TimeGPT 대 TiDE: 실제 사용 사례에서의 비교\n\n이 섹션에서는 고객 중 한 명의 실제 데이터셋을 사용하여 시간 GPT를 사용하여 매출을 예측하겠습니다. 이후 동일한 분석을 위해 TiDE와 TimeGPT의 예측 성능을 비교합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nTiDE [2]은 새로운 다변량 시계열 모델로, 정적 공변럇수(예: 제품 브랜드) 및 예측 기간 동안(예: 제품 가격) 알려진 또는 알려지지 않은 동적 공변럇수를 사용하여 정확한 예측을 생성할 수 있습니다. 복잡한 Transformer 아키텍처와는 달리, TiDE는 간단한 인코더-디코더 아키텍처와 잔차 연결을 기반으로 합니다:\n\n- 인코더는 과거 타겟 값 및 시계열의 공변럇수를 특성의 밀집 표현으로 매핑하는 역할을 합니다. 먼저 특성 프로젝션을 통해 동적 공변럇수의 차원을 줄입니다. 그런 다음, 밀집 인코더는 특성 프로젝션의 출력과 정적 공변럇수 및 과거 값이 연결된 것을 받아 하나의 임베딩 표현으로 매핑합니다.\n- 디코더는 임베딩 표현을 받아 미래 예측으로 변환합니다. 밀집 디코더는 임베딩 표현을 시간당 하나의 벡터로 매핑합니다. 그 후, 시계열 디코더는 밀집 디코더의 출력을 해당 시간 단계의 특성 프로젝션과 결합하여 예측을 생성합니다.\n- 마지막으로, 잔차 연결은 과거 값을 예측 기간 크기의 벡터로 선형 매핑하여 이를 시간적 디코더의 출력에 추가하여 최종 예측을 생성합니다.\n\n![이미지](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_8.png)\n\n데이터셋에는 미국 시장을 위한 주간 매출 데이터를 상세히 설명하는 195가지 고유한 시계열이 포함되어 있습니다. 역사적인 매출 데이터 외에도, 데이터셋에는 미국 법정 공휴일 및 이진 계절 특성 정보도 있습니다. 우리는 이 데이터셋을 보강하기 위해 이벤트 주(week)와 달(month) 식별자를 사용했습니다. 예측 기간은 16주로, 즉 미래 16주를 예측하고자 합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n친구야, 아래와 같이 라이브러리를 가져오는 것으로 시작해요:\n\n```js\nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport utils\n\nfrom nixtlats import TimeGPT\nfrom nixtlats.date_features import CountryHolidays\nfrom dotenv import load_dotenv\nfrom sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n\nload_dotenv()\n```\n\n다음으로, TimeGPT 클래스를 초기화해요. TimeGPT 토큰을 제공하여 시작해요. Nixtla 웹사이트에서 요청하실 수 있어요.\n\n```js\ntimegpt = TimeGPT(token=os.environ.get(\"TIMEGPT_KEY\"))\ntimegpt.validate_token()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터셋을 로드하기 전에 인증 토큰을 확인한 후 다음을 확인해 주세요:\n\n- 대상 변수는 숫자이어야 하며 결측값이 없어야 합니다.\n- 시작일부터 종료일까지의 날짜 순서에 빈 공간이 없는지 확인하세요.\n- 날짜 열은 Pandas에서 인식할 수 있는 형식이어야 합니다.\n- 문서에 따르면 데이터 정규화는 내부에서 처리되므로 해당 단계를 건너뛰어도 됩니다.\n- 여러 시계열을 예측하는 경우 각 시리즈를 고유하게 식별할 수 있는 열을 포함해야 하며, 이는 예측 함수에서 인수로 사용됩니다.\n- 외생적 특성이 필요한 경우 예측 기간을 위한 별도의 데이터셋이 필요합니다.\n\n```python\n# 데이터 프레임 읽고 날짜를 datetime으로 파싱\ndf = pd.read_csv('data/data.csv', parse_dates=['delivery_week'])\n```\n\n토론한 바와 같이 데이터셋을 보강하기 위해 주간과 월간의 이진 계절성 특성을 추가합니다:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# df에 주차(week)와 달(month)을 추가합니다.\ndf['week'] = df['delivery_week'].dt.isocalendar().week\ndf['month'] = df['delivery_week'].dt.month\n\n# 주차(week)와 달(month)을 원핫인코딩합니다.\ndf = pd.get_dummies(df, columns=['week', 'month'], dtype=int)\n```\n\n이제 TimeGPT가 예측에 사용할 데이터셋을 만들 준비가 되었습니다. 추가로, 예측 기간 내의 실제 매출 데이터와 해당 기간에 대한 외생 변수 특성을 포함하는 홀드아웃(holdout) 세트를 만들 것입니다.\n\n```js\n# 데이터 프레임을 자릅니다.\nforecast_df = df[df['delivery_week'] \u003c \"2023-10-16\"]\n\n# 홀드아웃(holdout) 세트를 위해 실제 매출 데이터 중 마지막 x 주를 사용합니다.\nholdout_df = df[(df['delivery_week'] \u003e= \"2023-10-16\") \u0026 (df['delivery_week'] \u003c= \"2024-02-05\")]\n```\n\n데이터를 분리한 후, 훈련 및 홀드아웃 데이터셋을 forecast() 함수로 넘겨 예측할 수 있습니다. 다음 매개변수를 설정해야합니다:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- df - 과거 데이터가 포함된 데이터 프레임입니다.\n- time_col - 시간 정보가 들어 있는 열입니다.\n- target_col - 과거 데이터가 들어 있는 열입니다.\n- X_df - 예측 기간을 위한 외생특징이 포함된 데이터 프레임입니다.\n- date_features - 미국의 공휴일과 같은 새로운 외생 특징의 지정을 허용합니다.\n- h - 예측 기간을 정의합니다.\n- level - 예측 간격 (80% 신뢰 구간)입니다.\n- freq - 데이터의 주기입니다. 우리의 경우 매주 월요일마다 발생합니다.\n- id_col - 다변량 시나리오에서 각 시계열을 식별하는 열입니다.\n- model - TimeGPT에는 단기용과 장기용으로 두 가지 모델이 있습니다. 예측 기간에 계절 주기가 하나 이상인 경우 장기용을 사용해야 합니다.\n- add_history - 과거 데이터의 적합 값이 반환됩니다.\n\n```js\n# 계절적 외부 요인이 포함된 목록 생성\nEXOGENOUS_FAETURES = [x for x in df.columns if ('week_' in x) | ('month_' in x)]\n\ntimegpt_fcst_ex_vars_df = timegpt.forecast(\n    df=forecast_df[['unique_id', 'delivery_week', 'target', 'marketing_events_1', 'marketing_events_2']+EXOGENOUS_FAETURES],\n    time_col='delivery_week',\n    target_col='target',\n    X_df=holdout_df[['unique_id', 'delivery_week', 'marketing_events_1', 'marketing_events_2']+EXOGENOUS_FAETURES],\n    date_features=[CountryHolidays(['US'])],\n    h=17,\n    level=[80],\n    freq='W-MON',\n    id_col='unique_id',\n    model='timegpt-1',\n    add_history=True,\n    )\n```\n\n예측은 몇 분 안에 실행됩니다. 그런 다음, 과거 데이터에 대한 적합 값과 예측 값을 포함하는 데이터 프레임이 반환됩니다. 또한 예측에서 외생 교란 변수의 중요성도 반환됩니다.\n\n```js\ntimegpt.weights_x.head(10).sort_values(by='weights').plot.barh(x='features', y='weights')\nplt.title('특징 중요도 - 상위 10개')\nplt.show()\n```  \n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 경우에 가장 중요한 10가지 공변럇값을 추출했는데, 그 중에서 마케팅 이벤트가 가장 중요함을 나타냅니다. 반대로, 계절별 및 휴일 공변랇값은 잔여적인 중요성을 가지고 있습니다.\n\n![이미지](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_9.png)\n\nadd_history=True로 설정했기 때문에 적합값과 예측을 플롯할 수 있습니다. 홀드아웃 세트에서 볼륨이 가장 높은 6개의 시리즈를 선택했습니다. 이들은 비즈니스에 더 관련이 있고 더 안정적인 패턴으로 예측하기가 더 쉬울 것입니다.\n\n```js\n# 볼륨에 따라 정렬된 시리즈 가져오기 \nseries = holdout_df.groupby('unique_id')['target'].sum().reset_index().sort_values(by='target', ascending=False)['unique_id'].tolist()\n\ntimegpt.plot(\n    forecast_df[['unique_id', 'delivery_week', 'target']], \n    timegpt_fcst_ex_vars_df,\n    time_col='delivery_week',\n    target_col='target',\n    unique_ids=series[:6],\n    level=[80], \n)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![Figure 10](/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_10.png)\n\nFigure 10을 보면 적합 값이 실제 값과 잘 일치하지만 예측은 일관성이 없습니다. 하나의 경우를 제외하고 대부분의 시계열에서 균일한 패턴을 보여줍니다 (우측 상단에서 확인할 수 있습니다). 또한, 모든 예측에는 우리가 기대하지 않았던 연이은 예상치 이상의 증가가 있습니다.\n\nTimeGPT에서 예측을 얻은 후 TiDE에서 생성된 예측을 로드하고 비교를 위해 예측 성능 지표를 계산할 수 있습니다. 비교 메트릭으로 실제 판매량을 유지하기 위해 평균 절대 백분율 오차(MAPE)를 사용했습니다.\n\n```javascript\n# TiDE와 TimeGPT에서 예측 로드\ntide_model_df = pd.read_csv('data/tide.csv', parse_dates=['delivery_week'])\ntimegpt_fcst_ex_vars_df = pd.read_csv('data/timegpt.csv', parse_dates=['delivery_week'])\n\n# TiDE 예측 및 실제 값을 병합하는 데이터 프레임\nmodel_eval_df = pd.merge(holdout_df[['unique_id', 'delivery_week', 'target']], tide_model_df[['unique_id', 'delivery_week', 'forecast']], on=['unique_id', 'delivery_week'], how='inner')\n\n# TimeGPT 예측 및 실제 값을 병합하는 데이터 프레임\nmodel_eval_df = pd.merge(model_eval_df, timegpt_fcst_ex_vars_df[['unique_id', 'delivery_week', 'TimeGPT']], on=['unique_id', 'delivery_week'], how='inner')\n\nutils.plot_model_comparison(model_eval_df)\n```  \n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 Figure 11에 표시된 것과 같습니다. TiDE는 16주 중 15주에 대해 195개의 시계열을 비교할 때 TimeGPT에 비해 평균 MAPE가 낮습니다. 두 모델 모두 동일한 정보에 액세스할 수 있지만, TimeGPT의 제로-숏 추론은 저희가 세밀하게 조정한 모델을 이기지 못했습니다.\n\n# 결론\n\n오늘날의 경쟁적인 환경에서 예측의 중요성은 과대평가될 수 없습니다. 효과적인 예측 방법은 운영 우수성을 추구하는 조직에게 중요하며, 이를 통해 운영을 더 효율적으로 계획하고 관리할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 시계열 예측의 최신 혁신 중 하나 인 foundation models의 발전을 탐구했습니다. 이러한 모델은 전문 지식이 부족한 기관들이 내부에서 SOTA 모델을 개발하는 데 필요한 특수 지식을 갖추지 못한 경우에도 정교한 알고리즘에 대한 접근을 민주화하기 위해 노력하고 있습니다. 이러한 노력은 유망해 보이지만, 우리의 분석에서는 여전히 정확한 예측을 제공하는 데 실패하는 것으로 나타났습니다. 구체적으로, TiDE가 zero-shot 추론 시나리오에서 TimeGPT를 크게 능가했습니다.\n\n그럼에도 불구하고, AI 기업들이 예측의 경계를 넓히기 위해 노력하는 것을 보는 것은 격려되는 일입니다. 컴퓨터 비전 및 NLP와 같은 다른 도메인이 더 많은 관심을 받고 있지만, 기관들에게 있어서 예측의 중요성을 간과해서는 안 됩니다.\n\n# 나에 대해\n\nAI 분야의 시리얼 창업가이자 리더. 기업을 위한 AI 제품을 개발하고 AI 중심 스타트업에 투자합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n창업자 @ ZAAI | LinkedIn | X/Twitter\n\n# 참고 자료\n\n[1] Garza, A., \u0026 Mergenthaler-Canseco, M. (2023). TimeGPT-1. arXiv:2310.03589에서 검색됨.\n\n[2] Abhimanyu Das, Weihao Kong, Andrew Leach, Shaan Mathur, Rajat Sen, Rose Yu. (2023) TiDE를 활용한 장기 예측: Time-series Dense Encoder. arXiv:2304.08424.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[3] 고스와미, M., 살페르, K., 쵸우드리, A., 카이, Y., 리, S., \u0026 더브라우스키, A. (2024). MOMENT: 개방형 시계열 기반 모델 패밀리. arXiv:2402.03885 (cs.LG)에서 가져옴.\n\n[4] 다스, A., 콩, W., 센, R., \u0026 조우, Y. (2024). 시계열 예측을 위한 디코더 전용 기반 모델. arXiv:2310.10688 (cs.CL)에서 가져옴.\n\n[5] 라술, K., 아쇼크, A., 윌리엄스, A. R., 고니아, H., 바그와트카르, R., 코라사니, A., 다르비시 바이아지, M. J., 아다모푸로스, G., 리아치, R., 하센, N., 비로스, M., 가르그, S., 슈나이더, A., 채파도스, N., 드루앵, A., 잔테데케시, V., 네우미바카, Y., \u0026 리시, I. (2024). Lag-Llama: 확률적 시계열 예측을 위한 기반 모델로. arXiv:2310.08278 (cs.LG)에서 가져옴.\n\n[6] 우, G., 리우, C., 쿠마르, A., 씨옹, C., 사바레세, S., \u0026 사후, D. (2024). 통합된 유니버설 시계열 예측 트랜스포머의 훈련. arXiv:2402.02592 (cs.LG)에서 가져옴.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[7] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., \u0026 Polosukhin, I. (2017). Attention Is All You Need. arXiv:1706.03762에서 가져옴.\n\n[8] Stankeviciute, K., Alaa, A. M., \u0026 van der Schaar, M. (2021). Conformal time-series forecasting. Advances in Neural Information Processing Systems (Vol. 34, pp. 6216–6228)에 소개됨.","ogImage":{"url":"/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-TimeGPTvsTiDEIsZero-ShotInferencetheFutureofForecastingorJustHype_0.png","tag":["Tech"],"readingTime":19},{"title":"새로운 R 및 Python IDE, Posit Positron 시작하기 사용법 가이드","description":"","date":"2024-07-12 19:38","slug":"2024-07-12-GettingStartedWithPositPositronthenewIDEforRandPython","content":"\n\n\n![image](/TIL/assets/img/2024-07-12-GettingStartedWithPositPositronthenewIDEforRandPython_0.png)\n\nPositron sounds like the latest Autobot to join Optimus Prime in the Transformer movies (and toys — can’t forget those!!). Instead, it is a new IDE meant to transform programming and data science workflows if its creator Posit has its way.\n\nPositron is an IDE, launched as a surprise Beta product by Posit. The new IDE is designed to allow data scientists to better explore data in both R and Python programs.\n\n## Some Background on Posit\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n포지트의 이름 선택은 흥미로운 역사를 갖고 있어요. 포지트는 주요 제품으로 인해 먼저 RStudio로 알려진 소프트웨어 개발 회사입니다. RStudio는 주로 R 프로그래머들 사이에서 매우 인기 있는 통합 개발 환경(IDE)로, 스크립트, 라이브러리, 시각화 및 생성된 데이터 개체를 표시하는 분할 창 레이아웃으로 유명해졌어요.\n\nRStudio는 reticulate를 실행할 수 있는 기능을 통합하여 Python을 R에서 실행할 수 있게 했어요. 그리고 최신화된 마크다운 스위트인 Quarto가 기능을 더욱 향상시켰어요. 결과적으로, RStudio는 상당한 규모의 Python 개발자들을 끌게 되었어요.\n\n# 시작하기\n\n포지트론을 시작하려면 GitHub 저장소의 릴리스 페이지를 통해 IDE를 다운로드해야 해요. 현재 베타 버전은 Windows 및 맥 OS에서 사용할 수 있어요. 물론, 페이지에서는 요구 사항을 설명하고 있어요 — 포지트가 더 많은 베타 버전을 출시할수록 IDE의 몇 가지 반복 버전을 볼 수 있을 거예요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nR 및 Python 언어는 일반 절차에 따라 설치되어야 합니다. 사용자는 R 버전 4.2 이상과 Python 3.8 이상을 갖추고 있어야 합니다.\n\nPython 사용자는 또한 Python을 실행하기 위한 IPykernel 패키지를 포함해야 합니다. 여기서 다운로드하는 방법을 배울 수 있습니다. 통상 Python 프로토콜을 사용하여 호출할 수 있습니다.\n\n설치된 경우 Positron은 언어 파일을 인식하여 기본 Python 및 R을 위한 패키지 및 라이브러리 설치에 시달리지 않고 시작할 수 있도록 합니다.\n\nPython 환경 설정이 다른 경우 드롭다운 메뉴도 있습니다. IDE 오른쪽 상단에 나타납니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 마크다운 형식으로 컨버팅 된 표입니다.\n\n\n| Tag        | Description                                                                             |\n|------------|-----------------------------------------------------------------------------------------|\n| img        | `\u003cimg\u003e` 태그는 이미지를 삽입할 때 사용합니다.                                                  |\n| div        | `\u003cdiv\u003e` 태그는 문서의 섹션을 나타내거나 스타일을 지정하기 위해 사용됩니다.                             |\n| p          | `\u003cp\u003e` 태그는 단락을 나타내며 텍스트를 그룹화할 때 사용됩니다.                                        |\n| a          | `\u003ca\u003e` 태그는 하이퍼링크를 생성할 때 사용되며 클릭 가능한 링크를 만듭니다.                          |\n| table      | `\u003ctable\u003e` 태그는 표를 만들기 위해 사용되며 여러 행과 열을 가질 수 있습니다.                           |\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPosit가 Positron을 개발할 때 Visual Studio 코드에 사용된 OSS(오픈 소스 소프트웨어) 아키텍처를 사용했어요. 그런 다음 Positron에는 RStudio와 유사한 데이터 탐색을 위한 목적의 독특한 기능들이 추가되었어요.\n\nRStudio 설정과 유사한 영역에 전용 패널이 있는 플로팅이 가능합니다. 또한 Shiny 앱을 표시하는 데도 작동하며, 사용자는 환경 내에서 R 기반 및 Python 기반 Shiny 앱을 모두 볼 수 있습니다.\n\n왼쪽 메뉴에는 Visual Studio 코드에 나타나는 아이콘과 같은 아이콘이 있어요 — 탐색, 검색, 소스 제어, 실행 및 디버그 아이콘입니다. 주요 차이점은 테스트 아이콘입니다. 이 테스트 아이콘을 사용하여 사용자는 Positron에서 실행된 프로그램을 위한 테스트 프레임워크를 구성할 수 있어요. 이를 통해 환경에서 간단한 테스트를 만드는 데 도움이 될 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데이터 탐색기를 사용하여 데이터 검사\n\nPositron의 가장 중요한 기능은 변수 검사와 플로팅을 지원하는 RStudio 스타일입니다. 변수 검사 기능을 사용하면 사용자가 데이터 크기 및 최근성에 따라 어떤 변수가 있는지 알 수 있습니다.\n\nGitHub 페이지에 따르면 데이터 탐색기에는 데이터 그리드, 요약 패널 및 필터 막대가 있습니다.\n\n- 데이터 그리드 — 개별 셀 및 열을 표시하는 스프레드시트 형식의 출력입니다. 또한 정렬 기능도 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n**2. 요약 패널** - 각 열 이름, 유형 및 결측 데이터 비율을 보여주는 디스플레이입니다. 탐색적 데이터 분석을 보완하는데 사용되며, 각 열 이름과 그에 해당하는 유형을 나타내는 아이콘을 나란히 표시합니다. 또한 인라인 막대 그래프 내에서 결측 데이터 양을 증가하는 백분율로 표시합니다.\n\n![이미지](/TIL/assets/img/2024-07-12-GettingStartedWithPositPositronthenewIDEforRandPython_3.png)\n\n**3. 필터 막대** - 열의 관측값 유형에 따라 특정 열을 필터링하는 기능을 제공합니다. 예를 들어, 문자열 열은 포함하거나 시작하거나 끝나거나 비어있거나 정확히 일치하는 등의 필터를 가지고 있습니다. 숫자 열은 논리 연산의 필터를 가지고 있어 작거나 크거나, 동일하거나, 두 값 사이에 포함되는 등의 작업을 수행할 수 있습니다.\n\n그림을 생성하기 위해 ggplot, txhousing로부터 데이터를 가져왔습니다. 데이터에는 9개의 열이 있습니다. 왼쪽에는 각 열의 요약 패널을 볼 수 있습니다. 그 옆에 데이터 그리드가 나타납니다. 오른쪽에는 변수 패널 아래에 생성한 변수인 q가 표시됩니다. q 변수는 텍사스 주택 데이터를 포함하는 것뿐입니다. 패널에는 q를 설명하는데 쓰이며, 사용된 데이터 오브젝트 유형(data.frame), 행 수(8602), 열 수(9)를 보여줍니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![Data Explorer Screenshot](/TIL/assets/img/2024-07-12-GettingStartedWithPositPositronthenewIDEforRandPython_4.png)\n\n데이터 익스플로러(Data Explorer)를 사용하면 Python(pandas)이나 R(data.frame, tibble, data.table)에서 해당 데이터 프레임을 표시할 수 있어, 대부분의 데이터 모델링 요구를 보완할 수 있습니다.\n\n또한 다른 데이터 유형인 polars에 대한 실험적 지원이 있습니다. 추가 Python 데이터 프레임 라이브러리도 곧 예상됩니다.\n\n# 확장 기능 추가 가능\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사용자들은 일반적으로 Visual Studio Code에서 사용하는 동일한 확장 프로그램을 추가할 수 있습니다. 아래 이미지에서 Prettier를 사용하여 Positron 계정에 어두운 테마를 적용했습니다.\n\n확장 프로그램의 가용성을 통해 개발자들은 다양한 상호작용이나 도구에 적응할 필요 없이 보다 개인화된 개발 환경을 구축할 수 있습니다.\n\n그러나 사용자들은 일반적으로 Visual Studio Code에서 필요한 R 및 Python 실행을 위해 어떤 확장 프로그램도 사용하지 않는 것이 좋습니다. 이러한 확장 프로그램에서 이미 필요한 기능이 Positron에 포함되어 있기 때문에 필요하지 않습니다. 이 통합은 VSC에 비해 일부 환경 \"불필요한\" 요소를 저장할 수 있으나, 아마도 VSC는 R 프로그래밍을 실행하기 위한 환경에서 확장 프로그램만이 필요할 것입니다.\n\n또한 Postiron 확장 프로그램을 찾고 설치하기 위해서는 OpenVSX(https://openvsx.org)를 사용해야 합니다. Microsoft Marketplace 대신 사용해야 합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# RStudio가 곧 대체될 것으로 기대하지 마세요\n\nPositron에 대한 초기 대중 응답은 긍정적이지만, 아직 IDE가 완전히 RStudio를 대체할 것인지에 대한 의문이 남아 있습니다. Positron을 시도한 대부분의 개발자들은 이를 RStudio의 대체품으로 극찬하고 있습니다.\n\nPosit의 수석 과학자 인 Hadley Wickham은 R 프로그래밍에 대해 방대한 글을 쓴 사람으로, Positron을 사용한 후 계속해서 지원이 가능하며 RStudio의 개발은 장래에 계속될 것이라고 팔로워들에게 안심시켰습니다. 그는 또 다른 게시물에서, 몇 가지 버그 해결이 남아 있기 때문에 처음 공부하는 학습자들에게는 문제가 해결된 IDE가 필요하다는 점을 주의했습니다.\n\n![Getting Started with Posit: Positron, the new IDE for R and Python](/TIL/assets/img/2024-07-12-GettingStartedWithPositPositronthenewIDEforRandPython_5.png)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n나 또한 Positron이 가져야했던 몇 가지 기능이 RStudio에 있다고 생각합니다. 적어도 변형으로써요. RStudio에서 파일을 빠르게 찾을 수 있고 어떤 라이브러리가 업데이트가 필요한지 확인하고 업데이트를 설치하고 함수 정의를 찾을 수 있는 것이 마음에 듭니다. 하지만 이 모든 것은 현재 R과 Python 사용이 혼합된 상태보다는 R 프로그래밍을 위해 설계되었습니다.\n\nPosit에는 Positron에서 유용한 도구가 있습니다. 이것이 어떻게 더 발전하고 개발자 및 데이터 과학자들 사이에서 어떻게 채택되어 나갈지 흥미롭게 살펴볼 만합니다.","ogImage":{"url":"/TIL/assets/img/2024-07-12-GettingStartedWithPositPositronthenewIDEforRandPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-GettingStartedWithPositPositronthenewIDEforRandPython_0.png","tag":["Tech"],"readingTime":9}],"page":"15","totalPageCount":34,"totalPageGroupCount":2,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"15"},"buildId":"xx51Gh_JNHDTBdDwrgykD","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>