<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Python으로 웹사이트에서 데이터를 쉽게 추출하는 방법 | TIL</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://13akstjq.github.io/TIL//post/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Python으로 웹사이트에서 데이터를 쉽게 추출하는 방법 | TIL" data-gatsby-head="true"/><meta property="og:title" content="Python으로 웹사이트에서 데이터를 쉽게 추출하는 방법 | TIL" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://TIL.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://13akstjq.github.io/TIL//post/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython" data-gatsby-head="true"/><meta name="twitter:title" content="Python으로 웹사이트에서 데이터를 쉽게 추출하는 방법 | TIL" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | TIL" data-gatsby-head="true"/><meta name="article:published_time" content="2024-07-12 20:27" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/TIL/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/TIL/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/TIL/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/TIL/favicons/favicon-96x96.png"/><link rel="icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/TIL/favicons/browserconfig.xml"/><link rel="preload" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/TIL/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/TIL/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/TIL/_next/static/chunks/webpack-21ffe88bdca56cba.js" defer=""></script><script src="/TIL/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/TIL/_next/static/chunks/main-a5eeabb286676ce6.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/TIL/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/TIL/_next/static/chunks/463-925361deb4cec4b1.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/post/%5Bslug%5D-9d7ebbd29b9e08ce.js" defer=""></script><script src="/TIL/_next/static/QAkYP0lvl03W-5CKD69kb/_buildManifest.js" defer=""></script><script src="/TIL/_next/static/QAkYP0lvl03W-5CKD69kb/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/TIL">TIL</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/TIL/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Python으로 웹사이트에서 데이터를 쉽게 추출하는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Python으로 웹사이트에서 데이터를 쉽게 추출하는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">TIL</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jul 12, 2024</span><span class="posts_reading_time__f7YPP">9<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<table>
<tbody><tr>
  <th>Library</th>
  <th>Purpose</th>
</tr>
<tr>
  <td>Requests</td>
  <td>For sending HTTP requests</td>
</tr>
<tr>
  <td>BeautifulSoup</td>
  <td>For parsing HTML and XML</td>
</tr>
<tr>
  <td>Tkinter</td>
  <td>For building the GUI</td>
</tr>
</tbody></table>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li><strong>Pandas</strong>: 추출된 데이터를 위한 데이터베이스를 생성하는 데 사용됩니다.</li>
<li><strong>Requests</strong>: 웹사이트에 접근 권한을 요청하는 데 사용됩니다.</li>
<li><strong>BeautifulSoup</strong>: 웹상에서 데이터를 찾는 데 사용됩니다.</li>
</ul>
<h1>작업: 이메일 목록 추출 및 CSV로 변환하기</h1>
<p>여러 주제에서 많은 이메일을 가져와야 했습니다.</p>
<p>"수동으로는 절대 할 수 없어" 라고 생각했습니다. 그렇게 하면 시간이 많이 걸리고 지루할 것이라고 생. 따라서 나는 파이썬 기술을 사용하기로 결정했습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>웹 사이트에는 다음과 같은 데이터가 있습니다:</p>
<p><img src="/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_1.png" alt="Data Table"></p>
<p>네, 과목 이름과 이메일이 포함된 표가 있습니다.</p>
<p>이 프로젝트의 목표는 이 데이터를 사용하여 CSV 파일을 생성하는 것입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>단계 1. 모듈 가져오기</h1>
<p>먼저 사용할 Python 라이브러리를 가져와 봅시다:</p>
<ul>
<li>pandas.</li>
<li>requests.</li>
<li>BeautifulSoup.</li>
</ul>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> <span class="hljs-title class_">BeautifulSoup</span>
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>단계 2. 데이터 찾기</h1>
<h2>2.1. 웹 스크래핑은 어떻게 작동되나요?</h2>
<p>웹에서 데이터를 추출하는 것이 가능한 이유는 무엇인가요?</p>
<p>답은 HTML(HyperText Markup Language)에 달려 있습니다. HTML은 웹 브라우저에서 표시할 문서의 표준 마크업 언어입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>웹사이트 어디에서든 마우스 오른쪽 버튼을 클릭하고 Inspect를 선택하면 웹의 코드가 오른쪽에 표시됩니다:</p>
<p><img src="/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_2.png" alt="image"></p>
<p>파이썬은 (일부 라이브러리와 함께) 이 HTML 코드를 "읽고" 원하는 데이터를 찾는 것입니다.</p>
<p>더 자세한 내용은 향후 기사에서 확인해보세요.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>2.2. HTML 가져오기 함수</h2>
<p>우선, 웹 사이트에서 HTML 코드를 가져와야 합니다.</p>
<p>URL을 매개변수로 하는 get_html 함수를 생성하는 방법은 다음과 같습니다:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> <span class="hljs-title class_">BeautifulSoup</span>

def <span class="hljs-title function_">get_html</span>(url):

    <span class="hljs-attr">try</span>:
        response = requests.<span class="hljs-title function_">get</span>(url) # 웹 사이트에서 <span class="hljs-variable constant_">HTML</span>을 요청합니다
        <span class="hljs-keyword">return</span> response.<span class="hljs-property">text</span>

    except <span class="hljs-title class_">Exception</span> <span class="hljs-keyword">as</span> <span class="hljs-attr">e</span>: # 가능한 오류를 처리하기 위한 예외 처리
        <span class="hljs-title function_">print</span>(f<span class="hljs-string">"웹 페이지를 가져오는 데 실패했습니다: {e}"</span>)
        <span class="hljs-keyword">return</span> <span class="hljs-string">""</span>emails = <span class="hljs-title function_">set</span>() # 중복을 피하기 위한 코드입니다
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>단계 3. 데이터 추출</h1>
<p>다음 단계는 우리가 원하는 데이터를 추출하는 것입니다.</p>
<p>우리는 이전 함수에서 HTML 코드를 가져오는 extract_data 함수를 만들 수 있습니다. 이는 다음 단계를 포함합니다:</p>
<ul>
<li>BeautifulSoup 클래스 초기화.</li>
<li>테이블을 찾는 변수 설정.</li>
<li>데이터를 수집할 빈 리스트.</li>
<li>데이터를 검색하는 for 루프.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> <span class="hljs-title class_">BeautifulSoup</span>

def <span class="hljs-title function_">get_html</span>(url):

    <span class="hljs-attr">try</span>:
        response = requests.<span class="hljs-title function_">get</span>(url) # 웹사이트로부터 <span class="hljs-variable constant_">HTML</span>을 요청합니다.
        <span class="hljs-keyword">return</span> response.<span class="hljs-property">text</span>

    except <span class="hljs-title class_">Exception</span> <span class="hljs-keyword">as</span> <span class="hljs-attr">e</span>: # 가능한 오류를 처리하기 위한 부분
        <span class="hljs-title function_">print</span>(f<span class="hljs-string">"웹 페이지를 가져오는 데 실패했습니다: {e}"</span>)
        <span class="hljs-keyword">return</span> <span class="hljs-string">""</span> # 중복을 피하기 위해 이메일 집합으로 설정

def <span class="hljs-title function_">extract_data</span>(html):

    soup = <span class="hljs-title class_">BeautifulSoup</span>(html, <span class="hljs-string">'html.parser'</span>) # <span class="hljs-title class_">BeautifulSoup</span> 클래스를 초기화
    table = soup.<span class="hljs-title function_">find</span>(<span class="hljs-string">'table'</span>) # 테이블을 찾습니다.
    data = [] # 데이터를 수집할 빈 리스트
    
    <span class="hljs-keyword">if</span> <span class="hljs-attr">table</span>:

        rows = table.<span class="hljs-title function_">find_all</span>(<span class="hljs-string">'tr'</span>) # 모든 테이블을 찾습니다.

        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> rows[<span class="hljs-number">1</span>:]:  # 헤더 행을 건너 뜁니다.
            cols = row.<span class="hljs-title function_">find_all</span>(<span class="hljs-string">'td'</span>) # 테이블에서 셀을 찾습니다.

            <span class="hljs-keyword">if</span> <span class="hljs-title function_">len</span>(cols) == <span class="hljs-number">4</span>:  # 항상 <span class="hljs-number">4</span>개의 열이 있다고 가정
                catedra_name = cols[<span class="hljs-number">0</span>].<span class="hljs-property">text</span>.<span class="hljs-title function_">strip</span>() # 과목 이름
                email = cols[<span class="hljs-number">1</span>].<span class="hljs-property">text</span>.<span class="hljs-title function_">strip</span>() # 이메일
                data.<span class="hljs-title function_">append</span>({<span class="hljs-string">'catedra'</span>: catedra_name, <span class="hljs-string">'email'</span>: email}) # 데이터 리스트에 추가
    
    <span class="hljs-keyword">return</span> data
</code></pre>
<h1>단계 4. 함수 호출 및 데이터 CSV로 저장</h1>
<p>이제 모든 준비가 되었으므로 함수를 호출해야 합니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> <span class="hljs-title class_">BeautifulSoup</span>

def <span class="hljs-title function_">get_html</span>(url):

    <span class="hljs-attr">try</span>:
        response = requests.<span class="hljs-title function_">get</span>(url) # 웹사이트에서 <span class="hljs-variable constant_">HTML</span> 가져오기
        <span class="hljs-keyword">return</span> response.<span class="hljs-property">text</span>

    except <span class="hljs-title class_">Exception</span> <span class="hljs-keyword">as</span> <span class="hljs-attr">e</span>: # 가능한 오류 처리
        <span class="hljs-title function_">print</span>(f<span class="hljs-string">"웹 페이지를 가져오는 데 실패했습니다: {e}"</span>)
        <span class="hljs-keyword">return</span> <span class="hljs-string">""</span> # 중복을 피하기 위해 이메일 집합

def <span class="hljs-title function_">extract_data</span>(html):

    soup = <span class="hljs-title class_">BeautifulSoup</span>(html, <span class="hljs-string">'html.parser'</span>) # <span class="hljs-title class_">BeautifulSoup</span> 클래스를 초기화
    table = soup.<span class="hljs-title function_">find</span>(<span class="hljs-string">'table'</span>) # 테이블 찾기
    data = [] # 데이터 수집을 위한 빈 리스트
    
    <span class="hljs-keyword">if</span> <span class="hljs-attr">table</span>:

        rows = table.<span class="hljs-title function_">find_all</span>(<span class="hljs-string">'tr'</span>) # 모든 테이블 찾기

        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> rows[<span class="hljs-number">1</span>:]:  # 헤더 행 건너 띄기
            cols = row.<span class="hljs-title function_">find_all</span>(<span class="hljs-string">'td'</span>)

            <span class="hljs-keyword">if</span> <span class="hljs-title function_">len</span>(cols) == <span class="hljs-number">4</span>:  # 항상 <span class="hljs-number">4</span>개의 열
                catedra_name = cols[<span class="hljs-number">0</span>].<span class="hljs-property">text</span>.<span class="hljs-title function_">strip</span>() # 과목 이름
                email = cols[<span class="hljs-number">1</span>].<span class="hljs-property">text</span>.<span class="hljs-title function_">strip</span>() # 이메일
                data.<span class="hljs-title function_">append</span>({<span class="hljs-string">'catedra'</span>: catedra_name, <span class="hljs-string">'email'</span>: email})
    
    <span class="hljs-keyword">return</span> data

url = <span class="hljs-string">"https://edipsicouba.net.ar/uncategorized/listado-mails-materias-electivas/"</span>  # 여러분의 링크 설정

html = <span class="hljs-title function_">get_html</span>(url) # <span class="hljs-title function_">get_html</span>() 함수 호출하여 내용을 변수에 저장
data = <span class="hljs-title function_">extract_data</span>(html) # <span class="hljs-title function_">extract_data</span>() 함수 호출하여 결과를 변수에 저장

df = pd.<span class="hljs-title class_">DataFrame</span>(data) # 데이터를 데이터프레임으로 변환
df.<span class="hljs-title function_">to_csv</span>(<span class="hljs-string">'mail_info.csv'</span>, index=<span class="hljs-title class_">False</span>) # 데이터프레임을 <span class="hljs-variable constant_">CSV</span> 파일로 저장

<span class="hljs-title function_">print</span>(<span class="hljs-string">"데이터가 성공적으로 추출되어 mail_info.csv로 저장되었습니다"</span>)
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>그게 다에요!</p>
<p>이렇게 하면 웹사이트의 테이블 안에서 데이터를 수집할 수 있어요.</p>
<p>또한, 이렇게 하면 Python을 사용하여 지루한 작업을 자동화할 수 있어요 😉</p>
<p>다음 글에서는 데이터 분석 프로젝트를 위해 슈퍼마켓에서 데이터를 수집하는 방법을 보여드릴게요.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>도와드릴 수 있는 방법:</h1>
<ul>
<li>새로운 무료 뉴스레터 'The Super Learning Lab'를 구독하세요.</li>
<li>곧 무료 학습 이북과 이메일 코스가 출시될 예정입니다!</li>
</ul>
<p><img src="/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_3.png" alt="HowToEasilyExtractDataFromAWebsiteWithPython_3"></p>
<h2>내 최고의 학습 기사들:</h2>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>안녕하세요!</p>
<p>가져와주셔서 감사합니다! 아래는 이번 주 발간물 내용입니다:</p>
<ul>
<li>Ultralearning으로 무엇이든 배우기</li>
<li>초안 속 9가지 Ultra-learning 원칙</li>
<li>Ultralearning을 활용하여 2개월 만에 무료로 독일어 배우기</li>
<li>학습을 슈퍼파워로 만들기</li>
<li>이것을 하지 않고 책을 읽는 것을 그만두세요</li>
</ul>
<p>만날 날을 기대하며,</p>
<p>Axel</p>
<h1>간단하고 쉬운 용어로 🚀</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>In Plain English 커뮤니티에 참여해 주셔서 감사합니다! 떠나시기 전에:</p>
<ul>
<li>작가에게 박수를 보내고 팔로우해주세요 👏️️</li>
<li>팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter</li>
<li>다른 플랫폼 방문하기: CoFeed | Differ</li>
<li>PlainEnglish.io에서 더 많은 콘텐츠 확인하기</li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Python으로 웹사이트에서 데이터를 쉽게 추출하는 방법","description":"","date":"2024-07-12 20:27","slug":"2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython","content":"\n\n\u003ctable\u003e\n\u003ctr\u003e\n  \u003cth\u003eLibrary\u003c/th\u003e\n  \u003cth\u003ePurpose\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eRequests\u003c/td\u003e\n  \u003ctd\u003eFor sending HTTP requests\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eBeautifulSoup\u003c/td\u003e\n  \u003ctd\u003eFor parsing HTML and XML\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eTkinter\u003c/td\u003e\n  \u003ctd\u003eFor building the GUI\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/table\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- **Pandas**: 추출된 데이터를 위한 데이터베이스를 생성하는 데 사용됩니다.\n- **Requests**: 웹사이트에 접근 권한을 요청하는 데 사용됩니다.\n- **BeautifulSoup**: 웹상에서 데이터를 찾는 데 사용됩니다.\n\n# 작업: 이메일 목록 추출 및 CSV로 변환하기\n\n여러 주제에서 많은 이메일을 가져와야 했습니다.\n\n\"수동으로는 절대 할 수 없어\" 라고 생각했습니다. 그렇게 하면 시간이 많이 걸리고 지루할 것이라고 생. 따라서 나는 파이썬 기술을 사용하기로 결정했습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n웹 사이트에는 다음과 같은 데이터가 있습니다:\n\n![Data Table](/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_1.png)\n\n네, 과목 이름과 이메일이 포함된 표가 있습니다.\n\n이 프로젝트의 목표는 이 데이터를 사용하여 CSV 파일을 생성하는 것입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 단계 1. 모듈 가져오기\n\n먼저 사용할 Python 라이브러리를 가져와 봅시다:\n\n- pandas.\n- requests.\n- BeautifulSoup.\n\n```js\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 단계 2. 데이터 찾기\n\n## 2.1. 웹 스크래핑은 어떻게 작동되나요?\n\n웹에서 데이터를 추출하는 것이 가능한 이유는 무엇인가요?\n\n답은 HTML(HyperText Markup Language)에 달려 있습니다. HTML은 웹 브라우저에서 표시할 문서의 표준 마크업 언어입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n웹사이트 어디에서든 마우스 오른쪽 버튼을 클릭하고 Inspect를 선택하면 웹의 코드가 오른쪽에 표시됩니다:\n\n![image](/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_2.png)\n\n파이썬은 (일부 라이브러리와 함께) 이 HTML 코드를 \"읽고\" 원하는 데이터를 찾는 것입니다.\n\n더 자세한 내용은 향후 기사에서 확인해보세요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 2.2. HTML 가져오기 함수\n\n우선, 웹 사이트에서 HTML 코드를 가져와야 합니다.\n\nURL을 매개변수로 하는 get_html 함수를 생성하는 방법은 다음과 같습니다:\n\n```js\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_html(url):\n\n    try:\n        response = requests.get(url) # 웹 사이트에서 HTML을 요청합니다\n        return response.text\n\n    except Exception as e: # 가능한 오류를 처리하기 위한 예외 처리\n        print(f\"웹 페이지를 가져오는 데 실패했습니다: {e}\")\n        return \"\"emails = set() # 중복을 피하기 위한 코드입니다\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 단계 3. 데이터 추출\n\n다음 단계는 우리가 원하는 데이터를 추출하는 것입니다.\n\n우리는 이전 함수에서 HTML 코드를 가져오는 extract_data 함수를 만들 수 있습니다. 이는 다음 단계를 포함합니다:\n\n- BeautifulSoup 클래스 초기화.\n- 테이블을 찾는 변수 설정.\n- 데이터를 수집할 빈 리스트.\n- 데이터를 검색하는 for 루프.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_html(url):\n\n    try:\n        response = requests.get(url) # 웹사이트로부터 HTML을 요청합니다.\n        return response.text\n\n    except Exception as e: # 가능한 오류를 처리하기 위한 부분\n        print(f\"웹 페이지를 가져오는 데 실패했습니다: {e}\")\n        return \"\" # 중복을 피하기 위해 이메일 집합으로 설정\n\ndef extract_data(html):\n\n    soup = BeautifulSoup(html, 'html.parser') # BeautifulSoup 클래스를 초기화\n    table = soup.find('table') # 테이블을 찾습니다.\n    data = [] # 데이터를 수집할 빈 리스트\n    \n    if table:\n\n        rows = table.find_all('tr') # 모든 테이블을 찾습니다.\n\n        for row in rows[1:]:  # 헤더 행을 건너 뜁니다.\n            cols = row.find_all('td') # 테이블에서 셀을 찾습니다.\n\n            if len(cols) == 4:  # 항상 4개의 열이 있다고 가정\n                catedra_name = cols[0].text.strip() # 과목 이름\n                email = cols[1].text.strip() # 이메일\n                data.append({'catedra': catedra_name, 'email': email}) # 데이터 리스트에 추가\n    \n    return data\n```\n\n# 단계 4. 함수 호출 및 데이터 CSV로 저장\n\n이제 모든 준비가 되었으므로 함수를 호출해야 합니다.\n\n```js\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_html(url):\n\n    try:\n        response = requests.get(url) # 웹사이트에서 HTML 가져오기\n        return response.text\n\n    except Exception as e: # 가능한 오류 처리\n        print(f\"웹 페이지를 가져오는 데 실패했습니다: {e}\")\n        return \"\" # 중복을 피하기 위해 이메일 집합\n\ndef extract_data(html):\n\n    soup = BeautifulSoup(html, 'html.parser') # BeautifulSoup 클래스를 초기화\n    table = soup.find('table') # 테이블 찾기\n    data = [] # 데이터 수집을 위한 빈 리스트\n    \n    if table:\n\n        rows = table.find_all('tr') # 모든 테이블 찾기\n\n        for row in rows[1:]:  # 헤더 행 건너 띄기\n            cols = row.find_all('td')\n\n            if len(cols) == 4:  # 항상 4개의 열\n                catedra_name = cols[0].text.strip() # 과목 이름\n                email = cols[1].text.strip() # 이메일\n                data.append({'catedra': catedra_name, 'email': email})\n    \n    return data\n\nurl = \"https://edipsicouba.net.ar/uncategorized/listado-mails-materias-electivas/\"  # 여러분의 링크 설정\n\nhtml = get_html(url) # get_html() 함수 호출하여 내용을 변수에 저장\ndata = extract_data(html) # extract_data() 함수 호출하여 결과를 변수에 저장\n\ndf = pd.DataFrame(data) # 데이터를 데이터프레임으로 변환\ndf.to_csv('mail_info.csv', index=False) # 데이터프레임을 CSV 파일로 저장\n\nprint(\"데이터가 성공적으로 추출되어 mail_info.csv로 저장되었습니다\")\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그게 다에요!\n\n이렇게 하면 웹사이트의 테이블 안에서 데이터를 수집할 수 있어요.\n\n또한, 이렇게 하면 Python을 사용하여 지루한 작업을 자동화할 수 있어요 😉\n\n다음 글에서는 데이터 분석 프로젝트를 위해 슈퍼마켓에서 데이터를 수집하는 방법을 보여드릴게요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 도와드릴 수 있는 방법:\n\n- 새로운 무료 뉴스레터 'The Super Learning Lab'를 구독하세요.\n- 곧 무료 학습 이북과 이메일 코스가 출시될 예정입니다!\n\n![HowToEasilyExtractDataFromAWebsiteWithPython_3](/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_3.png)\n\n## 내 최고의 학습 기사들:\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n안녕하세요!\n\n가져와주셔서 감사합니다! 아래는 이번 주 발간물 내용입니다:\n\n- Ultralearning으로 무엇이든 배우기\n- 초안 속 9가지 Ultra-learning 원칙\n- Ultralearning을 활용하여 2개월 만에 무료로 독일어 배우기\n- 학습을 슈퍼파워로 만들기\n- 이것을 하지 않고 책을 읽는 것을 그만두세요\n\n만날 날을 기대하며,\n\nAxel\n\n# 간단하고 쉬운 용어로 🚀\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nIn Plain English 커뮤니티에 참여해 주셔서 감사합니다! 떠나시기 전에:\n\n- 작가에게 박수를 보내고 팔로우해주세요 👏️️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문하기: CoFeed | Differ\n- PlainEnglish.io에서 더 많은 콘텐츠 확인하기","ogImage":{"url":"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_0.png","tag":["Tech"],"readingTime":9},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\n  \u003cth\u003eLibrary\u003c/th\u003e\n  \u003cth\u003ePurpose\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eRequests\u003c/td\u003e\n  \u003ctd\u003eFor sending HTTP requests\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eBeautifulSoup\u003c/td\u003e\n  \u003ctd\u003eFor parsing HTML and XML\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eTkinter\u003c/td\u003e\n  \u003ctd\u003eFor building the GUI\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePandas\u003c/strong\u003e: 추출된 데이터를 위한 데이터베이스를 생성하는 데 사용됩니다.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRequests\u003c/strong\u003e: 웹사이트에 접근 권한을 요청하는 데 사용됩니다.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBeautifulSoup\u003c/strong\u003e: 웹상에서 데이터를 찾는 데 사용됩니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e작업: 이메일 목록 추출 및 CSV로 변환하기\u003c/h1\u003e\n\u003cp\u003e여러 주제에서 많은 이메일을 가져와야 했습니다.\u003c/p\u003e\n\u003cp\u003e\"수동으로는 절대 할 수 없어\" 라고 생각했습니다. 그렇게 하면 시간이 많이 걸리고 지루할 것이라고 생. 따라서 나는 파이썬 기술을 사용하기로 결정했습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e웹 사이트에는 다음과 같은 데이터가 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_1.png\" alt=\"Data Table\"\u003e\u003c/p\u003e\n\u003cp\u003e네, 과목 이름과 이메일이 포함된 표가 있습니다.\u003c/p\u003e\n\u003cp\u003e이 프로젝트의 목표는 이 데이터를 사용하여 CSV 파일을 생성하는 것입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e단계 1. 모듈 가져오기\u003c/h1\u003e\n\u003cp\u003e먼저 사용할 Python 라이브러리를 가져와 봅시다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003epandas.\u003c/li\u003e\n\u003cli\u003erequests.\u003c/li\u003e\n\u003cli\u003eBeautifulSoup.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e requests\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e bs4 \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eBeautifulSoup\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e단계 2. 데이터 찾기\u003c/h1\u003e\n\u003ch2\u003e2.1. 웹 스크래핑은 어떻게 작동되나요?\u003c/h2\u003e\n\u003cp\u003e웹에서 데이터를 추출하는 것이 가능한 이유는 무엇인가요?\u003c/p\u003e\n\u003cp\u003e답은 HTML(HyperText Markup Language)에 달려 있습니다. HTML은 웹 브라우저에서 표시할 문서의 표준 마크업 언어입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e웹사이트 어디에서든 마우스 오른쪽 버튼을 클릭하고 Inspect를 선택하면 웹의 코드가 오른쪽에 표시됩니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_2.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e파이썬은 (일부 라이브러리와 함께) 이 HTML 코드를 \"읽고\" 원하는 데이터를 찾는 것입니다.\u003c/p\u003e\n\u003cp\u003e더 자세한 내용은 향후 기사에서 확인해보세요.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e2.2. HTML 가져오기 함수\u003c/h2\u003e\n\u003cp\u003e우선, 웹 사이트에서 HTML 코드를 가져와야 합니다.\u003c/p\u003e\n\u003cp\u003eURL을 매개변수로 하는 get_html 함수를 생성하는 방법은 다음과 같습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e requests\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e bs4 \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eBeautifulSoup\u003c/span\u003e\n\ndef \u003cspan class=\"hljs-title function_\"\u003eget_html\u003c/span\u003e(url):\n\n    \u003cspan class=\"hljs-attr\"\u003etry\u003c/span\u003e:\n        response = requests.\u003cspan class=\"hljs-title function_\"\u003eget\u003c/span\u003e(url) # 웹 사이트에서 \u003cspan class=\"hljs-variable constant_\"\u003eHTML\u003c/span\u003e을 요청합니다\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e response.\u003cspan class=\"hljs-property\"\u003etext\u003c/span\u003e\n\n    except \u003cspan class=\"hljs-title class_\"\u003eException\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ee\u003c/span\u003e: # 가능한 오류를 처리하기 위한 예외 처리\n        \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"웹 페이지를 가져오는 데 실패했습니다: {e}\"\u003c/span\u003e)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003eemails = \u003cspan class=\"hljs-title function_\"\u003eset\u003c/span\u003e() # 중복을 피하기 위한 코드입니다\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e단계 3. 데이터 추출\u003c/h1\u003e\n\u003cp\u003e다음 단계는 우리가 원하는 데이터를 추출하는 것입니다.\u003c/p\u003e\n\u003cp\u003e우리는 이전 함수에서 HTML 코드를 가져오는 extract_data 함수를 만들 수 있습니다. 이는 다음 단계를 포함합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBeautifulSoup 클래스 초기화.\u003c/li\u003e\n\u003cli\u003e테이블을 찾는 변수 설정.\u003c/li\u003e\n\u003cli\u003e데이터를 수집할 빈 리스트.\u003c/li\u003e\n\u003cli\u003e데이터를 검색하는 for 루프.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e requests\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e bs4 \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eBeautifulSoup\u003c/span\u003e\n\ndef \u003cspan class=\"hljs-title function_\"\u003eget_html\u003c/span\u003e(url):\n\n    \u003cspan class=\"hljs-attr\"\u003etry\u003c/span\u003e:\n        response = requests.\u003cspan class=\"hljs-title function_\"\u003eget\u003c/span\u003e(url) # 웹사이트로부터 \u003cspan class=\"hljs-variable constant_\"\u003eHTML\u003c/span\u003e을 요청합니다.\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e response.\u003cspan class=\"hljs-property\"\u003etext\u003c/span\u003e\n\n    except \u003cspan class=\"hljs-title class_\"\u003eException\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ee\u003c/span\u003e: # 가능한 오류를 처리하기 위한 부분\n        \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"웹 페이지를 가져오는 데 실패했습니다: {e}\"\u003c/span\u003e)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e # 중복을 피하기 위해 이메일 집합으로 설정\n\ndef \u003cspan class=\"hljs-title function_\"\u003eextract_data\u003c/span\u003e(html):\n\n    soup = \u003cspan class=\"hljs-title class_\"\u003eBeautifulSoup\u003c/span\u003e(html, \u003cspan class=\"hljs-string\"\u003e'html.parser'\u003c/span\u003e) # \u003cspan class=\"hljs-title class_\"\u003eBeautifulSoup\u003c/span\u003e 클래스를 초기화\n    table = soup.\u003cspan class=\"hljs-title function_\"\u003efind\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'table'\u003c/span\u003e) # 테이블을 찾습니다.\n    data = [] # 데이터를 수집할 빈 리스트\n    \n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003etable\u003c/span\u003e:\n\n        rows = table.\u003cspan class=\"hljs-title function_\"\u003efind_all\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'tr'\u003c/span\u003e) # 모든 테이블을 찾습니다.\n\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e row \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e rows[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e:]:  # 헤더 행을 건너 뜁니다.\n            cols = row.\u003cspan class=\"hljs-title function_\"\u003efind_all\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'td'\u003c/span\u003e) # 테이블에서 셀을 찾습니다.\n\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(cols) == \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e:  # 항상 \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e개의 열이 있다고 가정\n                catedra_name = cols[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-property\"\u003etext\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e() # 과목 이름\n                email = cols[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e].\u003cspan class=\"hljs-property\"\u003etext\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e() # 이메일\n                data.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e({\u003cspan class=\"hljs-string\"\u003e'catedra'\u003c/span\u003e: catedra_name, \u003cspan class=\"hljs-string\"\u003e'email'\u003c/span\u003e: email}) # 데이터 리스트에 추가\n    \n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e data\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e단계 4. 함수 호출 및 데이터 CSV로 저장\u003c/h1\u003e\n\u003cp\u003e이제 모든 준비가 되었으므로 함수를 호출해야 합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e requests\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e bs4 \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eBeautifulSoup\u003c/span\u003e\n\ndef \u003cspan class=\"hljs-title function_\"\u003eget_html\u003c/span\u003e(url):\n\n    \u003cspan class=\"hljs-attr\"\u003etry\u003c/span\u003e:\n        response = requests.\u003cspan class=\"hljs-title function_\"\u003eget\u003c/span\u003e(url) # 웹사이트에서 \u003cspan class=\"hljs-variable constant_\"\u003eHTML\u003c/span\u003e 가져오기\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e response.\u003cspan class=\"hljs-property\"\u003etext\u003c/span\u003e\n\n    except \u003cspan class=\"hljs-title class_\"\u003eException\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ee\u003c/span\u003e: # 가능한 오류 처리\n        \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"웹 페이지를 가져오는 데 실패했습니다: {e}\"\u003c/span\u003e)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e # 중복을 피하기 위해 이메일 집합\n\ndef \u003cspan class=\"hljs-title function_\"\u003eextract_data\u003c/span\u003e(html):\n\n    soup = \u003cspan class=\"hljs-title class_\"\u003eBeautifulSoup\u003c/span\u003e(html, \u003cspan class=\"hljs-string\"\u003e'html.parser'\u003c/span\u003e) # \u003cspan class=\"hljs-title class_\"\u003eBeautifulSoup\u003c/span\u003e 클래스를 초기화\n    table = soup.\u003cspan class=\"hljs-title function_\"\u003efind\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'table'\u003c/span\u003e) # 테이블 찾기\n    data = [] # 데이터 수집을 위한 빈 리스트\n    \n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003etable\u003c/span\u003e:\n\n        rows = table.\u003cspan class=\"hljs-title function_\"\u003efind_all\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'tr'\u003c/span\u003e) # 모든 테이블 찾기\n\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e row \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e rows[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e:]:  # 헤더 행 건너 띄기\n            cols = row.\u003cspan class=\"hljs-title function_\"\u003efind_all\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'td'\u003c/span\u003e)\n\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(cols) == \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e:  # 항상 \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e개의 열\n                catedra_name = cols[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-property\"\u003etext\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e() # 과목 이름\n                email = cols[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e].\u003cspan class=\"hljs-property\"\u003etext\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e() # 이메일\n                data.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e({\u003cspan class=\"hljs-string\"\u003e'catedra'\u003c/span\u003e: catedra_name, \u003cspan class=\"hljs-string\"\u003e'email'\u003c/span\u003e: email})\n    \n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e data\n\nurl = \u003cspan class=\"hljs-string\"\u003e\"https://edipsicouba.net.ar/uncategorized/listado-mails-materias-electivas/\"\u003c/span\u003e  # 여러분의 링크 설정\n\nhtml = \u003cspan class=\"hljs-title function_\"\u003eget_html\u003c/span\u003e(url) # \u003cspan class=\"hljs-title function_\"\u003eget_html\u003c/span\u003e() 함수 호출하여 내용을 변수에 저장\ndata = \u003cspan class=\"hljs-title function_\"\u003eextract_data\u003c/span\u003e(html) # \u003cspan class=\"hljs-title function_\"\u003eextract_data\u003c/span\u003e() 함수 호출하여 결과를 변수에 저장\n\ndf = pd.\u003cspan class=\"hljs-title class_\"\u003eDataFrame\u003c/span\u003e(data) # 데이터를 데이터프레임으로 변환\ndf.\u003cspan class=\"hljs-title function_\"\u003eto_csv\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'mail_info.csv'\u003c/span\u003e, index=\u003cspan class=\"hljs-title class_\"\u003eFalse\u003c/span\u003e) # 데이터프레임을 \u003cspan class=\"hljs-variable constant_\"\u003eCSV\u003c/span\u003e 파일로 저장\n\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"데이터가 성공적으로 추출되어 mail_info.csv로 저장되었습니다\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e그게 다에요!\u003c/p\u003e\n\u003cp\u003e이렇게 하면 웹사이트의 테이블 안에서 데이터를 수집할 수 있어요.\u003c/p\u003e\n\u003cp\u003e또한, 이렇게 하면 Python을 사용하여 지루한 작업을 자동화할 수 있어요 😉\u003c/p\u003e\n\u003cp\u003e다음 글에서는 데이터 분석 프로젝트를 위해 슈퍼마켓에서 데이터를 수집하는 방법을 보여드릴게요.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e도와드릴 수 있는 방법:\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e새로운 무료 뉴스레터 'The Super Learning Lab'를 구독하세요.\u003c/li\u003e\n\u003cli\u003e곧 무료 학습 이북과 이메일 코스가 출시될 예정입니다!\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_3.png\" alt=\"HowToEasilyExtractDataFromAWebsiteWithPython_3\"\u003e\u003c/p\u003e\n\u003ch2\u003e내 최고의 학습 기사들:\u003c/h2\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e안녕하세요!\u003c/p\u003e\n\u003cp\u003e가져와주셔서 감사합니다! 아래는 이번 주 발간물 내용입니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUltralearning으로 무엇이든 배우기\u003c/li\u003e\n\u003cli\u003e초안 속 9가지 Ultra-learning 원칙\u003c/li\u003e\n\u003cli\u003eUltralearning을 활용하여 2개월 만에 무료로 독일어 배우기\u003c/li\u003e\n\u003cli\u003e학습을 슈퍼파워로 만들기\u003c/li\u003e\n\u003cli\u003e이것을 하지 않고 책을 읽는 것을 그만두세요\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e만날 날을 기대하며,\u003c/p\u003e\n\u003cp\u003eAxel\u003c/p\u003e\n\u003ch1\u003e간단하고 쉬운 용어로 🚀\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eIn Plain English 커뮤니티에 참여해 주셔서 감사합니다! 떠나시기 전에:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e작가에게 박수를 보내고 팔로우해주세요 👏️️\u003c/li\u003e\n\u003cli\u003e팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\u003c/li\u003e\n\u003cli\u003e다른 플랫폼 방문하기: CoFeed | Differ\u003c/li\u003e\n\u003cli\u003ePlainEnglish.io에서 더 많은 콘텐츠 확인하기\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython"},"buildId":"QAkYP0lvl03W-5CKD69kb","assetPrefix":"/TIL","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>