<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법 | TIL</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://13akstjq.github.io/TIL//post/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법 | TIL" data-gatsby-head="true"/><meta property="og:title" content="Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법 | TIL" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://TIL.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://13akstjq.github.io/TIL//post/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown" data-gatsby-head="true"/><meta name="twitter:title" content="Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법 | TIL" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | TIL" data-gatsby-head="true"/><meta name="article:published_time" content="2024-07-12 19:50" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/TIL/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/TIL/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/TIL/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/TIL/favicons/favicon-96x96.png"/><link rel="icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/TIL/favicons/browserconfig.xml"/><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-5ecfd58aae5a7e3d.js" defer=""></script><script src="/_next/static/GnJ8pEcO5t2Vzpus740Q5/_buildManifest.js" defer=""></script><script src="/_next/static/GnJ8pEcO5t2Vzpus740Q5/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">TIL</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">TIL</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jul 12, 2024</span><span class="posts_reading_time__f7YPP">11<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<h1>요약</h1>
<p><strong>문맥:</strong> 제로샷 러닝(Zero-shot learning, ZSL)은 머신 러닝에서 cutting-edge한 방법론으로, 모델이 사전 노출 없이 새로운 객체를 인식할 수 있게 하여 인간 추론 능력을 모방합니다.</p>
<p><strong>문제:</strong> 기존 모델은 각 클래스에 대해 방대한 레이블 데이터가 필요하며, 이는 종종 실용적이지 않으며 확장 가능성을 제한합니다.</p>
<p><strong>접근:</strong> 본 보고서는 합성 데이터셋을 활용한 ZSL의 실용적 구현을 탐구하며, 특성 엔지니어링, 모델 훈련, 하이퍼파라미터 최적화 및 평가 지표에 대해 자세히 다룹니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>결과: 모델은 99.5%라는 높은 정확도를 달성하여, 혼동 행렬, 예측 분포도, 교차 검증 결과를 통해 보이지 않은 데이터를 분류하는 데 우수한 성능을 나타냈습니다.</p>
<p>결론: 제로샷 학습은 전통적인 지도 학습의 제약을 극복하는 데 강력한 도구로 작용하며, 강력한 일반화 능력과 다양한 실제 응용 가능성을 보여줍니다.</p>
<p>키워드: 제로샷 학습, 머신러닝 모델, 합성 데이터셋, 피처 엔지니어링, 하이퍼파라미터 최적화.</p>
<h1>소개</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>박물관에 들어가 새로운 동물을 그린 그림을 보게 된다면 어떤 기술들을 가지고 있는지를 살펴보면서, 비늘, 날개, 그리고 뱀 모양의 몸 등의 특징을 보고, 이것이 바로 용이라는 것을 유추할 수 있습니다. 용을 한번도 본 적이 없더라도 설명을 토대로 추론하고 인식하는 인간의 능력은 바로 인공 지능의 Zero-shot learning (ZSL)이 목표로 하는 것입니다. 데이터가 풍부하지만 항상 레이블이 되어있지 않은 세계에서, ZSL은 기계가 학습하는 방식의 한계를 뛰어넘어, 그동안 본 적 없는 물체를 식별하고 분류할 수 있도록 가능하게 합니다.</p>
<p><img src="/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png" alt="그림"></p>
<h1>Zero-Shot Learning의 이해</h1>
<p>Zero-shot learning은 기계 학습에서 혁신적인 방법으로, 모델이 직접적으로 그러한 특정 클래스에 대해 훈련을 받지 않아도 새로운 객체 클래스를 인식하도록 설계됩니다. 기존의 기계 학습 모델은 인식해야 하는 각 카테고리에 대해 많은 레이블이 달린 데이터가 필요합니다. 그러나 ZSL은 속성, 텍스트 설명 또는 임베딩과 같은 의미 정보를 활용하여 새롭고 보지 못한 클래스에 대해 합리적인 추측을 할 수 있도록합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>제로샷 러닝은 어떻게 작동하나요?</h1>
<ul>
<li>특성 추출: 모델은 훈련 단계에서 알려진 클래스에서 특성을 추출합니다. 이는 주로 이미지 인식 작업에는 사전 훈련된 합성곱 신경망(CNNs) 또는 텍스트에는 트랜스포머 모델을 사용하여 수행됩니다.</li>
<li>의미 임베딩: 보여지거나 보이지 않는 각 클래스는 의미 벡터와 연관됩니다. 이러한 벡터는 속성(예: 호랑이를 줄무늬가 있는 동물, 네 다리가 있고 날카로운 이빨을 가진 동물로 설명)에서 파생되거나 Word2Vec 또는 GloVe와 같은 단어 임베딩을 통해 처리된 텍스트 설명에서 얻을 수 있습니다.</li>
<li>매핑 함수: ZSL의 핵심은 시각적 특성을 의미 임베딩에 연결하는 매핑 함수에 있습니다. 모델이 새로운 이미지나 텍스트를 만나면 추출된 특성을 가장 가까운 의미 벡터에 매핑하여 보이지 않는 클래스를 인식하고 분류할 수 있게 합니다.</li>
</ul>
<h1>제로샷 러닝의 적용 분야</h1>
<ul>
<li>이미지 인식: ZSL은 야생 동물 모니터링과 같은 분야에서 설명적 속성을 기반으로 새로운 종을 식별하는 데 도움을 줄 수 있습니다. 예를 들어, 일반 동물에 대해 훈련된 모델은 해당 특성을 이해하여 새로 발견된 종을 인식할 수 있습니다.</li>
<li>자연어 처리(NLP): 설명에서 맥락적 정보를 사용하여, ZSL은 모델이 명시적으로 훈련받지 않은 주제에 대한 텍스트 분류나 감정 분석과 같은 작업을 처리할 수 있게 합니다.</li>
<li>추천 시스템: ZSL은 훈련 데이터에 없는 항목을 제안하여 사용자 경험과 참여를 향상시키는 방식으로 추천 시스템을 개선합니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>도전과 향후 방향</h1>
<p>제로샷 학습은 엄청난 잠재력을 제공하지만 도전도 있습니다:</p>
<ul>
<li>의미적 간극: 시각적 특징과 의미적 표현 간의 불일치는 잘못된 매핑으로 이어질 수 있습니다. 이 간극을 줄이는 것은 정확도 향상에 중요합니다.</li>
<li>속성 종속성: ZSL의 효과성은 의미적 특성이나 설명의 품질과 포괄성에 크게 의존합니다.</li>
<li>확장성: 많은 클래스를 인식하는 것은 계산적인 도전으로 남아 있으며, 효율적인 알고리즘과 견고한 매핑 함수가 필요합니다.</li>
</ul>
<p>연구자들은 이러한 도전에 대한 해결책을 적극적으로 탐구하고 있습니다. 개선된 임베딩 기술, 제로샷 및 퓨샷 학습을 결합한 하이브리드 모델, 그리고 보다 견고한 매핑 함수는 개발 중인 전략 중 일부입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>실용 예시</h1>
<p>아래에는 합성 데이터셋을 활용한 제로샷 러닝을 보여주는 포괄적인 파이썬 코드 블록이 있습니다. 예시에는 특성 기술, 특성 엔지니어링, 하이퍼파라미터 최적화, 교차 검증, 모델 예측, 메트릭, 플롯 및 결과 해석이 포함되어 있습니다. 이 코드는 scikit-learn, numpy, pandas, matplotlib 및 seaborn 라이브러리를 사용합니다.</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># 필요한 라이브러리 가져오기</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split, GridSearchCV
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report, confusion_matrix, accuracy_score
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler, LabelEncoder
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns

<span class="hljs-comment"># 합성 데이터셋 생성</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">create_synthetic_data</span>():
    np.random.seed(<span class="hljs-number">42</span>)
    n_samples = <span class="hljs-number">1000</span>
    features = np.random.rand(n_samples, <span class="hljs-number">5</span>)
    labels = (np.<span class="hljs-built_in">sum</span>(features, axis=<span class="hljs-number">1</span>) > <span class="hljs-number">2.5</span>).astype(<span class="hljs-built_in">int</span>)
    
    <span class="hljs-comment"># DataFrame으로 변환</span>
    df = pd.DataFrame(features, columns=[<span class="hljs-string">f'feature_<span class="hljs-subst">{i}</span>'</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>)])
    df[<span class="hljs-string">'label'</span>] = labels
    
    <span class="hljs-comment"># 제로샷 러닝을 위한 의미 정보 추가</span>
    semantic_info = {
        <span class="hljs-number">0</span>: <span class="hljs-string">'low_sum'</span>,
        <span class="hljs-number">1</span>: <span class="hljs-string">'high_sum'</span>
    }
    
    df[<span class="hljs-string">'semantic_label'</span>] = df[<span class="hljs-string">'label'</span>].<span class="hljs-built_in">map</span>(semantic_info)
    <span class="hljs-keyword">return</span> df

<span class="hljs-comment"># 합성 데이터셋 생성</span>
df = create_synthetic_data()

<span class="hljs-comment"># 특성 엔지니어링: 특성 표준화</span>
scaler = StandardScaler()
X = scaler.fit_transform(df.drop([<span class="hljs-string">'label'</span>, <span class="hljs-string">'semantic_label'</span>], axis=<span class="hljs-number">1</span>))
y = df[<span class="hljs-string">'label'</span>]

<span class="hljs-comment"># 데이터를 학습 및 테스트 세트로 분할</span>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>)

<span class="hljs-comment"># 제로샷 러닝 설정</span>
semantic_labels = df[<span class="hljs-string">'semantic_label'</span>].unique()
semantic_embeddings = {
    <span class="hljs-string">'low_sum'</span>: np.array([<span class="hljs-number">0.2</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.2</span>]),
    <span class="hljs-string">'high_sum'</span>: np.array([<span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>])
}

<span class="hljs-comment"># GridSearchCV를 사용한 하이퍼파라미터 최적화</span>
param_grid = {
    <span class="hljs-string">'C'</span>: [<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">10</span>],
    <span class="hljs-string">'solver'</span>: [<span class="hljs-string">'liblinear'</span>]
}

model = LogisticRegression()
grid_search = GridSearchCV(model, param_grid, cv=<span class="hljs-number">5</span>, scoring=<span class="hljs-string">'accuracy'</span>)
grid_search.fit(X_train, y_train)

<span class="hljs-comment"># Grid search에서 최적의 모델</span>
best_model = grid_search.best_estimator_

<span class="hljs-comment"># 예측</span>
y_pred = best_model.predict(X_test)

<span class="hljs-comment"># 평가 메트릭</span>
accuracy = accuracy_score(y_test, y_pred)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"정확도:"</span>, accuracy)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"분류 보고서:\n"</span>, classification_report(y_test, y_pred))

<span class="hljs-comment"># 혼동 행렬</span>
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=<span class="hljs-literal">True</span>, fmt=<span class="hljs-string">'d'</span>, cmap=<span class="hljs-string">'Blues'</span>)
plt.xlabel(<span class="hljs-string">'예측 라벨'</span>)
plt.ylabel(<span class="hljs-string">'실제 라벨'</span>)
plt.title(<span class="hljs-string">'혼동 행렬'</span>)
plt.show()

<span class="hljs-comment"># 결과 시각화</span>
plt.scatter(X_test[:, <span class="hljs-number">0</span>], X_test[:, <span class="hljs-number">1</span>], c=y_pred, cmap=<span class="hljs-string">'viridis'</span>, marker=<span class="hljs-string">'o'</span>)
plt.title(<span class="hljs-string">'제로샷 러닝 예측'</span>)
plt.xlabel(<span class="hljs-string">'특성 1'</span>)
plt.ylabel(<span class="hljs-string">'특성 2'</span>)
plt.show()

<span class="hljs-comment"># 결과 해석</span>
<span class="hljs-comment"># 합성 데이터를 사용하여 제로샷 러닝 모델의 성능을 확인할 수 있습니다.</span>
<span class="hljs-comment"># 혼동 행렬 및 분류 보고서를 통해 정확도 및 분류 성능을 파악할 수 있습니다.</span>

<span class="hljs-comment"># 교차 검증 결과</span>
results = pd.DataFrame(grid_search.cv_results_)
results.plot(kind=<span class="hljs-string">'bar'</span>, x=<span class="hljs-string">'param_C'</span>, y=<span class="hljs-string">'mean_test_score'</span>, yerr=<span class="hljs-string">'std_test_score'</span>, capsize=<span class="hljs-number">4</span>)
plt.xlabel(<span class="hljs-string">'C (정규화 매개변수)'</span>)
plt.ylabel(<span class="hljs-string">'평균 테스트 점수'</span>)
plt.title(<span class="hljs-string">'교차 검증 결과'</span>)
plt.show()

<span class="hljs-comment"># 마무리</span>
<span class="hljs-comment"># 제로샷 러닝은 의미 정보를 기반으로 보이지 않는 클래스를 예측할 수 있는 모델을 만듭니다.</span>
<span class="hljs-comment"># 합성 예시는 제로샷 러닝 모델이 제공된 속성을 기반으로 일반화할 수 있는 능력을 보여줍니다.</span>
</code></pre>
<p>이 코드는 합성 데이터셋을 활용하여 제로샷 러닝의 실용적인 예시를 제공하며, 데이터 생성부터 평가 및 결과 시각화까지의 전체 머신 러닝 파이프라인을 다룹니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>결과 해석</h2>
<p>혼동 행렬: 혼동 행렬은 분류 모델의 성능을 시각적으로 보여줍니다. 제공된 혼동 행렬에서:</p>
<ul>
<li>모형은 0 클래스의 경우 89개 및 1 클래스의 경우 110건을 정확하게 분류했습니다.</li>
<li>1 클래스의 하나의 사례가 0 클래스로 분류되는 잘못된 분류가 있었습니다.</li>
<li>0 클래스가 1 클래스로 잘못 분류된 경우는 없었습니다.</li>
</ul>
<p>이는 모델의 예측 정확도가 높음을 나타냅니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_1.png" alt="image"></p>
<p>정확도: 0.995 모델은 99.5%의 정확도를 달성했습니다. 이는 예측 중 99.5%가 정확했음을 나타냅니다. 이 뛰어난 정확도 점수는 모델이 이 데이터셋에서 매우 잘 수행한다는 것을 시사합니다.</p>
<p>분류 보고서: 분류 보고서는 각 클래스에 대한 정밀도, 재현율 및 f1-점수를 포함한 상세한 지표를 제공합니다:</p>
<ul>
<li>정밀도: 두 클래스 모두에 대한 정밀도가 매우 높습니다 (클래스 0의 경우 0.99, 클래스 1의 경우 1.00), 이는 모델이 매우 낮은 오검출률을 가지고 있다는 것을 나타냅니다.</li>
<li>재현율: 두 클래스 모두에 대한 재현율도 매우 높습니다 (클래스 0의 경우 1.00, 클래스 1의 경우 0.99), 이는 모델이 매우 낮은 오물체률을 가지고 있다는 것을 나타냅니다.</li>
<li>f1-점수: 정밀도와 재현율의 조화 평균인 f1-점수는 클래스 0의 경우 0.99, 클래스 1의 경우 1.00으로, 두 클래스에 대한 균형 잡힌 정확한 모델 성능을 시사합니다.</li>
<li>지원: 지원 값(클래스 0의 경우 89, 클래스 1의 경우 111)은 테스트 데이터셋의 각 클래스에 대한 실제 인스턴스를 나타냅니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>제로샷 러닝 예측 산점도: 산점도는 제로샷 러닝 예측을 시각화합니다. 각 포인트는 테스트 인스턴스를 나타내며, 다른 색상은 예측된 클래스를 나타냅니다. 포인트들의 명확한 군집화는 모델이 특징에 기반하여 두 클래스를 구별하는 능력을 나타냅니다.</p>
<p><img src="/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_2.png" alt="Zero-Shot Learning Predictions Scatter Plot"></p>
<p>교차 검증 결과: 막대 차트는 정규화 매개변수 CCC의 다른 값에 대한 교차 검증에서의 평균 테스트 점수를 보여줍니다:</p>
<ul>
<li>모델은 모든 테스트된 CCC 값에 대해 일관된 우수한 성능을 보이며, 평균 테스트 점수는 1.0에 가깝습니다.</li>
<li>오차 막대는 최소 테스트 점수의 표준 편차를 나타내며, 모델의 성능이 안정적이고 CCC의 선택에 지나치게 민감하지 않음을 시사합니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_3.png" alt="Zero-Shot Learning Approach"></p>
<p>최종 생각:</p>
<ul>
<li>모델은 뛰어난 성능을 보여주며 높은 정확도, 정밀도, 재현율 및 F1 점수를 가지고 있습니다.</li>
<li>혼동 행렬과 산점도는 모델의 능력을 추가로 확인하여 테스트 인스턴스를 최소 오류로 올바르게 분류합니다.</li>
<li>교차 검증 결과는 견고한 모델이 다양한 하이퍼파라미터 설정에서 잘 수행되는 것을 나타냅니다.</li>
</ul>
<p>이 zero-shot 학습 접근 방식은 합성 데이터셋을 사용하더라도 훌륭한 결과를 보여주며 의미 정보를 기반으로 보이지 않는 클래스를 정확하게 일반화하고 예측할 수 있는 모델의 능력을 강조합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>결론</h1>
<p>제로샷 학습은 머신 러닝에서 큰 발전을 의미하며 직접적인 경험 없이 새로운 개념을 일반화하고 인식하는 인간의 능력을 반영합니다. 우리가 제로샷 학습 기술을 계속 발전시키고 향상시킬수록, 더 유연하고 확장 가능하며 동적인 현실 세계 환경에서 작동할 수 있는 AI 시스템을 만들기에 더 근접해집니다. AI의 미래는 배우고 적응하는 능력에 있으며, 제로샷 학습은 이 방향으로의 중요한 한걸음입니다.</p>
<p>여러분의 의견을 듣고 싶습니다! 제로샷 학습이 귀하의 산업에서 AI의 미래를 어떻게 변화시킬 것으로 보십니까? 아래 댓글에 의견과 경험을 공유해주시고, 이 혁신적인 기술의 끝없는 가능성에 대한 대화를 이끌어봅시다!</p>
<h1>참고문헌</h1>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법","description":"","date":"2024-07-12 19:50","slug":"2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown","content":"\n\n# 요약\n\n**문맥:** 제로샷 러닝(Zero-shot learning, ZSL)은 머신 러닝에서 cutting-edge한 방법론으로, 모델이 사전 노출 없이 새로운 객체를 인식할 수 있게 하여 인간 추론 능력을 모방합니다.\n\n**문제:** 기존 모델은 각 클래스에 대해 방대한 레이블 데이터가 필요하며, 이는 종종 실용적이지 않으며 확장 가능성을 제한합니다.\n\n**접근:** 본 보고서는 합성 데이터셋을 활용한 ZSL의 실용적 구현을 탐구하며, 특성 엔지니어링, 모델 훈련, 하이퍼파라미터 최적화 및 평가 지표에 대해 자세히 다룹니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n결과: 모델은 99.5%라는 높은 정확도를 달성하여, 혼동 행렬, 예측 분포도, 교차 검증 결과를 통해 보이지 않은 데이터를 분류하는 데 우수한 성능을 나타냈습니다.\n\n결론: 제로샷 학습은 전통적인 지도 학습의 제약을 극복하는 데 강력한 도구로 작용하며, 강력한 일반화 능력과 다양한 실제 응용 가능성을 보여줍니다.\n\n키워드: 제로샷 학습, 머신러닝 모델, 합성 데이터셋, 피처 엔지니어링, 하이퍼파라미터 최적화.\n\n# 소개\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n박물관에 들어가 새로운 동물을 그린 그림을 보게 된다면 어떤 기술들을 가지고 있는지를 살펴보면서, 비늘, 날개, 그리고 뱀 모양의 몸 등의 특징을 보고, 이것이 바로 용이라는 것을 유추할 수 있습니다. 용을 한번도 본 적이 없더라도 설명을 토대로 추론하고 인식하는 인간의 능력은 바로 인공 지능의 Zero-shot learning (ZSL)이 목표로 하는 것입니다. 데이터가 풍부하지만 항상 레이블이 되어있지 않은 세계에서, ZSL은 기계가 학습하는 방식의 한계를 뛰어넘어, 그동안 본 적 없는 물체를 식별하고 분류할 수 있도록 가능하게 합니다.\n\n![그림](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png)\n\n# Zero-Shot Learning의 이해\n\nZero-shot learning은 기계 학습에서 혁신적인 방법으로, 모델이 직접적으로 그러한 특정 클래스에 대해 훈련을 받지 않아도 새로운 객체 클래스를 인식하도록 설계됩니다. 기존의 기계 학습 모델은 인식해야 하는 각 카테고리에 대해 많은 레이블이 달린 데이터가 필요합니다. 그러나 ZSL은 속성, 텍스트 설명 또는 임베딩과 같은 의미 정보를 활용하여 새롭고 보지 못한 클래스에 대해 합리적인 추측을 할 수 있도록합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 제로샷 러닝은 어떻게 작동하나요?\n\n- 특성 추출: 모델은 훈련 단계에서 알려진 클래스에서 특성을 추출합니다. 이는 주로 이미지 인식 작업에는 사전 훈련된 합성곱 신경망(CNNs) 또는 텍스트에는 트랜스포머 모델을 사용하여 수행됩니다.\n- 의미 임베딩: 보여지거나 보이지 않는 각 클래스는 의미 벡터와 연관됩니다. 이러한 벡터는 속성(예: 호랑이를 줄무늬가 있는 동물, 네 다리가 있고 날카로운 이빨을 가진 동물로 설명)에서 파생되거나 Word2Vec 또는 GloVe와 같은 단어 임베딩을 통해 처리된 텍스트 설명에서 얻을 수 있습니다.\n- 매핑 함수: ZSL의 핵심은 시각적 특성을 의미 임베딩에 연결하는 매핑 함수에 있습니다. 모델이 새로운 이미지나 텍스트를 만나면 추출된 특성을 가장 가까운 의미 벡터에 매핑하여 보이지 않는 클래스를 인식하고 분류할 수 있게 합니다.\n\n# 제로샷 러닝의 적용 분야\n\n- 이미지 인식: ZSL은 야생 동물 모니터링과 같은 분야에서 설명적 속성을 기반으로 새로운 종을 식별하는 데 도움을 줄 수 있습니다. 예를 들어, 일반 동물에 대해 훈련된 모델은 해당 특성을 이해하여 새로 발견된 종을 인식할 수 있습니다.\n- 자연어 처리(NLP): 설명에서 맥락적 정보를 사용하여, ZSL은 모델이 명시적으로 훈련받지 않은 주제에 대한 텍스트 분류나 감정 분석과 같은 작업을 처리할 수 있게 합니다.\n- 추천 시스템: ZSL은 훈련 데이터에 없는 항목을 제안하여 사용자 경험과 참여를 향상시키는 방식으로 추천 시스템을 개선합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 도전과 향후 방향\n\n제로샷 학습은 엄청난 잠재력을 제공하지만 도전도 있습니다:\n\n- 의미적 간극: 시각적 특징과 의미적 표현 간의 불일치는 잘못된 매핑으로 이어질 수 있습니다. 이 간극을 줄이는 것은 정확도 향상에 중요합니다.\n- 속성 종속성: ZSL의 효과성은 의미적 특성이나 설명의 품질과 포괄성에 크게 의존합니다.\n- 확장성: 많은 클래스를 인식하는 것은 계산적인 도전으로 남아 있으며, 효율적인 알고리즘과 견고한 매핑 함수가 필요합니다.\n\n연구자들은 이러한 도전에 대한 해결책을 적극적으로 탐구하고 있습니다. 개선된 임베딩 기술, 제로샷 및 퓨샷 학습을 결합한 하이브리드 모델, 그리고 보다 견고한 매핑 함수는 개발 중인 전략 중 일부입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 실용 예시\n\n아래에는 합성 데이터셋을 활용한 제로샷 러닝을 보여주는 포괄적인 파이썬 코드 블록이 있습니다. 예시에는 특성 기술, 특성 엔지니어링, 하이퍼파라미터 최적화, 교차 검증, 모델 예측, 메트릭, 플롯 및 결과 해석이 포함되어 있습니다. 이 코드는 scikit-learn, numpy, pandas, matplotlib 및 seaborn 라이브러리를 사용합니다.\n\n```python\n# 필요한 라이브러리 가져오기\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 합성 데이터셋 생성\ndef create_synthetic_data():\n    np.random.seed(42)\n    n_samples = 1000\n    features = np.random.rand(n_samples, 5)\n    labels = (np.sum(features, axis=1) \u003e 2.5).astype(int)\n    \n    # DataFrame으로 변환\n    df = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(1, 6)])\n    df['label'] = labels\n    \n    # 제로샷 러닝을 위한 의미 정보 추가\n    semantic_info = {\n        0: 'low_sum',\n        1: 'high_sum'\n    }\n    \n    df['semantic_label'] = df['label'].map(semantic_info)\n    return df\n\n# 합성 데이터셋 생성\ndf = create_synthetic_data()\n\n# 특성 엔지니어링: 특성 표준화\nscaler = StandardScaler()\nX = scaler.fit_transform(df.drop(['label', 'semantic_label'], axis=1))\ny = df['label']\n\n# 데이터를 학습 및 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 제로샷 러닝 설정\nsemantic_labels = df['semantic_label'].unique()\nsemantic_embeddings = {\n    'low_sum': np.array([0.2, 0.2, 0.2, 0.2, 0.2]),\n    'high_sum': np.array([0.8, 0.8, 0.8, 0.8, 0.8])\n}\n\n# GridSearchCV를 사용한 하이퍼파라미터 최적화\nparam_grid = {\n    'C': [0.1, 1, 10],\n    'solver': ['liblinear']\n}\n\nmodel = LogisticRegression()\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\n# Grid search에서 최적의 모델\nbest_model = grid_search.best_estimator_\n\n# 예측\ny_pred = best_model.predict(X_test)\n\n# 평가 메트릭\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"정확도:\", accuracy)\nprint(\"분류 보고서:\\n\", classification_report(y_test, y_pred))\n\n# 혼동 행렬\nconf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('예측 라벨')\nplt.ylabel('실제 라벨')\nplt.title('혼동 행렬')\nplt.show()\n\n# 결과 시각화\nplt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap='viridis', marker='o')\nplt.title('제로샷 러닝 예측')\nplt.xlabel('특성 1')\nplt.ylabel('특성 2')\nplt.show()\n\n# 결과 해석\n# 합성 데이터를 사용하여 제로샷 러닝 모델의 성능을 확인할 수 있습니다.\n# 혼동 행렬 및 분류 보고서를 통해 정확도 및 분류 성능을 파악할 수 있습니다.\n\n# 교차 검증 결과\nresults = pd.DataFrame(grid_search.cv_results_)\nresults.plot(kind='bar', x='param_C', y='mean_test_score', yerr='std_test_score', capsize=4)\nplt.xlabel('C (정규화 매개변수)')\nplt.ylabel('평균 테스트 점수')\nplt.title('교차 검증 결과')\nplt.show()\n\n# 마무리\n# 제로샷 러닝은 의미 정보를 기반으로 보이지 않는 클래스를 예측할 수 있는 모델을 만듭니다.\n# 합성 예시는 제로샷 러닝 모델이 제공된 속성을 기반으로 일반화할 수 있는 능력을 보여줍니다.\n```\n\n이 코드는 합성 데이터셋을 활용하여 제로샷 러닝의 실용적인 예시를 제공하며, 데이터 생성부터 평가 및 결과 시각화까지의 전체 머신 러닝 파이프라인을 다룹니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 결과 해석\n\n혼동 행렬: 혼동 행렬은 분류 모델의 성능을 시각적으로 보여줍니다. 제공된 혼동 행렬에서:\n\n- 모형은 0 클래스의 경우 89개 및 1 클래스의 경우 110건을 정확하게 분류했습니다.\n- 1 클래스의 하나의 사례가 0 클래스로 분류되는 잘못된 분류가 있었습니다.\n- 0 클래스가 1 클래스로 잘못 분류된 경우는 없었습니다.\n\n이는 모델의 예측 정확도가 높음을 나타냅니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![image](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_1.png)\n\n정확도: 0.995 모델은 99.5%의 정확도를 달성했습니다. 이는 예측 중 99.5%가 정확했음을 나타냅니다. 이 뛰어난 정확도 점수는 모델이 이 데이터셋에서 매우 잘 수행한다는 것을 시사합니다.\n\n분류 보고서: 분류 보고서는 각 클래스에 대한 정밀도, 재현율 및 f1-점수를 포함한 상세한 지표를 제공합니다:\n\n- 정밀도: 두 클래스 모두에 대한 정밀도가 매우 높습니다 (클래스 0의 경우 0.99, 클래스 1의 경우 1.00), 이는 모델이 매우 낮은 오검출률을 가지고 있다는 것을 나타냅니다.\n- 재현율: 두 클래스 모두에 대한 재현율도 매우 높습니다 (클래스 0의 경우 1.00, 클래스 1의 경우 0.99), 이는 모델이 매우 낮은 오물체률을 가지고 있다는 것을 나타냅니다.\n- f1-점수: 정밀도와 재현율의 조화 평균인 f1-점수는 클래스 0의 경우 0.99, 클래스 1의 경우 1.00으로, 두 클래스에 대한 균형 잡힌 정확한 모델 성능을 시사합니다.\n- 지원: 지원 값(클래스 0의 경우 89, 클래스 1의 경우 111)은 테스트 데이터셋의 각 클래스에 대한 실제 인스턴스를 나타냅니다.\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제로샷 러닝 예측 산점도: 산점도는 제로샷 러닝 예측을 시각화합니다. 각 포인트는 테스트 인스턴스를 나타내며, 다른 색상은 예측된 클래스를 나타냅니다. 포인트들의 명확한 군집화는 모델이 특징에 기반하여 두 클래스를 구별하는 능력을 나타냅니다.\n\n![Zero-Shot Learning Predictions Scatter Plot](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_2.png)\n\n교차 검증 결과: 막대 차트는 정규화 매개변수 CCC의 다른 값에 대한 교차 검증에서의 평균 테스트 점수를 보여줍니다:\n\n- 모델은 모든 테스트된 CCC 값에 대해 일관된 우수한 성능을 보이며, 평균 테스트 점수는 1.0에 가깝습니다.\n- 오차 막대는 최소 테스트 점수의 표준 편차를 나타내며, 모델의 성능이 안정적이고 CCC의 선택에 지나치게 민감하지 않음을 시사합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![Zero-Shot Learning Approach](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_3.png)\n\n최종 생각:\n\n- 모델은 뛰어난 성능을 보여주며 높은 정확도, 정밀도, 재현율 및 F1 점수를 가지고 있습니다.\n- 혼동 행렬과 산점도는 모델의 능력을 추가로 확인하여 테스트 인스턴스를 최소 오류로 올바르게 분류합니다.\n- 교차 검증 결과는 견고한 모델이 다양한 하이퍼파라미터 설정에서 잘 수행되는 것을 나타냅니다.\n\n이 zero-shot 학습 접근 방식은 합성 데이터셋을 사용하더라도 훌륭한 결과를 보여주며 의미 정보를 기반으로 보이지 않는 클래스를 정확하게 일반화하고 예측할 수 있는 모델의 능력을 강조합니다.\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n제로샷 학습은 머신 러닝에서 큰 발전을 의미하며 직접적인 경험 없이 새로운 개념을 일반화하고 인식하는 인간의 능력을 반영합니다. 우리가 제로샷 학습 기술을 계속 발전시키고 향상시킬수록, 더 유연하고 확장 가능하며 동적인 현실 세계 환경에서 작동할 수 있는 AI 시스템을 만들기에 더 근접해집니다. AI의 미래는 배우고 적응하는 능력에 있으며, 제로샷 학습은 이 방향으로의 중요한 한걸음입니다.\n\n여러분의 의견을 듣고 싶습니다! 제로샷 학습이 귀하의 산업에서 AI의 미래를 어떻게 변화시킬 것으로 보십니까? 아래 댓글에 의견과 경험을 공유해주시고, 이 혁신적인 기술의 끝없는 가능성에 대한 대화를 이끌어봅시다!\n\n# 참고문헌","ogImage":{"url":"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png","tag":["Tech"],"readingTime":11},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ch1\u003e요약\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e문맥:\u003c/strong\u003e 제로샷 러닝(Zero-shot learning, ZSL)은 머신 러닝에서 cutting-edge한 방법론으로, 모델이 사전 노출 없이 새로운 객체를 인식할 수 있게 하여 인간 추론 능력을 모방합니다.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e문제:\u003c/strong\u003e 기존 모델은 각 클래스에 대해 방대한 레이블 데이터가 필요하며, 이는 종종 실용적이지 않으며 확장 가능성을 제한합니다.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e접근:\u003c/strong\u003e 본 보고서는 합성 데이터셋을 활용한 ZSL의 실용적 구현을 탐구하며, 특성 엔지니어링, 모델 훈련, 하이퍼파라미터 최적화 및 평가 지표에 대해 자세히 다룹니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e결과: 모델은 99.5%라는 높은 정확도를 달성하여, 혼동 행렬, 예측 분포도, 교차 검증 결과를 통해 보이지 않은 데이터를 분류하는 데 우수한 성능을 나타냈습니다.\u003c/p\u003e\n\u003cp\u003e결론: 제로샷 학습은 전통적인 지도 학습의 제약을 극복하는 데 강력한 도구로 작용하며, 강력한 일반화 능력과 다양한 실제 응용 가능성을 보여줍니다.\u003c/p\u003e\n\u003cp\u003e키워드: 제로샷 학습, 머신러닝 모델, 합성 데이터셋, 피처 엔지니어링, 하이퍼파라미터 최적화.\u003c/p\u003e\n\u003ch1\u003e소개\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e박물관에 들어가 새로운 동물을 그린 그림을 보게 된다면 어떤 기술들을 가지고 있는지를 살펴보면서, 비늘, 날개, 그리고 뱀 모양의 몸 등의 특징을 보고, 이것이 바로 용이라는 것을 유추할 수 있습니다. 용을 한번도 본 적이 없더라도 설명을 토대로 추론하고 인식하는 인간의 능력은 바로 인공 지능의 Zero-shot learning (ZSL)이 목표로 하는 것입니다. 데이터가 풍부하지만 항상 레이블이 되어있지 않은 세계에서, ZSL은 기계가 학습하는 방식의 한계를 뛰어넘어, 그동안 본 적 없는 물체를 식별하고 분류할 수 있도록 가능하게 합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png\" alt=\"그림\"\u003e\u003c/p\u003e\n\u003ch1\u003eZero-Shot Learning의 이해\u003c/h1\u003e\n\u003cp\u003eZero-shot learning은 기계 학습에서 혁신적인 방법으로, 모델이 직접적으로 그러한 특정 클래스에 대해 훈련을 받지 않아도 새로운 객체 클래스를 인식하도록 설계됩니다. 기존의 기계 학습 모델은 인식해야 하는 각 카테고리에 대해 많은 레이블이 달린 데이터가 필요합니다. 그러나 ZSL은 속성, 텍스트 설명 또는 임베딩과 같은 의미 정보를 활용하여 새롭고 보지 못한 클래스에 대해 합리적인 추측을 할 수 있도록합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e제로샷 러닝은 어떻게 작동하나요?\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e특성 추출: 모델은 훈련 단계에서 알려진 클래스에서 특성을 추출합니다. 이는 주로 이미지 인식 작업에는 사전 훈련된 합성곱 신경망(CNNs) 또는 텍스트에는 트랜스포머 모델을 사용하여 수행됩니다.\u003c/li\u003e\n\u003cli\u003e의미 임베딩: 보여지거나 보이지 않는 각 클래스는 의미 벡터와 연관됩니다. 이러한 벡터는 속성(예: 호랑이를 줄무늬가 있는 동물, 네 다리가 있고 날카로운 이빨을 가진 동물로 설명)에서 파생되거나 Word2Vec 또는 GloVe와 같은 단어 임베딩을 통해 처리된 텍스트 설명에서 얻을 수 있습니다.\u003c/li\u003e\n\u003cli\u003e매핑 함수: ZSL의 핵심은 시각적 특성을 의미 임베딩에 연결하는 매핑 함수에 있습니다. 모델이 새로운 이미지나 텍스트를 만나면 추출된 특성을 가장 가까운 의미 벡터에 매핑하여 보이지 않는 클래스를 인식하고 분류할 수 있게 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e제로샷 러닝의 적용 분야\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e이미지 인식: ZSL은 야생 동물 모니터링과 같은 분야에서 설명적 속성을 기반으로 새로운 종을 식별하는 데 도움을 줄 수 있습니다. 예를 들어, 일반 동물에 대해 훈련된 모델은 해당 특성을 이해하여 새로 발견된 종을 인식할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e자연어 처리(NLP): 설명에서 맥락적 정보를 사용하여, ZSL은 모델이 명시적으로 훈련받지 않은 주제에 대한 텍스트 분류나 감정 분석과 같은 작업을 처리할 수 있게 합니다.\u003c/li\u003e\n\u003cli\u003e추천 시스템: ZSL은 훈련 데이터에 없는 항목을 제안하여 사용자 경험과 참여를 향상시키는 방식으로 추천 시스템을 개선합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e도전과 향후 방향\u003c/h1\u003e\n\u003cp\u003e제로샷 학습은 엄청난 잠재력을 제공하지만 도전도 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e의미적 간극: 시각적 특징과 의미적 표현 간의 불일치는 잘못된 매핑으로 이어질 수 있습니다. 이 간극을 줄이는 것은 정확도 향상에 중요합니다.\u003c/li\u003e\n\u003cli\u003e속성 종속성: ZSL의 효과성은 의미적 특성이나 설명의 품질과 포괄성에 크게 의존합니다.\u003c/li\u003e\n\u003cli\u003e확장성: 많은 클래스를 인식하는 것은 계산적인 도전으로 남아 있으며, 효율적인 알고리즘과 견고한 매핑 함수가 필요합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e연구자들은 이러한 도전에 대한 해결책을 적극적으로 탐구하고 있습니다. 개선된 임베딩 기술, 제로샷 및 퓨샷 학습을 결합한 하이브리드 모델, 그리고 보다 견고한 매핑 함수는 개발 중인 전략 중 일부입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e실용 예시\u003c/h1\u003e\n\u003cp\u003e아래에는 합성 데이터셋을 활용한 제로샷 러닝을 보여주는 포괄적인 파이썬 코드 블록이 있습니다. 예시에는 특성 기술, 특성 엔지니어링, 하이퍼파라미터 최적화, 교차 검증, 모델 예측, 메트릭, 플롯 및 결과 해석이 포함되어 있습니다. 이 코드는 scikit-learn, numpy, pandas, matplotlib 및 seaborn 라이브러리를 사용합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# 필요한 라이브러리 가져오기\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.model_selection \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e train_test_split, GridSearchCV\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e classification_report, confusion_matrix, accuracy_score\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.preprocessing \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e StandardScaler, LabelEncoder\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.linear_model \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e LogisticRegression\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.pyplot \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e seaborn \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e sns\n\n\u003cspan class=\"hljs-comment\"\u003e# 합성 데이터셋 생성\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ecreate_synthetic_data\u003c/span\u003e():\n    np.random.seed(\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n    n_samples = \u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e\n    features = np.random.rand(n_samples, \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n    labels = (np.\u003cspan class=\"hljs-built_in\"\u003esum\u003c/span\u003e(features, axis=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e) \u003e \u003cspan class=\"hljs-number\"\u003e2.5\u003c/span\u003e).astype(\u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e)\n    \n    \u003cspan class=\"hljs-comment\"\u003e# DataFrame으로 변환\u003c/span\u003e\n    df = pd.DataFrame(features, columns=[\u003cspan class=\"hljs-string\"\u003ef'feature_\u003cspan class=\"hljs-subst\"\u003e{i}\u003c/span\u003e'\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e)])\n    df[\u003cspan class=\"hljs-string\"\u003e'label'\u003c/span\u003e] = labels\n    \n    \u003cspan class=\"hljs-comment\"\u003e# 제로샷 러닝을 위한 의미 정보 추가\u003c/span\u003e\n    semantic_info = {\n        \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'low_sum'\u003c/span\u003e,\n        \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'high_sum'\u003c/span\u003e\n    }\n    \n    df[\u003cspan class=\"hljs-string\"\u003e'semantic_label'\u003c/span\u003e] = df[\u003cspan class=\"hljs-string\"\u003e'label'\u003c/span\u003e].\u003cspan class=\"hljs-built_in\"\u003emap\u003c/span\u003e(semantic_info)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e df\n\n\u003cspan class=\"hljs-comment\"\u003e# 합성 데이터셋 생성\u003c/span\u003e\ndf = create_synthetic_data()\n\n\u003cspan class=\"hljs-comment\"\u003e# 특성 엔지니어링: 특성 표준화\u003c/span\u003e\nscaler = StandardScaler()\nX = scaler.fit_transform(df.drop([\u003cspan class=\"hljs-string\"\u003e'label'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'semantic_label'\u003c/span\u003e], axis=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\ny = df[\u003cspan class=\"hljs-string\"\u003e'label'\u003c/span\u003e]\n\n\u003cspan class=\"hljs-comment\"\u003e# 데이터를 학습 및 테스트 세트로 분할\u003c/span\u003e\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 제로샷 러닝 설정\u003c/span\u003e\nsemantic_labels = df[\u003cspan class=\"hljs-string\"\u003e'semantic_label'\u003c/span\u003e].unique()\nsemantic_embeddings = {\n    \u003cspan class=\"hljs-string\"\u003e'low_sum'\u003c/span\u003e: np.array([\u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e]),\n    \u003cspan class=\"hljs-string\"\u003e'high_sum'\u003c/span\u003e: np.array([\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e])\n}\n\n\u003cspan class=\"hljs-comment\"\u003e# GridSearchCV를 사용한 하이퍼파라미터 최적화\u003c/span\u003e\nparam_grid = {\n    \u003cspan class=\"hljs-string\"\u003e'C'\u003c/span\u003e: [\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e],\n    \u003cspan class=\"hljs-string\"\u003e'solver'\u003c/span\u003e: [\u003cspan class=\"hljs-string\"\u003e'liblinear'\u003c/span\u003e]\n}\n\nmodel = LogisticRegression()\ngrid_search = GridSearchCV(model, param_grid, cv=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, scoring=\u003cspan class=\"hljs-string\"\u003e'accuracy'\u003c/span\u003e)\ngrid_search.fit(X_train, y_train)\n\n\u003cspan class=\"hljs-comment\"\u003e# Grid search에서 최적의 모델\u003c/span\u003e\nbest_model = grid_search.best_estimator_\n\n\u003cspan class=\"hljs-comment\"\u003e# 예측\u003c/span\u003e\ny_pred = best_model.predict(X_test)\n\n\u003cspan class=\"hljs-comment\"\u003e# 평가 메트릭\u003c/span\u003e\naccuracy = accuracy_score(y_test, y_pred)\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"정확도:\"\u003c/span\u003e, accuracy)\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"분류 보고서:\\n\"\u003c/span\u003e, classification_report(y_test, y_pred))\n\n\u003cspan class=\"hljs-comment\"\u003e# 혼동 행렬\u003c/span\u003e\nconf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(conf_matrix, annot=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e, fmt=\u003cspan class=\"hljs-string\"\u003e'd'\u003c/span\u003e, cmap=\u003cspan class=\"hljs-string\"\u003e'Blues'\u003c/span\u003e)\nplt.xlabel(\u003cspan class=\"hljs-string\"\u003e'예측 라벨'\u003c/span\u003e)\nplt.ylabel(\u003cspan class=\"hljs-string\"\u003e'실제 라벨'\u003c/span\u003e)\nplt.title(\u003cspan class=\"hljs-string\"\u003e'혼동 행렬'\u003c/span\u003e)\nplt.show()\n\n\u003cspan class=\"hljs-comment\"\u003e# 결과 시각화\u003c/span\u003e\nplt.scatter(X_test[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X_test[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], c=y_pred, cmap=\u003cspan class=\"hljs-string\"\u003e'viridis'\u003c/span\u003e, marker=\u003cspan class=\"hljs-string\"\u003e'o'\u003c/span\u003e)\nplt.title(\u003cspan class=\"hljs-string\"\u003e'제로샷 러닝 예측'\u003c/span\u003e)\nplt.xlabel(\u003cspan class=\"hljs-string\"\u003e'특성 1'\u003c/span\u003e)\nplt.ylabel(\u003cspan class=\"hljs-string\"\u003e'특성 2'\u003c/span\u003e)\nplt.show()\n\n\u003cspan class=\"hljs-comment\"\u003e# 결과 해석\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# 합성 데이터를 사용하여 제로샷 러닝 모델의 성능을 확인할 수 있습니다.\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# 혼동 행렬 및 분류 보고서를 통해 정확도 및 분류 성능을 파악할 수 있습니다.\u003c/span\u003e\n\n\u003cspan class=\"hljs-comment\"\u003e# 교차 검증 결과\u003c/span\u003e\nresults = pd.DataFrame(grid_search.cv_results_)\nresults.plot(kind=\u003cspan class=\"hljs-string\"\u003e'bar'\u003c/span\u003e, x=\u003cspan class=\"hljs-string\"\u003e'param_C'\u003c/span\u003e, y=\u003cspan class=\"hljs-string\"\u003e'mean_test_score'\u003c/span\u003e, yerr=\u003cspan class=\"hljs-string\"\u003e'std_test_score'\u003c/span\u003e, capsize=\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e)\nplt.xlabel(\u003cspan class=\"hljs-string\"\u003e'C (정규화 매개변수)'\u003c/span\u003e)\nplt.ylabel(\u003cspan class=\"hljs-string\"\u003e'평균 테스트 점수'\u003c/span\u003e)\nplt.title(\u003cspan class=\"hljs-string\"\u003e'교차 검증 결과'\u003c/span\u003e)\nplt.show()\n\n\u003cspan class=\"hljs-comment\"\u003e# 마무리\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# 제로샷 러닝은 의미 정보를 기반으로 보이지 않는 클래스를 예측할 수 있는 모델을 만듭니다.\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# 합성 예시는 제로샷 러닝 모델이 제공된 속성을 기반으로 일반화할 수 있는 능력을 보여줍니다.\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 코드는 합성 데이터셋을 활용하여 제로샷 러닝의 실용적인 예시를 제공하며, 데이터 생성부터 평가 및 결과 시각화까지의 전체 머신 러닝 파이프라인을 다룹니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e결과 해석\u003c/h2\u003e\n\u003cp\u003e혼동 행렬: 혼동 행렬은 분류 모델의 성능을 시각적으로 보여줍니다. 제공된 혼동 행렬에서:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e모형은 0 클래스의 경우 89개 및 1 클래스의 경우 110건을 정확하게 분류했습니다.\u003c/li\u003e\n\u003cli\u003e1 클래스의 하나의 사례가 0 클래스로 분류되는 잘못된 분류가 있었습니다.\u003c/li\u003e\n\u003cli\u003e0 클래스가 1 클래스로 잘못 분류된 경우는 없었습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이는 모델의 예측 정확도가 높음을 나타냅니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_1.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e정확도: 0.995 모델은 99.5%의 정확도를 달성했습니다. 이는 예측 중 99.5%가 정확했음을 나타냅니다. 이 뛰어난 정확도 점수는 모델이 이 데이터셋에서 매우 잘 수행한다는 것을 시사합니다.\u003c/p\u003e\n\u003cp\u003e분류 보고서: 분류 보고서는 각 클래스에 대한 정밀도, 재현율 및 f1-점수를 포함한 상세한 지표를 제공합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e정밀도: 두 클래스 모두에 대한 정밀도가 매우 높습니다 (클래스 0의 경우 0.99, 클래스 1의 경우 1.00), 이는 모델이 매우 낮은 오검출률을 가지고 있다는 것을 나타냅니다.\u003c/li\u003e\n\u003cli\u003e재현율: 두 클래스 모두에 대한 재현율도 매우 높습니다 (클래스 0의 경우 1.00, 클래스 1의 경우 0.99), 이는 모델이 매우 낮은 오물체률을 가지고 있다는 것을 나타냅니다.\u003c/li\u003e\n\u003cli\u003ef1-점수: 정밀도와 재현율의 조화 평균인 f1-점수는 클래스 0의 경우 0.99, 클래스 1의 경우 1.00으로, 두 클래스에 대한 균형 잡힌 정확한 모델 성능을 시사합니다.\u003c/li\u003e\n\u003cli\u003e지원: 지원 값(클래스 0의 경우 89, 클래스 1의 경우 111)은 테스트 데이터셋의 각 클래스에 대한 실제 인스턴스를 나타냅니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e제로샷 러닝 예측 산점도: 산점도는 제로샷 러닝 예측을 시각화합니다. 각 포인트는 테스트 인스턴스를 나타내며, 다른 색상은 예측된 클래스를 나타냅니다. 포인트들의 명확한 군집화는 모델이 특징에 기반하여 두 클래스를 구별하는 능력을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_2.png\" alt=\"Zero-Shot Learning Predictions Scatter Plot\"\u003e\u003c/p\u003e\n\u003cp\u003e교차 검증 결과: 막대 차트는 정규화 매개변수 CCC의 다른 값에 대한 교차 검증에서의 평균 테스트 점수를 보여줍니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e모델은 모든 테스트된 CCC 값에 대해 일관된 우수한 성능을 보이며, 평균 테스트 점수는 1.0에 가깝습니다.\u003c/li\u003e\n\u003cli\u003e오차 막대는 최소 테스트 점수의 표준 편차를 나타내며, 모델의 성능이 안정적이고 CCC의 선택에 지나치게 민감하지 않음을 시사합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_3.png\" alt=\"Zero-Shot Learning Approach\"\u003e\u003c/p\u003e\n\u003cp\u003e최종 생각:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e모델은 뛰어난 성능을 보여주며 높은 정확도, 정밀도, 재현율 및 F1 점수를 가지고 있습니다.\u003c/li\u003e\n\u003cli\u003e혼동 행렬과 산점도는 모델의 능력을 추가로 확인하여 테스트 인스턴스를 최소 오류로 올바르게 분류합니다.\u003c/li\u003e\n\u003cli\u003e교차 검증 결과는 견고한 모델이 다양한 하이퍼파라미터 설정에서 잘 수행되는 것을 나타냅니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 zero-shot 학습 접근 방식은 합성 데이터셋을 사용하더라도 훌륭한 결과를 보여주며 의미 정보를 기반으로 보이지 않는 클래스를 정확하게 일반화하고 예측할 수 있는 모델의 능력을 강조합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e제로샷 학습은 머신 러닝에서 큰 발전을 의미하며 직접적인 경험 없이 새로운 개념을 일반화하고 인식하는 인간의 능력을 반영합니다. 우리가 제로샷 학습 기술을 계속 발전시키고 향상시킬수록, 더 유연하고 확장 가능하며 동적인 현실 세계 환경에서 작동할 수 있는 AI 시스템을 만들기에 더 근접해집니다. AI의 미래는 배우고 적응하는 능력에 있으며, 제로샷 학습은 이 방향으로의 중요한 한걸음입니다.\u003c/p\u003e\n\u003cp\u003e여러분의 의견을 듣고 싶습니다! 제로샷 학습이 귀하의 산업에서 AI의 미래를 어떻게 변화시킬 것으로 보십니까? 아래 댓글에 의견과 경험을 공유해주시고, 이 혁신적인 기술의 끝없는 가능성에 대한 대화를 이끌어봅시다!\u003c/p\u003e\n\u003ch1\u003e참고문헌\u003c/h1\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown"},"buildId":"GnJ8pEcO5t2Vzpus740Q5","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>