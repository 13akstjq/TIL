<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Scikit-learn 2024 시각화 가이드 모델을 이해하기 쉽게 만드는 방법 | TIL</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://13akstjq.github.io/TIL//post/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Scikit-learn 2024 시각화 가이드 모델을 이해하기 쉽게 만드는 방법 | TIL" data-gatsby-head="true"/><meta property="og:title" content="Scikit-learn 2024 시각화 가이드 모델을 이해하기 쉽게 만드는 방법 | TIL" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://TIL.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://13akstjq.github.io/TIL//post/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak" data-gatsby-head="true"/><meta name="twitter:title" content="Scikit-learn 2024 시각화 가이드 모델을 이해하기 쉽게 만드는 방법 | TIL" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | TIL" data-gatsby-head="true"/><meta name="article:published_time" content="2024-07-09 20:32" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/TIL/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/TIL/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/TIL/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/TIL/favicons/favicon-96x96.png"/><link rel="icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/TIL/favicons/browserconfig.xml"/><link rel="preload" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/TIL/_next/static/css/0eef537492fed77a.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/0eef537492fed77a.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/TIL/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/TIL/_next/static/chunks/webpack-21ffe88bdca56cba.js" defer=""></script><script src="/TIL/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/TIL/_next/static/chunks/main-a5eeabb286676ce6.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/TIL/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/TIL/_next/static/chunks/348-02483b66b493dd81.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/post/%5Bslug%5D-8ded8b979ba73586.js" defer=""></script><script src="/TIL/_next/static/KUC9M_yIlA1Ugo01xmkHL/_buildManifest.js" defer=""></script><script src="/TIL/_next/static/KUC9M_yIlA1Ugo01xmkHL/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/TIL">TIL</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/TIL/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Scikit-learn 2024 시각화 가이드 모델을 이해하기 쉽게 만드는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Scikit-learn 2024 시각화 가이드 모델을 이해하기 쉽게 만드는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">TIL</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jul 9, 2024</span><span class="posts_reading_time__f7YPP">19<!-- --> min read</span></span></div></div></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>아래는 제가 요청하신 테이블을 Markdown 형식으로 변경한 것입니다.</p>













<table><thead><tr><th>Header One</th><th>Header Two</th></tr></thead><tbody><tr><td>Content One</td><td>Content Two</td></tr></tbody></table>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_1.png" alt="Scikit-learn Visualization Guide Making Models Speak"></p>
<p>이 그래프를 보면 동일한 데이터 세트에서 오른쪽 모델이 더 일반화하는 데 더 좋다는 것을 알 수 있습니다.</p>
<p>대부분의 머신러닝 서적은 시각화에 대해 matplotlib 코드를 사용하기를 선호합니다. 이는 다음과 같은 문제를 야기합니다:</p>
<ul>
<li>Matplotlib로 그리기에 대해 많은 내용을 배워야 합니다.</li>
<li>플로팅 코드가 노트북을 가득 채우므로 읽기 어려워집니다.</li>
<li>때로는 비즈니스 환경에서 이상적이지 않은 타사 라이브러리가 필요할 수 있습니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>좋은 소식이에요! Scikit-learn은 이제 Display 클래스를 제공하며 from_estimator 및 from_predictions과 같은 메소드를 사용하여 다양한 상황에서 그래프를 그리기가 훨씬 쉬워졌어요.</p>
<p>궁금하신가요? 이 멋진 API를 보여드릴게요.</p>
<h1>Scikit-learn Display API 소개</h1>
<h2>사용 가능한 API를 찾으려면 utils.discovery.all_displays를 사용하세요</h2>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Scikit-learn (sklearn)은 항상 새 릴리스에서 Display API를 추가하기 때문에 당신의 버전에서 무엇을 사용할 수 있는지 알아두는 것이 중요합니다.</p>
<p>Sklearn의 utils.discovery.all_displays를 사용하면 사용할 수 있는 클래스들을 볼 수 있습니다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> sklearn.utils.discovery <span class="hljs-keyword">import</span> all_displays

displays = all_displays()
displays
</code></pre>
<p>예를 들어, 내 Scikit-learn 1.4.0에서 이러한 클래스들을 사용할 수 있습니다:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">[
  (<span class="hljs-string">"CalibrationDisplay"</span>, sklearn.<span class="hljs-property">calibration</span>.<span class="hljs-property">CalibrationDisplay</span>),
  (<span class="hljs-string">"ConfusionMatrixDisplay"</span>, sklearn.<span class="hljs-property">metrics</span>.<span class="hljs-property">_plot</span>.<span class="hljs-property">confusion_matrix</span>.<span class="hljs-property">ConfusionMatrixDisplay</span>),
  (<span class="hljs-string">"DecisionBoundaryDisplay"</span>, sklearn.<span class="hljs-property">inspection</span>.<span class="hljs-property">_plot</span>.<span class="hljs-property">decision_boundary</span>.<span class="hljs-property">DecisionBoundaryDisplay</span>),
  (<span class="hljs-string">"DetCurveDisplay"</span>, sklearn.<span class="hljs-property">metrics</span>.<span class="hljs-property">_plot</span>.<span class="hljs-property">det_curve</span>.<span class="hljs-property">DetCurveDisplay</span>),
  (<span class="hljs-string">"LearningCurveDisplay"</span>, sklearn.<span class="hljs-property">model_selection</span>.<span class="hljs-property">_plot</span>.<span class="hljs-property">LearningCurveDisplay</span>),
  (<span class="hljs-string">"PartialDependenceDisplay"</span>, sklearn.<span class="hljs-property">inspection</span>.<span class="hljs-property">_plot</span>.<span class="hljs-property">partial_dependence</span>.<span class="hljs-property">PartialDependenceDisplay</span>),
  (<span class="hljs-string">"PrecisionRecallDisplay"</span>, sklearn.<span class="hljs-property">metrics</span>.<span class="hljs-property">_plot</span>.<span class="hljs-property">precision_recall_curve</span>.<span class="hljs-property">PrecisionRecallDisplay</span>),
  (<span class="hljs-string">"PredictionErrorDisplay"</span>, sklearn.<span class="hljs-property">metrics</span>.<span class="hljs-property">_plot</span>.<span class="hljs-property">regression</span>.<span class="hljs-property">PredictionErrorDisplay</span>),
  (<span class="hljs-string">"RocCurveDisplay"</span>, sklearn.<span class="hljs-property">metrics</span>.<span class="hljs-property">_plot</span>.<span class="hljs-property">roc_curve</span>.<span class="hljs-property">RocCurveDisplay</span>),
  (<span class="hljs-string">"ValidationCurveDisplay"</span>, sklearn.<span class="hljs-property">model_selection</span>.<span class="hljs-property">_plot</span>.<span class="hljs-property">ValidationCurveDisplay</span>),
];
</code></pre>
<h2>decision_boundaries를 위해 inspection.DecisionBoundaryDisplay 사용하기</h2>
<p>decision boundaries로 시작해보죠.</p>
<p>matplotlib를 사용하여 draw 하는 경우, 번거롭습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>np.linspace을 사용하여 좌표 범위 설정;</li>
<li>plt.meshgrid를 사용하여 그리드 계산;</li>
<li>plt.contourf를 사용하여 결정 경계를 채우기;</li>
<li>그런 다음 plt.scatter를 사용하여 데이터 포인트를 플로팅합니다.</li>
</ul>
<p>이제 inspection.DecisionBoundaryDisplay를 사용하여이 프로세스를 간소화 할 수 있습니다:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">inspection</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">DecisionBoundaryDisplay</span>
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">datasets</span> <span class="hljs-keyword">import</span> load_iris
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">svm</span> <span class="hljs-keyword">import</span> <span class="hljs-variable constant_">SVC</span>
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">pipeline</span> <span class="hljs-keyword">import</span> make_pipeline
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">preprocessing</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">StandardScaler</span>
<span class="hljs-keyword">import</span> matplotlib.<span class="hljs-property">pyplot</span> <span class="hljs-keyword">as</span> plt

iris = <span class="hljs-title function_">load_iris</span>(as_frame=<span class="hljs-title class_">True</span>)
X = iris.<span class="hljs-property">data</span>[[<span class="hljs-string">'petal length (cm)'</span>, <span class="hljs-string">'petal width (cm)'</span>]]
y = iris.<span class="hljs-property">target</span>


svc_clf = <span class="hljs-title function_">make_pipeline</span>(<span class="hljs-title class_">StandardScaler</span>(),
                        <span class="hljs-title function_">SVC</span>(kernel=<span class="hljs-string">'linear'</span>, C=<span class="hljs-number">1</span>))
svc_clf.<span class="hljs-title function_">fit</span>(X, y)

display = <span class="hljs-title class_">DecisionBoundaryDisplay</span>.<span class="hljs-title function_">from_estimator</span>(svc_clf, X,
                                                 grid_resolution=<span class="hljs-number">1000</span>,
                                                 xlabel=<span class="hljs-string">"Petal length (cm)"</span>,
                                                 ylabel=<span class="hljs-string">"Petal width (cm)"</span>)
plt.<span class="hljs-title function_">scatter</span>(X.<span class="hljs-property">iloc</span>[:, <span class="hljs-number">0</span>], X.<span class="hljs-property">iloc</span>[:, <span class="hljs-number">1</span>], c=y, edgecolors=<span class="hljs-string">'w'</span>)
plt.<span class="hljs-title function_">title</span>(<span class="hljs-string">"Decision Boundary"</span>)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<p>이 그림에서 최종 효과를 확인하십시오:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_2.png">
<p>기억해 주세요. Display 기능은 2D만 그릴 수 있으므로 데이터가 두 개의 특성 또는 축소된 차원만 가지고 있는지 확인하세요.</p>
<h2>확률 보정을 위해 calibration.CalibrationDisplay 사용</h2>
<p>분류 모델을 비교하기 위해 확률 보정 곡선은 모델이 예측에 자신감을 가지고 있는지를 보여줍니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>CalibrationDisplay는 모델의 predict_proba를 사용합니다. Support Vector Machine을 사용하는 경우 확률을 True로 설정해주세요:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">calibration</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">CalibrationDisplay</span>
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">model_selection</span> <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">datasets</span> <span class="hljs-keyword">import</span> make_classification
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">ensemble</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">HistGradientBoostingClassifier</span>

X, y = <span class="hljs-title function_">make_classification</span>(n_samples=<span class="hljs-number">1000</span>,
                           n_classes=<span class="hljs-number">2</span>, n_features=<span class="hljs-number">5</span>,
                           random_state=<span class="hljs-number">42</span>)
X_train, X_test, y_train, y_test = <span class="hljs-title function_">train_test_split</span>(X, y,
                                            test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">42</span>)
proba_clf = <span class="hljs-title function_">make_pipeline</span>(<span class="hljs-title class_">StandardScaler</span>(),
                          <span class="hljs-title function_">SVC</span>(kernel=<span class="hljs-string">"rbf"</span>, gamma=<span class="hljs-string">"auto"</span>,
                              C=<span class="hljs-number">10</span>, probability=<span class="hljs-title class_">True</span>))
proba_clf.<span class="hljs-title function_">fit</span>(X_train, y_train)

<span class="hljs-title class_">CalibrationDisplay</span>.<span class="hljs-title function_">from_estimator</span>(proba_clf,
                                            X_test, y_test)

hist_clf = <span class="hljs-title class_">HistGradientBoostingClassifier</span>()
hist_clf.<span class="hljs-title function_">fit</span>(X_train, y_train)

ax = plt.<span class="hljs-title function_">gca</span>()
<span class="hljs-title class_">CalibrationDisplay</span>.<span class="hljs-title function_">from_estimator</span>(hist_clf,
                                  X_test, y_test,
                                  ax=ax)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_3.png">
<h2>혼동 행렬에 대한 metrics.ConfusionMatrixDisplay 사용하기</h2>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>분류 모델을 평가하고 불균형 데이터를 다룰 때, 우리는 정밀도와 재현율을 살펴봅니다.</p>
<p>이들은 TP, FP, TN, FN으로 나뉘며, 혼동 행렬을 구성합니다.</p>
<p>혼동 행렬을 그리려면 metrics.ConfusionMatrixDisplay를 사용하세요. 이렇게 그림을 그릴 수 있고요, 이미 잘 알려져 있어서 자세하게 설명은 생략할게요.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">datasets</span> <span class="hljs-keyword">import</span> fetch_openml
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">ensemble</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">RandomForestClassifier</span>
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">metrics</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">ConfusionMatrixDisplay</span>

digits = <span class="hljs-title function_">fetch_openml</span>(<span class="hljs-string">'mnist_784'</span>, version=<span class="hljs-number">1</span>)
X, y = digits.<span class="hljs-property">data</span>, digits.<span class="hljs-property">target</span>
rf_clf = <span class="hljs-title class_">RandomForestClassifier</span>(max_depth=<span class="hljs-number">5</span>, random_state=<span class="hljs-number">42</span>)
rf_clf.<span class="hljs-title function_">fit</span>(X, y)

<span class="hljs-title class_">ConfusionMatrixDisplay</span>.<span class="hljs-title function_">from_estimator</span>(rf_clf, X, y)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>아래는 이미지 링크입니다:</p>
<p><img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_4.png" alt="Scikit-learn Visualization Guide"></p>
<h2>metrics.RocCurveDisplay 및 metrics.DetCurveDisplay</h2>
<p>이 두 가지가 함께 소개되는 이유는 종종 측정할 때 함께 사용하기 때문입니다.</p>
<p>RocCurveDisplay는 모델의 TPR 및 FPR을 비교합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이진 분류의 경우, 낮은 FPR과 높은 TPR을 원하기 때문에 좌상단이 가장 좋습니다. Roc 곡선은 이 쪽으로 휘어집니다.</p>
<p>Roc 곡선이 좌상단에 근접하여 유지되기 때문에 우하단이 비어 있는데, 이는 모델 간 차이를 파악하기 어렵게 만듭니다.</p>
<p>그래서 우리는 또한 FNR과 FPR로 Det 곡선을 그리는 DetCurveDisplay를 사용합니다. 이는 Roc 곡선보다 명확하게 만들어주는 데 더 많은 공간을 사용합니다.</p>
<p>Det 곡선의 완벽한 지점은 좌하단입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">metrics</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">RocCurveDisplay</span>
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">metrics</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">DetCurveDisplay</span>

X, y = <span class="hljs-title function_">make_classification</span>(n_samples=<span class="hljs-number">10_000</span>, n_features=<span class="hljs-number">5</span>,
                           n_classes=<span class="hljs-number">2</span>, n_informative=<span class="hljs-number">2</span>)
X_train, X_test, y_train, y_test = <span class="hljs-title function_">train_test_split</span>(X, y,
                                             test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">42</span>,
                                                   stratify=y)


classifiers = {
    <span class="hljs-string">"SVC"</span>: <span class="hljs-title function_">make_pipeline</span>(<span class="hljs-title class_">StandardScaler</span>(),
                        <span class="hljs-title function_">SVC</span>(kernel=<span class="hljs-string">"linear"</span>, C=<span class="hljs-number">0.1</span>, random_state=<span class="hljs-number">42</span>)),
    <span class="hljs-string">"Random Forest"</span>: <span class="hljs-title class_">RandomForestClassifier</span>(max_depth=<span class="hljs-number">5</span>, random_state=<span class="hljs-number">42</span>)
}

fig, [ax_roc, ax_det] = plt.<span class="hljs-title function_">subplots</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">4</span>))
<span class="hljs-keyword">for</span> name, clf <span class="hljs-keyword">in</span> classifiers.<span class="hljs-title function_">items</span>():
    clf.<span class="hljs-title function_">fit</span>(X_train, y_train)

    <span class="hljs-title class_">RocCurveDisplay</span>.<span class="hljs-title function_">from_estimator</span>(clf, X_test, y_test, ax=ax_roc, name=name)
    <span class="hljs-title class_">DetCurveDisplay</span>.<span class="hljs-title function_">from_estimator</span>(clf, X_test, y_test, ax=ax_det, name=name)
</code></pre>
<img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_5.png">
<h2>Using metrics.PrecisionRecallDisplay to adjust thresholds</h2>
<p>With imbalanced data, you might want to shift recall and precision.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>이메일 사기를 방지하려면 고정도가 필요합니다.</li>
<li>질병 선별을 위해서는 더 많은 사례를 포착하기 위해 고회수가 필요합니다.</li>
</ul>
<p>임계값을 조정할 수 있지만, 적절한 양이 무엇인지 궁금하신가요?</p>
<p>여기서 metrics.PrecisionRecallDisplay가 도움이 될 수 있습니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> xgboost <span class="hljs-keyword">import</span> <span class="hljs-title class_">XGBClassifier</span>
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">datasets</span> <span class="hljs-keyword">import</span> load_wine
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">metrics</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">PrecisionRecallDisplay</span>

wine = <span class="hljs-title function_">load_wine</span>()
X, y = wine.<span class="hljs-property">data</span>[wine.<span class="hljs-property">target</span>&#x3C;=<span class="hljs-number">1</span>], wine.<span class="hljs-property">target</span>[wine.<span class="hljs-property">target</span>&#x3C;=<span class="hljs-number">1</span>]
X_train, X_test, y_train, y_test = <span class="hljs-title function_">train_test_split</span>(X, y, test_size=<span class="hljs-number">0.3</span>, stratify=y, random_state=<span class="hljs-number">42</span>)

xgb_clf = <span class="hljs-title class_">XGBClassifier</span>()
xgb_clf.<span class="hljs-title function_">fit</span>(X_train, y_train)

<span class="hljs-title class_">PrecisionRecallDisplay</span>.<span class="hljs-title function_">from_estimator</span>(xgb_clf, X_test, y_test)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_6.png">
<p>Scikit-learn의 디자인을 따르는 모델은 여기처럼 그릴 수 있습니다. 편리하죠?</p>
<h2>회귀 모델에 metrics.PredictionErrorDisplay 사용하기</h2>
<p>우리는 분류에 대해 이야기했었는데, 이제 회귀에 대해 이야기해볼게요.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>사이킷런의 metrics.PredictionErrorDisplay는 회귀 모델을 평가하는 데 도움이 됩니다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVR
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> PredictionErrorDisplay

rng = np.random.default_rng(<span class="hljs-number">42</span>)
X = rng.random(size=(<span class="hljs-number">200</span>, <span class="hljs-number">2</span>)) * <span class="hljs-number">10</span>
y = X[:, <span class="hljs-number">0</span>]**<span class="hljs-number">2</span> + <span class="hljs-number">5</span> * X[:, <span class="hljs-number">1</span>] + <span class="hljs-number">10</span> + rng.normal(loc=<span class="hljs-number">0.0</span>, scale=<span class="hljs-number">0.1</span>, size=(<span class="hljs-number">200</span>,))

reg = make_pipeline(StandardScaler(), SVR(kernel=<span class="hljs-string">'linear'</span>, C=<span class="hljs-number">10</span>))
reg.fit(X, y)

fig, axes = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>))
PredictionErrorDisplay.from_estimator(reg, X, y, ax=axes[<span class="hljs-number">0</span>], kind=<span class="hljs-string">"actual_vs_predicted"</span>)
PredictionErrorDisplay.from_estimator(reg, X, y, ax=axes[<span class="hljs-number">1</span>], kind=<span class="hljs-string">"residual_vs_predicted"</span>)
plt.show()
</code></pre>
<p><img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_7.png" alt="Image"></p>
<p>그림에서와 같이 두 종류의 그래프를 그릴 수 있습니다. 왼쪽 그래프는 예측 대 실제 값 비교를 보여주며, 선형 회귀 분석에 적합합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>하지만 모든 데이터가 완벽하게 선형적이지는 않습니다. 그럴 때는 적절한 그래프를 사용하세요.</p>
<p>실제 대 예측 차이인 잔차 도표를 그려보세요.</p>
<p>이 도표의 바나나 모양은 데이터가 선형 회귀에 맞지 않을 수 있다는 것을 시사합니다.</p>
<p>선형에서 rbf 커널로 전환하는 것이 도움이 될 수 있습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">reg = <span class="hljs-title function_">make_pipeline</span>(<span class="hljs-title class_">StandardScaler</span>(), <span class="hljs-title function_">SVR</span>((kernel = <span class="hljs-string">"rbf"</span>), (C = <span class="hljs-number">10</span>)));
</code></pre>
<p><img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_8.png" alt="Image"></p>
<p>이렇게 rbf를 사용하면 잔차 플롯이 더 나아 보여요.</p>
<h2>학습 곡선에 model_selection.LearningCurveDisplay 사용하기</h2>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>성능을 평가한 후 LearningCurveDisplay를 사용하여 최적화를 살펴봅시다.</p>
<p>첫 번째로, 학습 곡선을 확인해봅시다. 이 모델이 다양한 학습 및 테스트 데이터로 얼마나 일반화되며, 과적합 또는 편향 문제가 있는지 살펴봅니다.</p>
<p>아래에서는 DecisionTreeClassifier와 GradientBoostingClassifier를 비교하여 학습 데이터가 변할 때 어떻게 작동하는지 살펴봅니다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier
<span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> GradientBoostingClassifier
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> LearningCurveDisplay

X, y = make_classification(n_samples=<span class="hljs-number">1000</span>, n_classes=<span class="hljs-number">2</span>, n_features=<span class="hljs-number">10</span>,
                           n_informative=<span class="hljs-number">2</span>, n_redundant=<span class="hljs-number">0</span>, n_repeated=<span class="hljs-number">0</span>)

tree_clf = DecisionTreeClassifier(max_depth=<span class="hljs-number">3</span>, random_state=<span class="hljs-number">42</span>)
gb_clf = GradientBoostingClassifier(n_estimators=<span class="hljs-number">50</span>, max_depth=<span class="hljs-number">3</span>, tol=<span class="hljs-number">1e-3</span>)

train_sizes = np.linspace(<span class="hljs-number">0.4</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">10</span>)
fig, axes = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">4</span>))
LearningCurveDisplay.from_estimator(tree_clf, X, y,
                                    train_sizes=train_sizes,
                                    ax=axes[<span class="hljs-number">0</span>],
                                    scoring=<span class="hljs-string">'accuracy'</span>)
axes[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">'DecisionTreeClassifier'</span>)
LearningCurveDisplay.from_estimator(gb_clf, X, y,
                                    train_sizes=train_sizes,
                                    ax=axes[<span class="hljs-number">1</span>],
                                    scoring=<span class="hljs-string">'accuracy'</span>)
axes[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">'GradientBoostingClassifier'</span>)
plt.show()
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_9.png">
<p>해당 그래프는 트리 기반 GradientBoostingClassifier가 훈련 데이터에서 높은 정확도를 유지하더라도, 테스트 데이터에서는 DecisionTreeClassifier와 비교하여 상당한 장점이 없다는 것을 보여줍니다.</p>
<h2>매개변수 튜닝 시 시각화를 위해 model_selection.ValidationCurveDisplay 사용</h2>
<p>그러므로, 다른 부분에 대해 일반화되지 않는 모델의 경우, 모델의 정규화 매개변수를 조정하여 성능을 미세 조정해 볼 수 있습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>전통적인 방법은 GridSearchCV 또는 Optuna와 같은 도구를 사용하여 모델을 조정하는 것이었지만, 이러한 방법은 전반적으로 성능이 가장 좋은 모델만 제공하며 조정 과정이 그다지 직관적이지 않습니다.</p>
<p>특정 매개변수를 조정하여 모델의 영향을 테스트하고 싶은 시나리오의 경우, model_selection.ValidationCurveDisplay를 사용하여 매개변수가 변경됨에 따라 모델이 어떻게 수행되는지 시각화하는 것을 권장합니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">model_selection</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">ValidationCurveDisplay</span>
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">linear_model</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">LogisticRegression</span>

param_name, param_range = <span class="hljs-string">"C"</span>, np.<span class="hljs-title function_">logspace</span>(-<span class="hljs-number">8</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>)
lr_clf = <span class="hljs-title class_">LogisticRegression</span>()

<span class="hljs-title class_">ValidationCurveDisplay</span>.<span class="hljs-title function_">from_estimator</span>(lr_clf, X, y,
                                      param_name=param_name,
                                      param_range=param_range,
                                      scoring=<span class="hljs-string">'f1_weighted'</span>,
                                      cv=<span class="hljs-number">5</span>, n_jobs=-<span class="hljs-number">1</span>)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<img src="/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_10.png">
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>아쉬운 점</h1>
<p>이러한 표시물을 모두 시도해본 후 몇 가지 아쉬운 점을 인정해야 합니다:</p>
<ul>
<li>가장 큰 아쉬움은 이러한 API의 대부분이 자세한 튜토리얼을 제공하지 않는다는 것입니다. 이것이 Scikit-learn의 철저한 문서와 비교되어 잘 알려지지 않은 이유일 것입니다.</li>
<li>이러한 API는 다양한 패키지에 흩어져 있어 한 곳에서 참조하기 어렵습니다.</li>
<li>코드는 여전히 매우 기본적입니다. 종종 Matplotlib의 API와 함께 사용하여 작업을 완료해야 합니다. 전형적인 예는 DecisionBoundaryDisplay인데, 결정 경계를 플로팅한 후에도 데이터 분포를 플로팅하기 위해 Matplotlib이 필요합니다.</li>
<li>확장하기 어렵습니다. 몇 가지 매개변수를 확인하는 메서드 외에 도구나 방법으로 내 모델 시각화 과정을 간단하게 하는 것은 힘듭니다. 많은 부분을 다시 작성해야 합니다.</li>
</ul>
<p>이러한 API들이 더 많은 관심을 받고, 버전이 업그레이드되는 과정에서 시각화 API를 사용하기가 더욱 쉬워지기를 희망합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>결론</h1>
<p>머신 러닝 여정에서 모델을 시각화로 설명하는 것은 그들을 훈련시키는 것만큼 중요합니다.</p>
<p>본문에서는 현재 버전의 scikit-learn에서 다양한 플로팅 API를 소개했습니다.</p>
<p>이러한 API를 사용하면 Matplotlib 코드를 간소화하고 학습 곡선을 완화시키며 모델 평가 프로세스를 간소화할 수 있습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>API에 대해 상세히 다루지 않아서 죄송합니다. 자세한 내용을 원하시면 관련 공식 문서를 확인해보세요.</p>
<p>이제 당신 차례입니다. 기계 학습 방법을 시각화하는 데 기대하는 점이 무엇인가요? 의견을 자유롭게 남겨 주세요.</p>
<p>이 글을 즐겼다면, 더 많은 첨단 데이터 과학 팁을 받고 싶다면 지금 구독하세요! 피드백과 질문은 언제나 환영합니다. 아래 댓글에서 토론해요!</p>
<p>이 기사는 원문이 Data Leads Future에 게재되었습니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Scikit-learn 2024 시각화 가이드 모델을 이해하기 쉽게 만드는 방법","description":"","date":"2024-07-09 20:32","slug":"2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak","content":"\n아래는 제가 요청하신 테이블을 Markdown 형식으로 변경한 것입니다.\n\n| Header One  | Header Two  |\n| ----------- | ----------- |\n| Content One | Content Two |\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Scikit-learn Visualization Guide Making Models Speak](/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_1.png)\n\n이 그래프를 보면 동일한 데이터 세트에서 오른쪽 모델이 더 일반화하는 데 더 좋다는 것을 알 수 있습니다.\n\n대부분의 머신러닝 서적은 시각화에 대해 matplotlib 코드를 사용하기를 선호합니다. 이는 다음과 같은 문제를 야기합니다:\n\n- Matplotlib로 그리기에 대해 많은 내용을 배워야 합니다.\n- 플로팅 코드가 노트북을 가득 채우므로 읽기 어려워집니다.\n- 때로는 비즈니스 환경에서 이상적이지 않은 타사 라이브러리가 필요할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n좋은 소식이에요! Scikit-learn은 이제 Display 클래스를 제공하며 from_estimator 및 from_predictions과 같은 메소드를 사용하여 다양한 상황에서 그래프를 그리기가 훨씬 쉬워졌어요.\n\n궁금하신가요? 이 멋진 API를 보여드릴게요.\n\n# Scikit-learn Display API 소개\n\n## 사용 가능한 API를 찾으려면 utils.discovery.all_displays를 사용하세요\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nScikit-learn (sklearn)은 항상 새 릴리스에서 Display API를 추가하기 때문에 당신의 버전에서 무엇을 사용할 수 있는지 알아두는 것이 중요합니다.\n\nSklearn의 utils.discovery.all_displays를 사용하면 사용할 수 있는 클래스들을 볼 수 있습니다.\n\n```python\nfrom sklearn.utils.discovery import all_displays\n\ndisplays = all_displays()\ndisplays\n```\n\n예를 들어, 내 Scikit-learn 1.4.0에서 이러한 클래스들을 사용할 수 있습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n[\n  (\"CalibrationDisplay\", sklearn.calibration.CalibrationDisplay),\n  (\"ConfusionMatrixDisplay\", sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay),\n  (\"DecisionBoundaryDisplay\", sklearn.inspection._plot.decision_boundary.DecisionBoundaryDisplay),\n  (\"DetCurveDisplay\", sklearn.metrics._plot.det_curve.DetCurveDisplay),\n  (\"LearningCurveDisplay\", sklearn.model_selection._plot.LearningCurveDisplay),\n  (\"PartialDependenceDisplay\", sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay),\n  (\"PrecisionRecallDisplay\", sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay),\n  (\"PredictionErrorDisplay\", sklearn.metrics._plot.regression.PredictionErrorDisplay),\n  (\"RocCurveDisplay\", sklearn.metrics._plot.roc_curve.RocCurveDisplay),\n  (\"ValidationCurveDisplay\", sklearn.model_selection._plot.ValidationCurveDisplay),\n];\n```\n\n## decision_boundaries를 위해 inspection.DecisionBoundaryDisplay 사용하기\n\ndecision boundaries로 시작해보죠.\n\nmatplotlib를 사용하여 draw 하는 경우, 번거롭습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- np.linspace을 사용하여 좌표 범위 설정;\n- plt.meshgrid를 사용하여 그리드 계산;\n- plt.contourf를 사용하여 결정 경계를 채우기;\n- 그런 다음 plt.scatter를 사용하여 데이터 포인트를 플로팅합니다.\n\n이제 inspection.DecisionBoundaryDisplay를 사용하여이 프로세스를 간소화 할 수 있습니다:\n\n```js\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.datasets import load_iris\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\niris = load_iris(as_frame=True)\nX = iris.data[['petal length (cm)', 'petal width (cm)']]\ny = iris.target\n\n\nsvc_clf = make_pipeline(StandardScaler(),\n                        SVC(kernel='linear', C=1))\nsvc_clf.fit(X, y)\n\ndisplay = DecisionBoundaryDisplay.from_estimator(svc_clf, X,\n                                                 grid_resolution=1000,\n                                                 xlabel=\"Petal length (cm)\",\n                                                 ylabel=\"Petal width (cm)\")\nplt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, edgecolors='w')\nplt.title(\"Decision Boundary\")\nplt.show()\n```\n\n이 그림에서 최종 효과를 확인하십시오:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_2.png\" /\u003e\n\n기억해 주세요. Display 기능은 2D만 그릴 수 있으므로 데이터가 두 개의 특성 또는 축소된 차원만 가지고 있는지 확인하세요.\n\n## 확률 보정을 위해 calibration.CalibrationDisplay 사용\n\n분류 모델을 비교하기 위해 확률 보정 곡선은 모델이 예측에 자신감을 가지고 있는지를 보여줍니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCalibrationDisplay는 모델의 predict_proba를 사용합니다. Support Vector Machine을 사용하는 경우 확률을 True로 설정해주세요:\n\n```js\nfrom sklearn.calibration import CalibrationDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nX, y = make_classification(n_samples=1000,\n                           n_classes=2, n_features=5,\n                           random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                            test_size=0.3, random_state=42)\nproba_clf = make_pipeline(StandardScaler(),\n                          SVC(kernel=\"rbf\", gamma=\"auto\",\n                              C=10, probability=True))\nproba_clf.fit(X_train, y_train)\n\nCalibrationDisplay.from_estimator(proba_clf,\n                                            X_test, y_test)\n\nhist_clf = HistGradientBoostingClassifier()\nhist_clf.fit(X_train, y_train)\n\nax = plt.gca()\nCalibrationDisplay.from_estimator(hist_clf,\n                                  X_test, y_test,\n                                  ax=ax)\nplt.show()\n```\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_3.png\" /\u003e\n\n## 혼동 행렬에 대한 metrics.ConfusionMatrixDisplay 사용하기\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n분류 모델을 평가하고 불균형 데이터를 다룰 때, 우리는 정밀도와 재현율을 살펴봅니다.\n\n이들은 TP, FP, TN, FN으로 나뉘며, 혼동 행렬을 구성합니다.\n\n혼동 행렬을 그리려면 metrics.ConfusionMatrixDisplay를 사용하세요. 이렇게 그림을 그릴 수 있고요, 이미 잘 알려져 있어서 자세하게 설명은 생략할게요.\n\n```js\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\ndigits = fetch_openml('mnist_784', version=1)\nX, y = digits.data, digits.target\nrf_clf = RandomForestClassifier(max_depth=5, random_state=42)\nrf_clf.fit(X, y)\n\nConfusionMatrixDisplay.from_estimator(rf_clf, X, y)\nplt.show()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 이미지 링크입니다:\n\n![Scikit-learn Visualization Guide](/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_4.png)\n\n## metrics.RocCurveDisplay 및 metrics.DetCurveDisplay\n\n이 두 가지가 함께 소개되는 이유는 종종 측정할 때 함께 사용하기 때문입니다.\n\nRocCurveDisplay는 모델의 TPR 및 FPR을 비교합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이진 분류의 경우, 낮은 FPR과 높은 TPR을 원하기 때문에 좌상단이 가장 좋습니다. Roc 곡선은 이 쪽으로 휘어집니다.\n\nRoc 곡선이 좌상단에 근접하여 유지되기 때문에 우하단이 비어 있는데, 이는 모델 간 차이를 파악하기 어렵게 만듭니다.\n\n그래서 우리는 또한 FNR과 FPR로 Det 곡선을 그리는 DetCurveDisplay를 사용합니다. 이는 Roc 곡선보다 명확하게 만들어주는 데 더 많은 공간을 사용합니다.\n\nDet 곡선의 완벽한 지점은 좌하단입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfrom sklearn.metrics import RocCurveDisplay\nfrom sklearn.metrics import DetCurveDisplay\n\nX, y = make_classification(n_samples=10_000, n_features=5,\n                           n_classes=2, n_informative=2)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                             test_size=0.3, random_state=42,\n                                                   stratify=y)\n\n\nclassifiers = {\n    \"SVC\": make_pipeline(StandardScaler(),\n                        SVC(kernel=\"linear\", C=0.1, random_state=42)),\n    \"Random Forest\": RandomForestClassifier(max_depth=5, random_state=42)\n}\n\nfig, [ax_roc, ax_det] = plt.subplots(1, 2, figsize=(10, 4))\nfor name, clf in classifiers.items():\n    clf.fit(X_train, y_train)\n\n    RocCurveDisplay.from_estimator(clf, X_test, y_test, ax=ax_roc, name=name)\n    DetCurveDisplay.from_estimator(clf, X_test, y_test, ax=ax_det, name=name)\n```\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_5.png\" /\u003e\n\n## Using metrics.PrecisionRecallDisplay to adjust thresholds\n\nWith imbalanced data, you might want to shift recall and precision.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이메일 사기를 방지하려면 고정도가 필요합니다.\n- 질병 선별을 위해서는 더 많은 사례를 포착하기 위해 고회수가 필요합니다.\n\n임계값을 조정할 수 있지만, 적절한 양이 무엇인지 궁금하신가요?\n\n여기서 metrics.PrecisionRecallDisplay가 도움이 될 수 있습니다.\n\n```js\nfrom xgboost import XGBClassifier\nfrom sklearn.datasets import load_wine\nfrom sklearn.metrics import PrecisionRecallDisplay\n\nwine = load_wine()\nX, y = wine.data[wine.target\u003c=1], wine.target[wine.target\u003c=1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n\nxgb_clf = XGBClassifier()\nxgb_clf.fit(X_train, y_train)\n\nPrecisionRecallDisplay.from_estimator(xgb_clf, X_test, y_test)\nplt.show()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_6.png\" /\u003e\n\nScikit-learn의 디자인을 따르는 모델은 여기처럼 그릴 수 있습니다. 편리하죠?\n\n## 회귀 모델에 metrics.PredictionErrorDisplay 사용하기\n\n우리는 분류에 대해 이야기했었는데, 이제 회귀에 대해 이야기해볼게요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사이킷런의 metrics.PredictionErrorDisplay는 회귀 모델을 평가하는 데 도움이 됩니다.\n\n```python\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import PredictionErrorDisplay\n\nrng = np.random.default_rng(42)\nX = rng.random(size=(200, 2)) * 10\ny = X[:, 0]**2 + 5 * X[:, 1] + 10 + rng.normal(loc=0.0, scale=0.1, size=(200,))\n\nreg = make_pipeline(StandardScaler(), SVR(kernel='linear', C=10))\nreg.fit(X, y)\n\nfig, axes = plt.subplots(1, 2, figsize=(8, 4))\nPredictionErrorDisplay.from_estimator(reg, X, y, ax=axes[0], kind=\"actual_vs_predicted\")\nPredictionErrorDisplay.from_estimator(reg, X, y, ax=axes[1], kind=\"residual_vs_predicted\")\nplt.show()\n```\n\n![Image](/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_7.png)\n\n그림에서와 같이 두 종류의 그래프를 그릴 수 있습니다. 왼쪽 그래프는 예측 대 실제 값 비교를 보여주며, 선형 회귀 분석에 적합합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 모든 데이터가 완벽하게 선형적이지는 않습니다. 그럴 때는 적절한 그래프를 사용하세요.\n\n실제 대 예측 차이인 잔차 도표를 그려보세요.\n\n이 도표의 바나나 모양은 데이터가 선형 회귀에 맞지 않을 수 있다는 것을 시사합니다.\n\n선형에서 rbf 커널로 전환하는 것이 도움이 될 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nreg = make_pipeline(StandardScaler(), SVR((kernel = \"rbf\"), (C = 10)));\n```\n\n![Image](/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_8.png)\n\n이렇게 rbf를 사용하면 잔차 플롯이 더 나아 보여요.\n\n## 학습 곡선에 model_selection.LearningCurveDisplay 사용하기\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n성능을 평가한 후 LearningCurveDisplay를 사용하여 최적화를 살펴봅시다.\n\n첫 번째로, 학습 곡선을 확인해봅시다. 이 모델이 다양한 학습 및 테스트 데이터로 얼마나 일반화되며, 과적합 또는 편향 문제가 있는지 살펴봅니다.\n\n아래에서는 DecisionTreeClassifier와 GradientBoostingClassifier를 비교하여 학습 데이터가 변할 때 어떻게 작동하는지 살펴봅니다.\n\n```python\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import LearningCurveDisplay\n\nX, y = make_classification(n_samples=1000, n_classes=2, n_features=10,\n                           n_informative=2, n_redundant=0, n_repeated=0)\n\ntree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\ngb_clf = GradientBoostingClassifier(n_estimators=50, max_depth=3, tol=1e-3)\n\ntrain_sizes = np.linspace(0.4, 1.0, 10)\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\nLearningCurveDisplay.from_estimator(tree_clf, X, y,\n                                    train_sizes=train_sizes,\n                                    ax=axes[0],\n                                    scoring='accuracy')\naxes[0].set_title('DecisionTreeClassifier')\nLearningCurveDisplay.from_estimator(gb_clf, X, y,\n                                    train_sizes=train_sizes,\n                                    ax=axes[1],\n                                    scoring='accuracy')\naxes[1].set_title('GradientBoostingClassifier')\nplt.show()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_9.png\" /\u003e\n\n해당 그래프는 트리 기반 GradientBoostingClassifier가 훈련 데이터에서 높은 정확도를 유지하더라도, 테스트 데이터에서는 DecisionTreeClassifier와 비교하여 상당한 장점이 없다는 것을 보여줍니다.\n\n## 매개변수 튜닝 시 시각화를 위해 model_selection.ValidationCurveDisplay 사용\n\n그러므로, 다른 부분에 대해 일반화되지 않는 모델의 경우, 모델의 정규화 매개변수를 조정하여 성능을 미세 조정해 볼 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n전통적인 방법은 GridSearchCV 또는 Optuna와 같은 도구를 사용하여 모델을 조정하는 것이었지만, 이러한 방법은 전반적으로 성능이 가장 좋은 모델만 제공하며 조정 과정이 그다지 직관적이지 않습니다.\n\n특정 매개변수를 조정하여 모델의 영향을 테스트하고 싶은 시나리오의 경우, model_selection.ValidationCurveDisplay를 사용하여 매개변수가 변경됨에 따라 모델이 어떻게 수행되는지 시각화하는 것을 권장합니다.\n\n```js\nfrom sklearn.model_selection import ValidationCurveDisplay\nfrom sklearn.linear_model import LogisticRegression\n\nparam_name, param_range = \"C\", np.logspace(-8, 3, 10)\nlr_clf = LogisticRegression()\n\nValidationCurveDisplay.from_estimator(lr_clf, X, y,\n                                      param_name=param_name,\n                                      param_range=param_range,\n                                      scoring='f1_weighted',\n                                      cv=5, n_jobs=-1)\nplt.show()\n```\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_10.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 아쉬운 점\n\n이러한 표시물을 모두 시도해본 후 몇 가지 아쉬운 점을 인정해야 합니다:\n\n- 가장 큰 아쉬움은 이러한 API의 대부분이 자세한 튜토리얼을 제공하지 않는다는 것입니다. 이것이 Scikit-learn의 철저한 문서와 비교되어 잘 알려지지 않은 이유일 것입니다.\n- 이러한 API는 다양한 패키지에 흩어져 있어 한 곳에서 참조하기 어렵습니다.\n- 코드는 여전히 매우 기본적입니다. 종종 Matplotlib의 API와 함께 사용하여 작업을 완료해야 합니다. 전형적인 예는 DecisionBoundaryDisplay인데, 결정 경계를 플로팅한 후에도 데이터 분포를 플로팅하기 위해 Matplotlib이 필요합니다.\n- 확장하기 어렵습니다. 몇 가지 매개변수를 확인하는 메서드 외에 도구나 방법으로 내 모델 시각화 과정을 간단하게 하는 것은 힘듭니다. 많은 부분을 다시 작성해야 합니다.\n\n이러한 API들이 더 많은 관심을 받고, 버전이 업그레이드되는 과정에서 시각화 API를 사용하기가 더욱 쉬워지기를 희망합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n머신 러닝 여정에서 모델을 시각화로 설명하는 것은 그들을 훈련시키는 것만큼 중요합니다.\n\n본문에서는 현재 버전의 scikit-learn에서 다양한 플로팅 API를 소개했습니다.\n\n이러한 API를 사용하면 Matplotlib 코드를 간소화하고 학습 곡선을 완화시키며 모델 평가 프로세스를 간소화할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAPI에 대해 상세히 다루지 않아서 죄송합니다. 자세한 내용을 원하시면 관련 공식 문서를 확인해보세요.\n\n이제 당신 차례입니다. 기계 학습 방법을 시각화하는 데 기대하는 점이 무엇인가요? 의견을 자유롭게 남겨 주세요.\n\n이 글을 즐겼다면, 더 많은 첨단 데이터 과학 팁을 받고 싶다면 지금 구독하세요! 피드백과 질문은 언제나 환영합니다. 아래 댓글에서 토론해요!\n\n이 기사는 원문이 Data Leads Future에 게재되었습니다.\n","ogImage":{"url":"/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_0.png","tag":["Tech"],"readingTime":19},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e아래는 제가 요청하신 테이블을 Markdown 형식으로 변경한 것입니다.\u003c/p\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eHeader One\u003c/th\u003e\u003cth\u003eHeader Two\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eContent One\u003c/td\u003e\u003ctd\u003eContent Two\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_1.png\" alt=\"Scikit-learn Visualization Guide Making Models Speak\"\u003e\u003c/p\u003e\n\u003cp\u003e이 그래프를 보면 동일한 데이터 세트에서 오른쪽 모델이 더 일반화하는 데 더 좋다는 것을 알 수 있습니다.\u003c/p\u003e\n\u003cp\u003e대부분의 머신러닝 서적은 시각화에 대해 matplotlib 코드를 사용하기를 선호합니다. 이는 다음과 같은 문제를 야기합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMatplotlib로 그리기에 대해 많은 내용을 배워야 합니다.\u003c/li\u003e\n\u003cli\u003e플로팅 코드가 노트북을 가득 채우므로 읽기 어려워집니다.\u003c/li\u003e\n\u003cli\u003e때로는 비즈니스 환경에서 이상적이지 않은 타사 라이브러리가 필요할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e좋은 소식이에요! Scikit-learn은 이제 Display 클래스를 제공하며 from_estimator 및 from_predictions과 같은 메소드를 사용하여 다양한 상황에서 그래프를 그리기가 훨씬 쉬워졌어요.\u003c/p\u003e\n\u003cp\u003e궁금하신가요? 이 멋진 API를 보여드릴게요.\u003c/p\u003e\n\u003ch1\u003eScikit-learn Display API 소개\u003c/h1\u003e\n\u003ch2\u003e사용 가능한 API를 찾으려면 utils.discovery.all_displays를 사용하세요\u003c/h2\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eScikit-learn (sklearn)은 항상 새 릴리스에서 Display API를 추가하기 때문에 당신의 버전에서 무엇을 사용할 수 있는지 알아두는 것이 중요합니다.\u003c/p\u003e\n\u003cp\u003eSklearn의 utils.discovery.all_displays를 사용하면 사용할 수 있는 클래스들을 볼 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.utils.discovery \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e all_displays\n\ndisplays = all_displays()\ndisplays\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e예를 들어, 내 Scikit-learn 1.4.0에서 이러한 클래스들을 사용할 수 있습니다:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e[\n  (\u003cspan class=\"hljs-string\"\u003e\"CalibrationDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003ecalibration\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eCalibrationDisplay\u003c/span\u003e),\n  (\u003cspan class=\"hljs-string\"\u003e\"ConfusionMatrixDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003e_plot\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003econfusion_matrix\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eConfusionMatrixDisplay\u003c/span\u003e),\n  (\u003cspan class=\"hljs-string\"\u003e\"DecisionBoundaryDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003einspection\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003e_plot\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003edecision_boundary\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eDecisionBoundaryDisplay\u003c/span\u003e),\n  (\u003cspan class=\"hljs-string\"\u003e\"DetCurveDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003e_plot\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003edet_curve\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eDetCurveDisplay\u003c/span\u003e),\n  (\u003cspan class=\"hljs-string\"\u003e\"LearningCurveDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003emodel_selection\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003e_plot\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eLearningCurveDisplay\u003c/span\u003e),\n  (\u003cspan class=\"hljs-string\"\u003e\"PartialDependenceDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003einspection\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003e_plot\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003epartial_dependence\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ePartialDependenceDisplay\u003c/span\u003e),\n  (\u003cspan class=\"hljs-string\"\u003e\"PrecisionRecallDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003e_plot\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eprecision_recall_curve\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ePrecisionRecallDisplay\u003c/span\u003e),\n  (\u003cspan class=\"hljs-string\"\u003e\"PredictionErrorDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003e_plot\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eregression\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ePredictionErrorDisplay\u003c/span\u003e),\n  (\u003cspan class=\"hljs-string\"\u003e\"RocCurveDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003e_plot\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eroc_curve\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eRocCurveDisplay\u003c/span\u003e),\n  (\u003cspan class=\"hljs-string\"\u003e\"ValidationCurveDisplay\"\u003c/span\u003e, sklearn.\u003cspan class=\"hljs-property\"\u003emodel_selection\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003e_plot\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eValidationCurveDisplay\u003c/span\u003e),\n];\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003edecision_boundaries를 위해 inspection.DecisionBoundaryDisplay 사용하기\u003c/h2\u003e\n\u003cp\u003edecision boundaries로 시작해보죠.\u003c/p\u003e\n\u003cp\u003ematplotlib를 사용하여 draw 하는 경우, 번거롭습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003enp.linspace을 사용하여 좌표 범위 설정;\u003c/li\u003e\n\u003cli\u003eplt.meshgrid를 사용하여 그리드 계산;\u003c/li\u003e\n\u003cli\u003eplt.contourf를 사용하여 결정 경계를 채우기;\u003c/li\u003e\n\u003cli\u003e그런 다음 plt.scatter를 사용하여 데이터 포인트를 플로팅합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이제 inspection.DecisionBoundaryDisplay를 사용하여이 프로세스를 간소화 할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003einspection\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eDecisionBoundaryDisplay\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003edatasets\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e load_iris\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003esvm\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eSVC\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003epipeline\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e make_pipeline\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003epreprocessing\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eStandardScaler\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.\u003cspan class=\"hljs-property\"\u003epyplot\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\niris = \u003cspan class=\"hljs-title function_\"\u003eload_iris\u003c/span\u003e(as_frame=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)\nX = iris.\u003cspan class=\"hljs-property\"\u003edata\u003c/span\u003e[[\u003cspan class=\"hljs-string\"\u003e'petal length (cm)'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'petal width (cm)'\u003c/span\u003e]]\ny = iris.\u003cspan class=\"hljs-property\"\u003etarget\u003c/span\u003e\n\n\nsvc_clf = \u003cspan class=\"hljs-title function_\"\u003emake_pipeline\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003eStandardScaler\u003c/span\u003e(),\n                        \u003cspan class=\"hljs-title function_\"\u003eSVC\u003c/span\u003e(kernel=\u003cspan class=\"hljs-string\"\u003e'linear'\u003c/span\u003e, C=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\nsvc_clf.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X, y)\n\ndisplay = \u003cspan class=\"hljs-title class_\"\u003eDecisionBoundaryDisplay\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_estimator\u003c/span\u003e(svc_clf, X,\n                                                 grid_resolution=\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e,\n                                                 xlabel=\u003cspan class=\"hljs-string\"\u003e\"Petal length (cm)\"\u003c/span\u003e,\n                                                 ylabel=\u003cspan class=\"hljs-string\"\u003e\"Petal width (cm)\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(X.\u003cspan class=\"hljs-property\"\u003eiloc\u003c/span\u003e[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X.\u003cspan class=\"hljs-property\"\u003eiloc\u003c/span\u003e[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], c=y, edgecolors=\u003cspan class=\"hljs-string\"\u003e'w'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etitle\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Decision Boundary\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 그림에서 최종 효과를 확인하십시오:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_2.png\"\u003e\n\u003cp\u003e기억해 주세요. Display 기능은 2D만 그릴 수 있으므로 데이터가 두 개의 특성 또는 축소된 차원만 가지고 있는지 확인하세요.\u003c/p\u003e\n\u003ch2\u003e확률 보정을 위해 calibration.CalibrationDisplay 사용\u003c/h2\u003e\n\u003cp\u003e분류 모델을 비교하기 위해 확률 보정 곡선은 모델이 예측에 자신감을 가지고 있는지를 보여줍니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eCalibrationDisplay는 모델의 predict_proba를 사용합니다. Support Vector Machine을 사용하는 경우 확률을 True로 설정해주세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003ecalibration\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eCalibrationDisplay\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emodel_selection\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e train_test_split\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003edatasets\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e make_classification\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003eensemble\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eHistGradientBoostingClassifier\u003c/span\u003e\n\nX, y = \u003cspan class=\"hljs-title function_\"\u003emake_classification\u003c/span\u003e(n_samples=\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e,\n                           n_classes=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, n_features=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e,\n                           random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\nX_train, X_test, y_train, y_test = \u003cspan class=\"hljs-title function_\"\u003etrain_test_split\u003c/span\u003e(X, y,\n                                            test_size=\u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\nproba_clf = \u003cspan class=\"hljs-title function_\"\u003emake_pipeline\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003eStandardScaler\u003c/span\u003e(),\n                          \u003cspan class=\"hljs-title function_\"\u003eSVC\u003c/span\u003e(kernel=\u003cspan class=\"hljs-string\"\u003e\"rbf\"\u003c/span\u003e, gamma=\u003cspan class=\"hljs-string\"\u003e\"auto\"\u003c/span\u003e,\n                              C=\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, probability=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e))\nproba_clf.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X_train, y_train)\n\n\u003cspan class=\"hljs-title class_\"\u003eCalibrationDisplay\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_estimator\u003c/span\u003e(proba_clf,\n                                            X_test, y_test)\n\nhist_clf = \u003cspan class=\"hljs-title class_\"\u003eHistGradientBoostingClassifier\u003c/span\u003e()\nhist_clf.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X_train, y_train)\n\nax = plt.\u003cspan class=\"hljs-title function_\"\u003egca\u003c/span\u003e()\n\u003cspan class=\"hljs-title class_\"\u003eCalibrationDisplay\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_estimator\u003c/span\u003e(hist_clf,\n                                  X_test, y_test,\n                                  ax=ax)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_3.png\"\u003e\n\u003ch2\u003e혼동 행렬에 대한 metrics.ConfusionMatrixDisplay 사용하기\u003c/h2\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e분류 모델을 평가하고 불균형 데이터를 다룰 때, 우리는 정밀도와 재현율을 살펴봅니다.\u003c/p\u003e\n\u003cp\u003e이들은 TP, FP, TN, FN으로 나뉘며, 혼동 행렬을 구성합니다.\u003c/p\u003e\n\u003cp\u003e혼동 행렬을 그리려면 metrics.ConfusionMatrixDisplay를 사용하세요. 이렇게 그림을 그릴 수 있고요, 이미 잘 알려져 있어서 자세하게 설명은 생략할게요.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003edatasets\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e fetch_openml\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003eensemble\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eRandomForestClassifier\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eConfusionMatrixDisplay\u003c/span\u003e\n\ndigits = \u003cspan class=\"hljs-title function_\"\u003efetch_openml\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'mnist_784'\u003c/span\u003e, version=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\nX, y = digits.\u003cspan class=\"hljs-property\"\u003edata\u003c/span\u003e, digits.\u003cspan class=\"hljs-property\"\u003etarget\u003c/span\u003e\nrf_clf = \u003cspan class=\"hljs-title class_\"\u003eRandomForestClassifier\u003c/span\u003e(max_depth=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\nrf_clf.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X, y)\n\n\u003cspan class=\"hljs-title class_\"\u003eConfusionMatrixDisplay\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_estimator\u003c/span\u003e(rf_clf, X, y)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e아래는 이미지 링크입니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_4.png\" alt=\"Scikit-learn Visualization Guide\"\u003e\u003c/p\u003e\n\u003ch2\u003emetrics.RocCurveDisplay 및 metrics.DetCurveDisplay\u003c/h2\u003e\n\u003cp\u003e이 두 가지가 함께 소개되는 이유는 종종 측정할 때 함께 사용하기 때문입니다.\u003c/p\u003e\n\u003cp\u003eRocCurveDisplay는 모델의 TPR 및 FPR을 비교합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이진 분류의 경우, 낮은 FPR과 높은 TPR을 원하기 때문에 좌상단이 가장 좋습니다. Roc 곡선은 이 쪽으로 휘어집니다.\u003c/p\u003e\n\u003cp\u003eRoc 곡선이 좌상단에 근접하여 유지되기 때문에 우하단이 비어 있는데, 이는 모델 간 차이를 파악하기 어렵게 만듭니다.\u003c/p\u003e\n\u003cp\u003e그래서 우리는 또한 FNR과 FPR로 Det 곡선을 그리는 DetCurveDisplay를 사용합니다. 이는 Roc 곡선보다 명확하게 만들어주는 데 더 많은 공간을 사용합니다.\u003c/p\u003e\n\u003cp\u003eDet 곡선의 완벽한 지점은 좌하단입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eRocCurveDisplay\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eDetCurveDisplay\u003c/span\u003e\n\nX, y = \u003cspan class=\"hljs-title function_\"\u003emake_classification\u003c/span\u003e(n_samples=\u003cspan class=\"hljs-number\"\u003e10_000\u003c/span\u003e, n_features=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e,\n                           n_classes=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, n_informative=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)\nX_train, X_test, y_train, y_test = \u003cspan class=\"hljs-title function_\"\u003etrain_test_split\u003c/span\u003e(X, y,\n                                             test_size=\u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e,\n                                                   stratify=y)\n\n\nclassifiers = {\n    \u003cspan class=\"hljs-string\"\u003e\"SVC\"\u003c/span\u003e: \u003cspan class=\"hljs-title function_\"\u003emake_pipeline\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003eStandardScaler\u003c/span\u003e(),\n                        \u003cspan class=\"hljs-title function_\"\u003eSVC\u003c/span\u003e(kernel=\u003cspan class=\"hljs-string\"\u003e\"linear\"\u003c/span\u003e, C=\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)),\n    \u003cspan class=\"hljs-string\"\u003e\"Random Forest\"\u003c/span\u003e: \u003cspan class=\"hljs-title class_\"\u003eRandomForestClassifier\u003c/span\u003e(max_depth=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n}\n\nfig, [ax_roc, ax_det] = plt.\u003cspan class=\"hljs-title function_\"\u003esubplots\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, figsize=(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e))\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e name, clf \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e classifiers.\u003cspan class=\"hljs-title function_\"\u003eitems\u003c/span\u003e():\n    clf.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X_train, y_train)\n\n    \u003cspan class=\"hljs-title class_\"\u003eRocCurveDisplay\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_estimator\u003c/span\u003e(clf, X_test, y_test, ax=ax_roc, name=name)\n    \u003cspan class=\"hljs-title class_\"\u003eDetCurveDisplay\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_estimator\u003c/span\u003e(clf, X_test, y_test, ax=ax_det, name=name)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_5.png\"\u003e\n\u003ch2\u003eUsing metrics.PrecisionRecallDisplay to adjust thresholds\u003c/h2\u003e\n\u003cp\u003eWith imbalanced data, you might want to shift recall and precision.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e이메일 사기를 방지하려면 고정도가 필요합니다.\u003c/li\u003e\n\u003cli\u003e질병 선별을 위해서는 더 많은 사례를 포착하기 위해 고회수가 필요합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e임계값을 조정할 수 있지만, 적절한 양이 무엇인지 궁금하신가요?\u003c/p\u003e\n\u003cp\u003e여기서 metrics.PrecisionRecallDisplay가 도움이 될 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e xgboost \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eXGBClassifier\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003edatasets\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e load_wine\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003ePrecisionRecallDisplay\u003c/span\u003e\n\nwine = \u003cspan class=\"hljs-title function_\"\u003eload_wine\u003c/span\u003e()\nX, y = wine.\u003cspan class=\"hljs-property\"\u003edata\u003c/span\u003e[wine.\u003cspan class=\"hljs-property\"\u003etarget\u003c/span\u003e\u0026#x3C;=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], wine.\u003cspan class=\"hljs-property\"\u003etarget\u003c/span\u003e[wine.\u003cspan class=\"hljs-property\"\u003etarget\u003c/span\u003e\u0026#x3C;=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\nX_train, X_test, y_train, y_test = \u003cspan class=\"hljs-title function_\"\u003etrain_test_split\u003c/span\u003e(X, y, test_size=\u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, stratify=y, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n\nxgb_clf = \u003cspan class=\"hljs-title class_\"\u003eXGBClassifier\u003c/span\u003e()\nxgb_clf.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X_train, y_train)\n\n\u003cspan class=\"hljs-title class_\"\u003ePrecisionRecallDisplay\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_estimator\u003c/span\u003e(xgb_clf, X_test, y_test)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_6.png\"\u003e\n\u003cp\u003eScikit-learn의 디자인을 따르는 모델은 여기처럼 그릴 수 있습니다. 편리하죠?\u003c/p\u003e\n\u003ch2\u003e회귀 모델에 metrics.PredictionErrorDisplay 사용하기\u003c/h2\u003e\n\u003cp\u003e우리는 분류에 대해 이야기했었는데, 이제 회귀에 대해 이야기해볼게요.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e사이킷런의 metrics.PredictionErrorDisplay는 회귀 모델을 평가하는 데 도움이 됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.svm \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SVR\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e PredictionErrorDisplay\n\nrng = np.random.default_rng(\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\nX = rng.random(size=(\u003cspan class=\"hljs-number\"\u003e200\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)) * \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e\ny = X[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]**\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e + \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e * X[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e] + \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e + rng.normal(loc=\u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e, scale=\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, size=(\u003cspan class=\"hljs-number\"\u003e200\u003c/span\u003e,))\n\nreg = make_pipeline(StandardScaler(), SVR(kernel=\u003cspan class=\"hljs-string\"\u003e'linear'\u003c/span\u003e, C=\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e))\nreg.fit(X, y)\n\nfig, axes = plt.subplots(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, figsize=(\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e))\nPredictionErrorDisplay.from_estimator(reg, X, y, ax=axes[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], kind=\u003cspan class=\"hljs-string\"\u003e\"actual_vs_predicted\"\u003c/span\u003e)\nPredictionErrorDisplay.from_estimator(reg, X, y, ax=axes[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], kind=\u003cspan class=\"hljs-string\"\u003e\"residual_vs_predicted\"\u003c/span\u003e)\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_7.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e그림에서와 같이 두 종류의 그래프를 그릴 수 있습니다. 왼쪽 그래프는 예측 대 실제 값 비교를 보여주며, 선형 회귀 분석에 적합합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e하지만 모든 데이터가 완벽하게 선형적이지는 않습니다. 그럴 때는 적절한 그래프를 사용하세요.\u003c/p\u003e\n\u003cp\u003e실제 대 예측 차이인 잔차 도표를 그려보세요.\u003c/p\u003e\n\u003cp\u003e이 도표의 바나나 모양은 데이터가 선형 회귀에 맞지 않을 수 있다는 것을 시사합니다.\u003c/p\u003e\n\u003cp\u003e선형에서 rbf 커널로 전환하는 것이 도움이 될 수 있습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ereg = \u003cspan class=\"hljs-title function_\"\u003emake_pipeline\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003eStandardScaler\u003c/span\u003e(), \u003cspan class=\"hljs-title function_\"\u003eSVR\u003c/span\u003e((kernel = \u003cspan class=\"hljs-string\"\u003e\"rbf\"\u003c/span\u003e), (C = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e)));\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_8.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e이렇게 rbf를 사용하면 잔차 플롯이 더 나아 보여요.\u003c/p\u003e\n\u003ch2\u003e학습 곡선에 model_selection.LearningCurveDisplay 사용하기\u003c/h2\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e성능을 평가한 후 LearningCurveDisplay를 사용하여 최적화를 살펴봅시다.\u003c/p\u003e\n\u003cp\u003e첫 번째로, 학습 곡선을 확인해봅시다. 이 모델이 다양한 학습 및 테스트 데이터로 얼마나 일반화되며, 과적합 또는 편향 문제가 있는지 살펴봅니다.\u003c/p\u003e\n\u003cp\u003e아래에서는 DecisionTreeClassifier와 GradientBoostingClassifier를 비교하여 학습 데이터가 변할 때 어떻게 작동하는지 살펴봅니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.tree \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e DecisionTreeClassifier\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.ensemble \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e GradientBoostingClassifier\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.model_selection \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e LearningCurveDisplay\n\nX, y = make_classification(n_samples=\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e, n_classes=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, n_features=\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e,\n                           n_informative=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, n_redundant=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, n_repeated=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)\n\ntree_clf = DecisionTreeClassifier(max_depth=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\ngb_clf = GradientBoostingClassifier(n_estimators=\u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e, max_depth=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, tol=\u003cspan class=\"hljs-number\"\u003e1e-3\u003c/span\u003e)\n\ntrain_sizes = np.linspace(\u003cspan class=\"hljs-number\"\u003e0.4\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1.0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e)\nfig, axes = plt.subplots(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, figsize=(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e))\nLearningCurveDisplay.from_estimator(tree_clf, X, y,\n                                    train_sizes=train_sizes,\n                                    ax=axes[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e],\n                                    scoring=\u003cspan class=\"hljs-string\"\u003e'accuracy'\u003c/span\u003e)\naxes[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].set_title(\u003cspan class=\"hljs-string\"\u003e'DecisionTreeClassifier'\u003c/span\u003e)\nLearningCurveDisplay.from_estimator(gb_clf, X, y,\n                                    train_sizes=train_sizes,\n                                    ax=axes[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e],\n                                    scoring=\u003cspan class=\"hljs-string\"\u003e'accuracy'\u003c/span\u003e)\naxes[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e].set_title(\u003cspan class=\"hljs-string\"\u003e'GradientBoostingClassifier'\u003c/span\u003e)\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_9.png\"\u003e\n\u003cp\u003e해당 그래프는 트리 기반 GradientBoostingClassifier가 훈련 데이터에서 높은 정확도를 유지하더라도, 테스트 데이터에서는 DecisionTreeClassifier와 비교하여 상당한 장점이 없다는 것을 보여줍니다.\u003c/p\u003e\n\u003ch2\u003e매개변수 튜닝 시 시각화를 위해 model_selection.ValidationCurveDisplay 사용\u003c/h2\u003e\n\u003cp\u003e그러므로, 다른 부분에 대해 일반화되지 않는 모델의 경우, 모델의 정규화 매개변수를 조정하여 성능을 미세 조정해 볼 수 있습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e전통적인 방법은 GridSearchCV 또는 Optuna와 같은 도구를 사용하여 모델을 조정하는 것이었지만, 이러한 방법은 전반적으로 성능이 가장 좋은 모델만 제공하며 조정 과정이 그다지 직관적이지 않습니다.\u003c/p\u003e\n\u003cp\u003e특정 매개변수를 조정하여 모델의 영향을 테스트하고 싶은 시나리오의 경우, model_selection.ValidationCurveDisplay를 사용하여 매개변수가 변경됨에 따라 모델이 어떻게 수행되는지 시각화하는 것을 권장합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emodel_selection\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eValidationCurveDisplay\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003elinear_model\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eLogisticRegression\u003c/span\u003e\n\nparam_name, param_range = \u003cspan class=\"hljs-string\"\u003e\"C\"\u003c/span\u003e, np.\u003cspan class=\"hljs-title function_\"\u003elogspace\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e)\nlr_clf = \u003cspan class=\"hljs-title class_\"\u003eLogisticRegression\u003c/span\u003e()\n\n\u003cspan class=\"hljs-title class_\"\u003eValidationCurveDisplay\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_estimator\u003c/span\u003e(lr_clf, X, y,\n                                      param_name=param_name,\n                                      param_range=param_range,\n                                      scoring=\u003cspan class=\"hljs-string\"\u003e'f1_weighted'\u003c/span\u003e,\n                                      cv=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, n_jobs=-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak_10.png\"\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e아쉬운 점\u003c/h1\u003e\n\u003cp\u003e이러한 표시물을 모두 시도해본 후 몇 가지 아쉬운 점을 인정해야 합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e가장 큰 아쉬움은 이러한 API의 대부분이 자세한 튜토리얼을 제공하지 않는다는 것입니다. 이것이 Scikit-learn의 철저한 문서와 비교되어 잘 알려지지 않은 이유일 것입니다.\u003c/li\u003e\n\u003cli\u003e이러한 API는 다양한 패키지에 흩어져 있어 한 곳에서 참조하기 어렵습니다.\u003c/li\u003e\n\u003cli\u003e코드는 여전히 매우 기본적입니다. 종종 Matplotlib의 API와 함께 사용하여 작업을 완료해야 합니다. 전형적인 예는 DecisionBoundaryDisplay인데, 결정 경계를 플로팅한 후에도 데이터 분포를 플로팅하기 위해 Matplotlib이 필요합니다.\u003c/li\u003e\n\u003cli\u003e확장하기 어렵습니다. 몇 가지 매개변수를 확인하는 메서드 외에 도구나 방법으로 내 모델 시각화 과정을 간단하게 하는 것은 힘듭니다. 많은 부분을 다시 작성해야 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이러한 API들이 더 많은 관심을 받고, 버전이 업그레이드되는 과정에서 시각화 API를 사용하기가 더욱 쉬워지기를 희망합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e머신 러닝 여정에서 모델을 시각화로 설명하는 것은 그들을 훈련시키는 것만큼 중요합니다.\u003c/p\u003e\n\u003cp\u003e본문에서는 현재 버전의 scikit-learn에서 다양한 플로팅 API를 소개했습니다.\u003c/p\u003e\n\u003cp\u003e이러한 API를 사용하면 Matplotlib 코드를 간소화하고 학습 곡선을 완화시키며 모델 평가 프로세스를 간소화할 수 있습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eAPI에 대해 상세히 다루지 않아서 죄송합니다. 자세한 내용을 원하시면 관련 공식 문서를 확인해보세요.\u003c/p\u003e\n\u003cp\u003e이제 당신 차례입니다. 기계 학습 방법을 시각화하는 데 기대하는 점이 무엇인가요? 의견을 자유롭게 남겨 주세요.\u003c/p\u003e\n\u003cp\u003e이 글을 즐겼다면, 더 많은 첨단 데이터 과학 팁을 받고 싶다면 지금 구독하세요! 피드백과 질문은 언제나 환영합니다. 아래 댓글에서 토론해요!\u003c/p\u003e\n\u003cp\u003e이 기사는 원문이 Data Leads Future에 게재되었습니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-07-09-Scikit-learnVisualizationGuideMakingModelsSpeak"},"buildId":"KUC9M_yIlA1Ugo01xmkHL","assetPrefix":"/TIL","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>