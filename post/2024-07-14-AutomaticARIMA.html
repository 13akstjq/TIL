<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>자동 ARIMA 모델 사용 방법 | TIL</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://13akstjq.github.io/TIL//post/2024-07-14-AutomaticARIMA" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="자동 ARIMA 모델 사용 방법 | TIL" data-gatsby-head="true"/><meta property="og:title" content="자동 ARIMA 모델 사용 방법 | TIL" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/TIL/assets/img/2024-07-14-AutomaticARIMA_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://TIL.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://13akstjq.github.io/TIL//post/2024-07-14-AutomaticARIMA" data-gatsby-head="true"/><meta name="twitter:title" content="자동 ARIMA 모델 사용 방법 | TIL" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/TIL/assets/img/2024-07-14-AutomaticARIMA_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | TIL" data-gatsby-head="true"/><meta name="article:published_time" content="2024-07-14 19:49" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/TIL/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/TIL/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/TIL/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/TIL/favicons/favicon-96x96.png"/><link rel="icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/TIL/favicons/browserconfig.xml"/><link rel="preload" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/TIL/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/TIL/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/TIL/_next/static/chunks/webpack-21ffe88bdca56cba.js" defer=""></script><script src="/TIL/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/TIL/_next/static/chunks/main-a5eeabb286676ce6.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/TIL/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/TIL/_next/static/chunks/463-925361deb4cec4b1.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/post/%5Bslug%5D-9d7ebbd29b9e08ce.js" defer=""></script><script src="/TIL/_next/static/FuXRqV9h16krA5Mvtd6Dn/_buildManifest.js" defer=""></script><script src="/TIL/_next/static/FuXRqV9h16krA5Mvtd6Dn/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/TIL">TIL</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/TIL/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">자동 ARIMA 모델 사용 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="자동 ARIMA 모델 사용 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">TIL</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jul 14, 2024</span><span class="posts_reading_time__f7YPP">25<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-07-14-AutomaticARIMA&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>자동 모델 선택 및 다단계 예측</p>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_0.png" alt="이미지"></p>
<p>ARIMA (AutoRegressive Integrated Moving Average)은 시계열 예측 및 분석에 사용되는 통계 모델입니다. ARIMA의 기원은 1900년대 초반으로 거슬러 올라가며 자기회귀(AR) 모델과 이동평균 (MA) 모델이 별도로 발전됐습니다. 두 모델 모두 현실 시계열 데이터의 복잡한 역학을 포착하기에는 충분하지 않은 것으로 나타납니다. 1960년대에 세 통계학자인 조지 E. P. 박스, 그윌림 M. 젠킨스, 그리고 그레고리 C. 레인절이 "시계열 분석: 예측과 제어"라는 책에서 AR과 MA 모델을 공식적으로 통합하여 ARIMA를 만들었습니다.</p>
<p>ARIMA는 아마도 가장 잘 알려진 패러다임이지만, 왜 이 "현대적인" 시계열 서적에 포함시키는 걸까요? 주된 이유는 AR과 MA가 현대적인 시계열 기술에서 많은 흔적을 남겨주었기 때문입니다. ARIMA에 대한 기본 이해는 다른 복잡한 모델에 걸쳐 활용할 수 있게 해줍니다. 예를 들어, NeuralProphet의 4장에서 AR 모듈을 보았고, 12장과 13장에서는 AR 항목을 감독 학습 모델에서 특징으로 볼 것입니다. 이 책에 ARIMA를 포함한 두 번째 이유는 최근의 코드 개발로 자동 모델 선택과 다단계 예측이 가능해졌기 때문입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>챕터 4: "튜토리얼 II: 트렌드 + 계절성 + 휴일 및 이벤트 + 자기 회귀(AR) + 지연 회귀자 + 미래 회귀자."</li>
<li>챕터 12: "트리 기반 시계열 예측에 대한 튜토리얼"</li>
<li>챕터 13: "다단계 시계열 예측에 대한 튜토리얼."</li>
</ul>
<p>오늘날의 코드 라이브러리를 사용하면 최적의 ARIMA 모델을 선택할 수 있습니다. 표준 ARIMA 학파에서 교육을 받은 경우, 최적의 AR 및 MA 순서를 선택하기위한 규정화된 지침을 외우고 있는 사람도 있을 것입니다. 모델 사양을 결정하기 위해 자동 상관 함수(ACF) 및 부분 자동 상관 함수(PACF)를 사용해야 합니다. 그러나 나는 그런 규정화된 지침을 잊어버리고 그냥 여러 순서의 후보 모델을 만들어 최적의 모델을 선택합니다. 왜 최상의 모델을 선택하기 위해 많은 모델을 생성하지 않을까요? 이러한 이유로, Python의 "pmdarima"와 같은 편리한 라이브러리가 있어 최적 사양을 자동화하는 데 도움이 됩니다. 이 장을 "자동 ARIMA"라고 제목 지어 이 이점을 강조하고자 합니다. 그래도 이 챕터에서는 차이, ACF 및 PACF의 개념을 다룰 것입니다.</p>
<p>"statsmodels"와 "pmdarima"와 같은 현대의 코드 라이브러리는 단기 예측이 아닌 다단계 예측을 가능하게 합니다. 이를 수행하기 위해 모델을 재귀적으로 적용하여 예측을 생성하는 방법에 대해 배우게 될 것입니다. 일반적으로 다단계 예측을 생성하는 두 가지 기본 전략이 있습니다: 재귀적 방법과 직접 방법. 우리는 챕터 13 "다단계 시계열 예측에 대한 튜토리얼"에서 이를 배울 것입니다. 두 전략은 ARIMA와 lightGBM 또는 XGB와 같은 트리 기반 모델에 채택되어 다단계 예측을 생성합니다.</p>
<p>마지막으로, 많은 사용 사례에서 우리는 점 추정치에 만족하지 않고 예측 구간을 필요로 합니다. 잠재적 불확실성을 평가하기 위해 가능한 값의 범위가 필요합니다. "pmdarima"와 "statsmodels"는 신뢰 구간을 반환합니다. 반면에, Part II "확률적 예측을 얻기"의 5부터 8 챕터에서 예측 구간을 위한 더 많은 기술을 배웠습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>제 5장: 시계열 확률 예측을 위한 몬테카를로 시뮬레이션</li>
<li>제 6장: 시계열 확률 예측을 위한 분위 회귀</li>
<li>제 7장: 시계열 확률 예측을 위한 형식 예측</li>
<li>제 8장: 시계열 확률 예측을 위한 형식화된 분위 회귀</li>
</ul>
<p>이 글에서는 이론과 실무를 포괄적으로 설명하겠습니다. 실제 데이터를 사용하여 모델 구축과 예측을 안내할 예정이에요. 이미 알고 계신 부분은 건너뛰셔도 괜찮아요. Python 노트북은 여기서 다운로드할 수 있어요. 다룰 주제들은 다음과 같아요:</p>
<ul>
<li>ARIMA 모델</li>
<li>차분</li>
<li>ACF 사용하여 MA의 차수 제안</li>
<li>PACF 사용하여 AR의 차수 제안</li>
<li>pmdarima 라이브러리 사용하여 최적 모델 자동 탐색</li>
<li>다단계 예측</li>
<li>statsmodels 사용하여 모델을 반복적으로 업데이트</li>
<li>SARIMA 모델</li>
</ul>
<p>먼저 데이터를 불러오겠습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>데이터 전처리</p>
<p>카글의 아보카도 판매 데이터를 사용할 것입니다.</p>
<pre><code class="hljs language-js">%matplotlib inline
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-keyword">from</span> google.<span class="hljs-property">colab</span> <span class="hljs-keyword">import</span> drive
drive.<span class="hljs-title function_">mount</span>(<span class="hljs-string">'/content/gdrive'</span>)

path = <span class="hljs-string">'/content/gdrive/My Drive/data/time_series'</span>
data = pd.<span class="hljs-title function_">read_csv</span>(path + <span class="hljs-string">'/avocado_monthly.csv'</span>, index_col=<span class="hljs-string">'Date'</span>)
data.<span class="hljs-title function_">sort_values</span>(by=<span class="hljs-string">'Total Volume'</span>, ascending=<span class="hljs-title class_">False</span>)
</code></pre>
<p>(A) 그림은 이 데이터셋의 일부를 보여줍니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_1.png" alt="그림"></p>
<p>이 데이터 세트에서는 하나의 일변량 시계열만 사용할 것입니다.</p>
<pre><code class="hljs language-js"># <span class="hljs-string">'유기농'</span> 및 <span class="hljs-string">'TotalUS'</span> 지역인 하나의 시계열만 사용합니다.
df = data[(data[<span class="hljs-string">'type'</span>]==<span class="hljs-string">'organic'</span>) &#x26; (data[<span class="hljs-string">'region'</span>]==<span class="hljs-string">'TotalUS'</span>)].<span class="hljs-title function_">copy</span>()
df = df[<span class="hljs-string">'Total Volume'</span>]
df.<span class="hljs-property">columns</span> = [<span class="hljs-string">'y'</span>]
df = df[pd.<span class="hljs-title function_">to_datetime</span>(df.<span class="hljs-property">index</span>)&#x3C;=pd.<span class="hljs-title function_">to_datetime</span>(<span class="hljs-string">'2018-02-01'</span>)]

# 일변량 시계열 그래프 그리기
plt.<span class="hljs-title function_">figure</span>(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">4</span>))
plt.<span class="hljs-title function_">plot</span>(df)
plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">"날짜"</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">"볼륨"</span>)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<p>그림 (B)는 일변량 시계열 그래프를 보여줍니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_2.png" alt="그림"></p>
<p>이후에는 80%를 인-타임 훈련 데이터로 사용하고 나머지 20%는 아웃-오브-타임 테스트 데이터로 사용합니다.</p>
<pre><code class="hljs language-js"># <span class="hljs-title class_">Train</span>-test-split
train_len = <span class="hljs-title function_">int</span>(df.<span class="hljs-property">shape</span>[<span class="hljs-number">0</span>] * <span class="hljs-number">0.8</span>)
test_len = df.<span class="hljs-property">shape</span>[<span class="hljs-number">0</span>] - train_len
train, test = df[:train_len], df[<span class="hljs-attr">train_len</span>:]
<span class="hljs-title function_">print</span>(f<span class="hljs-string">"{train_len}개의 훈련 샘플"</span>)
<span class="hljs-title function_">print</span>(f<span class="hljs-string">"{df.shape[0] - train_len}개의 테스트 샘플"</span>)
</code></pre>
<p>좋아요. 이제 우리는 정의부터 시작합시다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>ARIMA 모델들</p>
<p>ARIMA는 단변량 시계열 데이터를 사용하여 미래 값을 예측하는 모델 클래스입니다. 이 모델들은 시계열 데이터의 과거 또는 이전 값, 즉 자기 회귀(AR) 항목과 이동 평균(MA) 항목인 이동 예측 오차의 지연된 값들을 사용하여 미래 값을 예측합니다. ARIMA이란 "자기 회귀-통합-이동 평균"의 약자로, "AR", "I", "MA"로 구성됩니다. 여기서 ARIMA의 "I"는 "통합(integrated)"을 의미하며, 이는 시계열 데이터가 안정성을 달성하기 위해 차분된 것을 나타냅니다. 안정적인 시계열 데이터는 시간이 지나도 평균, 분산 및 자기 상관이 일정하므로 모델링하기 쉽습니다. ARIMA(p,d,q) 모델로 수학적으로 표현하면 다음과 같습니다:</p>
<p>Markdown 형식으로 테이블 태그를 변경하십시오.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_3.png" alt="AutomaticARIMA_3"></p>
<p>ARIMA 표기법에 친숙해지기 위해 위 식을 적용해 봅시다.</p>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_4.png" alt="AutomaticARIMA_4"></p>
<p>일반적으로 AR만 또는 MA만, 또는 p와 q가 모두 4 미만이기 때문에 우변에 많은 항이 없습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>차이화</p>
<p>차이화의 목표는 시계열을 안정적으로 만드는 것입니다. 시계열에서 안정성이란 값의 평균이 시간에 따라 일정하다는 것을 의미합니다. 다시 말해, 안정적인 시계열은 일정한 평균을 갖습니다. 이전 코드는 원래 시계열, 1차 차이화(한 번 차이화), 그리고 2차 차이화(두 번 차이화)를 플롯합니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np, pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> statsmodels.<span class="hljs-property">graphics</span>.<span class="hljs-property">tsaplots</span> <span class="hljs-keyword">import</span> plot_acf, plot_pacf
<span class="hljs-keyword">from</span> statsmodels.<span class="hljs-property">tsa</span>.<span class="hljs-property">stattools</span> <span class="hljs-keyword">import</span> adfuller
<span class="hljs-keyword">import</span> matplotlib.<span class="hljs-property">pyplot</span> <span class="hljs-keyword">as</span> plt
plt.<span class="hljs-property">rcParams</span>.<span class="hljs-title function_">update</span>({<span class="hljs-string">'figure.figsize'</span>:(<span class="hljs-number">10</span>,<span class="hljs-number">6</span>), <span class="hljs-string">'figure.dpi'</span>:<span class="hljs-number">100</span>})
lag_len = <span class="hljs-number">15</span>
fig, axes = plt.<span class="hljs-title function_">subplots</span>(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, sharex=<span class="hljs-title class_">True</span>)

# <span class="hljs-title class_">Original</span> <span class="hljs-title class_">Series</span>
axes[<span class="hljs-number">0</span>].<span class="hljs-title function_">plot</span>(train.<span class="hljs-property">values</span>); axes[<span class="hljs-number">0</span>].<span class="hljs-title function_">set_title</span>(<span class="hljs-string">'Original Series'</span>)

# 1st <span class="hljs-title class_">Differencing</span>
axes[<span class="hljs-number">1</span>].<span class="hljs-title function_">plot</span>(train.<span class="hljs-title function_">diff</span>()); axes[<span class="hljs-number">1</span>].<span class="hljs-title function_">set_title</span>(<span class="hljs-string">'1st Order Differencing'</span>)


# 2nd <span class="hljs-title class_">Differencing</span>
axes[<span class="hljs-number">2</span>].<span class="hljs-title function_">plot</span>(train.<span class="hljs-title function_">diff</span>().<span class="hljs-title function_">diff</span>()); axes[<span class="hljs-number">2</span>].<span class="hljs-title function_">set_title</span>(<span class="hljs-string">'2nd Order Differencing'</span>)

axes[<span class="hljs-number">0</span>].<span class="hljs-property">xaxis</span>.<span class="hljs-title function_">set_major_locator</span>(<span class="hljs-title class_">MultipleLocator</span>(<span class="hljs-number">30</span>))

plt.<span class="hljs-title function_">show</span>()
</code></pre>
<p>도 (C)는 학습 데이터의 원래 시계열, 1차 차이화, 그리고 2차 차이화에 대한 플롯을 보여줍니다. 1차 및 2차 차이화된 시계열은 안정적입니다. 즉, 모델은 최소한 한 번은 차이화되어야 합니다. 일반적으로 1차 차이화만으로 충분합니다. 안정적인 시계열에 대한 차이화는 여전히 안정적일 것입니다. 1차 차이화가 이미 안정적이라면 2차 차이화를 얻기 위해 과도하게 차이화할 필요가 없습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_5.png">
<p>이제 ACF를 사용하여 MA(order)를 얻는 방법에 대해 이해해 봅시다.</p>
<p>ACF를 사용하여 MA(order)를 제안합니다.</p>
<p>이미 두 변수 간의 상관 계수에 익숙하실 것입니다. 이는 그들의 관계를 측정합니다. -1과 1 사이의 값을 갖습니다. 양의/음의 상관 계수는 두 변수 간에 양의/음의 관계가 있음을 의미합니다. 상관 계수가 1일 경우 완벽한 양의 선형 관계를, 0.0일 경우 변수 간의 선형 관계가 없음을 나타냅니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>ACF는 자기상관함수(Autocorrelation Function)의 약자입니다. 이것은 시계열과 그 지연된 버전 간의 상관관계를 측정합니다. ACF는 시계열의 시간 t와 시간 t-k에서의 값들 간의 상관관계로 계산됩니다. 여기서 k는 래그(지연) 번호를 나타냅니다. ACF(k)는 래그 k에서의 자기상관을 나타냅니다. 자기상관을 시각화해봅시다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_acf
plt.rcParams.update({<span class="hljs-string">'figure.figsize'</span>:(<span class="hljs-number">10</span>,<span class="hljs-number">6</span>), <span class="hljs-string">'figure.dpi'</span>:<span class="hljs-number">100</span>})
lag_len = <span class="hljs-number">15</span>
fig, axes = plt.subplots(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, sharex=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># 원 데이터</span>
plot_acf(train.values[<span class="hljs-number">0</span>:lag_len], ax=axes[<span class="hljs-number">0</span>], title = <span class="hljs-string">'ACF - 원 데이터'</span>)

<span class="hljs-comment"># 1차 차분</span>
plot_acf(train.diff().dropna()[<span class="hljs-number">0</span>:lag_len], ax=axes[<span class="hljs-number">1</span>], title = <span class="hljs-string">'ACF - 1차 차분'</span>)

<span class="hljs-comment"># 2차 차분</span>
plot_acf(train.diff().diff().dropna()[<span class="hljs-number">0</span>:lag_len], ax=axes[<span class="hljs-number">2</span>], title = <span class="hljs-string">'ACF - 2차 차분'</span>)

plt.show()
</code></pre>
<p>(D) 그림은 자기상관을 보여줍니다. 첫 번째 막대의 상관 계수는 1.0인데, 이는 y_t와 그 자신의 상관관계를 나타냅니다. 파란 영역은 유의수준을 의미합니다. 유의수준을 넘는 막대는 통계적으로 유의미하다는 것을 의미합니다. 보시다시피, 1차 차분 라인에서의 래그 1은 유의미합니다. 이는 모델이 래그 1 항을 포함하고 있으며 1차 차분이 있다는 것을 의미합니다.</p>
<img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_6.png">
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이제 PACF를 배워 봅시다.</p>
<p>PACF를 사용하여 AR의 순서를 제안하세요.</p>
<p>ACF는 시계열과 그 이전 시간 단계의 관련성을 측정합니다. 현재 시계열 값이 과거 값들과 얼마나 연관이 있는지를 알려줍니다. 반면 PACF는 시계열과 그 이전 시간 단계의 부분 상관 관계를 측정하며, 해당 시간 단계 이전의 모든 이전 시간 단계 값을 고려한 후의 영향을 고려합니다. 이는 현재 시계열 값과 특정 시간 지연 값 사이의 직접적인 관계가 있는지 여부를 결정하는 데 도움이 됩니다. 특히 (E) 그림에서 PACF 지연 1이 중요하다고 합니다. 이는 유의 수준을 넘어섰기 때문입니다. 지연 2도 중요하다고 판명되었는데, 약간의 노력으로 유의 선을 넘었습니다(파란색 영역).</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_pacf
plt.rcParams.update({<span class="hljs-string">'figure.figsize'</span>:(<span class="hljs-number">10</span>,<span class="hljs-number">6</span>), <span class="hljs-string">'figure.dpi'</span>:<span class="hljs-number">100</span>})
lag_len = <span class="hljs-number">15</span>
fig, axes = plt.subplots(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, sharex=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># Original Series</span>
plot_pacf(train.values[<span class="hljs-number">0</span>:lag_len], ax=axes[<span class="hljs-number">0</span>], title = <span class="hljs-string">'PACF - Original series'</span>)

<span class="hljs-comment"># 1st Differencing</span>
plot_pacf(train.diff().dropna()[<span class="hljs-number">0</span>:lag_len], ax=axes[<span class="hljs-number">1</span>], title = <span class="hljs-string">'PACF - 1st differencing'</span>)

<span class="hljs-comment"># 2nd Differencing</span>
plot_pacf(train.diff().diff().dropna()[<span class="hljs-number">0</span>:lag_len], ax=axes[<span class="hljs-number">2</span>], title = <span class="hljs-string">'PACF - 2nd differencing'</span>)

plt.show()
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>(E) 그림은 PACF 플롯을 보여줍니다.</p>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_7.png" alt="PACF 그림"></p>
<p>그림 (C), (D), (E)의 차이, ACF 및 PACF는 ARIMA(1, 1, 1)을 제안합니다. 만약 이 진단을 알지 못한다고 가정하더라도, 여전히 auto_ARIMA()를 사용하여 모델 사양의 범위를 찾을 수 있습니다.</p>
<p>auto_ARIMA() 사용하여 최적 모델을 자동으로 탐색하는 방법</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> pmdarima <span class="hljs-keyword">as</span> pm
model = pm.auto_arima(train,
                      d=<span class="hljs-literal">None</span>,
                      seasonal=<span class="hljs-literal">False</span>,
                      stepwise=<span class="hljs-literal">True</span>,
                      suppress_warnings=<span class="hljs-literal">True</span>,
                      error_action=<span class="hljs-string">"ignore"</span>,
                      max_p=<span class="hljs-literal">None</span>,
                      max_order=<span class="hljs-literal">None</span>,
                      trace=<span class="hljs-literal">True</span>)
</code></pre>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_8.png" alt="Automatic ARIMA"></p>
<p>아카이케 정보 기준(Akaike Information Criterion, AIC) 값은 모델 성능 지표입니다. 이 값은 2 * 모델 파라미터 수 - 2 * 최대 우도(L)입니다. 값이 작을수록 모델이 더 잘 맞는 것을 나타냅니다.</p>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_9.png" alt="Automatic ARIMA"></p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Figure(F)에서 가장 낮은 AIC 값은 3,301.526입니다. ARIMA(1, 1, 1)(0, 0, 0)입니다. 계절성 구성요소는 (0, 0, 0)입니다. 계절 차분이 없기 때문에 "seasonal=False"로 하이퍼파라미터를 끔 처리했습니다. 나중에 ARIMA에서 다시 활성화할 것입니다.</p>
<p>다중 기간 예측</p>
<p>"pmdarima"의 "predict" 함수를 사용하면 미래 시점의 기간 수를 지정할 수 있습니다. 미래 시점을 테스트 데이터의 길이로 설정합니다. 그리고 "return_conf_int = True"와 "alpha = 0.05"로 설정하여 95% 신뢰 수준의 신뢰 구간을 반환합니다.</p>
<pre><code class="hljs language-js"># test_len의 길이에 대한 다중 기간 예측 생성
fcast = model.<span class="hljs-title function_">predict</span>(n_periods=test_len, return_conf_int=<span class="hljs-title class_">True</span>, alpha=<span class="hljs-number">0.05</span>)
forecasts = fcast[<span class="hljs-number">0</span>]
confidence_intervals = fcast[<span class="hljs-number">1</span>]
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>모델의 성능을 평가해 봅시다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error, mean_absolute_percentage_error
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"MAPE: <span class="hljs-subst">{mean_absolute_percentage_error(test, forecasts)}</span>"</span>)
</code></pre>
<p>평균 절대 백분율 오차는 0.1490595592393948 또는 14.9% 입니다. 다음으로 실제 값과 예측값을 그래프로 그려보겠습니다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_it</span>():
    fig, ax = plt.subplots(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">4</span>))

    <span class="hljs-comment"># 실제 vs. 예측</span>
    ax.plot(train, color=<span class="hljs-string">'blue'</span>, label=<span class="hljs-string">'Training data'</span>)
    ax.plot(test.index, forecasts, color=<span class="hljs-string">'red'</span>, marker=<span class="hljs-string">'o'</span>,
                label=<span class="hljs-string">'Predicted'</span>)
    ax.plot(test.index, test, color=<span class="hljs-string">'green'</span>, label=<span class="hljs-string">'Test data'</span>)
    ax.set_title(<span class="hljs-string">'아보카도 판매량'</span>)
    ax.set_xlabel(<span class="hljs-string">'날짜'</span>)
    ax.set_ylabel(<span class="hljs-string">'양'</span>)
    conf_int = np.asarray(confidence_intervals)

    <span class="hljs-comment"># 신뢰 구간</span>
    ax.fill_between(test.index,
                        conf_int[:, <span class="hljs-number">0</span>], conf_int[:, <span class="hljs-number">1</span>],
                        alpha=<span class="hljs-number">0.9</span>, color=<span class="hljs-string">'orange'</span>,
                        label=<span class="hljs-string">"신뢰 구간"</span>)
    <span class="hljs-comment"># 주요 눈금이 20의 배수인 플롯 생성</span>
    ax.legend()
    ax.xaxis.set_major_locator(MultipleLocator(<span class="hljs-number">20</span>))
    plt.show()

plot_it()
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>표 (G)는 학습, 테스트 데이터, 예측값 및 신뢰 구간의 시계열을 제공합니다.</p>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_10.png" alt="Figure G"></p>
<p>표 (G)의 예측 값은 일정 기간 이후에 고정값에 수렴하며 예측 가능성이 있습니다. 인상적으로 보이지 않습니다. 각 반복에서 모델을 업데이트하여 개선할 수 있습니다.</p>
<p>각 반복에서 모델을 업데이트해보세요.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>각 예측은 예측 시계열에 새로운 관측치를 추가합니다. 모델이 정적인 경우, 예측된 시계열은 최종적으로 직선이 되어 그래프(G)에 표시됩니다. 각 반복에서 추가된 관측치로 모델을 업데이트할 수 있습니다.</p>
<p>우리는 시간 외 시험 기간의 각 반복에서 한 기간을 예측한 후, 새로운 예측을 모델을 업데이트하는 데 사용할 것입니다. "return_conf_int = True" 및 "alpha= 5%"를 지정하여 95% 신뢰 수준의 예측 구간을 추가할 수 있습니다.</p>
<pre><code class="hljs language-js"># <span class="hljs-attr">https</span>:<span class="hljs-comment">//alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.ARIMA.html#pmdarima.arima.ARIMA.update</span>
def <span class="hljs-title function_">one_period_forecast</span>():
    fcast = model.<span class="hljs-title function_">predict</span>(n_periods=<span class="hljs-number">1</span>, return_conf_int=<span class="hljs-title class_">True</span>, alpha=<span class="hljs-number">0.05</span>)
    # fcast는 두 개의 리스트로 구성됩니다.
    # 첫 번째 리스트는 예측입니다.
    forecasts = fcast[<span class="hljs-number">0</span>].<span class="hljs-title function_">tolist</span>()
    # 두 번째 리스트는 신뢰 구간입니다.
    confidence_intervals = fcast[<span class="hljs-number">1</span>]
    <span class="hljs-keyword">return</span> ( forecasts, 
             np.<span class="hljs-title function_">asarray</span>(confidence_intervals).<span class="hljs-title function_">tolist</span>()[<span class="hljs-number">0</span>])

forecasts = []
confidence_intervals = []

<span class="hljs-keyword">for</span> add_obs <span class="hljs-keyword">in</span> <span class="hljs-attr">test</span>:
    fc, conf = <span class="hljs-title function_">one_period_forecast</span>()
    forecasts.<span class="hljs-title function_">append</span>(fc)
    confidence_intervals.<span class="hljs-title function_">append</span>(conf)
    # 기존 모델 업데이트
    model.<span class="hljs-title function_">update</span>(add_obs)

<span class="hljs-title function_">plot_it</span>()
</code></pre>
<p>그림 (H)은 예측값이 테스트 값과 더 잘 일치함을 보여줍니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_11.png">
<p>모델 성능은 어떤가요?</p>
<pre><code class="hljs language-js"><span class="hljs-title function_">print</span>(f<span class="hljs-string">"MAPE: {mean_absolute_percentage_error(test, forecasts)}"</span>)
</code></pre>
<p>MAPE는 0.11766234388644323으로, 약 11.7%보다 약간 향상되었습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>우리 연구를 위한 데이터는 여러 해에 걸친 시계열 데이터이기 때문에 강력한 계절성을 갖고 있다고 의심됩니다. 우리는 Seasonal ARIMA를 사용하여 모델을 완화할 것입니다.</p>
<p>SARIMA 모델</p>
<p>SARIMA 모델은 계절적 시계열 데이터를 다루는 데 특히 설계되었습니다. ARIMA 모델의 비계절적 구성요소 (AR, I 및 MA)에 추가로 SARIMA 모델에는 데이터의 계절적 패턴을 포착하는 계절적 구성요소 (SAR, SI 및 SMA)가 포함되어 있습니다. SARIMA 모델의 SAR 구성요소는 ARIMA 모델의 AR 구성요소와 유사하지만 시계열의 계절적 지연된 값에 작용합니다. SI 구성요소는 ARIMA 모델의 I 구성요소와 유사하지만 시계열의 계절적 차이에 적용됩니다. 마지막으로, SMA 구성요소는 ARIMA 모델의 MA 구성요소와 유사하지만 시계열의 계절적 지연된 오차에 작용합니다.</p>
<p>요약하자면, SARIMA는 단순히 계절 급변을 적용합니다. 계절적 급변은 일반적인 급변과 유사합니다. 연이은 용어를 빼는 대신, 계절적 급변은 이전 계절의 값에서 값을 뺍니다. SARIMA 모델은 일반적으로 SARIMA(p,d,q)(P,D,Q)[S]로 표기됩니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>p은 계절적 자기회귀항의 차수를 나타냅니다.</li>
<li>q는 계절적 이동평균항의 차수를 나타냅니다.</li>
<li>Q는 계절적 차분의 차수를 나타냅니다.</li>
<li>S는 12개월과 같은 계절 사이클을 나타냅니다.</li>
</ul>
<p>계절 ARIMA 모델은 데이터의 계절 패턴을 포착하기 위해 추가 매개변수를 통합합니다. 다음 구성 요소를 추가합니다:</p>
<ul>
<li>계절적 AR 항: 이러한 항목은 현재 관측치와 계절 간격의 특정 차이 관측치 사이의 관계를 나타냅니다. 데이터의 계절적 패턴을 캡처합니다.</li>
<li>계절적 MA 항: 이러한 항목은 현재 관측치와 계절 간격의 특정 기간의 선행 예측 오류 사이의 관계를 나타냅니다. 데이터의 계절적 변동성을 캡처합니다.</li>
</ul>
<p>SARIMA 모델링은 매우 쉽습니다. 해야 할 일은 하이퍼파라미터 "seasonal"을 "True"로 변경하는 것뿐입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> pmdarima <span class="hljs-keyword">as</span> pm
model = pm.auto_arima(train,
                      <span class="hljs-comment"># You just need to turn the seasonal to "True"</span>
                      seasonal=<span class="hljs-literal">True</span>,
                      start_P=<span class="hljs-number">1</span>,
                      start_q=<span class="hljs-number">1</span>,
                      max_p=<span class="hljs-literal">None</span>,
                      max_q=<span class="hljs-literal">None</span>,
                      m=<span class="hljs-number">12</span>,
                      d=<span class="hljs-number">1</span>,
                      D=<span class="hljs-number">1</span>,
                      trace=<span class="hljs-literal">True</span>,
                      error_action=<span class="hljs-string">'ignore'</span>,
                      suppress_warnings=<span class="hljs-literal">True</span>,
                      stepwise=<span class="hljs-literal">True</span>)
model.summary()
</code></pre>
<p>한 가지 모델을 만들었어요. 그림 (I)은 최적의 모델이 ARIMA(0,1,1)(0,1,1)[12]임을 보여줍니다.</p>
<img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_12.png">
<p>결과를 그래픽으로 표시하고 각 반복마다 모델 업데이트를 활성화해봅시다. 그림 (J)에 플롯이 표시됩니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">forecasts = []
confidence_intervals = []

<span class="hljs-keyword">for</span> add_obs <span class="hljs-keyword">in</span> <span class="hljs-attr">test</span>:
    fc, conf = <span class="hljs-title function_">one_period_forecast</span>()
    forecasts.<span class="hljs-title function_">append</span>(fc)
    confidence_intervals.<span class="hljs-title function_">append</span>(conf)
    # <span class="hljs-title class_">Updates</span> the existing model
    model.<span class="hljs-title function_">update</span>(add_obs)

# <span class="hljs-title class_">Plot</span> the results
<span class="hljs-title function_">plot_it</span>()

# <span class="hljs-title class_">Calculate</span> <span class="hljs-variable constant_">MAPE</span>
<span class="hljs-title function_">print</span>(f<span class="hljs-string">"MAPE: {mean_absolute_percentage_error(test, forecasts)}"</span>)
</code></pre>
<p>MAPE는 0.11918293096560012 또는 11.9%입니다. 이것은 위의 ARIMA 모델에 비해 뚜렷한 개선이 없어 보입니다. 모델의 간결성 원칙에 따라, 우리는 SARIMA 대신 ARIMA 모델을 사용할 것입니다.</p>
<p><img src="/TIL/assets/img/2024-07-14-AutomaticARIMA_13.png" alt="이미지"></p>
<p>결론</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 게시물에서는 고전적인 ARIMA 및 SARIMA 모델 사양을 검토했습니다. 최적 모델을 자동으로 검색하기 위해 pmdarima 라이브러리의 사용법을 배웠습니다. 또한 ARIMA 및 SARIMA에 대한 다기간 예측 생성 방법을 배웠습니다.</p>
<p>우리는 복잡성이 증가하는 시계열 데이터를 모델링할 것입니다. 여러 Python 라이브러리가 복잡한 데이터 구조에 대한 해결책을 제공합니다. 우리는 이러한 데이터 솔루션을 10장에서 배울 것입니다: 시계열 데이터 형식 변환의 비밀.</p>
<p>참고문헌</p>
<ul>
<li>[1] Box, G. E. P., Jenkins, G. M., and Reinsel, G. C. (2015). 시계열 분석: 예측 및 제어 (5판). John Wiley &#x26; Sons.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>샘플 eBook 챕터(무료): <a href="https://github.com/dataman-git/modern-time-series/blob/main/20240522beauty_TOC.pdf" rel="nofollow" target="_blank">여기</a></p>
<ul>
<li>아름다운 형식으로 책을 재현하고 즐거운 독서 경험을 제공하기 위해 The Innovation Press, LLC 직원 여러분께 감사드립니다. 우리는 Teachable 플랫폼을 선택하여 전 세계 독자들에게 번거로운 과부하 없이 eBook을 유통합니다. 신용 카드 거래는 Teachable.com이 안전하고 기밀리에 처리합니다.</li>
</ul>
<p>Teachable.com의 eBook: $22.50
<a href="https://drdataman.teachable.com/p/home" rel="nofollow" target="_blank">여기</a></p>
<p>Amazon.com에서 인쇄판: $65 <a href="https://a.co/d/25FVsMx" rel="nofollow" target="_blank">링크</a></p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>프린트 버전은 윤광 처리 커버, 컬러 인쇄, 아름다운 스프링어 글꼴 및 레이아웃을 채택하여 즐거운 독서 경험을 제공합니다. 7.5 x 9.25인치의 품격 높은 크기는 서재에 있는 대부분의 책과 어울립니다.</li>
<li>"이 책은 Kuo의 시계열 분석에 대한 깊은 이해와 예측 분석 및 이상 탐지에 대한 응용을 증명하는 것입니다. 이 책은 독자들이 실제 세계의 문제에 대처하기 위한 필수적인 기술을 제공합니다. 데이터 과학 분야로의 직업 전환을 고려하는 사람들에게 특히 가치 있는 자료입니다. Kuo는 전통적인 기술 뿐만 아니라 최신 기술에 대해 자세히 탐구합니다. Kuo는 신경망 및 다른 고급 알고리즘에 대한 논의를 통합하여, 분야의 최신 동향과 발전을 반영합니다. 이는 독자가 확립된 방법뿐만 아니라 데이터 과학 분야에서 가장 현재이고 혁신적인 기술을 다루는 데 대비할 수 있도록 보장합니다. Kuo의 생생한 글쓰기 스타일로 책의 명료함과 접근성은 높아졌습니다. 그는 복잡한 수학 및 통계 개념을 신비롭지 않게 만들면서도 엄격성을 희생하지 않았습니다."</li>
</ul>
<h1>현대적인 시계열 예측: 예측 분석 및 이상 탐지를 위한</h1>
<p>제로 장: 서문</p>
<p>1장: 소개</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>장 2: 비즈니스 예측을 위한 선지자</h1>
<h1>장 3: 튜토리얼 I: 트렌드 + 계절성 + 휴일 및 이벤트</h1>
<h1>장 4: 튜토리얼 II: 트렌드 + 계절성 + 휴일 및 이벤트 + 자기회귀(AR) + 지연 회귀자 + 미래 회귀자</h1>
<h1>장 5: 시계열 데이터의 변화점 탐지</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Chapter 6: 시계열 확률 예측을 위한 몬테카를로 시뮬레이션</p>
<p>Chapter 7: 시계열 확률 예측을 위한 분위 회귀</p>
<p>Chapter 8: 시계열 확률 예측을 위한 일치 예측</p>
<p>Chapter 9: 시계열 확률 예측을 위한 일치화된 분위 회귀</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>제 10장: 자동 ARIMA!</h1>
<h1>제 11장: 시계열 데이터 형식 쉽게 만들기</h1>
<h1>제 12장: 다기간 확률 예측을 위한 선형 회귀</h1>
<h1>제 13장: 트리 기반 시계열 모델을 위한 피처 엔지니어링</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>14장: 다기간 시계열 예측을 위한 두 가지 기본 전략</h1>
<h1>15장: 다기간 시계열 확률적 예측을 위한 Tree 기반 XGB, LightGBM 및 CatBoost 모델</h1>
<h1>16장: 시계열 모델링 기술의 진화</h1>
<h1>17장: 시계열 확률적 예측을 위한 Deep Learning 기반 DeepAR</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Chapter 18: 주가에 대한 확률적 예측을 위한 응용</p>
<p>Chapter 19: RNN부터 Transformer 기반 시계열 모델까지</p>
<p>Chapter 20: 해석 가능한 시계열 예측을 위한 Temporal Fusion Transformer</p>
<p>Chapter 21: 시계열 예측을 위한 오픈소스 Lag-Llama 튜토리얼</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"자동 ARIMA 모델 사용 방법","description":"","date":"2024-07-14 19:49","slug":"2024-07-14-AutomaticARIMA","content":"\n\n자동 모델 선택 및 다단계 예측\n\n![이미지](/TIL/assets/img/2024-07-14-AutomaticARIMA_0.png)\n\nARIMA (AutoRegressive Integrated Moving Average)은 시계열 예측 및 분석에 사용되는 통계 모델입니다. ARIMA의 기원은 1900년대 초반으로 거슬러 올라가며 자기회귀(AR) 모델과 이동평균 (MA) 모델이 별도로 발전됐습니다. 두 모델 모두 현실 시계열 데이터의 복잡한 역학을 포착하기에는 충분하지 않은 것으로 나타납니다. 1960년대에 세 통계학자인 조지 E. P. 박스, 그윌림 M. 젠킨스, 그리고 그레고리 C. 레인절이 \"시계열 분석: 예측과 제어\"라는 책에서 AR과 MA 모델을 공식적으로 통합하여 ARIMA를 만들었습니다.\n\nARIMA는 아마도 가장 잘 알려진 패러다임이지만, 왜 이 \"현대적인\" 시계열 서적에 포함시키는 걸까요? 주된 이유는 AR과 MA가 현대적인 시계열 기술에서 많은 흔적을 남겨주었기 때문입니다. ARIMA에 대한 기본 이해는 다른 복잡한 모델에 걸쳐 활용할 수 있게 해줍니다. 예를 들어, NeuralProphet의 4장에서 AR 모듈을 보았고, 12장과 13장에서는 AR 항목을 감독 학습 모델에서 특징으로 볼 것입니다. 이 책에 ARIMA를 포함한 두 번째 이유는 최근의 코드 개발로 자동 모델 선택과 다단계 예측이 가능해졌기 때문입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 챕터 4: \"튜토리얼 II: 트렌드 + 계절성 + 휴일 및 이벤트 + 자기 회귀(AR) + 지연 회귀자 + 미래 회귀자.\"\n- 챕터 12: \"트리 기반 시계열 예측에 대한 튜토리얼\"\n- 챕터 13: \"다단계 시계열 예측에 대한 튜토리얼.\"\n\n오늘날의 코드 라이브러리를 사용하면 최적의 ARIMA 모델을 선택할 수 있습니다. 표준 ARIMA 학파에서 교육을 받은 경우, 최적의 AR 및 MA 순서를 선택하기위한 규정화된 지침을 외우고 있는 사람도 있을 것입니다. 모델 사양을 결정하기 위해 자동 상관 함수(ACF) 및 부분 자동 상관 함수(PACF)를 사용해야 합니다. 그러나 나는 그런 규정화된 지침을 잊어버리고 그냥 여러 순서의 후보 모델을 만들어 최적의 모델을 선택합니다. 왜 최상의 모델을 선택하기 위해 많은 모델을 생성하지 않을까요? 이러한 이유로, Python의 \"pmdarima\"와 같은 편리한 라이브러리가 있어 최적 사양을 자동화하는 데 도움이 됩니다. 이 장을 \"자동 ARIMA\"라고 제목 지어 이 이점을 강조하고자 합니다. 그래도 이 챕터에서는 차이, ACF 및 PACF의 개념을 다룰 것입니다.\n\n\"statsmodels\"와 \"pmdarima\"와 같은 현대의 코드 라이브러리는 단기 예측이 아닌 다단계 예측을 가능하게 합니다. 이를 수행하기 위해 모델을 재귀적으로 적용하여 예측을 생성하는 방법에 대해 배우게 될 것입니다. 일반적으로 다단계 예측을 생성하는 두 가지 기본 전략이 있습니다: 재귀적 방법과 직접 방법. 우리는 챕터 13 \"다단계 시계열 예측에 대한 튜토리얼\"에서 이를 배울 것입니다. 두 전략은 ARIMA와 lightGBM 또는 XGB와 같은 트리 기반 모델에 채택되어 다단계 예측을 생성합니다.\n\n마지막으로, 많은 사용 사례에서 우리는 점 추정치에 만족하지 않고 예측 구간을 필요로 합니다. 잠재적 불확실성을 평가하기 위해 가능한 값의 범위가 필요합니다. \"pmdarima\"와 \"statsmodels\"는 신뢰 구간을 반환합니다. 반면에, Part II \"확률적 예측을 얻기\"의 5부터 8 챕터에서 예측 구간을 위한 더 많은 기술을 배웠습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 제 5장: 시계열 확률 예측을 위한 몬테카를로 시뮬레이션\n- 제 6장: 시계열 확률 예측을 위한 분위 회귀\n- 제 7장: 시계열 확률 예측을 위한 형식 예측\n- 제 8장: 시계열 확률 예측을 위한 형식화된 분위 회귀\n\n이 글에서는 이론과 실무를 포괄적으로 설명하겠습니다. 실제 데이터를 사용하여 모델 구축과 예측을 안내할 예정이에요. 이미 알고 계신 부분은 건너뛰셔도 괜찮아요. Python 노트북은 여기서 다운로드할 수 있어요. 다룰 주제들은 다음과 같아요:\n\n- ARIMA 모델\n- 차분\n- ACF 사용하여 MA의 차수 제안\n- PACF 사용하여 AR의 차수 제안\n- pmdarima 라이브러리 사용하여 최적 모델 자동 탐색\n- 다단계 예측\n- statsmodels 사용하여 모델을 반복적으로 업데이트\n- SARIMA 모델\n\n먼저 데이터를 불러오겠습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터 전처리\n\n카글의 아보카도 판매 데이터를 사용할 것입니다.\n\n```js\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nfrom google.colab import drive\ndrive.mount('/content/gdrive')\n\npath = '/content/gdrive/My Drive/data/time_series'\ndata = pd.read_csv(path + '/avocado_monthly.csv', index_col='Date')\ndata.sort_values(by='Total Volume', ascending=False)\n```\n\n(A) 그림은 이 데이터셋의 일부를 보여줍니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![그림](/TIL/assets/img/2024-07-14-AutomaticARIMA_1.png)\n\n이 데이터 세트에서는 하나의 일변량 시계열만 사용할 것입니다.\n\n```js\n# '유기농' 및 'TotalUS' 지역인 하나의 시계열만 사용합니다.\ndf = data[(data['type']=='organic') \u0026 (data['region']=='TotalUS')].copy()\ndf = df['Total Volume']\ndf.columns = ['y']\ndf = df[pd.to_datetime(df.index)\u003c=pd.to_datetime('2018-02-01')]\n\n# 일변량 시계열 그래프 그리기\nplt.figure(figsize=(10,4))\nplt.plot(df)\nplt.xlabel(\"날짜\")\nplt.ylabel(\"볼륨\")\nplt.show()\n```\n\n그림 (B)는 일변량 시계열 그래프를 보여줍니다.\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![그림](/TIL/assets/img/2024-07-14-AutomaticARIMA_2.png)\n\n이후에는 80%를 인-타임 훈련 데이터로 사용하고 나머지 20%는 아웃-오브-타임 테스트 데이터로 사용합니다.\n\n```js\n# Train-test-split\ntrain_len = int(df.shape[0] * 0.8)\ntest_len = df.shape[0] - train_len\ntrain, test = df[:train_len], df[train_len:]\nprint(f\"{train_len}개의 훈련 샘플\")\nprint(f\"{df.shape[0] - train_len}개의 테스트 샘플\")\n```\n\n좋아요. 이제 우리는 정의부터 시작합시다.\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nARIMA 모델들\n\nARIMA는 단변량 시계열 데이터를 사용하여 미래 값을 예측하는 모델 클래스입니다. 이 모델들은 시계열 데이터의 과거 또는 이전 값, 즉 자기 회귀(AR) 항목과 이동 평균(MA) 항목인 이동 예측 오차의 지연된 값들을 사용하여 미래 값을 예측합니다. ARIMA이란 \"자기 회귀-통합-이동 평균\"의 약자로, \"AR\", \"I\", \"MA\"로 구성됩니다. 여기서 ARIMA의 \"I\"는 \"통합(integrated)\"을 의미하며, 이는 시계열 데이터가 안정성을 달성하기 위해 차분된 것을 나타냅니다. 안정적인 시계열 데이터는 시간이 지나도 평균, 분산 및 자기 상관이 일정하므로 모델링하기 쉽습니다. ARIMA(p,d,q) 모델로 수학적으로 표현하면 다음과 같습니다:\n\nMarkdown 형식으로 테이블 태그를 변경하십시오.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n![AutomaticARIMA_3](/TIL/assets/img/2024-07-14-AutomaticARIMA_3.png)\n\nARIMA 표기법에 친숙해지기 위해 위 식을 적용해 봅시다.\n\n![AutomaticARIMA_4](/TIL/assets/img/2024-07-14-AutomaticARIMA_4.png)\n\n일반적으로 AR만 또는 MA만, 또는 p와 q가 모두 4 미만이기 때문에 우변에 많은 항이 없습니다.\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n차이화\n\n차이화의 목표는 시계열을 안정적으로 만드는 것입니다. 시계열에서 안정성이란 값의 평균이 시간에 따라 일정하다는 것을 의미합니다. 다시 말해, 안정적인 시계열은 일정한 평균을 갖습니다. 이전 코드는 원래 시계열, 1차 차이화(한 번 차이화), 그리고 2차 차이화(두 번 차이화)를 플롯합니다.\n\n```js\nimport numpy as np, pandas as pd\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'figure.figsize':(10,6), 'figure.dpi':100})\nlag_len = 15\nfig, axes = plt.subplots(3, 1, sharex=True)\n\n# Original Series\naxes[0].plot(train.values); axes[0].set_title('Original Series')\n\n# 1st Differencing\naxes[1].plot(train.diff()); axes[1].set_title('1st Order Differencing')\n\n\n# 2nd Differencing\naxes[2].plot(train.diff().diff()); axes[2].set_title('2nd Order Differencing')\n\naxes[0].xaxis.set_major_locator(MultipleLocator(30))\n\nplt.show()\n```\n\n도 (C)는 학습 데이터의 원래 시계열, 1차 차이화, 그리고 2차 차이화에 대한 플롯을 보여줍니다. 1차 및 2차 차이화된 시계열은 안정적입니다. 즉, 모델은 최소한 한 번은 차이화되어야 합니다. 일반적으로 1차 차이화만으로 충분합니다. 안정적인 시계열에 대한 차이화는 여전히 안정적일 것입니다. 1차 차이화가 이미 안정적이라면 2차 차이화를 얻기 위해 과도하게 차이화할 필요가 없습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_5.png\" /\u003e\n\n이제 ACF를 사용하여 MA(order)를 얻는 방법에 대해 이해해 봅시다.\n\nACF를 사용하여 MA(order)를 제안합니다.\n\n이미 두 변수 간의 상관 계수에 익숙하실 것입니다. 이는 그들의 관계를 측정합니다. -1과 1 사이의 값을 갖습니다. 양의/음의 상관 계수는 두 변수 간에 양의/음의 관계가 있음을 의미합니다. 상관 계수가 1일 경우 완벽한 양의 선형 관계를, 0.0일 경우 변수 간의 선형 관계가 없음을 나타냅니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nACF는 자기상관함수(Autocorrelation Function)의 약자입니다. 이것은 시계열과 그 지연된 버전 간의 상관관계를 측정합니다. ACF는 시계열의 시간 t와 시간 t-k에서의 값들 간의 상관관계로 계산됩니다. 여기서 k는 래그(지연) 번호를 나타냅니다. ACF(k)는 래그 k에서의 자기상관을 나타냅니다. 자기상관을 시각화해봅시다.\n\n```python\nfrom statsmodels.graphics.tsaplots import plot_acf\nplt.rcParams.update({'figure.figsize':(10,6), 'figure.dpi':100})\nlag_len = 15\nfig, axes = plt.subplots(3, 1, sharex=True)\n\n# 원 데이터\nplot_acf(train.values[0:lag_len], ax=axes[0], title = 'ACF - 원 데이터')\n\n# 1차 차분\nplot_acf(train.diff().dropna()[0:lag_len], ax=axes[1], title = 'ACF - 1차 차분')\n\n# 2차 차분\nplot_acf(train.diff().diff().dropna()[0:lag_len], ax=axes[2], title = 'ACF - 2차 차분')\n\nplt.show()\n```\n\n(D) 그림은 자기상관을 보여줍니다. 첫 번째 막대의 상관 계수는 1.0인데, 이는 y_t와 그 자신의 상관관계를 나타냅니다. 파란 영역은 유의수준을 의미합니다. 유의수준을 넘는 막대는 통계적으로 유의미하다는 것을 의미합니다. 보시다시피, 1차 차분 라인에서의 래그 1은 유의미합니다. 이는 모델이 래그 1 항을 포함하고 있으며 1차 차분이 있다는 것을 의미합니다.\n\n\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_6.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 PACF를 배워 봅시다.\n\nPACF를 사용하여 AR의 순서를 제안하세요.\n\nACF는 시계열과 그 이전 시간 단계의 관련성을 측정합니다. 현재 시계열 값이 과거 값들과 얼마나 연관이 있는지를 알려줍니다. 반면 PACF는 시계열과 그 이전 시간 단계의 부분 상관 관계를 측정하며, 해당 시간 단계 이전의 모든 이전 시간 단계 값을 고려한 후의 영향을 고려합니다. 이는 현재 시계열 값과 특정 시간 지연 값 사이의 직접적인 관계가 있는지 여부를 결정하는 데 도움이 됩니다. 특히 (E) 그림에서 PACF 지연 1이 중요하다고 합니다. 이는 유의 수준을 넘어섰기 때문입니다. 지연 2도 중요하다고 판명되었는데, 약간의 노력으로 유의 선을 넘었습니다(파란색 영역).\n\n```python\nfrom statsmodels.graphics.tsaplots import plot_pacf\nplt.rcParams.update({'figure.figsize':(10,6), 'figure.dpi':100})\nlag_len = 15\nfig, axes = plt.subplots(3, 1, sharex=True)\n\n# Original Series\nplot_pacf(train.values[0:lag_len], ax=axes[0], title = 'PACF - Original series')\n\n# 1st Differencing\nplot_pacf(train.diff().dropna()[0:lag_len], ax=axes[1], title = 'PACF - 1st differencing')\n\n# 2nd Differencing\nplot_pacf(train.diff().diff().dropna()[0:lag_len], ax=axes[2], title = 'PACF - 2nd differencing')\n\nplt.show()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n(E) 그림은 PACF 플롯을 보여줍니다.\n\n![PACF 그림](/TIL/assets/img/2024-07-14-AutomaticARIMA_7.png)\n\n그림 (C), (D), (E)의 차이, ACF 및 PACF는 ARIMA(1, 1, 1)을 제안합니다. 만약 이 진단을 알지 못한다고 가정하더라도, 여전히 auto_ARIMA()를 사용하여 모델 사양의 범위를 찾을 수 있습니다.\n\nauto_ARIMA() 사용하여 최적 모델을 자동으로 탐색하는 방법\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nimport pmdarima as pm\nmodel = pm.auto_arima(train,\n                      d=None,\n                      seasonal=False,\n                      stepwise=True,\n                      suppress_warnings=True,\n                      error_action=\"ignore\",\n                      max_p=None,\n                      max_order=None,\n                      trace=True)\n```\n\n![Automatic ARIMA](/TIL/assets/img/2024-07-14-AutomaticARIMA_8.png)\n\n아카이케 정보 기준(Akaike Information Criterion, AIC) 값은 모델 성능 지표입니다. 이 값은 2 * 모델 파라미터 수 - 2 * 최대 우도(L)입니다. 값이 작을수록 모델이 더 잘 맞는 것을 나타냅니다.\n\n![Automatic ARIMA](/TIL/assets/img/2024-07-14-AutomaticARIMA_9.png)\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFigure(F)에서 가장 낮은 AIC 값은 3,301.526입니다. ARIMA(1, 1, 1)(0, 0, 0)입니다. 계절성 구성요소는 (0, 0, 0)입니다. 계절 차분이 없기 때문에 \"seasonal=False\"로 하이퍼파라미터를 끔 처리했습니다. 나중에 ARIMA에서 다시 활성화할 것입니다.\n\n다중 기간 예측\n\n\"pmdarima\"의 \"predict\" 함수를 사용하면 미래 시점의 기간 수를 지정할 수 있습니다. 미래 시점을 테스트 데이터의 길이로 설정합니다. 그리고 \"return_conf_int = True\"와 \"alpha = 0.05\"로 설정하여 95% 신뢰 수준의 신뢰 구간을 반환합니다.\n\n```js\n# test_len의 길이에 대한 다중 기간 예측 생성\nfcast = model.predict(n_periods=test_len, return_conf_int=True, alpha=0.05)\nforecasts = fcast[0]\nconfidence_intervals = fcast[1]\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델의 성능을 평가해 봅시다.\n\n```python\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\nprint(f\"MAPE: {mean_absolute_percentage_error(test, forecasts)}\")\n```\n\n평균 절대 백분율 오차는 0.1490595592393948 또는 14.9% 입니다. 다음으로 실제 값과 예측값을 그래프로 그려보겠습니다.\n\n```python\ndef plot_it():\n    fig, ax = plt.subplots(figsize=(12,4))\n\n    # 실제 vs. 예측\n    ax.plot(train, color='blue', label='Training data')\n    ax.plot(test.index, forecasts, color='red', marker='o',\n                label='Predicted')\n    ax.plot(test.index, test, color='green', label='Test data')\n    ax.set_title('아보카도 판매량')\n    ax.set_xlabel('날짜')\n    ax.set_ylabel('양')\n    conf_int = np.asarray(confidence_intervals)\n\n    # 신뢰 구간\n    ax.fill_between(test.index,\n                        conf_int[:, 0], conf_int[:, 1],\n                        alpha=0.9, color='orange',\n                        label=\"신뢰 구간\")\n    # 주요 눈금이 20의 배수인 플롯 생성\n    ax.legend()\n    ax.xaxis.set_major_locator(MultipleLocator(20))\n    plt.show()\n\nplot_it()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n표 (G)는 학습, 테스트 데이터, 예측값 및 신뢰 구간의 시계열을 제공합니다.\n\n![Figure G](/TIL/assets/img/2024-07-14-AutomaticARIMA_10.png)\n\n표 (G)의 예측 값은 일정 기간 이후에 고정값에 수렴하며 예측 가능성이 있습니다. 인상적으로 보이지 않습니다. 각 반복에서 모델을 업데이트하여 개선할 수 있습니다.\n\n각 반복에서 모델을 업데이트해보세요.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n각 예측은 예측 시계열에 새로운 관측치를 추가합니다. 모델이 정적인 경우, 예측된 시계열은 최종적으로 직선이 되어 그래프(G)에 표시됩니다. 각 반복에서 추가된 관측치로 모델을 업데이트할 수 있습니다.\n\n우리는 시간 외 시험 기간의 각 반복에서 한 기간을 예측한 후, 새로운 예측을 모델을 업데이트하는 데 사용할 것입니다. \"return_conf_int = True\" 및 \"alpha= 5%\"를 지정하여 95% 신뢰 수준의 예측 구간을 추가할 수 있습니다.\n\n```js\n# https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.ARIMA.html#pmdarima.arima.ARIMA.update\ndef one_period_forecast():\n    fcast = model.predict(n_periods=1, return_conf_int=True, alpha=0.05)\n    # fcast는 두 개의 리스트로 구성됩니다.\n    # 첫 번째 리스트는 예측입니다.\n    forecasts = fcast[0].tolist()\n    # 두 번째 리스트는 신뢰 구간입니다.\n    confidence_intervals = fcast[1]\n    return ( forecasts, \n             np.asarray(confidence_intervals).tolist()[0])\n\nforecasts = []\nconfidence_intervals = []\n\nfor add_obs in test:\n    fc, conf = one_period_forecast()\n    forecasts.append(fc)\n    confidence_intervals.append(conf)\n    # 기존 모델 업데이트\n    model.update(add_obs)\n\nplot_it()\n```\n\n그림 (H)은 예측값이 테스트 값과 더 잘 일치함을 보여줍니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_11.png\" /\u003e\n\n모델 성능은 어떤가요?\n\n```js\nprint(f\"MAPE: {mean_absolute_percentage_error(test, forecasts)}\")\n```\n\nMAPE는 0.11766234388644323으로, 약 11.7%보다 약간 향상되었습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리 연구를 위한 데이터는 여러 해에 걸친 시계열 데이터이기 때문에 강력한 계절성을 갖고 있다고 의심됩니다. 우리는 Seasonal ARIMA를 사용하여 모델을 완화할 것입니다.\n\nSARIMA 모델\n\nSARIMA 모델은 계절적 시계열 데이터를 다루는 데 특히 설계되었습니다. ARIMA 모델의 비계절적 구성요소 (AR, I 및 MA)에 추가로 SARIMA 모델에는 데이터의 계절적 패턴을 포착하는 계절적 구성요소 (SAR, SI 및 SMA)가 포함되어 있습니다. SARIMA 모델의 SAR 구성요소는 ARIMA 모델의 AR 구성요소와 유사하지만 시계열의 계절적 지연된 값에 작용합니다. SI 구성요소는 ARIMA 모델의 I 구성요소와 유사하지만 시계열의 계절적 차이에 적용됩니다. 마지막으로, SMA 구성요소는 ARIMA 모델의 MA 구성요소와 유사하지만 시계열의 계절적 지연된 오차에 작용합니다.\n\n요약하자면, SARIMA는 단순히 계절 급변을 적용합니다. 계절적 급변은 일반적인 급변과 유사합니다. 연이은 용어를 빼는 대신, 계절적 급변은 이전 계절의 값에서 값을 뺍니다. SARIMA 모델은 일반적으로 SARIMA(p,d,q)(P,D,Q)[S]로 표기됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- p은 계절적 자기회귀항의 차수를 나타냅니다.\n- q는 계절적 이동평균항의 차수를 나타냅니다.\n- Q는 계절적 차분의 차수를 나타냅니다.\n- S는 12개월과 같은 계절 사이클을 나타냅니다.\n\n계절 ARIMA 모델은 데이터의 계절 패턴을 포착하기 위해 추가 매개변수를 통합합니다. 다음 구성 요소를 추가합니다:\n\n- 계절적 AR 항: 이러한 항목은 현재 관측치와 계절 간격의 특정 차이 관측치 사이의 관계를 나타냅니다. 데이터의 계절적 패턴을 캡처합니다.\n- 계절적 MA 항: 이러한 항목은 현재 관측치와 계절 간격의 특정 기간의 선행 예측 오류 사이의 관계를 나타냅니다. 데이터의 계절적 변동성을 캡처합니다.\n\nSARIMA 모델링은 매우 쉽습니다. 해야 할 일은 하이퍼파라미터 \"seasonal\"을 \"True\"로 변경하는 것뿐입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nimport pmdarima as pm\nmodel = pm.auto_arima(train,\n                      # You just need to turn the seasonal to \"True\"\n                      seasonal=True,\n                      start_P=1,\n                      start_q=1,\n                      max_p=None,\n                      max_q=None,\n                      m=12,\n                      d=1,\n                      D=1,\n                      trace=True,\n                      error_action='ignore',\n                      suppress_warnings=True,\n                      stepwise=True)\nmodel.summary()\r\n```\n\n한 가지 모델을 만들었어요. 그림 (I)은 최적의 모델이 ARIMA(0,1,1)(0,1,1)[12]임을 보여줍니다.\n\n\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_12.png\" /\u003e\n\n결과를 그래픽으로 표시하고 각 반복마다 모델 업데이트를 활성화해봅시다. 그림 (J)에 플롯이 표시됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nforecasts = []\nconfidence_intervals = []\n\nfor add_obs in test:\n    fc, conf = one_period_forecast()\n    forecasts.append(fc)\n    confidence_intervals.append(conf)\n    # Updates the existing model\n    model.update(add_obs)\n\n# Plot the results\nplot_it()\n\n# Calculate MAPE\nprint(f\"MAPE: {mean_absolute_percentage_error(test, forecasts)}\")\n```\n\nMAPE는 0.11918293096560012 또는 11.9%입니다. 이것은 위의 ARIMA 모델에 비해 뚜렷한 개선이 없어 보입니다. 모델의 간결성 원칙에 따라, 우리는 SARIMA 대신 ARIMA 모델을 사용할 것입니다.\n\n![이미지](/TIL/assets/img/2024-07-14-AutomaticARIMA_13.png)\n\n결론\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물에서는 고전적인 ARIMA 및 SARIMA 모델 사양을 검토했습니다. 최적 모델을 자동으로 검색하기 위해 pmdarima 라이브러리의 사용법을 배웠습니다. 또한 ARIMA 및 SARIMA에 대한 다기간 예측 생성 방법을 배웠습니다.\n\n우리는 복잡성이 증가하는 시계열 데이터를 모델링할 것입니다. 여러 Python 라이브러리가 복잡한 데이터 구조에 대한 해결책을 제공합니다. 우리는 이러한 데이터 솔루션을 10장에서 배울 것입니다: 시계열 데이터 형식 변환의 비밀.\n\n참고문헌\n\n- [1] Box, G. E. P., Jenkins, G. M., and Reinsel, G. C. (2015). 시계열 분석: 예측 및 제어 (5판). John Wiley \u0026 Sons.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n샘플 eBook 챕터(무료): [여기](https://github.com/dataman-git/modern-time-series/blob/main/20240522beauty_TOC.pdf)\n\n- 아름다운 형식으로 책을 재현하고 즐거운 독서 경험을 제공하기 위해 The Innovation Press, LLC 직원 여러분께 감사드립니다. 우리는 Teachable 플랫폼을 선택하여 전 세계 독자들에게 번거로운 과부하 없이 eBook을 유통합니다. 신용 카드 거래는 Teachable.com이 안전하고 기밀리에 처리합니다.\n\nTeachable.com의 eBook: $22.50\n[여기](https://drdataman.teachable.com/p/home)\n\nAmazon.com에서 인쇄판: $65 [링크](https://a.co/d/25FVsMx)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 프린트 버전은 윤광 처리 커버, 컬러 인쇄, 아름다운 스프링어 글꼴 및 레이아웃을 채택하여 즐거운 독서 경험을 제공합니다. 7.5 x 9.25인치의 품격 높은 크기는 서재에 있는 대부분의 책과 어울립니다.\n- \"이 책은 Kuo의 시계열 분석에 대한 깊은 이해와 예측 분석 및 이상 탐지에 대한 응용을 증명하는 것입니다. 이 책은 독자들이 실제 세계의 문제에 대처하기 위한 필수적인 기술을 제공합니다. 데이터 과학 분야로의 직업 전환을 고려하는 사람들에게 특히 가치 있는 자료입니다. Kuo는 전통적인 기술 뿐만 아니라 최신 기술에 대해 자세히 탐구합니다. Kuo는 신경망 및 다른 고급 알고리즘에 대한 논의를 통합하여, 분야의 최신 동향과 발전을 반영합니다. 이는 독자가 확립된 방법뿐만 아니라 데이터 과학 분야에서 가장 현재이고 혁신적인 기술을 다루는 데 대비할 수 있도록 보장합니다. Kuo의 생생한 글쓰기 스타일로 책의 명료함과 접근성은 높아졌습니다. 그는 복잡한 수학 및 통계 개념을 신비롭지 않게 만들면서도 엄격성을 희생하지 않았습니다.\"\n\n# 현대적인 시계열 예측: 예측 분석 및 이상 탐지를 위한\n\n제로 장: 서문\n\n1장: 소개\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 장 2: 비즈니스 예측을 위한 선지자\n\n# 장 3: 튜토리얼 I: 트렌드 + 계절성 + 휴일 및 이벤트\n\n# 장 4: 튜토리얼 II: 트렌드 + 계절성 + 휴일 및 이벤트 + 자기회귀(AR) + 지연 회귀자 + 미래 회귀자\n\n# 장 5: 시계열 데이터의 변화점 탐지\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nChapter 6: 시계열 확률 예측을 위한 몬테카를로 시뮬레이션\n\nChapter 7: 시계열 확률 예측을 위한 분위 회귀\n\nChapter 8: 시계열 확률 예측을 위한 일치 예측\n\nChapter 9: 시계열 확률 예측을 위한 일치화된 분위 회귀\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 제 10장: 자동 ARIMA!\n\n# 제 11장: 시계열 데이터 형식 쉽게 만들기\n\n# 제 12장: 다기간 확률 예측을 위한 선형 회귀\n\n# 제 13장: 트리 기반 시계열 모델을 위한 피처 엔지니어링\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 14장: 다기간 시계열 예측을 위한 두 가지 기본 전략\n\n# 15장: 다기간 시계열 확률적 예측을 위한 Tree 기반 XGB, LightGBM 및 CatBoost 모델\n\n# 16장: 시계열 모델링 기술의 진화\n\n# 17장: 시계열 확률적 예측을 위한 Deep Learning 기반 DeepAR\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nChapter 18: 주가에 대한 확률적 예측을 위한 응용\n\nChapter 19: RNN부터 Transformer 기반 시계열 모델까지\n\nChapter 20: 해석 가능한 시계열 예측을 위한 Temporal Fusion Transformer\n\nChapter 21: 시계열 예측을 위한 오픈소스 Lag-Llama 튜토리얼","ogImage":{"url":"/TIL/assets/img/2024-07-14-AutomaticARIMA_0.png"},"coverImage":"/TIL/assets/img/2024-07-14-AutomaticARIMA_0.png","tag":["Tech"],"readingTime":25},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e자동 모델 선택 및 다단계 예측\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003eARIMA (AutoRegressive Integrated Moving Average)은 시계열 예측 및 분석에 사용되는 통계 모델입니다. ARIMA의 기원은 1900년대 초반으로 거슬러 올라가며 자기회귀(AR) 모델과 이동평균 (MA) 모델이 별도로 발전됐습니다. 두 모델 모두 현실 시계열 데이터의 복잡한 역학을 포착하기에는 충분하지 않은 것으로 나타납니다. 1960년대에 세 통계학자인 조지 E. P. 박스, 그윌림 M. 젠킨스, 그리고 그레고리 C. 레인절이 \"시계열 분석: 예측과 제어\"라는 책에서 AR과 MA 모델을 공식적으로 통합하여 ARIMA를 만들었습니다.\u003c/p\u003e\n\u003cp\u003eARIMA는 아마도 가장 잘 알려진 패러다임이지만, 왜 이 \"현대적인\" 시계열 서적에 포함시키는 걸까요? 주된 이유는 AR과 MA가 현대적인 시계열 기술에서 많은 흔적을 남겨주었기 때문입니다. ARIMA에 대한 기본 이해는 다른 복잡한 모델에 걸쳐 활용할 수 있게 해줍니다. 예를 들어, NeuralProphet의 4장에서 AR 모듈을 보았고, 12장과 13장에서는 AR 항목을 감독 학습 모델에서 특징으로 볼 것입니다. 이 책에 ARIMA를 포함한 두 번째 이유는 최근의 코드 개발로 자동 모델 선택과 다단계 예측이 가능해졌기 때문입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e챕터 4: \"튜토리얼 II: 트렌드 + 계절성 + 휴일 및 이벤트 + 자기 회귀(AR) + 지연 회귀자 + 미래 회귀자.\"\u003c/li\u003e\n\u003cli\u003e챕터 12: \"트리 기반 시계열 예측에 대한 튜토리얼\"\u003c/li\u003e\n\u003cli\u003e챕터 13: \"다단계 시계열 예측에 대한 튜토리얼.\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e오늘날의 코드 라이브러리를 사용하면 최적의 ARIMA 모델을 선택할 수 있습니다. 표준 ARIMA 학파에서 교육을 받은 경우, 최적의 AR 및 MA 순서를 선택하기위한 규정화된 지침을 외우고 있는 사람도 있을 것입니다. 모델 사양을 결정하기 위해 자동 상관 함수(ACF) 및 부분 자동 상관 함수(PACF)를 사용해야 합니다. 그러나 나는 그런 규정화된 지침을 잊어버리고 그냥 여러 순서의 후보 모델을 만들어 최적의 모델을 선택합니다. 왜 최상의 모델을 선택하기 위해 많은 모델을 생성하지 않을까요? 이러한 이유로, Python의 \"pmdarima\"와 같은 편리한 라이브러리가 있어 최적 사양을 자동화하는 데 도움이 됩니다. 이 장을 \"자동 ARIMA\"라고 제목 지어 이 이점을 강조하고자 합니다. 그래도 이 챕터에서는 차이, ACF 및 PACF의 개념을 다룰 것입니다.\u003c/p\u003e\n\u003cp\u003e\"statsmodels\"와 \"pmdarima\"와 같은 현대의 코드 라이브러리는 단기 예측이 아닌 다단계 예측을 가능하게 합니다. 이를 수행하기 위해 모델을 재귀적으로 적용하여 예측을 생성하는 방법에 대해 배우게 될 것입니다. 일반적으로 다단계 예측을 생성하는 두 가지 기본 전략이 있습니다: 재귀적 방법과 직접 방법. 우리는 챕터 13 \"다단계 시계열 예측에 대한 튜토리얼\"에서 이를 배울 것입니다. 두 전략은 ARIMA와 lightGBM 또는 XGB와 같은 트리 기반 모델에 채택되어 다단계 예측을 생성합니다.\u003c/p\u003e\n\u003cp\u003e마지막으로, 많은 사용 사례에서 우리는 점 추정치에 만족하지 않고 예측 구간을 필요로 합니다. 잠재적 불확실성을 평가하기 위해 가능한 값의 범위가 필요합니다. \"pmdarima\"와 \"statsmodels\"는 신뢰 구간을 반환합니다. 반면에, Part II \"확률적 예측을 얻기\"의 5부터 8 챕터에서 예측 구간을 위한 더 많은 기술을 배웠습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e제 5장: 시계열 확률 예측을 위한 몬테카를로 시뮬레이션\u003c/li\u003e\n\u003cli\u003e제 6장: 시계열 확률 예측을 위한 분위 회귀\u003c/li\u003e\n\u003cli\u003e제 7장: 시계열 확률 예측을 위한 형식 예측\u003c/li\u003e\n\u003cli\u003e제 8장: 시계열 확률 예측을 위한 형식화된 분위 회귀\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 글에서는 이론과 실무를 포괄적으로 설명하겠습니다. 실제 데이터를 사용하여 모델 구축과 예측을 안내할 예정이에요. 이미 알고 계신 부분은 건너뛰셔도 괜찮아요. Python 노트북은 여기서 다운로드할 수 있어요. 다룰 주제들은 다음과 같아요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eARIMA 모델\u003c/li\u003e\n\u003cli\u003e차분\u003c/li\u003e\n\u003cli\u003eACF 사용하여 MA의 차수 제안\u003c/li\u003e\n\u003cli\u003ePACF 사용하여 AR의 차수 제안\u003c/li\u003e\n\u003cli\u003epmdarima 라이브러리 사용하여 최적 모델 자동 탐색\u003c/li\u003e\n\u003cli\u003e다단계 예측\u003c/li\u003e\n\u003cli\u003estatsmodels 사용하여 모델을 반복적으로 업데이트\u003c/li\u003e\n\u003cli\u003eSARIMA 모델\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e먼저 데이터를 불러오겠습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e데이터 전처리\u003c/p\u003e\n\u003cp\u003e카글의 아보카도 판매 데이터를 사용할 것입니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e%matplotlib inline\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e matplotlib \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pyplot \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e google.\u003cspan class=\"hljs-property\"\u003ecolab\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e drive\ndrive.\u003cspan class=\"hljs-title function_\"\u003emount\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'/content/gdrive'\u003c/span\u003e)\n\npath = \u003cspan class=\"hljs-string\"\u003e'/content/gdrive/My Drive/data/time_series'\u003c/span\u003e\ndata = pd.\u003cspan class=\"hljs-title function_\"\u003eread_csv\u003c/span\u003e(path + \u003cspan class=\"hljs-string\"\u003e'/avocado_monthly.csv'\u003c/span\u003e, index_col=\u003cspan class=\"hljs-string\"\u003e'Date'\u003c/span\u003e)\ndata.\u003cspan class=\"hljs-title function_\"\u003esort_values\u003c/span\u003e(by=\u003cspan class=\"hljs-string\"\u003e'Total Volume'\u003c/span\u003e, ascending=\u003cspan class=\"hljs-title class_\"\u003eFalse\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(A) 그림은 이 데이터셋의 일부를 보여줍니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_1.png\" alt=\"그림\"\u003e\u003c/p\u003e\n\u003cp\u003e이 데이터 세트에서는 하나의 일변량 시계열만 사용할 것입니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-string\"\u003e'유기농'\u003c/span\u003e 및 \u003cspan class=\"hljs-string\"\u003e'TotalUS'\u003c/span\u003e 지역인 하나의 시계열만 사용합니다.\ndf = data[(data[\u003cspan class=\"hljs-string\"\u003e'type'\u003c/span\u003e]==\u003cspan class=\"hljs-string\"\u003e'organic'\u003c/span\u003e) \u0026#x26; (data[\u003cspan class=\"hljs-string\"\u003e'region'\u003c/span\u003e]==\u003cspan class=\"hljs-string\"\u003e'TotalUS'\u003c/span\u003e)].\u003cspan class=\"hljs-title function_\"\u003ecopy\u003c/span\u003e()\ndf = df[\u003cspan class=\"hljs-string\"\u003e'Total Volume'\u003c/span\u003e]\ndf.\u003cspan class=\"hljs-property\"\u003ecolumns\u003c/span\u003e = [\u003cspan class=\"hljs-string\"\u003e'y'\u003c/span\u003e]\ndf = df[pd.\u003cspan class=\"hljs-title function_\"\u003eto_datetime\u003c/span\u003e(df.\u003cspan class=\"hljs-property\"\u003eindex\u003c/span\u003e)\u0026#x3C;=pd.\u003cspan class=\"hljs-title function_\"\u003eto_datetime\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'2018-02-01'\u003c/span\u003e)]\n\n# 일변량 시계열 그래프 그리기\nplt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e(figsize=(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e))\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e(df)\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"날짜\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"볼륨\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e그림 (B)는 일변량 시계열 그래프를 보여줍니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_2.png\" alt=\"그림\"\u003e\u003c/p\u003e\n\u003cp\u003e이후에는 80%를 인-타임 훈련 데이터로 사용하고 나머지 20%는 아웃-오브-타임 테스트 데이터로 사용합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-title class_\"\u003eTrain\u003c/span\u003e-test-split\ntrain_len = \u003cspan class=\"hljs-title function_\"\u003eint\u003c/span\u003e(df.\u003cspan class=\"hljs-property\"\u003eshape\u003c/span\u003e[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e] * \u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\ntest_len = df.\u003cspan class=\"hljs-property\"\u003eshape\u003c/span\u003e[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e] - train_len\ntrain, test = df[:train_len], df[\u003cspan class=\"hljs-attr\"\u003etrain_len\u003c/span\u003e:]\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"{train_len}개의 훈련 샘플\"\u003c/span\u003e)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"{df.shape[0] - train_len}개의 테스트 샘플\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e좋아요. 이제 우리는 정의부터 시작합시다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eARIMA 모델들\u003c/p\u003e\n\u003cp\u003eARIMA는 단변량 시계열 데이터를 사용하여 미래 값을 예측하는 모델 클래스입니다. 이 모델들은 시계열 데이터의 과거 또는 이전 값, 즉 자기 회귀(AR) 항목과 이동 평균(MA) 항목인 이동 예측 오차의 지연된 값들을 사용하여 미래 값을 예측합니다. ARIMA이란 \"자기 회귀-통합-이동 평균\"의 약자로, \"AR\", \"I\", \"MA\"로 구성됩니다. 여기서 ARIMA의 \"I\"는 \"통합(integrated)\"을 의미하며, 이는 시계열 데이터가 안정성을 달성하기 위해 차분된 것을 나타냅니다. 안정적인 시계열 데이터는 시간이 지나도 평균, 분산 및 자기 상관이 일정하므로 모델링하기 쉽습니다. ARIMA(p,d,q) 모델로 수학적으로 표현하면 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003eMarkdown 형식으로 테이블 태그를 변경하십시오.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_3.png\" alt=\"AutomaticARIMA_3\"\u003e\u003c/p\u003e\n\u003cp\u003eARIMA 표기법에 친숙해지기 위해 위 식을 적용해 봅시다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_4.png\" alt=\"AutomaticARIMA_4\"\u003e\u003c/p\u003e\n\u003cp\u003e일반적으로 AR만 또는 MA만, 또는 p와 q가 모두 4 미만이기 때문에 우변에 많은 항이 없습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e차이화\u003c/p\u003e\n\u003cp\u003e차이화의 목표는 시계열을 안정적으로 만드는 것입니다. 시계열에서 안정성이란 값의 평균이 시간에 따라 일정하다는 것을 의미합니다. 다시 말해, 안정적인 시계열은 일정한 평균을 갖습니다. 이전 코드는 원래 시계열, 1차 차이화(한 번 차이화), 그리고 2차 차이화(두 번 차이화)를 플롯합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np, pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e statsmodels.\u003cspan class=\"hljs-property\"\u003egraphics\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003etsaplots\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e plot_acf, plot_pacf\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e statsmodels.\u003cspan class=\"hljs-property\"\u003etsa\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003estattools\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e adfuller\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.\u003cspan class=\"hljs-property\"\u003epyplot\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\nplt.\u003cspan class=\"hljs-property\"\u003ercParams\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eupdate\u003c/span\u003e({\u003cspan class=\"hljs-string\"\u003e'figure.figsize'\u003c/span\u003e:(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e), \u003cspan class=\"hljs-string\"\u003e'figure.dpi'\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e})\nlag_len = \u003cspan class=\"hljs-number\"\u003e15\u003c/span\u003e\nfig, axes = plt.\u003cspan class=\"hljs-title function_\"\u003esubplots\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, sharex=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)\n\n# \u003cspan class=\"hljs-title class_\"\u003eOriginal\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSeries\u003c/span\u003e\naxes[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e(train.\u003cspan class=\"hljs-property\"\u003evalues\u003c/span\u003e); axes[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eset_title\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'Original Series'\u003c/span\u003e)\n\n# 1st \u003cspan class=\"hljs-title class_\"\u003eDifferencing\u003c/span\u003e\naxes[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e(train.\u003cspan class=\"hljs-title function_\"\u003ediff\u003c/span\u003e()); axes[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eset_title\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'1st Order Differencing'\u003c/span\u003e)\n\n\n# 2nd \u003cspan class=\"hljs-title class_\"\u003eDifferencing\u003c/span\u003e\naxes[\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e(train.\u003cspan class=\"hljs-title function_\"\u003ediff\u003c/span\u003e().\u003cspan class=\"hljs-title function_\"\u003ediff\u003c/span\u003e()); axes[\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eset_title\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'2nd Order Differencing'\u003c/span\u003e)\n\naxes[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-property\"\u003exaxis\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eset_major_locator\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003eMultipleLocator\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e))\n\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e도 (C)는 학습 데이터의 원래 시계열, 1차 차이화, 그리고 2차 차이화에 대한 플롯을 보여줍니다. 1차 및 2차 차이화된 시계열은 안정적입니다. 즉, 모델은 최소한 한 번은 차이화되어야 합니다. 일반적으로 1차 차이화만으로 충분합니다. 안정적인 시계열에 대한 차이화는 여전히 안정적일 것입니다. 1차 차이화가 이미 안정적이라면 2차 차이화를 얻기 위해 과도하게 차이화할 필요가 없습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_5.png\"\u003e\n\u003cp\u003e이제 ACF를 사용하여 MA(order)를 얻는 방법에 대해 이해해 봅시다.\u003c/p\u003e\n\u003cp\u003eACF를 사용하여 MA(order)를 제안합니다.\u003c/p\u003e\n\u003cp\u003e이미 두 변수 간의 상관 계수에 익숙하실 것입니다. 이는 그들의 관계를 측정합니다. -1과 1 사이의 값을 갖습니다. 양의/음의 상관 계수는 두 변수 간에 양의/음의 관계가 있음을 의미합니다. 상관 계수가 1일 경우 완벽한 양의 선형 관계를, 0.0일 경우 변수 간의 선형 관계가 없음을 나타냅니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eACF는 자기상관함수(Autocorrelation Function)의 약자입니다. 이것은 시계열과 그 지연된 버전 간의 상관관계를 측정합니다. ACF는 시계열의 시간 t와 시간 t-k에서의 값들 간의 상관관계로 계산됩니다. 여기서 k는 래그(지연) 번호를 나타냅니다. ACF(k)는 래그 k에서의 자기상관을 나타냅니다. 자기상관을 시각화해봅시다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e statsmodels.graphics.tsaplots \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e plot_acf\nplt.rcParams.update({\u003cspan class=\"hljs-string\"\u003e'figure.figsize'\u003c/span\u003e:(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e), \u003cspan class=\"hljs-string\"\u003e'figure.dpi'\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e})\nlag_len = \u003cspan class=\"hljs-number\"\u003e15\u003c/span\u003e\nfig, axes = plt.subplots(\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, sharex=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 원 데이터\u003c/span\u003e\nplot_acf(train.values[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e:lag_len], ax=axes[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], title = \u003cspan class=\"hljs-string\"\u003e'ACF - 원 데이터'\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 1차 차분\u003c/span\u003e\nplot_acf(train.diff().dropna()[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e:lag_len], ax=axes[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], title = \u003cspan class=\"hljs-string\"\u003e'ACF - 1차 차분'\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 2차 차분\u003c/span\u003e\nplot_acf(train.diff().diff().dropna()[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e:lag_len], ax=axes[\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e], title = \u003cspan class=\"hljs-string\"\u003e'ACF - 2차 차분'\u003c/span\u003e)\n\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(D) 그림은 자기상관을 보여줍니다. 첫 번째 막대의 상관 계수는 1.0인데, 이는 y_t와 그 자신의 상관관계를 나타냅니다. 파란 영역은 유의수준을 의미합니다. 유의수준을 넘는 막대는 통계적으로 유의미하다는 것을 의미합니다. 보시다시피, 1차 차분 라인에서의 래그 1은 유의미합니다. 이는 모델이 래그 1 항을 포함하고 있으며 1차 차분이 있다는 것을 의미합니다.\u003c/p\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_6.png\"\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이제 PACF를 배워 봅시다.\u003c/p\u003e\n\u003cp\u003ePACF를 사용하여 AR의 순서를 제안하세요.\u003c/p\u003e\n\u003cp\u003eACF는 시계열과 그 이전 시간 단계의 관련성을 측정합니다. 현재 시계열 값이 과거 값들과 얼마나 연관이 있는지를 알려줍니다. 반면 PACF는 시계열과 그 이전 시간 단계의 부분 상관 관계를 측정하며, 해당 시간 단계 이전의 모든 이전 시간 단계 값을 고려한 후의 영향을 고려합니다. 이는 현재 시계열 값과 특정 시간 지연 값 사이의 직접적인 관계가 있는지 여부를 결정하는 데 도움이 됩니다. 특히 (E) 그림에서 PACF 지연 1이 중요하다고 합니다. 이는 유의 수준을 넘어섰기 때문입니다. 지연 2도 중요하다고 판명되었는데, 약간의 노력으로 유의 선을 넘었습니다(파란색 영역).\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e statsmodels.graphics.tsaplots \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e plot_pacf\nplt.rcParams.update({\u003cspan class=\"hljs-string\"\u003e'figure.figsize'\u003c/span\u003e:(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e), \u003cspan class=\"hljs-string\"\u003e'figure.dpi'\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e})\nlag_len = \u003cspan class=\"hljs-number\"\u003e15\u003c/span\u003e\nfig, axes = plt.subplots(\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, sharex=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# Original Series\u003c/span\u003e\nplot_pacf(train.values[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e:lag_len], ax=axes[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], title = \u003cspan class=\"hljs-string\"\u003e'PACF - Original series'\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 1st Differencing\u003c/span\u003e\nplot_pacf(train.diff().dropna()[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e:lag_len], ax=axes[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], title = \u003cspan class=\"hljs-string\"\u003e'PACF - 1st differencing'\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 2nd Differencing\u003c/span\u003e\nplot_pacf(train.diff().diff().dropna()[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e:lag_len], ax=axes[\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e], title = \u003cspan class=\"hljs-string\"\u003e'PACF - 2nd differencing'\u003c/span\u003e)\n\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e(E) 그림은 PACF 플롯을 보여줍니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_7.png\" alt=\"PACF 그림\"\u003e\u003c/p\u003e\n\u003cp\u003e그림 (C), (D), (E)의 차이, ACF 및 PACF는 ARIMA(1, 1, 1)을 제안합니다. 만약 이 진단을 알지 못한다고 가정하더라도, 여전히 auto_ARIMA()를 사용하여 모델 사양의 범위를 찾을 수 있습니다.\u003c/p\u003e\n\u003cp\u003eauto_ARIMA() 사용하여 최적 모델을 자동으로 탐색하는 방법\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pmdarima \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pm\nmodel = pm.auto_arima(train,\n                      d=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e,\n                      seasonal=\u003cspan class=\"hljs-literal\"\u003eFalse\u003c/span\u003e,\n                      stepwise=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n                      suppress_warnings=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n                      error_action=\u003cspan class=\"hljs-string\"\u003e\"ignore\"\u003c/span\u003e,\n                      max_p=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e,\n                      max_order=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e,\n                      trace=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_8.png\" alt=\"Automatic ARIMA\"\u003e\u003c/p\u003e\n\u003cp\u003e아카이케 정보 기준(Akaike Information Criterion, AIC) 값은 모델 성능 지표입니다. 이 값은 2 * 모델 파라미터 수 - 2 * 최대 우도(L)입니다. 값이 작을수록 모델이 더 잘 맞는 것을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_9.png\" alt=\"Automatic ARIMA\"\u003e\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eFigure(F)에서 가장 낮은 AIC 값은 3,301.526입니다. ARIMA(1, 1, 1)(0, 0, 0)입니다. 계절성 구성요소는 (0, 0, 0)입니다. 계절 차분이 없기 때문에 \"seasonal=False\"로 하이퍼파라미터를 끔 처리했습니다. 나중에 ARIMA에서 다시 활성화할 것입니다.\u003c/p\u003e\n\u003cp\u003e다중 기간 예측\u003c/p\u003e\n\u003cp\u003e\"pmdarima\"의 \"predict\" 함수를 사용하면 미래 시점의 기간 수를 지정할 수 있습니다. 미래 시점을 테스트 데이터의 길이로 설정합니다. 그리고 \"return_conf_int = True\"와 \"alpha = 0.05\"로 설정하여 95% 신뢰 수준의 신뢰 구간을 반환합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# test_len의 길이에 대한 다중 기간 예측 생성\nfcast = model.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(n_periods=test_len, return_conf_int=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.05\u003c/span\u003e)\nforecasts = fcast[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\nconfidence_intervals = fcast[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e모델의 성능을 평가해 봅시다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e mean_squared_error, mean_absolute_percentage_error\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef\"MAPE: \u003cspan class=\"hljs-subst\"\u003e{mean_absolute_percentage_error(test, forecasts)}\u003c/span\u003e\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e평균 절대 백분율 오차는 0.1490595592393948 또는 14.9% 입니다. 다음으로 실제 값과 예측값을 그래프로 그려보겠습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eplot_it\u003c/span\u003e():\n    fig, ax = plt.subplots(figsize=(\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e))\n\n    \u003cspan class=\"hljs-comment\"\u003e# 실제 vs. 예측\u003c/span\u003e\n    ax.plot(train, color=\u003cspan class=\"hljs-string\"\u003e'blue'\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e'Training data'\u003c/span\u003e)\n    ax.plot(test.index, forecasts, color=\u003cspan class=\"hljs-string\"\u003e'red'\u003c/span\u003e, marker=\u003cspan class=\"hljs-string\"\u003e'o'\u003c/span\u003e,\n                label=\u003cspan class=\"hljs-string\"\u003e'Predicted'\u003c/span\u003e)\n    ax.plot(test.index, test, color=\u003cspan class=\"hljs-string\"\u003e'green'\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e'Test data'\u003c/span\u003e)\n    ax.set_title(\u003cspan class=\"hljs-string\"\u003e'아보카도 판매량'\u003c/span\u003e)\n    ax.set_xlabel(\u003cspan class=\"hljs-string\"\u003e'날짜'\u003c/span\u003e)\n    ax.set_ylabel(\u003cspan class=\"hljs-string\"\u003e'양'\u003c/span\u003e)\n    conf_int = np.asarray(confidence_intervals)\n\n    \u003cspan class=\"hljs-comment\"\u003e# 신뢰 구간\u003c/span\u003e\n    ax.fill_between(test.index,\n                        conf_int[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], conf_int[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e],\n                        alpha=\u003cspan class=\"hljs-number\"\u003e0.9\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'orange'\u003c/span\u003e,\n                        label=\u003cspan class=\"hljs-string\"\u003e\"신뢰 구간\"\u003c/span\u003e)\n    \u003cspan class=\"hljs-comment\"\u003e# 주요 눈금이 20의 배수인 플롯 생성\u003c/span\u003e\n    ax.legend()\n    ax.xaxis.set_major_locator(MultipleLocator(\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e))\n    plt.show()\n\nplot_it()\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e표 (G)는 학습, 테스트 데이터, 예측값 및 신뢰 구간의 시계열을 제공합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_10.png\" alt=\"Figure G\"\u003e\u003c/p\u003e\n\u003cp\u003e표 (G)의 예측 값은 일정 기간 이후에 고정값에 수렴하며 예측 가능성이 있습니다. 인상적으로 보이지 않습니다. 각 반복에서 모델을 업데이트하여 개선할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e각 반복에서 모델을 업데이트해보세요.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e각 예측은 예측 시계열에 새로운 관측치를 추가합니다. 모델이 정적인 경우, 예측된 시계열은 최종적으로 직선이 되어 그래프(G)에 표시됩니다. 각 반복에서 추가된 관측치로 모델을 업데이트할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e우리는 시간 외 시험 기간의 각 반복에서 한 기간을 예측한 후, 새로운 예측을 모델을 업데이트하는 데 사용할 것입니다. \"return_conf_int = True\" 및 \"alpha= 5%\"를 지정하여 95% 신뢰 수준의 예측 구간을 추가할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-attr\"\u003ehttps\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.ARIMA.html#pmdarima.arima.ARIMA.update\u003c/span\u003e\ndef \u003cspan class=\"hljs-title function_\"\u003eone_period_forecast\u003c/span\u003e():\n    fcast = model.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(n_periods=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, return_conf_int=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.05\u003c/span\u003e)\n    # fcast는 두 개의 리스트로 구성됩니다.\n    # 첫 번째 리스트는 예측입니다.\n    forecasts = fcast[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003etolist\u003c/span\u003e()\n    # 두 번째 리스트는 신뢰 구간입니다.\n    confidence_intervals = fcast[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e ( forecasts, \n             np.\u003cspan class=\"hljs-title function_\"\u003easarray\u003c/span\u003e(confidence_intervals).\u003cspan class=\"hljs-title function_\"\u003etolist\u003c/span\u003e()[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e])\n\nforecasts = []\nconfidence_intervals = []\n\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e add_obs \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003etest\u003c/span\u003e:\n    fc, conf = \u003cspan class=\"hljs-title function_\"\u003eone_period_forecast\u003c/span\u003e()\n    forecasts.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(fc)\n    confidence_intervals.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(conf)\n    # 기존 모델 업데이트\n    model.\u003cspan class=\"hljs-title function_\"\u003eupdate\u003c/span\u003e(add_obs)\n\n\u003cspan class=\"hljs-title function_\"\u003eplot_it\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e그림 (H)은 예측값이 테스트 값과 더 잘 일치함을 보여줍니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_11.png\"\u003e\n\u003cp\u003e모델 성능은 어떤가요?\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"MAPE: {mean_absolute_percentage_error(test, forecasts)}\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMAPE는 0.11766234388644323으로, 약 11.7%보다 약간 향상되었습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e우리 연구를 위한 데이터는 여러 해에 걸친 시계열 데이터이기 때문에 강력한 계절성을 갖고 있다고 의심됩니다. 우리는 Seasonal ARIMA를 사용하여 모델을 완화할 것입니다.\u003c/p\u003e\n\u003cp\u003eSARIMA 모델\u003c/p\u003e\n\u003cp\u003eSARIMA 모델은 계절적 시계열 데이터를 다루는 데 특히 설계되었습니다. ARIMA 모델의 비계절적 구성요소 (AR, I 및 MA)에 추가로 SARIMA 모델에는 데이터의 계절적 패턴을 포착하는 계절적 구성요소 (SAR, SI 및 SMA)가 포함되어 있습니다. SARIMA 모델의 SAR 구성요소는 ARIMA 모델의 AR 구성요소와 유사하지만 시계열의 계절적 지연된 값에 작용합니다. SI 구성요소는 ARIMA 모델의 I 구성요소와 유사하지만 시계열의 계절적 차이에 적용됩니다. 마지막으로, SMA 구성요소는 ARIMA 모델의 MA 구성요소와 유사하지만 시계열의 계절적 지연된 오차에 작용합니다.\u003c/p\u003e\n\u003cp\u003e요약하자면, SARIMA는 단순히 계절 급변을 적용합니다. 계절적 급변은 일반적인 급변과 유사합니다. 연이은 용어를 빼는 대신, 계절적 급변은 이전 계절의 값에서 값을 뺍니다. SARIMA 모델은 일반적으로 SARIMA(p,d,q)(P,D,Q)[S]로 표기됩니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003ep은 계절적 자기회귀항의 차수를 나타냅니다.\u003c/li\u003e\n\u003cli\u003eq는 계절적 이동평균항의 차수를 나타냅니다.\u003c/li\u003e\n\u003cli\u003eQ는 계절적 차분의 차수를 나타냅니다.\u003c/li\u003e\n\u003cli\u003eS는 12개월과 같은 계절 사이클을 나타냅니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e계절 ARIMA 모델은 데이터의 계절 패턴을 포착하기 위해 추가 매개변수를 통합합니다. 다음 구성 요소를 추가합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e계절적 AR 항: 이러한 항목은 현재 관측치와 계절 간격의 특정 차이 관측치 사이의 관계를 나타냅니다. 데이터의 계절적 패턴을 캡처합니다.\u003c/li\u003e\n\u003cli\u003e계절적 MA 항: 이러한 항목은 현재 관측치와 계절 간격의 특정 기간의 선행 예측 오류 사이의 관계를 나타냅니다. 데이터의 계절적 변동성을 캡처합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSARIMA 모델링은 매우 쉽습니다. 해야 할 일은 하이퍼파라미터 \"seasonal\"을 \"True\"로 변경하는 것뿐입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pmdarima \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pm\nmodel = pm.auto_arima(train,\n                      \u003cspan class=\"hljs-comment\"\u003e# You just need to turn the seasonal to \"True\"\u003c/span\u003e\n                      seasonal=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n                      start_P=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n                      start_q=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n                      max_p=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e,\n                      max_q=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e,\n                      m=\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e,\n                      d=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n                      D=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n                      trace=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n                      error_action=\u003cspan class=\"hljs-string\"\u003e'ignore'\u003c/span\u003e,\n                      suppress_warnings=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n                      stepwise=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\nmodel.summary()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e한 가지 모델을 만들었어요. 그림 (I)은 최적의 모델이 ARIMA(0,1,1)(0,1,1)[12]임을 보여줍니다.\u003c/p\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_12.png\"\u003e\n\u003cp\u003e결과를 그래픽으로 표시하고 각 반복마다 모델 업데이트를 활성화해봅시다. 그림 (J)에 플롯이 표시됩니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eforecasts = []\nconfidence_intervals = []\n\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e add_obs \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003etest\u003c/span\u003e:\n    fc, conf = \u003cspan class=\"hljs-title function_\"\u003eone_period_forecast\u003c/span\u003e()\n    forecasts.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(fc)\n    confidence_intervals.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(conf)\n    # \u003cspan class=\"hljs-title class_\"\u003eUpdates\u003c/span\u003e the existing model\n    model.\u003cspan class=\"hljs-title function_\"\u003eupdate\u003c/span\u003e(add_obs)\n\n# \u003cspan class=\"hljs-title class_\"\u003ePlot\u003c/span\u003e the results\n\u003cspan class=\"hljs-title function_\"\u003eplot_it\u003c/span\u003e()\n\n# \u003cspan class=\"hljs-title class_\"\u003eCalculate\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eMAPE\u003c/span\u003e\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"MAPE: {mean_absolute_percentage_error(test, forecasts)}\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMAPE는 0.11918293096560012 또는 11.9%입니다. 이것은 위의 ARIMA 모델에 비해 뚜렷한 개선이 없어 보입니다. 모델의 간결성 원칙에 따라, 우리는 SARIMA 대신 ARIMA 모델을 사용할 것입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-14-AutomaticARIMA_13.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e결론\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 게시물에서는 고전적인 ARIMA 및 SARIMA 모델 사양을 검토했습니다. 최적 모델을 자동으로 검색하기 위해 pmdarima 라이브러리의 사용법을 배웠습니다. 또한 ARIMA 및 SARIMA에 대한 다기간 예측 생성 방법을 배웠습니다.\u003c/p\u003e\n\u003cp\u003e우리는 복잡성이 증가하는 시계열 데이터를 모델링할 것입니다. 여러 Python 라이브러리가 복잡한 데이터 구조에 대한 해결책을 제공합니다. 우리는 이러한 데이터 솔루션을 10장에서 배울 것입니다: 시계열 데이터 형식 변환의 비밀.\u003c/p\u003e\n\u003cp\u003e참고문헌\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e[1] Box, G. E. P., Jenkins, G. M., and Reinsel, G. C. (2015). 시계열 분석: 예측 및 제어 (5판). John Wiley \u0026#x26; Sons.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e샘플 eBook 챕터(무료): \u003ca href=\"https://github.com/dataman-git/modern-time-series/blob/main/20240522beauty_TOC.pdf\" rel=\"nofollow\" target=\"_blank\"\u003e여기\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e아름다운 형식으로 책을 재현하고 즐거운 독서 경험을 제공하기 위해 The Innovation Press, LLC 직원 여러분께 감사드립니다. 우리는 Teachable 플랫폼을 선택하여 전 세계 독자들에게 번거로운 과부하 없이 eBook을 유통합니다. 신용 카드 거래는 Teachable.com이 안전하고 기밀리에 처리합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTeachable.com의 eBook: $22.50\n\u003ca href=\"https://drdataman.teachable.com/p/home\" rel=\"nofollow\" target=\"_blank\"\u003e여기\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAmazon.com에서 인쇄판: $65 \u003ca href=\"https://a.co/d/25FVsMx\" rel=\"nofollow\" target=\"_blank\"\u003e링크\u003c/a\u003e\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e프린트 버전은 윤광 처리 커버, 컬러 인쇄, 아름다운 스프링어 글꼴 및 레이아웃을 채택하여 즐거운 독서 경험을 제공합니다. 7.5 x 9.25인치의 품격 높은 크기는 서재에 있는 대부분의 책과 어울립니다.\u003c/li\u003e\n\u003cli\u003e\"이 책은 Kuo의 시계열 분석에 대한 깊은 이해와 예측 분석 및 이상 탐지에 대한 응용을 증명하는 것입니다. 이 책은 독자들이 실제 세계의 문제에 대처하기 위한 필수적인 기술을 제공합니다. 데이터 과학 분야로의 직업 전환을 고려하는 사람들에게 특히 가치 있는 자료입니다. Kuo는 전통적인 기술 뿐만 아니라 최신 기술에 대해 자세히 탐구합니다. Kuo는 신경망 및 다른 고급 알고리즘에 대한 논의를 통합하여, 분야의 최신 동향과 발전을 반영합니다. 이는 독자가 확립된 방법뿐만 아니라 데이터 과학 분야에서 가장 현재이고 혁신적인 기술을 다루는 데 대비할 수 있도록 보장합니다. Kuo의 생생한 글쓰기 스타일로 책의 명료함과 접근성은 높아졌습니다. 그는 복잡한 수학 및 통계 개념을 신비롭지 않게 만들면서도 엄격성을 희생하지 않았습니다.\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e현대적인 시계열 예측: 예측 분석 및 이상 탐지를 위한\u003c/h1\u003e\n\u003cp\u003e제로 장: 서문\u003c/p\u003e\n\u003cp\u003e1장: 소개\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e장 2: 비즈니스 예측을 위한 선지자\u003c/h1\u003e\n\u003ch1\u003e장 3: 튜토리얼 I: 트렌드 + 계절성 + 휴일 및 이벤트\u003c/h1\u003e\n\u003ch1\u003e장 4: 튜토리얼 II: 트렌드 + 계절성 + 휴일 및 이벤트 + 자기회귀(AR) + 지연 회귀자 + 미래 회귀자\u003c/h1\u003e\n\u003ch1\u003e장 5: 시계열 데이터의 변화점 탐지\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eChapter 6: 시계열 확률 예측을 위한 몬테카를로 시뮬레이션\u003c/p\u003e\n\u003cp\u003eChapter 7: 시계열 확률 예측을 위한 분위 회귀\u003c/p\u003e\n\u003cp\u003eChapter 8: 시계열 확률 예측을 위한 일치 예측\u003c/p\u003e\n\u003cp\u003eChapter 9: 시계열 확률 예측을 위한 일치화된 분위 회귀\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e제 10장: 자동 ARIMA!\u003c/h1\u003e\n\u003ch1\u003e제 11장: 시계열 데이터 형식 쉽게 만들기\u003c/h1\u003e\n\u003ch1\u003e제 12장: 다기간 확률 예측을 위한 선형 회귀\u003c/h1\u003e\n\u003ch1\u003e제 13장: 트리 기반 시계열 모델을 위한 피처 엔지니어링\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e14장: 다기간 시계열 예측을 위한 두 가지 기본 전략\u003c/h1\u003e\n\u003ch1\u003e15장: 다기간 시계열 확률적 예측을 위한 Tree 기반 XGB, LightGBM 및 CatBoost 모델\u003c/h1\u003e\n\u003ch1\u003e16장: 시계열 모델링 기술의 진화\u003c/h1\u003e\n\u003ch1\u003e17장: 시계열 확률적 예측을 위한 Deep Learning 기반 DeepAR\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eChapter 18: 주가에 대한 확률적 예측을 위한 응용\u003c/p\u003e\n\u003cp\u003eChapter 19: RNN부터 Transformer 기반 시계열 모델까지\u003c/p\u003e\n\u003cp\u003eChapter 20: 해석 가능한 시계열 예측을 위한 Temporal Fusion Transformer\u003c/p\u003e\n\u003cp\u003eChapter 21: 시계열 예측을 위한 오픈소스 Lag-Llama 튜토리얼\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-07-14-AutomaticARIMA"},"buildId":"FuXRqV9h16krA5Mvtd6Dn","assetPrefix":"/TIL","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>