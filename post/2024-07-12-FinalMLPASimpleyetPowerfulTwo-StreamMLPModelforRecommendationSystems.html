<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>FinalMLP 추천 시스템을 위한 간단하지만 강력한 Two-Stream MLP 모델 사용 방법 | TIL</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://13akstjq.github.io/TIL//post/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="FinalMLP 추천 시스템을 위한 간단하지만 강력한 Two-Stream MLP 모델 사용 방법 | TIL" data-gatsby-head="true"/><meta property="og:title" content="FinalMLP 추천 시스템을 위한 간단하지만 강력한 Two-Stream MLP 모델 사용 방법 | TIL" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://TIL.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://13akstjq.github.io/TIL//post/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems" data-gatsby-head="true"/><meta name="twitter:title" content="FinalMLP 추천 시스템을 위한 간단하지만 강력한 Two-Stream MLP 모델 사용 방법 | TIL" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | TIL" data-gatsby-head="true"/><meta name="article:published_time" content="2024-07-12 20:35" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/TIL/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/TIL/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/TIL/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/TIL/favicons/favicon-96x96.png"/><link rel="icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/TIL/favicons/browserconfig.xml"/><link rel="preload" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/TIL/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/TIL/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/TIL/_next/static/chunks/webpack-21ffe88bdca56cba.js" defer=""></script><script src="/TIL/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/TIL/_next/static/chunks/main-a5eeabb286676ce6.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/TIL/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/TIL/_next/static/chunks/348-02483b66b493dd81.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/post/%5Bslug%5D-8ded8b979ba73586.js" defer=""></script><script src="/TIL/_next/static/N1mNhRlQaHCliEGDvPEpG/_buildManifest.js" defer=""></script><script src="/TIL/_next/static/N1mNhRlQaHCliEGDvPEpG/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/TIL">TIL</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/TIL/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">FinalMLP 추천 시스템을 위한 간단하지만 강력한 Two-Stream MLP 모델 사용 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="FinalMLP 추천 시스템을 위한 간단하지만 강력한 Two-Stream MLP 모델 사용 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">TIL</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jul 12, 2024</span><span class="posts_reading_time__f7YPP">22<!-- --> min read</span></span></div></div></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>이 게시물은 Rafael Guedes와 공동 저자로 작성되었습니다.</p>
<h1>소개</h1>
<p>세계는 모두가 원하는 것을 거의 한 번 클릭으로 모두 얻을 수 있는 디지턈 시대로 발전해 왔습니다. 접근성, 편의성 및 다양한 제공 효과는 소비자에게 새로운 도전과 함께 제공됩니다. 소비자가 옵션의 바다 속에서 검색하는 대신 맞춤 선택을 받을 수 있는 방법은 무엇일까요? 바로 추천 시스템이 여기에서 나타납니다.</p>
<p>추천 시스템은 조직이 교차 판매와 장꼬 아이템의 판매를 증가시키고, 고객들이 가장 좋아하는 것을 분석하여 의사 결정을 개선하는 데 유용합니다. 뿐만 아니라, 고객의 과거 행동을 학습하여 특정한 고객 선호도에 따라 제품 집합을 순위 매길 수 있습니다. 추천 시스템을 사용하는 조직은 향상된 고객 경험을 제공함으로써 경쟁사보다 한 발 앞서 있습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 기사에서는 온라인 광고 및 추천 시스템에서의 클릭 수 예측을 향상시키기 위해 설계된 새로운 모델인 FinalMLP에 초점을 맞춥니다. Advanced features like gating and interaction aggregation layers를 갖춘 두 개의 다층 퍼셉트론(MLP) 네트워크를 통합하여, FinalMLP은 기존의 단일 스트림 MLP 모델과 고급 두 개의 스트림 CTR 모델보다 우수한 성능을 보입니다. 저자들은 FinalMLP의 효과를 벤치마크 데이터셋 및 실제 온라인 A/B 테스트를 통해 확인했습니다.</p>
<p>FinalMLP의 상세한 내용과 작동 방식에 초점을 맞추면서, 공개 데이터셋에 적용하고 구현하는 방법에 대한 안내도 제공합니다. 우리는 책 추천 설정에서 FinalMLP의 정확도를 테스트하고, 저자들이 제안한 두 개의 스트림 아키텍처를 활용하여 예측을 설명하는 능력을 평가합니다.</p>
<p>항상 그렇듯이, 코드는 저희의 GitHub에서 이용 가능합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>FinalMLP: 두 개의 MLP 위에 (F)eature gating 및 (IN)teraction (A)ggregation (L)ayers가 추가된 모델</h1>
<p>FinalMLP [1]은 DualMLP [2] 위에 구축된 두 개의 스트림 Multi-Layer Perceptron (MLP) 모델로, 다음과 같은 2가지 새로운 개념을 도입하여 향상시킵니다:</p>
<ul>
<li>Gating 기반의 특징 선택은 두 스트림 간의 차이를 증가시켜, 각 스트림이 서로 다른 특징 세트로부터 서로 다른 패턴을 학습하도록 만듭니다. 예를 들어, 하나의 스트림은 사용자 특징을 처리하고, 다른 하나는 항목 특징에 중점을 둡니다.</li>
<li>Multi-Head Bilinear Fusion은 두 스트림에서 나온 출력을 결합하는 방법을 개선하여 특징 상호작용을 모델링합니다. 이는 덧셈 또는 연결과 같은 선형 연산에 의존하는 전통적인 방식을 사용할 때 발생하지 않을 수 있습니다.</li>
</ul>
<p><img src="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_1.png" alt="이미지"></p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>작동 방법은 무엇인가요?</h1>
<p>이전에 언급한 대로, FinalMLP는 서로 다른 관점에서 특징 상호 작용을 학습하는 두 개의 간단하고 병렬 MLP 네트워크로 구성된 Two-Stream CTR 모델입니다. 다음과 같은 주요 구성 요소로 구성되어 있습니다:</p>
<p>특징 임베딩 레이어는 고차원 및 희소한 원시 특징을 밀집 숫자 표현으로 매핑하는 일반적인 방법입니다. 범주형, 숫자, 또는 다중 값이어도 각 특징은 임베딩 벡터로 변환되고 Feature Selection 모듈에 입력하기 전에 연결됩니다.</p>
<p>범주형 특징은 원-핫 특징 벡터로 변환되며, 학습 가능한 임베딩 행렬에 의해 곱해져 어휘 크기 n과 임베딩 차원 d를 가진 임베딩을 생성합니다[3].</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>숫자형 특성은 1) 숫자 값을 이산형 특성으로 버킷팅하고 이를 범주형 특성으로 다루거나 2) 정규화된 스칼라 값 xj가 주어지면, 임베딩은 xj를 field j의 모든 특성에 대한 공유 임베딩 벡터 vj와 곱한 것으로 주어질 수 있습니다 [3].</p>
<p>다중값 특성은 값 시퀀스를 하나의 길이가 k인 원-핫 인코딩 벡터로 변환한 다음 학습 가능한 임베딩 행렬과 곱하여 임베딩을 생성할 수 있습니다 [3].</p>
<p><img src="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_2.png" alt="이미지"></p>
<p>특성 선택 레이어는 모델 예측에 중요한 영향을 미치도록 중요한 특성에 더 높은 영향을 미치도록 잡음이 많은 특성을 억제하기 위한 특성 중요도 가중치를 얻기 위해 사용됩니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>언급한 대로, FinalMLP는 게이팅 기반 특성 선택, 그리고 게이트 메커니즘을 갖춘 MLP를 사용합니다. 이 MLP는 임베딩을 입력으로 받아들이고, 입력과 동일한 차원의 가중치 벡터를 생성합니다. 특성 중요도 가중치는 시그모이드 함수를 가중치 벡터에 적용하여 [0, 2] 범위의 벡터를 생성하는 방식으로 얻어집니다. 가중된 특성은 특성 임베딩과 특성 중요도 가중치 사이의 요소별 곱셈을 통해 얻어집니다.</p>
<p>이 과정을 통해 두 스트림 간 균질한 학습이 감소되어 특성 상호작용의 보다 보완적인 학습이 가능해집니다. 유저나 아이템 차원에 집중하도록 각 스트림에 독립적으로 적용되어 특성 입력을 구분합니다.</p>
<p><img src="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_3.png" alt=""></p>
<p>양 스트림의 출력을 결합하여 최종 예측 확률을 얻기 위해 스트림 수준 융합 계층이 필요합니다. 일반적으로 두 출력을 결합하는 것은 합산 또는 연결 작업을 기반으로 합니다. 그러나 FinalMLP의 저자들은 선형 조합이 실패할 수 있는 특성 상호작용 정보를 얻기 위해 두 출력을 결합하는 데에 양선형 상호작용 집계 계층을 제안합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>저자들은 어텐션 레이어에서 영감을 받아 멀티 헤드 바이리니어 퓨전 레이어로 발전시킨 바이리니어 퓨전을 소개했습니다. 이는 계산 복잡성을 줄이고 모델의 확장성을 향상시키는 데 사용됩니다.</p>
<p>바이리니어 퓨전 방정식은 다음과 같이 구성됩니다:</p>
<p><img src="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_4.png" alt="image"></p>
<p>여기서 σ는 시그모이드 함수, b는 편향 항목이며, o1은 한 스트림의 출력입니다. w1은 o1에 적용되는 학습 가능한 가중치이고, o2는 다른 스트림의 출력이며, w2는 o2에 적용되는 학습 가능한 가중치입니다. 마지막으로, w3는 특성 상호작용 정보를 추출하는 바이리니어 항목의 학습 가능한 매트릭스입니다. w3가 제로 매트릭스로 설정되면 전통적인 연결 퓨전으로 약화됩니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Bilinear Fusion과 Multi-Head Bilinear Fusion의 차이점은, 두 스트림에서 전체 벡터를 사용하는 대신 출력 o1과 o2를 k 개의 하위 공간으로 나눈다는 것입니다. 각 하위 공간에서 이루어진 bilinear 퓨전은 sigmoid 함수에 공급하여 최종 확률을 생성합니다.</p>
<p><img src="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_5.png" alt="그림"></p>
<h1>FinalMLP로 도서 추천 모델 만들기</h1>
<p>이 섹션에서는 FinalMLP를 Kaggle의 Public Domain 라이선스(CC0)로 공개된 데이터셋에 구현할 것입니다. 이 데이터셋에는 사용자, 책, 그리고 사용자가 책에 부여한 등급에 관한 정보가 포함되어 있습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>데이터셋은 다음과 같이 구성되어 있습니다:</p>
<ul>
<li>사용자 ID — 사용자를 식별하는 ID</li>
<li>위치 — 사용자의 도시, 주, 국가가 콤마로 구분된 문자열</li>
<li>나이 — 사용자의 나이</li>
<li>ISBN — 책 식별자</li>
<li>책 평점 — 특정 책에 대한 사용자의 평점</li>
<li>책 제목 — 책의 제목</li>
<li>책 저자 — 책의 저자</li>
<li>출판 연도 — 책이 출판된 연도</li>
<li>출판사 — 책을 출판한 편집자</li>
</ul>
<p>우리는 각 사용자에 대한 관련성을 기반으로 책을 순위 지정할 것입니다. 그 후에는 우리의 순위 지정과 실제 순위(사용자가 지정한 평점에 따라 책을 정렬함)를 비교하기 위해 정규화 된 할인 누적 이익 (nDCG)를 사용할 것입니다.</p>
<p>nDCG는 결과의 순위를 측정하여 추천 시스템의 품질을 평가하는 메트릭스입니다. 각 항목의 관련성과 결과 목록에서의 위치를 고려하여 상위 순위에 더 많은 중요성을 부여합니다. nDCG는 낮은 순위 항목의 이익을 할인하는 할인 누적 이익(DCG)과 완벽한 순위를 감안한 이상적인 DCG (iDCG)를 비교하여 계산됩니다. 이 정규화된 점수는 0에서 1 사이의 범위를 가지며, 1은 이상적인 순위를 나타냅니다. 따라서 nDCG는 어떻게 시스템이 사용자에게 관련 정보를 효과적으로 제공하는지 이해하는 데 도움이 됩니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>우리는 먼저 라이브러리를 가져와요:</p>
<pre><code class="hljs language-python">%matplotlib inline
%load_ext autoreload
%autoreload <span class="hljs-number">2</span>

<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> ndcg_score
<span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA
<span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> logging
<span class="hljs-keyword">from</span> fuxictr.utils <span class="hljs-keyword">import</span> load_config, set_logger, print_to_json
<span class="hljs-keyword">from</span> fuxictr.features <span class="hljs-keyword">import</span> FeatureMap
<span class="hljs-keyword">from</span> fuxictr.pytorch.torch_utils <span class="hljs-keyword">import</span> seed_everything
<span class="hljs-keyword">from</span> fuxictr.pytorch.dataloaders <span class="hljs-keyword">import</span> H5DataLoader
<span class="hljs-keyword">from</span> fuxictr.preprocess <span class="hljs-keyword">import</span> FeatureProcessor, build_dataset
<span class="hljs-keyword">import</span> src
<span class="hljs-keyword">import</span> gc
<span class="hljs-keyword">import</span> os
</code></pre>
<p>그런 다음, 세 개의 데이터 세트를로드하고 단일 데이터 세트로 병합합니다:</p>
<pre><code class="hljs language-python">books_df = pd.read_csv(<span class="hljs-string">'data/book/Books.csv'</span>)
users_df = pd.read_csv(<span class="hljs-string">'data/book/Users.csv'</span>)
ratings_df = pd.read_csv(<span class="hljs-string">'data/book/Ratings.csv'</span>)

df = pd.merge(users_df, ratings_df, on=<span class="hljs-string">'User-ID'</span>, how=<span class="hljs-string">'left'</span>)
df = pd.merge(df, books_df, on=<span class="hljs-string">'ISBN'</span>, how=<span class="hljs-string">'left'</span>)
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>그 후, 데이터에 문제점을 식별하기 위해 탐색적 데이터 분석을 수행합니다:</p>
<ul>
<li>사용자가 책에 평가를 내리지 않은 관측치를 제거합니다.</li>
</ul>
<pre><code class="hljs language-js">df = df[df[<span class="hljs-string">'Book-Rating'</span>].<span class="hljs-title function_">notnull</span>()]
</code></pre>
<ul>
<li>누락된 값 확인 및 누락된 Book-Author 및 Publisher를 알 수 없는 카테고리로 대체합니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-title function_">print</span>(df.<span class="hljs-property">columns</span>[df.<span class="hljs-title function_">isna</span>().<span class="hljs-title function_">any</span>()].<span class="hljs-title function_">tolist</span>())

df[<span class="hljs-string">'Book-Author'</span>] = df[<span class="hljs-string">'Book-Author'</span>].<span class="hljs-title function_">fillna</span>(<span class="hljs-string">'unknown'</span>)
df[<span class="hljs-string">'Publisher'</span>] = df[<span class="hljs-string">'Publisher'</span>].<span class="hljs-title function_">fillna</span>(<span class="hljs-string">'unknown'</span>)
</code></pre>
<ul>
<li>Remove observations with missing information about the book.</li>
</ul>
<pre><code class="hljs language-js">df = df[df[<span class="hljs-string">'Book-Title'</span>].<span class="hljs-title function_">notnull</span>()]
</code></pre>
<ul>
<li>Replace non-integer Year-of-Publication with null values.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-python">df[<span class="hljs-string">'Year-Of-Publication'</span>] = pd.to_numeric(df[<span class="hljs-string">'Year-Of-Publication'</span>], errors=<span class="hljs-string">'coerce'</span>)
</code></pre>
<ul>
<li>이상을 식별하려면 나이, 출판 연도 및 도서 평점 분포를 확인해보세요.</li>
</ul>
<pre><code class="hljs language-python">plt.rcParams[<span class="hljs-string">"figure.figsize"</span>] = (<span class="hljs-number">20</span>, <span class="hljs-number">3</span>)
sns.histplot(data=df, x=<span class="hljs-string">'Age'</span>)
plt.title(<span class="hljs-string">'나이 분포'</span>)
plt.show()

sns.histplot(data=df, x=<span class="hljs-string">'Year-Of-Publication'</span>)
plt.title(<span class="hljs-string">'출판 연도 분포'</span>)
plt.show()

sns.histplot(data=df, x=<span class="hljs-string">'Book-Rating'</span>)
plt.title(<span class="hljs-string">'도서 평점 분포'</span>)
plt.show()
</code></pre>
<p><img src="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_6.png" alt="이미지"></p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>마침내, 데이터 정리를 다음과 같이 진행합니다:</p>
<ul>
<li>나이가 100 (오기로 보이는 값)인 경우, 나중에 처리할 결측값으로 대체합니다.</li>
<li>데이터셋이 Kaggle에 발행된 시점인 2021년을 상한으로 제한하고, 발행년도가 0인 경우에는 나중에 처리할 결측값으로 대체합니다.</li>
<li>사용자가 독서는 했지만 평점은 남기지 않은 경우 평점이 0인 관측치를 제거합니다.</li>
<li>위치 정보에서 3가지 새로운 특성(도시, 주, 국가)를 생성합니다. 너무 노이즈가 많은 도시 정보는 사용하지 않습니다.</li>
<li>FinalMLP를 위한 이진 레이블을 생성합니다. 평점이 7보다 높은 책을 사용자에게 관련성 있는 것으로 간주합니다.</li>
</ul>
<pre><code class="hljs language-js">df[<span class="hljs-string">'Age'</span>] = np.<span class="hljs-title function_">where</span>(df[<span class="hljs-string">'Age'</span>] > <span class="hljs-number">100</span>, <span class="hljs-title class_">None</span>, df[<span class="hljs-string">'Age'</span>])

df[<span class="hljs-string">'Year-Of-Publication'</span>] = np.<span class="hljs-title function_">where</span>(df[<span class="hljs-string">'Year-Of-Publication'</span>].<span class="hljs-title function_">clip</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2021</span>) &#x3C;= <span class="hljs-number">0</span>, <span class="hljs-title class_">None</span>, df[<span class="hljs-string">'Year-Of-Publication'</span>])
df = df[df[<span class="hljs-string">'Book-Rating'</span>] > <span class="hljs-number">0</span>]
df[<span class="hljs-string">'city'</span>] = df[<span class="hljs-string">'Location'</span>].<span class="hljs-title function_">apply</span>(lambda <span class="hljs-attr">x</span>: x.<span class="hljs-title function_">split</span>(<span class="hljs-string">','</span>)[<span class="hljs-number">0</span>].<span class="hljs-title function_">strip</span>()) # too noisy, we will not use
df[<span class="hljs-string">'state'</span>] = df[<span class="hljs-string">'Location'</span>].<span class="hljs-title function_">apply</span>(lambda <span class="hljs-attr">x</span>: x.<span class="hljs-title function_">split</span>(<span class="hljs-string">','</span>)[<span class="hljs-number">1</span>].<span class="hljs-title function_">strip</span>())
df[<span class="hljs-string">'country'</span>] = df[<span class="hljs-string">'Location'</span>].<span class="hljs-title function_">apply</span>(lambda <span class="hljs-attr">x</span>: x.<span class="hljs-title function_">split</span>(<span class="hljs-string">','</span>)[<span class="hljs-number">2</span>].<span class="hljs-title function_">strip</span>())
df[<span class="hljs-string">'label'</span>] = (df[<span class="hljs-string">'Book-Rating'</span>] > <span class="hljs-number">7</span>)*<span class="hljs-number">1</span>
</code></pre>
<p>데이터셋을 정리하면, 랜덤으로 사용자의 70%를 훈련용, 10%를 검증용, 20%를 테스트용으로 나눠서 데이터를 분할합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"># 고유 사용자 목록 생성
users = df[<span class="hljs-string">'User-ID'</span>].<span class="hljs-title function_">unique</span>()

# 목록 섞기
random.<span class="hljs-title function_">shuffle</span>(users)
# 학습용, 검증용 및 테스트용 사용자 목록 생성
train_users = users[:<span class="hljs-title function_">int</span>(<span class="hljs-number">0.7</span>*<span class="hljs-title function_">len</span>(users))]
val_users = users[<span class="hljs-title function_">int</span>(<span class="hljs-number">0.7</span>*<span class="hljs-title function_">len</span>(users)):<span class="hljs-title function_">int</span>(<span class="hljs-number">0.8</span>*<span class="hljs-title function_">len</span>(users))]
test_users = users[<span class="hljs-title function_">int</span>(<span class="hljs-number">0.8</span>*<span class="hljs-title function_">len</span>(users)):]
# 학습, 검증 및 테스트 데이터프레임
train_df = df[df[<span class="hljs-string">'User-ID'</span>].<span class="hljs-title function_">isin</span>(train_users)]
val_df = df[df[<span class="hljs-string">'User-ID'</span>].<span class="hljs-title function_">isin</span>(val_users)]
test_df = df[df[<span class="hljs-string">'User-ID'</span>].<span class="hljs-title function_">isin</span>(test_users)]
</code></pre>
<p>모델에 데이터를 제공하기 전에 데이터에 일부 전처리를 적용할 것입니다:</p>
<p>텍스트 특성인 Book-Title에 대한 다국어 인코더를 사용하여 임베딩을 생성하고, 80%의 분산이 설명되도록 PCA를 사용하여 차원을 축소합니다.</p>
<p>다국어 인코더를 사용하는 이유는 제목이 서로 다른 언어로 작성되기 때문입니다. 또한, 책이 다른 책보다 더 많은 사용자에 의해 읽혔을 경우 차원 축소에 편향이 주입되지 않도록 먼저 고유한 Book-Title을 추출합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"># 임베딩 생성
train_embeddings = utils.<span class="hljs-title function_">create_embeddings</span>(train_df.<span class="hljs-title function_">copy</span>(), <span class="hljs-string">"Book-Title"</span>)
val_embeddings = utils.<span class="hljs-title function_">create_embeddings</span>(val_df.<span class="hljs-title function_">copy</span>(), <span class="hljs-string">"Book-Title"</span>)
test_embeddings = utils.<span class="hljs-title function_">create_embeddings</span>(test_df.<span class="hljs-title function_">copy</span>(), <span class="hljs-string">"Book-Title"</span>)

# <span class="hljs-variable constant_">PCA</span>를 사용하여 차원 축소
train_embeddings, pca = utils.<span class="hljs-title function_">reduce_dimensionality</span>(train_embeddings, <span class="hljs-number">0.8</span>)
val_embeddings = pca.<span class="hljs-title function_">transform</span>(val_embeddings)
test_embeddings = pca.<span class="hljs-title function_">transform</span>(test_embeddings)
# 데이터프레임에 임베딩 추가
train_df = utils.<span class="hljs-title function_">add_embeddings_to_df</span>(train_df, train_embeddings, <span class="hljs-string">"Book-Title"</span>)
val_df = utils.<span class="hljs-title function_">add_embeddings_to_df</span>(val_df, val_embeddings, <span class="hljs-string">"Book-Title"</span>)
test_df = utils.<span class="hljs-title function_">add_embeddings_to_df</span>(test_df, test_embeddings, <span class="hljs-string">"Book-Title"</span>)
</code></pre>
<p>숫자형 특성의 결측값은 중앙값으로 채우고 MinMaxScaler를 사용하여 데이터를 정규화합니다.</p>
<pre><code class="hljs language-js"># 숫자형 열 설정
<span class="hljs-variable constant_">NUMERICAL_COLUMNS</span> = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> train_df.<span class="hljs-property">columns</span> <span class="hljs-keyword">if</span> <span class="hljs-string">"Book-Title_"</span> <span class="hljs-keyword">in</span> i] + [<span class="hljs-string">'Age'</span>, <span class="hljs-string">'Year-Of-Publication'</span>]

# 전처리 파이프라인 정의 및 데이터 변환
pipe = utils.<span class="hljs-title function_">define_pipeline</span>(<span class="hljs-variable constant_">NUMERICAL_COLUMNS</span>)
train_df[<span class="hljs-variable constant_">NUMERICAL_COLUMNS</span>] = pipe.<span class="hljs-title function_">fit_transform</span>(train_df[<span class="hljs-variable constant_">NUMERICAL_COLUMNS</span>])
val_df[<span class="hljs-variable constant_">NUMERICAL_COLUMNS</span>] = pipe.<span class="hljs-title function_">transform</span>(val_df[<span class="hljs-variable constant_">NUMERICAL_COLUMNS</span>])
test_df[<span class="hljs-variable constant_">NUMERICAL_COLUMNS</span>] = pipe.<span class="hljs-title function_">transform</span>(test_df[<span class="hljs-variable constant_">NUMERICAL_COLUMNS</span>])
</code></pre>
<p>FinalMLP에 제공할 준비가 된 모든 데이터로 dataset_config.yaml 및 model_config.yaml 두 개의 yaml 구성 파일을 만들어야 합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>dataset_config.yaml 파일은 모델에서 사용할 feature들을 정의하는 역할을 합니다. 또한 이들의 데이터 유형을 정의하고(Embedding 레이어에서 다르게 처리됨) 훈련, 검증, 테스트 세트의 경로를 정의합니다. 아래는 구성 파일의 주요 부분을 확인할 수 있습니다:</p>
<p>FinalMLP_book:
data_root: ./data/book/
feature_cols:
-   active: true
dtype: float
name: [Age, Book-Title_0, Book-Title_1, Book-Title_2, Book-Title_3, Book-Title_4, Book-Title_5, Book-Title_6, Book-Title_7,
Book-Title_8, ...]
type: numeric
-   active: true
dtype: str
name: [Book-Author, Year-Of-Publication, Publisher, state, country]
type: categorical
fill_na: unknown
label_col: {dtype: float, name: label}
min_categr_count: 1
test_data: ./data/book/test.csv
train_data: ./data/book/train.csv
valid_data: ./data/book/valid.csv</p>
<p>model_config.yaml 파일은 모델의 하이퍼파라미터를 설정하는 역할을 합니다. 사용자 feature를 처리할 스트림과 아이템 feature를 처리할 스트림을 정의해야 합니다. 파일은 다음과 같이 정의되어야 합니다:</p>
<p>FinalMLP_book:
dataset_id: FinalMLP_book
fs1_context: [Age, state, country]
fs2_context: [Book-Author, Year-Of-Publication, Publisher, Book-Title_0, Book-Title_1, Book-Title_2, Book-Title_3,
Book-Title_4, Book-Title_5, ...]
model_root: ./checkpoints/FinalMLP_book/</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>파이썬으로 돌아가서 최근에 생성된 설정 파일을 로드합니다. 그런 다음, 특성 매핑을 만듭니다 (즉, 각 범주형 특성에 몇 가지 카테고리가 있는지, 다른 특성에서 누락된 값이 있을 경우 어떻게 대체해야 하는지 등). CSV 파일을 h5 파일로 변환합니다.</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># 모델 및 데이터셋 구성 가져오기</span>
experiment_id = <span class="hljs-string">'FinalMLP_book'</span>
params = load_config(<span class="hljs-string">f"config/<span class="hljs-subst">{experiment_id}</span>/"</span>, experiment_id)
params[<span class="hljs-string">'gpu'</span>] = -<span class="hljs-number">1</span> <span class="hljs-comment"># CPU</span>
set_logger(params)
logging.info(<span class="hljs-string">"Params: "</span> + print_to_json(params))
seed_everything(seed=params[<span class="hljs-string">'seed'</span>])

<span class="hljs-comment"># 특성 매핑 생성 및 데이터를 h5 형식으로 변환</span>
data_dir = os.path.join(params[<span class="hljs-string">'data_root'</span>], params[<span class="hljs-string">'dataset_id'</span>])
feature_map_json = os.path.join(data_dir, <span class="hljs-string">"feature_map.json"</span>)
<span class="hljs-keyword">if</span> params[<span class="hljs-string">"data_format"</span>] == <span class="hljs-string">"csv"</span>:
    <span class="hljs-comment"># 특성 매핑 빌드 및 h5 데이터 변환</span>
    feature_encoder = FeatureProcessor(**params)
    params[<span class="hljs-string">"train_data"</span>], params[<span class="hljs-string">"valid_data"</span>], params[<span class="hljs-string">"test_data"</span>] = \\
        build_dataset(feature_encoder, **params)
feature_map = FeatureMap(params[<span class="hljs-string">'dataset_id'</span>], data_dir)
feature_map.load(feature_map_json, params)
logging.info(<span class="hljs-string">"Feature specs: "</span> + print_to_json(feature_map.features))
</code></pre>
<p>이후에 모델의 훈련 프로세스를 시작할 수 있습니다.</p>
<pre><code class="hljs language-python">model_class = <span class="hljs-built_in">getattr</span>(src, params[<span class="hljs-string">'model'</span>])
model = model_class(feature_map, **params)
model.count_parameters() <span class="hljs-comment"># 모델에서 사용하는 매개변수 수를 출력</span>

train_gen, valid_gen = H5DataLoader(feature_map, stage=<span class="hljs-string">'train'</span>, **params).make_iterator()
model.fit(train_gen, validation_data=valid_gen, **params)
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>마침내 보이지 않는 데이터를 예측할 수 있게 되었습니다. 관측치들의 점수를 얻기 위해 배치 크기를 1로 변경하기만 하면 됩니다.</p>
<pre><code class="hljs language-js"># 관측치들의 점수를 얻기
params[<span class="hljs-string">'batch_size'</span>] = <span class="hljs-number">1</span>
test_gen = <span class="hljs-title function_">H5DataLoader</span>(feature_map, stage=<span class="hljs-string">'test'</span>, **params).<span class="hljs-title function_">make_iterator</span>()
test_df[<span class="hljs-string">'score'</span>] = model.<span class="hljs-title function_">predict</span>(test_gen)
</code></pre>
<p>우리는 한 명의 고객을 선택했는데, 이 고객은 여러 권의 책을 평가하고 각 책에 대해 다른 평점을 매겨서 맞춤 순위를 설정할 수 있도록 했습니다. nDCG 점수는 0.986362로 나타났는데, 2권의 책을 1위에서 잘못 배치했기 때문입니다.</p>
<p>우리는 FinalMLP를 평가하기 위해 Recall을 사용했습니다. Recall은 시스템이 전체 중에서 모든 관련 항목을 식별하는 능력을 측정하는 지표로, 전체 관련 항목 중 검색된 관련 항목의 비율로 나타냅니다. Recall@K와 같이 Recall@3을 지정하면 시스템이 상위 K개의 추천 내에서 관련 항목을 식별하는 능력에 초점을 맞춥니다. 이것은 사용자들이 주로 상위 추천에 주목하는 추천 시스템을 평가하는 데 중요합니다. K(예: 3)의 선택은 일반적인 사용자 행동과 애플리케이션 맥락에 따라 달라집니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 고객의 Recall@3을 살펴보면, 상위 3위 안에 가장 관련성 있는 책이 세 권 모두 들어있기 때문에 100%입니다.</p>
<pre><code class="hljs language-js">true_relevance = np.<span class="hljs-title function_">asarray</span>([test_df[test_df[<span class="hljs-string">'User-ID'</span>] == <span class="hljs-number">1113</span>][<span class="hljs-string">'Book-Rating'</span>].<span class="hljs-title function_">tolist</span>()])
y_relevance = np.<span class="hljs-title function_">asarray</span>([test_df[test_df[<span class="hljs-string">'User-ID'</span>] == <span class="hljs-number">1113</span>][<span class="hljs-string">'score'</span>].<span class="hljs-title function_">tolist</span>()])

<span class="hljs-title function_">ndcg_score</span>(true_relevance, y_relevance)
</code></pre>
<p>남은 테스트 세트에 대한 nDCG 점수를 계산하고, Figure 7에서 FinalMLP 성능을 CatBoost Ranker와 비교했습니다. 두 모델 모두 잘 수행했지만, 이 테스트 세트에서 FinalMLP가 조금 더 우수한 성능을 보였습니다. 사용자 당 평균 nDCG가 0.963298인 반면 CatBoost Ranker는 0.959977에 그쳤습니다.</p>
<img src="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_7.png">
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>해석 가능성 측면에서 이 모델은 특성 선택을 수행하여 가중치 벡터를 추출할 수 있게 합니다. 그러나 각 특성의 중요성을 해석하고 이해하는 것은 간단하지 않습니다. 임베딩 레이어 이후에는 930차원 벡터가 생성되어 원래 특성으로 재매핑하기가 어려워집니다. 그럼에도 불구하고, 이전에 언급된 선형 항으로 주어진 선형 처리 후 각 스트림의 출력의 절대값을 추출함으로써 각 스트림의 중요성을 이해해 볼 수 있습니다.</p>
<p>이를 위해 InteractionAggregation 모듈을 변경하고 각 단계 후에 선형 변환된 값 추출을 위해 다음 코드 라인을 추가해야 합니다:</p>
<pre><code class="hljs language-js">...     
    self.<span class="hljs-property">x_importance</span> = []
    self.<span class="hljs-property">y_importance</span> = []
  def <span class="hljs-title function_">forward</span>(self, x, y):
          self.<span class="hljs-property">x_importance</span>.<span class="hljs-title function_">append</span>(torch.<span class="hljs-title function_">sum</span>(torch.<span class="hljs-title function_">abs</span>(self.<span class="hljs-title function_">w_x</span>(x))))
          self.<span class="hljs-property">y_importance</span>.<span class="hljs-title function_">append</span>(torch.<span class="hljs-title function_">sum</span>(torch.<span class="hljs-title function_">abs</span>(self.<span class="hljs-title function_">w_y</span>(y))))
...
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>한 번 훈련을 받으면, 각 스트림의 선형 변환 결과에서 절대 값을 예측하고 플롯할 수 있습니다. 그림 8에 보여진 것처럼, 상품 스트림이 사용자 스트림보다 중요성이 높습니다. 이는 상품에 대한 기능이 훨씬 많기 때문이지만 사용자 특성이 상당히 일반적이기 때문에 발생합니다.</p>
<p><img src="/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_9.png" alt="이미지"></p>
<h1>결론</h1>
<p>추천 시스템은 사용자 경험을 향상시켜 맞춤형 추천을 제공하며, 성장과 혁신을 이끄는 데이터 기반 의사 결정을 기관에 제공하여 사용자 경험을 향상시킵니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 기사에서는 추천 시스템용으로 개발된 가장 최근 모델 중 하나를 소개했습니다. FinalMLP는 두 개의 독립 네트워크를 가진 딥 러닝 모델입니다. 각 네트워크는 사용자와 항목 이 두 가지 다른 관점 중 하나에 중점을 둡니다. 각 네트워크로부터 학습된 다른 패턴은 그 다음 각 네트워크의 학습 내용을 결합하는 책합층에 공급됩니다. 사용자-항목 쌍 상호 작용의 단일 뷰를 생성하여 최종 점수를 생성합니다. 이 모델은 CatBoost Ranker를 이겼으며 우리의 사용 사례에서 잘 수행했습니다.</p>
<p>알고리즘 선택은 해결하려는 문제와 데이터셋에 따라 다를 수 있음을 유의해 주세요. 항상 여러 방법을 상호 비교하는 것이 좋은 실천 방법입니다. 또한 xDeepFM, AutoInt, DHEN 또는 DLRM을 테스트하는 것도 고려할 수 있습니다.</p>
<h1>내 소개</h1>
<p>인공지능 분야의 시리얼 기업가 및 리더입니다. 비즈니스를 위한 인공지능 제품을 개발하고 인공지능에 초점을 맞춘 스타트업에 투자합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>창립자 @ ZAAI | LinkedIn | X/Twitter</p>
<h1>참고 문헌</h1>
<p>[1] Kelong Mao, Jieming Zhu, Liangcai Su, Guohao Cai, Yuru Li, Zhenhua Dong. FinalMLP: CTR 예측을 위한 향상된 이차원 MLP 모델. arXiv:2304.00902, 2023.</p>
<p>[2] Jiajun Fei, Ziyu Zhu, Wenlei Liu, Zhidong Deng, Mingyang Li, Huanjun Deng, Shuo Zhang. DuMLP-Pin: 집합 특성 추출을 위한 이중-MLP-내적 불변 네트워크. arXiv:2203.04007, 2022.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>[3] Jieming Zhu, Jinyang Liu, Shuai Yang, Qi Zhang, Xiuqiang He. BARS-CTR: Open Benchmarking for Click-Through Rate Prediction. arXiv:2009.05794, 2020.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"FinalMLP 추천 시스템을 위한 간단하지만 강력한 Two-Stream MLP 모델 사용 방법","description":"","date":"2024-07-12 20:35","slug":"2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems","content":"\n\n이 게시물은 Rafael Guedes와 공동 저자로 작성되었습니다.\n\n# 소개\n\n세계는 모두가 원하는 것을 거의 한 번 클릭으로 모두 얻을 수 있는 디지턈 시대로 발전해 왔습니다. 접근성, 편의성 및 다양한 제공 효과는 소비자에게 새로운 도전과 함께 제공됩니다. 소비자가 옵션의 바다 속에서 검색하는 대신 맞춤 선택을 받을 수 있는 방법은 무엇일까요? 바로 추천 시스템이 여기에서 나타납니다.\n\n추천 시스템은 조직이 교차 판매와 장꼬 아이템의 판매를 증가시키고, 고객들이 가장 좋아하는 것을 분석하여 의사 결정을 개선하는 데 유용합니다. 뿐만 아니라, 고객의 과거 행동을 학습하여 특정한 고객 선호도에 따라 제품 집합을 순위 매길 수 있습니다. 추천 시스템을 사용하는 조직은 향상된 고객 경험을 제공함으로써 경쟁사보다 한 발 앞서 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 온라인 광고 및 추천 시스템에서의 클릭 수 예측을 향상시키기 위해 설계된 새로운 모델인 FinalMLP에 초점을 맞춥니다. Advanced features like gating and interaction aggregation layers를 갖춘 두 개의 다층 퍼셉트론(MLP) 네트워크를 통합하여, FinalMLP은 기존의 단일 스트림 MLP 모델과 고급 두 개의 스트림 CTR 모델보다 우수한 성능을 보입니다. 저자들은 FinalMLP의 효과를 벤치마크 데이터셋 및 실제 온라인 A/B 테스트를 통해 확인했습니다.\n\nFinalMLP의 상세한 내용과 작동 방식에 초점을 맞추면서, 공개 데이터셋에 적용하고 구현하는 방법에 대한 안내도 제공합니다. 우리는 책 추천 설정에서 FinalMLP의 정확도를 테스트하고, 저자들이 제안한 두 개의 스트림 아키텍처를 활용하여 예측을 설명하는 능력을 평가합니다.\n\n항상 그렇듯이, 코드는 저희의 GitHub에서 이용 가능합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# FinalMLP: 두 개의 MLP 위에 (F)eature gating 및 (IN)teraction (A)ggregation (L)ayers가 추가된 모델\n\nFinalMLP [1]은 DualMLP [2] 위에 구축된 두 개의 스트림 Multi-Layer Perceptron (MLP) 모델로, 다음과 같은 2가지 새로운 개념을 도입하여 향상시킵니다:\n\n- Gating 기반의 특징 선택은 두 스트림 간의 차이를 증가시켜, 각 스트림이 서로 다른 특징 세트로부터 서로 다른 패턴을 학습하도록 만듭니다. 예를 들어, 하나의 스트림은 사용자 특징을 처리하고, 다른 하나는 항목 특징에 중점을 둡니다.\n- Multi-Head Bilinear Fusion은 두 스트림에서 나온 출력을 결합하는 방법을 개선하여 특징 상호작용을 모델링합니다. 이는 덧셈 또는 연결과 같은 선형 연산에 의존하는 전통적인 방식을 사용할 때 발생하지 않을 수 있습니다.\n\n![이미지](/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_1.png)\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 작동 방법은 무엇인가요?\n\n이전에 언급한 대로, FinalMLP는 서로 다른 관점에서 특징 상호 작용을 학습하는 두 개의 간단하고 병렬 MLP 네트워크로 구성된 Two-Stream CTR 모델입니다. 다음과 같은 주요 구성 요소로 구성되어 있습니다:\n\n특징 임베딩 레이어는 고차원 및 희소한 원시 특징을 밀집 숫자 표현으로 매핑하는 일반적인 방법입니다. 범주형, 숫자, 또는 다중 값이어도 각 특징은 임베딩 벡터로 변환되고 Feature Selection 모듈에 입력하기 전에 연결됩니다.\n\n범주형 특징은 원-핫 특징 벡터로 변환되며, 학습 가능한 임베딩 행렬에 의해 곱해져 어휘 크기 n과 임베딩 차원 d를 가진 임베딩을 생성합니다[3].\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n숫자형 특성은 1) 숫자 값을 이산형 특성으로 버킷팅하고 이를 범주형 특성으로 다루거나 2) 정규화된 스칼라 값 xj가 주어지면, 임베딩은 xj를 field j의 모든 특성에 대한 공유 임베딩 벡터 vj와 곱한 것으로 주어질 수 있습니다 [3].\n\n다중값 특성은 값 시퀀스를 하나의 길이가 k인 원-핫 인코딩 벡터로 변환한 다음 학습 가능한 임베딩 행렬과 곱하여 임베딩을 생성할 수 있습니다 [3].\n\n![이미지](/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_2.png)\n\n특성 선택 레이어는 모델 예측에 중요한 영향을 미치도록 중요한 특성에 더 높은 영향을 미치도록 잡음이 많은 특성을 억제하기 위한 특성 중요도 가중치를 얻기 위해 사용됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n언급한 대로, FinalMLP는 게이팅 기반 특성 선택, 그리고 게이트 메커니즘을 갖춘 MLP를 사용합니다. 이 MLP는 임베딩을 입력으로 받아들이고, 입력과 동일한 차원의 가중치 벡터를 생성합니다. 특성 중요도 가중치는 시그모이드 함수를 가중치 벡터에 적용하여 [0, 2] 범위의 벡터를 생성하는 방식으로 얻어집니다. 가중된 특성은 특성 임베딩과 특성 중요도 가중치 사이의 요소별 곱셈을 통해 얻어집니다.\n\n이 과정을 통해 두 스트림 간 균질한 학습이 감소되어 특성 상호작용의 보다 보완적인 학습이 가능해집니다. 유저나 아이템 차원에 집중하도록 각 스트림에 독립적으로 적용되어 특성 입력을 구분합니다.\n\n![](/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_3.png)\n\n양 스트림의 출력을 결합하여 최종 예측 확률을 얻기 위해 스트림 수준 융합 계층이 필요합니다. 일반적으로 두 출력을 결합하는 것은 합산 또는 연결 작업을 기반으로 합니다. 그러나 FinalMLP의 저자들은 선형 조합이 실패할 수 있는 특성 상호작용 정보를 얻기 위해 두 출력을 결합하는 데에 양선형 상호작용 집계 계층을 제안합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저자들은 어텐션 레이어에서 영감을 받아 멀티 헤드 바이리니어 퓨전 레이어로 발전시킨 바이리니어 퓨전을 소개했습니다. 이는 계산 복잡성을 줄이고 모델의 확장성을 향상시키는 데 사용됩니다.\n\n바이리니어 퓨전 방정식은 다음과 같이 구성됩니다:\n\n![image](/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_4.png)\n\n여기서 σ는 시그모이드 함수, b는 편향 항목이며, o1은 한 스트림의 출력입니다. w1은 o1에 적용되는 학습 가능한 가중치이고, o2는 다른 스트림의 출력이며, w2는 o2에 적용되는 학습 가능한 가중치입니다. 마지막으로, w3는 특성 상호작용 정보를 추출하는 바이리니어 항목의 학습 가능한 매트릭스입니다. w3가 제로 매트릭스로 설정되면 전통적인 연결 퓨전으로 약화됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBilinear Fusion과 Multi-Head Bilinear Fusion의 차이점은, 두 스트림에서 전체 벡터를 사용하는 대신 출력 o1과 o2를 k 개의 하위 공간으로 나눈다는 것입니다. 각 하위 공간에서 이루어진 bilinear 퓨전은 sigmoid 함수에 공급하여 최종 확률을 생성합니다.\n\n![그림](/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_5.png)\n\n# FinalMLP로 도서 추천 모델 만들기\n\n이 섹션에서는 FinalMLP를 Kaggle의 Public Domain 라이선스(CC0)로 공개된 데이터셋에 구현할 것입니다. 이 데이터셋에는 사용자, 책, 그리고 사용자가 책에 부여한 등급에 관한 정보가 포함되어 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터셋은 다음과 같이 구성되어 있습니다:\n\n- 사용자 ID — 사용자를 식별하는 ID\n- 위치 — 사용자의 도시, 주, 국가가 콤마로 구분된 문자열\n- 나이 — 사용자의 나이\n- ISBN — 책 식별자\n- 책 평점 — 특정 책에 대한 사용자의 평점\n- 책 제목 — 책의 제목\n- 책 저자 — 책의 저자\n- 출판 연도 — 책이 출판된 연도\n- 출판사 — 책을 출판한 편집자\n\n우리는 각 사용자에 대한 관련성을 기반으로 책을 순위 지정할 것입니다. 그 후에는 우리의 순위 지정과 실제 순위(사용자가 지정한 평점에 따라 책을 정렬함)를 비교하기 위해 정규화 된 할인 누적 이익 (nDCG)를 사용할 것입니다.\n\nnDCG는 결과의 순위를 측정하여 추천 시스템의 품질을 평가하는 메트릭스입니다. 각 항목의 관련성과 결과 목록에서의 위치를 고려하여 상위 순위에 더 많은 중요성을 부여합니다. nDCG는 낮은 순위 항목의 이익을 할인하는 할인 누적 이익(DCG)과 완벽한 순위를 감안한 이상적인 DCG (iDCG)를 비교하여 계산됩니다. 이 정규화된 점수는 0에서 1 사이의 범위를 가지며, 1은 이상적인 순위를 나타냅니다. 따라서 nDCG는 어떻게 시스템이 사용자에게 관련 정보를 효과적으로 제공하는지 이해하는 데 도움이 됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 먼저 라이브러리를 가져와요:\n\n```python\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nfrom sklearn.metrics import ndcg_score\nfrom sklearn.decomposition import PCA\nfrom sentence_transformers import SentenceTransformer\nimport os\nimport logging\nfrom fuxictr.utils import load_config, set_logger, print_to_json\nfrom fuxictr.features import FeatureMap\nfrom fuxictr.pytorch.torch_utils import seed_everything\nfrom fuxictr.pytorch.dataloaders import H5DataLoader\nfrom fuxictr.preprocess import FeatureProcessor, build_dataset\nimport src\nimport gc\nimport os\n```\n\n그런 다음, 세 개의 데이터 세트를로드하고 단일 데이터 세트로 병합합니다:\n\n```python\nbooks_df = pd.read_csv('data/book/Books.csv')\nusers_df = pd.read_csv('data/book/Users.csv')\nratings_df = pd.read_csv('data/book/Ratings.csv')\n\ndf = pd.merge(users_df, ratings_df, on='User-ID', how='left')\ndf = pd.merge(df, books_df, on='ISBN', how='left')\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 후, 데이터에 문제점을 식별하기 위해 탐색적 데이터 분석을 수행합니다:\n\n- 사용자가 책에 평가를 내리지 않은 관측치를 제거합니다.\n\n```js\ndf = df[df['Book-Rating'].notnull()]\n```\n\n- 누락된 값 확인 및 누락된 Book-Author 및 Publisher를 알 수 없는 카테고리로 대체합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nprint(df.columns[df.isna().any()].tolist())\n\ndf['Book-Author'] = df['Book-Author'].fillna('unknown')\ndf['Publisher'] = df['Publisher'].fillna('unknown')\n```\n\n- Remove observations with missing information about the book.\n\n```js\ndf = df[df['Book-Title'].notnull()]\n```\n\n- Replace non-integer Year-of-Publication with null values.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\ndf['Year-Of-Publication'] = pd.to_numeric(df['Year-Of-Publication'], errors='coerce')\n```\n\n- 이상을 식별하려면 나이, 출판 연도 및 도서 평점 분포를 확인해보세요.\n\n```python\nplt.rcParams[\"figure.figsize\"] = (20, 3)\nsns.histplot(data=df, x='Age')\nplt.title('나이 분포')\nplt.show()\n\nsns.histplot(data=df, x='Year-Of-Publication')\nplt.title('출판 연도 분포')\nplt.show()\n\nsns.histplot(data=df, x='Book-Rating')\nplt.title('도서 평점 분포')\nplt.show()\n```\n\n![이미지](/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_6.png)\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마침내, 데이터 정리를 다음과 같이 진행합니다:\n\n- 나이가 100 (오기로 보이는 값)인 경우, 나중에 처리할 결측값으로 대체합니다.\n- 데이터셋이 Kaggle에 발행된 시점인 2021년을 상한으로 제한하고, 발행년도가 0인 경우에는 나중에 처리할 결측값으로 대체합니다.\n- 사용자가 독서는 했지만 평점은 남기지 않은 경우 평점이 0인 관측치를 제거합니다.\n- 위치 정보에서 3가지 새로운 특성(도시, 주, 국가)를 생성합니다. 너무 노이즈가 많은 도시 정보는 사용하지 않습니다.\n- FinalMLP를 위한 이진 레이블을 생성합니다. 평점이 7보다 높은 책을 사용자에게 관련성 있는 것으로 간주합니다.\n\n```js\ndf['Age'] = np.where(df['Age'] \u003e 100, None, df['Age'])\n\ndf['Year-Of-Publication'] = np.where(df['Year-Of-Publication'].clip(0, 2021) \u003c= 0, None, df['Year-Of-Publication'])\ndf = df[df['Book-Rating'] \u003e 0]\ndf['city'] = df['Location'].apply(lambda x: x.split(',')[0].strip()) # too noisy, we will not use\ndf['state'] = df['Location'].apply(lambda x: x.split(',')[1].strip())\ndf['country'] = df['Location'].apply(lambda x: x.split(',')[2].strip())\ndf['label'] = (df['Book-Rating'] \u003e 7)*1\n```\n\n데이터셋을 정리하면, 랜덤으로 사용자의 70%를 훈련용, 10%를 검증용, 20%를 테스트용으로 나눠서 데이터를 분할합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 고유 사용자 목록 생성\nusers = df['User-ID'].unique()\n\n# 목록 섞기\nrandom.shuffle(users)\n# 학습용, 검증용 및 테스트용 사용자 목록 생성\ntrain_users = users[:int(0.7*len(users))]\nval_users = users[int(0.7*len(users)):int(0.8*len(users))]\ntest_users = users[int(0.8*len(users)):]\n# 학습, 검증 및 테스트 데이터프레임\ntrain_df = df[df['User-ID'].isin(train_users)]\nval_df = df[df['User-ID'].isin(val_users)]\ntest_df = df[df['User-ID'].isin(test_users)]\r\n```\n\n모델에 데이터를 제공하기 전에 데이터에 일부 전처리를 적용할 것입니다:\n\n텍스트 특성인 Book-Title에 대한 다국어 인코더를 사용하여 임베딩을 생성하고, 80%의 분산이 설명되도록 PCA를 사용하여 차원을 축소합니다.\n\n다국어 인코더를 사용하는 이유는 제목이 서로 다른 언어로 작성되기 때문입니다. 또한, 책이 다른 책보다 더 많은 사용자에 의해 읽혔을 경우 차원 축소에 편향이 주입되지 않도록 먼저 고유한 Book-Title을 추출합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 임베딩 생성\ntrain_embeddings = utils.create_embeddings(train_df.copy(), \"Book-Title\")\nval_embeddings = utils.create_embeddings(val_df.copy(), \"Book-Title\")\ntest_embeddings = utils.create_embeddings(test_df.copy(), \"Book-Title\")\n\n# PCA를 사용하여 차원 축소\ntrain_embeddings, pca = utils.reduce_dimensionality(train_embeddings, 0.8)\nval_embeddings = pca.transform(val_embeddings)\ntest_embeddings = pca.transform(test_embeddings)\n# 데이터프레임에 임베딩 추가\ntrain_df = utils.add_embeddings_to_df(train_df, train_embeddings, \"Book-Title\")\nval_df = utils.add_embeddings_to_df(val_df, val_embeddings, \"Book-Title\")\ntest_df = utils.add_embeddings_to_df(test_df, test_embeddings, \"Book-Title\")\n```\n\n숫자형 특성의 결측값은 중앙값으로 채우고 MinMaxScaler를 사용하여 데이터를 정규화합니다.\n\n```js\n# 숫자형 열 설정\nNUMERICAL_COLUMNS = [i for i in train_df.columns if \"Book-Title_\" in i] + ['Age', 'Year-Of-Publication']\n\n# 전처리 파이프라인 정의 및 데이터 변환\npipe = utils.define_pipeline(NUMERICAL_COLUMNS)\ntrain_df[NUMERICAL_COLUMNS] = pipe.fit_transform(train_df[NUMERICAL_COLUMNS])\nval_df[NUMERICAL_COLUMNS] = pipe.transform(val_df[NUMERICAL_COLUMNS])\ntest_df[NUMERICAL_COLUMNS] = pipe.transform(test_df[NUMERICAL_COLUMNS])\n```\n\nFinalMLP에 제공할 준비가 된 모든 데이터로 dataset_config.yaml 및 model_config.yaml 두 개의 yaml 구성 파일을 만들어야 합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ndataset_config.yaml 파일은 모델에서 사용할 feature들을 정의하는 역할을 합니다. 또한 이들의 데이터 유형을 정의하고(Embedding 레이어에서 다르게 처리됨) 훈련, 검증, 테스트 세트의 경로를 정의합니다. 아래는 구성 파일의 주요 부분을 확인할 수 있습니다:\n\n\nFinalMLP_book:\n    data_root: ./data/book/\n    feature_cols:\n    -   active: true\n        dtype: float\n        name: [Age, Book-Title_0, Book-Title_1, Book-Title_2, Book-Title_3, Book-Title_4, Book-Title_5, Book-Title_6, Book-Title_7,\n        Book-Title_8, ...]\n        type: numeric\n    -   active: true\n        dtype: str\n        name: [Book-Author, Year-Of-Publication, Publisher, state, country]\n        type: categorical\n        fill_na: unknown\n    label_col: {dtype: float, name: label}\n    min_categr_count: 1\n    test_data: ./data/book/test.csv\n    train_data: ./data/book/train.csv\n    valid_data: ./data/book/valid.csv\n\n\nmodel_config.yaml 파일은 모델의 하이퍼파라미터를 설정하는 역할을 합니다. 사용자 feature를 처리할 스트림과 아이템 feature를 처리할 스트림을 정의해야 합니다. 파일은 다음과 같이 정의되어야 합니다:\n\n\nFinalMLP_book:\n dataset_id: FinalMLP_book\n fs1_context: [Age, state, country]\n fs2_context: [Book-Author, Year-Of-Publication, Publisher, Book-Title_0, Book-Title_1, Book-Title_2, Book-Title_3,\n     Book-Title_4, Book-Title_5, ...]\n model_root: ./checkpoints/FinalMLP_book/\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬으로 돌아가서 최근에 생성된 설정 파일을 로드합니다. 그런 다음, 특성 매핑을 만듭니다 (즉, 각 범주형 특성에 몇 가지 카테고리가 있는지, 다른 특성에서 누락된 값이 있을 경우 어떻게 대체해야 하는지 등). CSV 파일을 h5 파일로 변환합니다.\n\n```python\n# 모델 및 데이터셋 구성 가져오기\nexperiment_id = 'FinalMLP_book'\nparams = load_config(f\"config/{experiment_id}/\", experiment_id)\nparams['gpu'] = -1 # CPU\nset_logger(params)\nlogging.info(\"Params: \" + print_to_json(params))\nseed_everything(seed=params['seed'])\n\n# 특성 매핑 생성 및 데이터를 h5 형식으로 변환\ndata_dir = os.path.join(params['data_root'], params['dataset_id'])\nfeature_map_json = os.path.join(data_dir, \"feature_map.json\")\nif params[\"data_format\"] == \"csv\":\n    # 특성 매핑 빌드 및 h5 데이터 변환\n    feature_encoder = FeatureProcessor(**params)\n    params[\"train_data\"], params[\"valid_data\"], params[\"test_data\"] = \\\\\n        build_dataset(feature_encoder, **params)\nfeature_map = FeatureMap(params['dataset_id'], data_dir)\nfeature_map.load(feature_map_json, params)\nlogging.info(\"Feature specs: \" + print_to_json(feature_map.features))\n```\n\n이후에 모델의 훈련 프로세스를 시작할 수 있습니다.\n\n```python\nmodel_class = getattr(src, params['model'])\nmodel = model_class(feature_map, **params)\nmodel.count_parameters() # 모델에서 사용하는 매개변수 수를 출력\n\ntrain_gen, valid_gen = H5DataLoader(feature_map, stage='train', **params).make_iterator()\nmodel.fit(train_gen, validation_data=valid_gen, **params)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마침내 보이지 않는 데이터를 예측할 수 있게 되었습니다. 관측치들의 점수를 얻기 위해 배치 크기를 1로 변경하기만 하면 됩니다.\n\n```js\n# 관측치들의 점수를 얻기\nparams['batch_size'] = 1\ntest_gen = H5DataLoader(feature_map, stage='test', **params).make_iterator()\ntest_df['score'] = model.predict(test_gen)\n```\n\n우리는 한 명의 고객을 선택했는데, 이 고객은 여러 권의 책을 평가하고 각 책에 대해 다른 평점을 매겨서 맞춤 순위를 설정할 수 있도록 했습니다. nDCG 점수는 0.986362로 나타났는데, 2권의 책을 1위에서 잘못 배치했기 때문입니다.\n\n우리는 FinalMLP를 평가하기 위해 Recall을 사용했습니다. Recall은 시스템이 전체 중에서 모든 관련 항목을 식별하는 능력을 측정하는 지표로, 전체 관련 항목 중 검색된 관련 항목의 비율로 나타냅니다. Recall@K와 같이 Recall@3을 지정하면 시스템이 상위 K개의 추천 내에서 관련 항목을 식별하는 능력에 초점을 맞춥니다. 이것은 사용자들이 주로 상위 추천에 주목하는 추천 시스템을 평가하는 데 중요합니다. K(예: 3)의 선택은 일반적인 사용자 행동과 애플리케이션 맥락에 따라 달라집니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 고객의 Recall@3을 살펴보면, 상위 3위 안에 가장 관련성 있는 책이 세 권 모두 들어있기 때문에 100%입니다.\n\n```js\ntrue_relevance = np.asarray([test_df[test_df['User-ID'] == 1113]['Book-Rating'].tolist()])\ny_relevance = np.asarray([test_df[test_df['User-ID'] == 1113]['score'].tolist()])\n\nndcg_score(true_relevance, y_relevance)\n```\n\n남은 테스트 세트에 대한 nDCG 점수를 계산하고, Figure 7에서 FinalMLP 성능을 CatBoost Ranker와 비교했습니다. 두 모델 모두 잘 수행했지만, 이 테스트 세트에서 FinalMLP가 조금 더 우수한 성능을 보였습니다. 사용자 당 평균 nDCG가 0.963298인 반면 CatBoost Ranker는 0.959977에 그쳤습니다.\n\n\u003cimg src=\"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_7.png\" /\u003e\n\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n해석 가능성 측면에서 이 모델은 특성 선택을 수행하여 가중치 벡터를 추출할 수 있게 합니다. 그러나 각 특성의 중요성을 해석하고 이해하는 것은 간단하지 않습니다. 임베딩 레이어 이후에는 930차원 벡터가 생성되어 원래 특성으로 재매핑하기가 어려워집니다. 그럼에도 불구하고, 이전에 언급된 선형 항으로 주어진 선형 처리 후 각 스트림의 출력의 절대값을 추출함으로써 각 스트림의 중요성을 이해해 볼 수 있습니다.\n\n이를 위해 InteractionAggregation 모듈을 변경하고 각 단계 후에 선형 변환된 값 추출을 위해 다음 코드 라인을 추가해야 합니다:\n\n```js\n...     \n    self.x_importance = []\n    self.y_importance = []\n  def forward(self, x, y):\n          self.x_importance.append(torch.sum(torch.abs(self.w_x(x))))\n          self.y_importance.append(torch.sum(torch.abs(self.w_y(y))))\n...\n```\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 번 훈련을 받으면, 각 스트림의 선형 변환 결과에서 절대 값을 예측하고 플롯할 수 있습니다. 그림 8에 보여진 것처럼, 상품 스트림이 사용자 스트림보다 중요성이 높습니다. 이는 상품에 대한 기능이 훨씬 많기 때문이지만 사용자 특성이 상당히 일반적이기 때문에 발생합니다.\n\n![이미지](/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_9.png)\n\n# 결론\n\n추천 시스템은 사용자 경험을 향상시켜 맞춤형 추천을 제공하며, 성장과 혁신을 이끄는 데이터 기반 의사 결정을 기관에 제공하여 사용자 경험을 향상시킵니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 추천 시스템용으로 개발된 가장 최근 모델 중 하나를 소개했습니다. FinalMLP는 두 개의 독립 네트워크를 가진 딥 러닝 모델입니다. 각 네트워크는 사용자와 항목 이 두 가지 다른 관점 중 하나에 중점을 둡니다. 각 네트워크로부터 학습된 다른 패턴은 그 다음 각 네트워크의 학습 내용을 결합하는 책합층에 공급됩니다. 사용자-항목 쌍 상호 작용의 단일 뷰를 생성하여 최종 점수를 생성합니다. 이 모델은 CatBoost Ranker를 이겼으며 우리의 사용 사례에서 잘 수행했습니다.\n\n알고리즘 선택은 해결하려는 문제와 데이터셋에 따라 다를 수 있음을 유의해 주세요. 항상 여러 방법을 상호 비교하는 것이 좋은 실천 방법입니다. 또한 xDeepFM, AutoInt, DHEN 또는 DLRM을 테스트하는 것도 고려할 수 있습니다.\n\n# 내 소개\n\n인공지능 분야의 시리얼 기업가 및 리더입니다. 비즈니스를 위한 인공지능 제품을 개발하고 인공지능에 초점을 맞춘 스타트업에 투자합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n창립자 @ ZAAI | LinkedIn | X/Twitter\n\n# 참고 문헌\n\n[1] Kelong Mao, Jieming Zhu, Liangcai Su, Guohao Cai, Yuru Li, Zhenhua Dong. FinalMLP: CTR 예측을 위한 향상된 이차원 MLP 모델. arXiv:2304.00902, 2023.\n\n[2] Jiajun Fei, Ziyu Zhu, Wenlei Liu, Zhidong Deng, Mingyang Li, Huanjun Deng, Shuo Zhang. DuMLP-Pin: 집합 특성 추출을 위한 이중-MLP-내적 불변 네트워크. arXiv:2203.04007, 2022.\n\n\u003c!-- TIL 수평 --\u003e\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[3] Jieming Zhu, Jinyang Liu, Shuai Yang, Qi Zhang, Xiuqiang He. BARS-CTR: Open Benchmarking for Click-Through Rate Prediction. arXiv:2009.05794, 2020.","ogImage":{"url":"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_0.png","tag":["Tech"],"readingTime":22},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e이 게시물은 Rafael Guedes와 공동 저자로 작성되었습니다.\u003c/p\u003e\n\u003ch1\u003e소개\u003c/h1\u003e\n\u003cp\u003e세계는 모두가 원하는 것을 거의 한 번 클릭으로 모두 얻을 수 있는 디지턈 시대로 발전해 왔습니다. 접근성, 편의성 및 다양한 제공 효과는 소비자에게 새로운 도전과 함께 제공됩니다. 소비자가 옵션의 바다 속에서 검색하는 대신 맞춤 선택을 받을 수 있는 방법은 무엇일까요? 바로 추천 시스템이 여기에서 나타납니다.\u003c/p\u003e\n\u003cp\u003e추천 시스템은 조직이 교차 판매와 장꼬 아이템의 판매를 증가시키고, 고객들이 가장 좋아하는 것을 분석하여 의사 결정을 개선하는 데 유용합니다. 뿐만 아니라, 고객의 과거 행동을 학습하여 특정한 고객 선호도에 따라 제품 집합을 순위 매길 수 있습니다. 추천 시스템을 사용하는 조직은 향상된 고객 경험을 제공함으로써 경쟁사보다 한 발 앞서 있습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 기사에서는 온라인 광고 및 추천 시스템에서의 클릭 수 예측을 향상시키기 위해 설계된 새로운 모델인 FinalMLP에 초점을 맞춥니다. Advanced features like gating and interaction aggregation layers를 갖춘 두 개의 다층 퍼셉트론(MLP) 네트워크를 통합하여, FinalMLP은 기존의 단일 스트림 MLP 모델과 고급 두 개의 스트림 CTR 모델보다 우수한 성능을 보입니다. 저자들은 FinalMLP의 효과를 벤치마크 데이터셋 및 실제 온라인 A/B 테스트를 통해 확인했습니다.\u003c/p\u003e\n\u003cp\u003eFinalMLP의 상세한 내용과 작동 방식에 초점을 맞추면서, 공개 데이터셋에 적용하고 구현하는 방법에 대한 안내도 제공합니다. 우리는 책 추천 설정에서 FinalMLP의 정확도를 테스트하고, 저자들이 제안한 두 개의 스트림 아키텍처를 활용하여 예측을 설명하는 능력을 평가합니다.\u003c/p\u003e\n\u003cp\u003e항상 그렇듯이, 코드는 저희의 GitHub에서 이용 가능합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003eFinalMLP: 두 개의 MLP 위에 (F)eature gating 및 (IN)teraction (A)ggregation (L)ayers가 추가된 모델\u003c/h1\u003e\n\u003cp\u003eFinalMLP [1]은 DualMLP [2] 위에 구축된 두 개의 스트림 Multi-Layer Perceptron (MLP) 모델로, 다음과 같은 2가지 새로운 개념을 도입하여 향상시킵니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGating 기반의 특징 선택은 두 스트림 간의 차이를 증가시켜, 각 스트림이 서로 다른 특징 세트로부터 서로 다른 패턴을 학습하도록 만듭니다. 예를 들어, 하나의 스트림은 사용자 특징을 처리하고, 다른 하나는 항목 특징에 중점을 둡니다.\u003c/li\u003e\n\u003cli\u003eMulti-Head Bilinear Fusion은 두 스트림에서 나온 출력을 결합하는 방법을 개선하여 특징 상호작용을 모델링합니다. 이는 덧셈 또는 연결과 같은 선형 연산에 의존하는 전통적인 방식을 사용할 때 발생하지 않을 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e작동 방법은 무엇인가요?\u003c/h1\u003e\n\u003cp\u003e이전에 언급한 대로, FinalMLP는 서로 다른 관점에서 특징 상호 작용을 학습하는 두 개의 간단하고 병렬 MLP 네트워크로 구성된 Two-Stream CTR 모델입니다. 다음과 같은 주요 구성 요소로 구성되어 있습니다:\u003c/p\u003e\n\u003cp\u003e특징 임베딩 레이어는 고차원 및 희소한 원시 특징을 밀집 숫자 표현으로 매핑하는 일반적인 방법입니다. 범주형, 숫자, 또는 다중 값이어도 각 특징은 임베딩 벡터로 변환되고 Feature Selection 모듈에 입력하기 전에 연결됩니다.\u003c/p\u003e\n\u003cp\u003e범주형 특징은 원-핫 특징 벡터로 변환되며, 학습 가능한 임베딩 행렬에 의해 곱해져 어휘 크기 n과 임베딩 차원 d를 가진 임베딩을 생성합니다[3].\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e숫자형 특성은 1) 숫자 값을 이산형 특성으로 버킷팅하고 이를 범주형 특성으로 다루거나 2) 정규화된 스칼라 값 xj가 주어지면, 임베딩은 xj를 field j의 모든 특성에 대한 공유 임베딩 벡터 vj와 곱한 것으로 주어질 수 있습니다 [3].\u003c/p\u003e\n\u003cp\u003e다중값 특성은 값 시퀀스를 하나의 길이가 k인 원-핫 인코딩 벡터로 변환한 다음 학습 가능한 임베딩 행렬과 곱하여 임베딩을 생성할 수 있습니다 [3].\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e특성 선택 레이어는 모델 예측에 중요한 영향을 미치도록 중요한 특성에 더 높은 영향을 미치도록 잡음이 많은 특성을 억제하기 위한 특성 중요도 가중치를 얻기 위해 사용됩니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e언급한 대로, FinalMLP는 게이팅 기반 특성 선택, 그리고 게이트 메커니즘을 갖춘 MLP를 사용합니다. 이 MLP는 임베딩을 입력으로 받아들이고, 입력과 동일한 차원의 가중치 벡터를 생성합니다. 특성 중요도 가중치는 시그모이드 함수를 가중치 벡터에 적용하여 [0, 2] 범위의 벡터를 생성하는 방식으로 얻어집니다. 가중된 특성은 특성 임베딩과 특성 중요도 가중치 사이의 요소별 곱셈을 통해 얻어집니다.\u003c/p\u003e\n\u003cp\u003e이 과정을 통해 두 스트림 간 균질한 학습이 감소되어 특성 상호작용의 보다 보완적인 학습이 가능해집니다. 유저나 아이템 차원에 집중하도록 각 스트림에 독립적으로 적용되어 특성 입력을 구분합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_3.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e양 스트림의 출력을 결합하여 최종 예측 확률을 얻기 위해 스트림 수준 융합 계층이 필요합니다. 일반적으로 두 출력을 결합하는 것은 합산 또는 연결 작업을 기반으로 합니다. 그러나 FinalMLP의 저자들은 선형 조합이 실패할 수 있는 특성 상호작용 정보를 얻기 위해 두 출력을 결합하는 데에 양선형 상호작용 집계 계층을 제안합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e저자들은 어텐션 레이어에서 영감을 받아 멀티 헤드 바이리니어 퓨전 레이어로 발전시킨 바이리니어 퓨전을 소개했습니다. 이는 계산 복잡성을 줄이고 모델의 확장성을 향상시키는 데 사용됩니다.\u003c/p\u003e\n\u003cp\u003e바이리니어 퓨전 방정식은 다음과 같이 구성됩니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_4.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e여기서 σ는 시그모이드 함수, b는 편향 항목이며, o1은 한 스트림의 출력입니다. w1은 o1에 적용되는 학습 가능한 가중치이고, o2는 다른 스트림의 출력이며, w2는 o2에 적용되는 학습 가능한 가중치입니다. 마지막으로, w3는 특성 상호작용 정보를 추출하는 바이리니어 항목의 학습 가능한 매트릭스입니다. w3가 제로 매트릭스로 설정되면 전통적인 연결 퓨전으로 약화됩니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eBilinear Fusion과 Multi-Head Bilinear Fusion의 차이점은, 두 스트림에서 전체 벡터를 사용하는 대신 출력 o1과 o2를 k 개의 하위 공간으로 나눈다는 것입니다. 각 하위 공간에서 이루어진 bilinear 퓨전은 sigmoid 함수에 공급하여 최종 확률을 생성합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_5.png\" alt=\"그림\"\u003e\u003c/p\u003e\n\u003ch1\u003eFinalMLP로 도서 추천 모델 만들기\u003c/h1\u003e\n\u003cp\u003e이 섹션에서는 FinalMLP를 Kaggle의 Public Domain 라이선스(CC0)로 공개된 데이터셋에 구현할 것입니다. 이 데이터셋에는 사용자, 책, 그리고 사용자가 책에 부여한 등급에 관한 정보가 포함되어 있습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e데이터셋은 다음과 같이 구성되어 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e사용자 ID — 사용자를 식별하는 ID\u003c/li\u003e\n\u003cli\u003e위치 — 사용자의 도시, 주, 국가가 콤마로 구분된 문자열\u003c/li\u003e\n\u003cli\u003e나이 — 사용자의 나이\u003c/li\u003e\n\u003cli\u003eISBN — 책 식별자\u003c/li\u003e\n\u003cli\u003e책 평점 — 특정 책에 대한 사용자의 평점\u003c/li\u003e\n\u003cli\u003e책 제목 — 책의 제목\u003c/li\u003e\n\u003cli\u003e책 저자 — 책의 저자\u003c/li\u003e\n\u003cli\u003e출판 연도 — 책이 출판된 연도\u003c/li\u003e\n\u003cli\u003e출판사 — 책을 출판한 편집자\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e우리는 각 사용자에 대한 관련성을 기반으로 책을 순위 지정할 것입니다. 그 후에는 우리의 순위 지정과 실제 순위(사용자가 지정한 평점에 따라 책을 정렬함)를 비교하기 위해 정규화 된 할인 누적 이익 (nDCG)를 사용할 것입니다.\u003c/p\u003e\n\u003cp\u003enDCG는 결과의 순위를 측정하여 추천 시스템의 품질을 평가하는 메트릭스입니다. 각 항목의 관련성과 결과 목록에서의 위치를 고려하여 상위 순위에 더 많은 중요성을 부여합니다. nDCG는 낮은 순위 항목의 이익을 할인하는 할인 누적 이익(DCG)과 완벽한 순위를 감안한 이상적인 DCG (iDCG)를 비교하여 계산됩니다. 이 정규화된 점수는 0에서 1 사이의 범위를 가지며, 1은 이상적인 순위를 나타냅니다. 따라서 nDCG는 어떻게 시스템이 사용자에게 관련 정보를 효과적으로 제공하는지 이해하는 데 도움이 됩니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e우리는 먼저 라이브러리를 가져와요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e%matplotlib inline\n%load_ext autoreload\n%autoreload \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\n\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e seaborn \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e sns\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.pyplot \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e random\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e ndcg_score\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.decomposition \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e PCA\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sentence_transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SentenceTransformer\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e logging\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e fuxictr.utils \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e load_config, set_logger, print_to_json\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e fuxictr.features \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e FeatureMap\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e fuxictr.pytorch.torch_utils \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e seed_everything\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e fuxictr.pytorch.dataloaders \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e H5DataLoader\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e fuxictr.preprocess \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e FeatureProcessor, build_dataset\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e src\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e gc\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e그런 다음, 세 개의 데이터 세트를로드하고 단일 데이터 세트로 병합합니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003ebooks_df = pd.read_csv(\u003cspan class=\"hljs-string\"\u003e'data/book/Books.csv'\u003c/span\u003e)\nusers_df = pd.read_csv(\u003cspan class=\"hljs-string\"\u003e'data/book/Users.csv'\u003c/span\u003e)\nratings_df = pd.read_csv(\u003cspan class=\"hljs-string\"\u003e'data/book/Ratings.csv'\u003c/span\u003e)\n\ndf = pd.merge(users_df, ratings_df, on=\u003cspan class=\"hljs-string\"\u003e'User-ID'\u003c/span\u003e, how=\u003cspan class=\"hljs-string\"\u003e'left'\u003c/span\u003e)\ndf = pd.merge(df, books_df, on=\u003cspan class=\"hljs-string\"\u003e'ISBN'\u003c/span\u003e, how=\u003cspan class=\"hljs-string\"\u003e'left'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e그 후, 데이터에 문제점을 식별하기 위해 탐색적 데이터 분석을 수행합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e사용자가 책에 평가를 내리지 않은 관측치를 제거합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edf = df[df[\u003cspan class=\"hljs-string\"\u003e'Book-Rating'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003enotnull\u003c/span\u003e()]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e누락된 값 확인 및 누락된 Book-Author 및 Publisher를 알 수 없는 카테고리로 대체합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(df.\u003cspan class=\"hljs-property\"\u003ecolumns\u003c/span\u003e[df.\u003cspan class=\"hljs-title function_\"\u003eisna\u003c/span\u003e().\u003cspan class=\"hljs-title function_\"\u003eany\u003c/span\u003e()].\u003cspan class=\"hljs-title function_\"\u003etolist\u003c/span\u003e())\n\ndf[\u003cspan class=\"hljs-string\"\u003e'Book-Author'\u003c/span\u003e] = df[\u003cspan class=\"hljs-string\"\u003e'Book-Author'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003efillna\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'unknown'\u003c/span\u003e)\ndf[\u003cspan class=\"hljs-string\"\u003e'Publisher'\u003c/span\u003e] = df[\u003cspan class=\"hljs-string\"\u003e'Publisher'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003efillna\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'unknown'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eRemove observations with missing information about the book.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edf = df[df[\u003cspan class=\"hljs-string\"\u003e'Book-Title'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003enotnull\u003c/span\u003e()]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eReplace non-integer Year-of-Publication with null values.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003edf[\u003cspan class=\"hljs-string\"\u003e'Year-Of-Publication'\u003c/span\u003e] = pd.to_numeric(df[\u003cspan class=\"hljs-string\"\u003e'Year-Of-Publication'\u003c/span\u003e], errors=\u003cspan class=\"hljs-string\"\u003e'coerce'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e이상을 식별하려면 나이, 출판 연도 및 도서 평점 분포를 확인해보세요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003eplt.rcParams[\u003cspan class=\"hljs-string\"\u003e\"figure.figsize\"\u003c/span\u003e] = (\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e)\nsns.histplot(data=df, x=\u003cspan class=\"hljs-string\"\u003e'Age'\u003c/span\u003e)\nplt.title(\u003cspan class=\"hljs-string\"\u003e'나이 분포'\u003c/span\u003e)\nplt.show()\n\nsns.histplot(data=df, x=\u003cspan class=\"hljs-string\"\u003e'Year-Of-Publication'\u003c/span\u003e)\nplt.title(\u003cspan class=\"hljs-string\"\u003e'출판 연도 분포'\u003c/span\u003e)\nplt.show()\n\nsns.histplot(data=df, x=\u003cspan class=\"hljs-string\"\u003e'Book-Rating'\u003c/span\u003e)\nplt.title(\u003cspan class=\"hljs-string\"\u003e'도서 평점 분포'\u003c/span\u003e)\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_6.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e마침내, 데이터 정리를 다음과 같이 진행합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e나이가 100 (오기로 보이는 값)인 경우, 나중에 처리할 결측값으로 대체합니다.\u003c/li\u003e\n\u003cli\u003e데이터셋이 Kaggle에 발행된 시점인 2021년을 상한으로 제한하고, 발행년도가 0인 경우에는 나중에 처리할 결측값으로 대체합니다.\u003c/li\u003e\n\u003cli\u003e사용자가 독서는 했지만 평점은 남기지 않은 경우 평점이 0인 관측치를 제거합니다.\u003c/li\u003e\n\u003cli\u003e위치 정보에서 3가지 새로운 특성(도시, 주, 국가)를 생성합니다. 너무 노이즈가 많은 도시 정보는 사용하지 않습니다.\u003c/li\u003e\n\u003cli\u003eFinalMLP를 위한 이진 레이블을 생성합니다. 평점이 7보다 높은 책을 사용자에게 관련성 있는 것으로 간주합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edf[\u003cspan class=\"hljs-string\"\u003e'Age'\u003c/span\u003e] = np.\u003cspan class=\"hljs-title function_\"\u003ewhere\u003c/span\u003e(df[\u003cspan class=\"hljs-string\"\u003e'Age'\u003c/span\u003e] \u003e \u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e, \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e, df[\u003cspan class=\"hljs-string\"\u003e'Age'\u003c/span\u003e])\n\ndf[\u003cspan class=\"hljs-string\"\u003e'Year-Of-Publication'\u003c/span\u003e] = np.\u003cspan class=\"hljs-title function_\"\u003ewhere\u003c/span\u003e(df[\u003cspan class=\"hljs-string\"\u003e'Year-Of-Publication'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eclip\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2021\u003c/span\u003e) \u0026#x3C;= \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e, df[\u003cspan class=\"hljs-string\"\u003e'Year-Of-Publication'\u003c/span\u003e])\ndf = df[df[\u003cspan class=\"hljs-string\"\u003e'Book-Rating'\u003c/span\u003e] \u003e \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\ndf[\u003cspan class=\"hljs-string\"\u003e'city'\u003c/span\u003e] = df[\u003cspan class=\"hljs-string\"\u003e'Location'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eapply\u003c/span\u003e(lambda \u003cspan class=\"hljs-attr\"\u003ex\u003c/span\u003e: x.\u003cspan class=\"hljs-title function_\"\u003esplit\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e','\u003c/span\u003e)[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e()) # too noisy, we will not use\ndf[\u003cspan class=\"hljs-string\"\u003e'state'\u003c/span\u003e] = df[\u003cspan class=\"hljs-string\"\u003e'Location'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eapply\u003c/span\u003e(lambda \u003cspan class=\"hljs-attr\"\u003ex\u003c/span\u003e: x.\u003cspan class=\"hljs-title function_\"\u003esplit\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e','\u003c/span\u003e)[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e())\ndf[\u003cspan class=\"hljs-string\"\u003e'country'\u003c/span\u003e] = df[\u003cspan class=\"hljs-string\"\u003e'Location'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eapply\u003c/span\u003e(lambda \u003cspan class=\"hljs-attr\"\u003ex\u003c/span\u003e: x.\u003cspan class=\"hljs-title function_\"\u003esplit\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e','\u003c/span\u003e)[\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e())\ndf[\u003cspan class=\"hljs-string\"\u003e'label'\u003c/span\u003e] = (df[\u003cspan class=\"hljs-string\"\u003e'Book-Rating'\u003c/span\u003e] \u003e \u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e)*\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e데이터셋을 정리하면, 랜덤으로 사용자의 70%를 훈련용, 10%를 검증용, 20%를 테스트용으로 나눠서 데이터를 분할합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 고유 사용자 목록 생성\nusers = df[\u003cspan class=\"hljs-string\"\u003e'User-ID'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eunique\u003c/span\u003e()\n\n# 목록 섞기\nrandom.\u003cspan class=\"hljs-title function_\"\u003eshuffle\u003c/span\u003e(users)\n# 학습용, 검증용 및 테스트용 사용자 목록 생성\ntrain_users = users[:\u003cspan class=\"hljs-title function_\"\u003eint\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e*\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(users))]\nval_users = users[\u003cspan class=\"hljs-title function_\"\u003eint\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e*\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(users)):\u003cspan class=\"hljs-title function_\"\u003eint\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e*\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(users))]\ntest_users = users[\u003cspan class=\"hljs-title function_\"\u003eint\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e*\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(users)):]\n# 학습, 검증 및 테스트 데이터프레임\ntrain_df = df[df[\u003cspan class=\"hljs-string\"\u003e'User-ID'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eisin\u003c/span\u003e(train_users)]\nval_df = df[df[\u003cspan class=\"hljs-string\"\u003e'User-ID'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eisin\u003c/span\u003e(val_users)]\ntest_df = df[df[\u003cspan class=\"hljs-string\"\u003e'User-ID'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eisin\u003c/span\u003e(test_users)]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e모델에 데이터를 제공하기 전에 데이터에 일부 전처리를 적용할 것입니다:\u003c/p\u003e\n\u003cp\u003e텍스트 특성인 Book-Title에 대한 다국어 인코더를 사용하여 임베딩을 생성하고, 80%의 분산이 설명되도록 PCA를 사용하여 차원을 축소합니다.\u003c/p\u003e\n\u003cp\u003e다국어 인코더를 사용하는 이유는 제목이 서로 다른 언어로 작성되기 때문입니다. 또한, 책이 다른 책보다 더 많은 사용자에 의해 읽혔을 경우 차원 축소에 편향이 주입되지 않도록 먼저 고유한 Book-Title을 추출합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 임베딩 생성\ntrain_embeddings = utils.\u003cspan class=\"hljs-title function_\"\u003ecreate_embeddings\u003c/span\u003e(train_df.\u003cspan class=\"hljs-title function_\"\u003ecopy\u003c/span\u003e(), \u003cspan class=\"hljs-string\"\u003e\"Book-Title\"\u003c/span\u003e)\nval_embeddings = utils.\u003cspan class=\"hljs-title function_\"\u003ecreate_embeddings\u003c/span\u003e(val_df.\u003cspan class=\"hljs-title function_\"\u003ecopy\u003c/span\u003e(), \u003cspan class=\"hljs-string\"\u003e\"Book-Title\"\u003c/span\u003e)\ntest_embeddings = utils.\u003cspan class=\"hljs-title function_\"\u003ecreate_embeddings\u003c/span\u003e(test_df.\u003cspan class=\"hljs-title function_\"\u003ecopy\u003c/span\u003e(), \u003cspan class=\"hljs-string\"\u003e\"Book-Title\"\u003c/span\u003e)\n\n# \u003cspan class=\"hljs-variable constant_\"\u003ePCA\u003c/span\u003e를 사용하여 차원 축소\ntrain_embeddings, pca = utils.\u003cspan class=\"hljs-title function_\"\u003ereduce_dimensionality\u003c/span\u003e(train_embeddings, \u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\nval_embeddings = pca.\u003cspan class=\"hljs-title function_\"\u003etransform\u003c/span\u003e(val_embeddings)\ntest_embeddings = pca.\u003cspan class=\"hljs-title function_\"\u003etransform\u003c/span\u003e(test_embeddings)\n# 데이터프레임에 임베딩 추가\ntrain_df = utils.\u003cspan class=\"hljs-title function_\"\u003eadd_embeddings_to_df\u003c/span\u003e(train_df, train_embeddings, \u003cspan class=\"hljs-string\"\u003e\"Book-Title\"\u003c/span\u003e)\nval_df = utils.\u003cspan class=\"hljs-title function_\"\u003eadd_embeddings_to_df\u003c/span\u003e(val_df, val_embeddings, \u003cspan class=\"hljs-string\"\u003e\"Book-Title\"\u003c/span\u003e)\ntest_df = utils.\u003cspan class=\"hljs-title function_\"\u003eadd_embeddings_to_df\u003c/span\u003e(test_df, test_embeddings, \u003cspan class=\"hljs-string\"\u003e\"Book-Title\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e숫자형 특성의 결측값은 중앙값으로 채우고 MinMaxScaler를 사용하여 데이터를 정규화합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 숫자형 열 설정\n\u003cspan class=\"hljs-variable constant_\"\u003eNUMERICAL_COLUMNS\u003c/span\u003e = [i \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e train_df.\u003cspan class=\"hljs-property\"\u003ecolumns\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"Book-Title_\"\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e i] + [\u003cspan class=\"hljs-string\"\u003e'Age'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'Year-Of-Publication'\u003c/span\u003e]\n\n# 전처리 파이프라인 정의 및 데이터 변환\npipe = utils.\u003cspan class=\"hljs-title function_\"\u003edefine_pipeline\u003c/span\u003e(\u003cspan class=\"hljs-variable constant_\"\u003eNUMERICAL_COLUMNS\u003c/span\u003e)\ntrain_df[\u003cspan class=\"hljs-variable constant_\"\u003eNUMERICAL_COLUMNS\u003c/span\u003e] = pipe.\u003cspan class=\"hljs-title function_\"\u003efit_transform\u003c/span\u003e(train_df[\u003cspan class=\"hljs-variable constant_\"\u003eNUMERICAL_COLUMNS\u003c/span\u003e])\nval_df[\u003cspan class=\"hljs-variable constant_\"\u003eNUMERICAL_COLUMNS\u003c/span\u003e] = pipe.\u003cspan class=\"hljs-title function_\"\u003etransform\u003c/span\u003e(val_df[\u003cspan class=\"hljs-variable constant_\"\u003eNUMERICAL_COLUMNS\u003c/span\u003e])\ntest_df[\u003cspan class=\"hljs-variable constant_\"\u003eNUMERICAL_COLUMNS\u003c/span\u003e] = pipe.\u003cspan class=\"hljs-title function_\"\u003etransform\u003c/span\u003e(test_df[\u003cspan class=\"hljs-variable constant_\"\u003eNUMERICAL_COLUMNS\u003c/span\u003e])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFinalMLP에 제공할 준비가 된 모든 데이터로 dataset_config.yaml 및 model_config.yaml 두 개의 yaml 구성 파일을 만들어야 합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003edataset_config.yaml 파일은 모델에서 사용할 feature들을 정의하는 역할을 합니다. 또한 이들의 데이터 유형을 정의하고(Embedding 레이어에서 다르게 처리됨) 훈련, 검증, 테스트 세트의 경로를 정의합니다. 아래는 구성 파일의 주요 부분을 확인할 수 있습니다:\u003c/p\u003e\n\u003cp\u003eFinalMLP_book:\ndata_root: ./data/book/\nfeature_cols:\n-   active: true\ndtype: float\nname: [Age, Book-Title_0, Book-Title_1, Book-Title_2, Book-Title_3, Book-Title_4, Book-Title_5, Book-Title_6, Book-Title_7,\nBook-Title_8, ...]\ntype: numeric\n-   active: true\ndtype: str\nname: [Book-Author, Year-Of-Publication, Publisher, state, country]\ntype: categorical\nfill_na: unknown\nlabel_col: {dtype: float, name: label}\nmin_categr_count: 1\ntest_data: ./data/book/test.csv\ntrain_data: ./data/book/train.csv\nvalid_data: ./data/book/valid.csv\u003c/p\u003e\n\u003cp\u003emodel_config.yaml 파일은 모델의 하이퍼파라미터를 설정하는 역할을 합니다. 사용자 feature를 처리할 스트림과 아이템 feature를 처리할 스트림을 정의해야 합니다. 파일은 다음과 같이 정의되어야 합니다:\u003c/p\u003e\n\u003cp\u003eFinalMLP_book:\ndataset_id: FinalMLP_book\nfs1_context: [Age, state, country]\nfs2_context: [Book-Author, Year-Of-Publication, Publisher, Book-Title_0, Book-Title_1, Book-Title_2, Book-Title_3,\nBook-Title_4, Book-Title_5, ...]\nmodel_root: ./checkpoints/FinalMLP_book/\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e파이썬으로 돌아가서 최근에 생성된 설정 파일을 로드합니다. 그런 다음, 특성 매핑을 만듭니다 (즉, 각 범주형 특성에 몇 가지 카테고리가 있는지, 다른 특성에서 누락된 값이 있을 경우 어떻게 대체해야 하는지 등). CSV 파일을 h5 파일로 변환합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# 모델 및 데이터셋 구성 가져오기\u003c/span\u003e\nexperiment_id = \u003cspan class=\"hljs-string\"\u003e'FinalMLP_book'\u003c/span\u003e\nparams = load_config(\u003cspan class=\"hljs-string\"\u003ef\"config/\u003cspan class=\"hljs-subst\"\u003e{experiment_id}\u003c/span\u003e/\"\u003c/span\u003e, experiment_id)\nparams[\u003cspan class=\"hljs-string\"\u003e'gpu'\u003c/span\u003e] = -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e \u003cspan class=\"hljs-comment\"\u003e# CPU\u003c/span\u003e\nset_logger(params)\nlogging.info(\u003cspan class=\"hljs-string\"\u003e\"Params: \"\u003c/span\u003e + print_to_json(params))\nseed_everything(seed=params[\u003cspan class=\"hljs-string\"\u003e'seed'\u003c/span\u003e])\n\n\u003cspan class=\"hljs-comment\"\u003e# 특성 매핑 생성 및 데이터를 h5 형식으로 변환\u003c/span\u003e\ndata_dir = os.path.join(params[\u003cspan class=\"hljs-string\"\u003e'data_root'\u003c/span\u003e], params[\u003cspan class=\"hljs-string\"\u003e'dataset_id'\u003c/span\u003e])\nfeature_map_json = os.path.join(data_dir, \u003cspan class=\"hljs-string\"\u003e\"feature_map.json\"\u003c/span\u003e)\n\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e params[\u003cspan class=\"hljs-string\"\u003e\"data_format\"\u003c/span\u003e] == \u003cspan class=\"hljs-string\"\u003e\"csv\"\u003c/span\u003e:\n    \u003cspan class=\"hljs-comment\"\u003e# 특성 매핑 빌드 및 h5 데이터 변환\u003c/span\u003e\n    feature_encoder = FeatureProcessor(**params)\n    params[\u003cspan class=\"hljs-string\"\u003e\"train_data\"\u003c/span\u003e], params[\u003cspan class=\"hljs-string\"\u003e\"valid_data\"\u003c/span\u003e], params[\u003cspan class=\"hljs-string\"\u003e\"test_data\"\u003c/span\u003e] = \\\\\n        build_dataset(feature_encoder, **params)\nfeature_map = FeatureMap(params[\u003cspan class=\"hljs-string\"\u003e'dataset_id'\u003c/span\u003e], data_dir)\nfeature_map.load(feature_map_json, params)\nlogging.info(\u003cspan class=\"hljs-string\"\u003e\"Feature specs: \"\u003c/span\u003e + print_to_json(feature_map.features))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이후에 모델의 훈련 프로세스를 시작할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003emodel_class = \u003cspan class=\"hljs-built_in\"\u003egetattr\u003c/span\u003e(src, params[\u003cspan class=\"hljs-string\"\u003e'model'\u003c/span\u003e])\nmodel = model_class(feature_map, **params)\nmodel.count_parameters() \u003cspan class=\"hljs-comment\"\u003e# 모델에서 사용하는 매개변수 수를 출력\u003c/span\u003e\n\ntrain_gen, valid_gen = H5DataLoader(feature_map, stage=\u003cspan class=\"hljs-string\"\u003e'train'\u003c/span\u003e, **params).make_iterator()\nmodel.fit(train_gen, validation_data=valid_gen, **params)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e마침내 보이지 않는 데이터를 예측할 수 있게 되었습니다. 관측치들의 점수를 얻기 위해 배치 크기를 1로 변경하기만 하면 됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 관측치들의 점수를 얻기\nparams[\u003cspan class=\"hljs-string\"\u003e'batch_size'\u003c/span\u003e] = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\ntest_gen = \u003cspan class=\"hljs-title function_\"\u003eH5DataLoader\u003c/span\u003e(feature_map, stage=\u003cspan class=\"hljs-string\"\u003e'test'\u003c/span\u003e, **params).\u003cspan class=\"hljs-title function_\"\u003emake_iterator\u003c/span\u003e()\ntest_df[\u003cspan class=\"hljs-string\"\u003e'score'\u003c/span\u003e] = model.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(test_gen)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e우리는 한 명의 고객을 선택했는데, 이 고객은 여러 권의 책을 평가하고 각 책에 대해 다른 평점을 매겨서 맞춤 순위를 설정할 수 있도록 했습니다. nDCG 점수는 0.986362로 나타났는데, 2권의 책을 1위에서 잘못 배치했기 때문입니다.\u003c/p\u003e\n\u003cp\u003e우리는 FinalMLP를 평가하기 위해 Recall을 사용했습니다. Recall은 시스템이 전체 중에서 모든 관련 항목을 식별하는 능력을 측정하는 지표로, 전체 관련 항목 중 검색된 관련 항목의 비율로 나타냅니다. Recall@K와 같이 Recall@3을 지정하면 시스템이 상위 K개의 추천 내에서 관련 항목을 식별하는 능력에 초점을 맞춥니다. 이것은 사용자들이 주로 상위 추천에 주목하는 추천 시스템을 평가하는 데 중요합니다. K(예: 3)의 선택은 일반적인 사용자 행동과 애플리케이션 맥락에 따라 달라집니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 고객의 Recall@3을 살펴보면, 상위 3위 안에 가장 관련성 있는 책이 세 권 모두 들어있기 때문에 100%입니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003etrue_relevance = np.\u003cspan class=\"hljs-title function_\"\u003easarray\u003c/span\u003e([test_df[test_df[\u003cspan class=\"hljs-string\"\u003e'User-ID'\u003c/span\u003e] == \u003cspan class=\"hljs-number\"\u003e1113\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e'Book-Rating'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003etolist\u003c/span\u003e()])\ny_relevance = np.\u003cspan class=\"hljs-title function_\"\u003easarray\u003c/span\u003e([test_df[test_df[\u003cspan class=\"hljs-string\"\u003e'User-ID'\u003c/span\u003e] == \u003cspan class=\"hljs-number\"\u003e1113\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e'score'\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003etolist\u003c/span\u003e()])\n\n\u003cspan class=\"hljs-title function_\"\u003endcg_score\u003c/span\u003e(true_relevance, y_relevance)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e남은 테스트 세트에 대한 nDCG 점수를 계산하고, Figure 7에서 FinalMLP 성능을 CatBoost Ranker와 비교했습니다. 두 모델 모두 잘 수행했지만, 이 테스트 세트에서 FinalMLP가 조금 더 우수한 성능을 보였습니다. 사용자 당 평균 nDCG가 0.963298인 반면 CatBoost Ranker는 0.959977에 그쳤습니다.\u003c/p\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_7.png\"\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e해석 가능성 측면에서 이 모델은 특성 선택을 수행하여 가중치 벡터를 추출할 수 있게 합니다. 그러나 각 특성의 중요성을 해석하고 이해하는 것은 간단하지 않습니다. 임베딩 레이어 이후에는 930차원 벡터가 생성되어 원래 특성으로 재매핑하기가 어려워집니다. 그럼에도 불구하고, 이전에 언급된 선형 항으로 주어진 선형 처리 후 각 스트림의 출력의 절대값을 추출함으로써 각 스트림의 중요성을 이해해 볼 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이를 위해 InteractionAggregation 모듈을 변경하고 각 단계 후에 선형 변환된 값 추출을 위해 다음 코드 라인을 추가해야 합니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e...     \n    self.\u003cspan class=\"hljs-property\"\u003ex_importance\u003c/span\u003e = []\n    self.\u003cspan class=\"hljs-property\"\u003ey_importance\u003c/span\u003e = []\n  def \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(self, x, y):\n          self.\u003cspan class=\"hljs-property\"\u003ex_importance\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(torch.\u003cspan class=\"hljs-title function_\"\u003esum\u003c/span\u003e(torch.\u003cspan class=\"hljs-title function_\"\u003eabs\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003ew_x\u003c/span\u003e(x))))\n          self.\u003cspan class=\"hljs-property\"\u003ey_importance\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(torch.\u003cspan class=\"hljs-title function_\"\u003esum\u003c/span\u003e(torch.\u003cspan class=\"hljs-title function_\"\u003eabs\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003ew_y\u003c/span\u003e(y))))\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e한 번 훈련을 받으면, 각 스트림의 선형 변환 결과에서 절대 값을 예측하고 플롯할 수 있습니다. 그림 8에 보여진 것처럼, 상품 스트림이 사용자 스트림보다 중요성이 높습니다. 이는 상품에 대한 기능이 훨씬 많기 때문이지만 사용자 특성이 상당히 일반적이기 때문에 발생합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems_9.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e추천 시스템은 사용자 경험을 향상시켜 맞춤형 추천을 제공하며, 성장과 혁신을 이끄는 데이터 기반 의사 결정을 기관에 제공하여 사용자 경험을 향상시킵니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 기사에서는 추천 시스템용으로 개발된 가장 최근 모델 중 하나를 소개했습니다. FinalMLP는 두 개의 독립 네트워크를 가진 딥 러닝 모델입니다. 각 네트워크는 사용자와 항목 이 두 가지 다른 관점 중 하나에 중점을 둡니다. 각 네트워크로부터 학습된 다른 패턴은 그 다음 각 네트워크의 학습 내용을 결합하는 책합층에 공급됩니다. 사용자-항목 쌍 상호 작용의 단일 뷰를 생성하여 최종 점수를 생성합니다. 이 모델은 CatBoost Ranker를 이겼으며 우리의 사용 사례에서 잘 수행했습니다.\u003c/p\u003e\n\u003cp\u003e알고리즘 선택은 해결하려는 문제와 데이터셋에 따라 다를 수 있음을 유의해 주세요. 항상 여러 방법을 상호 비교하는 것이 좋은 실천 방법입니다. 또한 xDeepFM, AutoInt, DHEN 또는 DLRM을 테스트하는 것도 고려할 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e내 소개\u003c/h1\u003e\n\u003cp\u003e인공지능 분야의 시리얼 기업가 및 리더입니다. 비즈니스를 위한 인공지능 제품을 개발하고 인공지능에 초점을 맞춘 스타트업에 투자합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e창립자 @ ZAAI | LinkedIn | X/Twitter\u003c/p\u003e\n\u003ch1\u003e참고 문헌\u003c/h1\u003e\n\u003cp\u003e[1] Kelong Mao, Jieming Zhu, Liangcai Su, Guohao Cai, Yuru Li, Zhenhua Dong. FinalMLP: CTR 예측을 위한 향상된 이차원 MLP 모델. arXiv:2304.00902, 2023.\u003c/p\u003e\n\u003cp\u003e[2] Jiajun Fei, Ziyu Zhu, Wenlei Liu, Zhidong Deng, Mingyang Li, Huanjun Deng, Shuo Zhang. DuMLP-Pin: 집합 특성 추출을 위한 이중-MLP-내적 불변 네트워크. arXiv:2203.04007, 2022.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e[3] Jieming Zhu, Jinyang Liu, Shuai Yang, Qi Zhang, Xiuqiang He. BARS-CTR: Open Benchmarking for Click-Through Rate Prediction. arXiv:2009.05794, 2020.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-07-12-FinalMLPASimpleyetPowerfulTwo-StreamMLPModelforRecommendationSystems"},"buildId":"N1mNhRlQaHCliEGDvPEpG","assetPrefix":"/TIL","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>