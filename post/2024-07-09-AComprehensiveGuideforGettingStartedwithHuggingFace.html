<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Hugging Face 시작을 위한 종합 가이드 | TIL</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://13akstjq.github.io/TIL//post/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Hugging Face 시작을 위한 종합 가이드 | TIL" data-gatsby-head="true"/><meta property="og:title" content="Hugging Face 시작을 위한 종합 가이드 | TIL" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://TIL.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://13akstjq.github.io/TIL//post/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace" data-gatsby-head="true"/><meta name="twitter:title" content="Hugging Face 시작을 위한 종합 가이드 | TIL" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | TIL" data-gatsby-head="true"/><meta name="article:published_time" content="2024-07-09 21:02" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/TIL/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/TIL/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/TIL/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/TIL/favicons/favicon-96x96.png"/><link rel="icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/TIL/favicons/browserconfig.xml"/><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-5ecfd58aae5a7e3d.js" defer=""></script><script src="/_next/static/xx51Gh_JNHDTBdDwrgykD/_buildManifest.js" defer=""></script><script src="/_next/static/xx51Gh_JNHDTBdDwrgykD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">TIL</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Hugging Face 시작을 위한 종합 가이드</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Hugging Face 시작을 위한 종합 가이드" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">TIL</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jul 9, 2024</span><span class="posts_reading_time__f7YPP">11<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png" alt="Hugging Face"></p>
<p>대규모 언어 모델들의 급격한 발전으로 다양한 작업을 해결하기 위해 적용되는 경우가 많아졌으며, Hugging Face에 대한 지식은 반드시 알아둬야 할 필수요소가 되었습니다.</p>
<p>왜 Hugging Face를 사용해야 할까요? Hugging Face는 다양한 오픈 소스 모델에 대한 접근성을 제공하는 데 중요한 역할을 합니다. 이 플랫폼 덕분에 데이터 과학자, 개발자 및 연구자들은 최신 모델을 쉽게 탐색하고 활용할 수 있습니다.</p>
<p>본문에서는 Hugging Face의 잠재력, 이를 활용하는 방법 및 가능한 사용 사례에 대해 설명하겠습니다. 시작해봅시다!</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>목차:</p>
<ul>
<li>Hugging Face란 무엇인가요?</li>
<li>Hugging Face의 기본 구성 요소</li>
<li>Open LLM Leaderboard란 무엇인가요?</li>
<li>Hugging Face에 접근하는 방법</li>
<li>Hugging Face로 놀기 시작하기</li>
<li>Transformers 라이브러리 활용하기</li>
</ul>
<h2>Hugging Face란 무엇인가요?</h2>
<img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_1.png">
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>허깅페이스는 다양한 작업을 위한 사전 훈련 모델에 민주적인 접근을 제공하는 허브입니다. 번역, 요약, 질의응답, 객체 감지, 이미지 분할 등 다양한 작업에 사용됩니다. 사용자들이 오픈 소스 모델에 기여할 것을 장려합니다.</p>
<p>이 중심화된 저장소의 매력은 허깅페이스 트랜스포머(Hugging Face Transformers)로, 모델을 쉽게 다운로드하고 불러오며 미세 조정할 수 있는 매우 인기 있는 파이썬 라이브러리입니다.</p>
<p>모델뿐만 아니라 데이터셋과 기계 학습 데모인 허깅페이스 스페이스(Hugging Face Spaces)도 호스팅합니다.</p>
<h2>허깅페이스의 기본 구성요소</h2>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>허깅페이스에는 모델, 데이터셋 및 스페이스 세 가지 주요 구성 요소가 있어요.</p>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_2.png" alt="image"></p>
<p>모델 페이지에 들어가보면 수많은 오픈소스 모델로 인해 압도될 수 있지만 걱정 마세요. 먼저 해결하고자 하는 작업을 식별한 후 해당 작업으로 필터링하는 것이 권장됩니다. 작업을 선택한 후에는 인기도와 다운로드 횟수 같은 다양한 기준에 따라 모델을 정렬할 수 있어요.</p>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_3.png" alt="image"></p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>모델과 마찬가지로, 다양한 종류의 데이터셋이 있어서 다양한 작업에 활용할 수 있습니다. 이전과 마찬가지로 최종 목표에 따라 작업별로 필터링하고 결과를 정렬하는 것이 중요합니다.</p>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_4.png" alt="이미지"></p>
<p>마지막으로, Hugging Face 스페이스라는 기계 학습 데모를 빠르게 살펴볼 수 있습니다. Hugging Face 스페이스에서는 Streamlit, Gradio, 그리고 FastAPI를 기반으로 한 대화형 애플리케이션을 통해 모델을 실행할 수 있습니다. 다시 말해, Hugging Face 스페이스를 통해 직관적인 인터페이스를 통해 간접적으로 모델과 상호 작용할 수 있습니다.</p>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_5.png" alt="이미지"></p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>위에는 입력 텍스트로부터 이미지를 생성하는 전문 공간 예시가 있습니다. 이 데모인 PixArt-Sigma는 4K 해상도에서 이미지를 생성할 수 있는 PixArt-Sigma 1024px 확산 변환 모델을 활용합니다.</p>
<h2>오픈 LLM 리더보드란?</h2>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_6.png" alt="image"></p>
<p>Hugging Face의 또 다른 중요한 기여는 오픈 LLM 리더보드입니다. 이는 오픈 소스 LLMs와 챗봇을 추적하고 평가할 수 있는 머신 러닝 데모 또는 Hugging Face 공간입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>모델 페이지와 마찬가지로 사용 가능한 모델이 너무 많습니다. 과업을 해결하기 위해 필요한 모델 유형을 식별한 후 이를 기반으로 결과를 필터링하는 것이 좋습니다.</p>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_7.png" alt="이미지"></p>
<p>예를 들어, 처음부터 훈련된 모델만 추적하길 원한다고 가정해 봅시다. 이 경우 "사전 훈련된 모델"을 선택하여 필터링해야 합니다.</p>
<p>필터를 수정하면 리더보드 상단의 모델 대부분이 Meta 및 Databricks와 같은 대규모 기술 회사에서 나온 것을 알 수 있을 것입니다. 이것은 모든 회사가 이러한 대규모 모델을 훈련시키기에 컴퓨팅 능력을 갖추지 못한 이유입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>Hugging Face에 접속하는 방법</h2>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_8.png" alt="hugging-face-image"></p>
<p>노트북에서 Hugging Face의 모델과 데이터셋에 액세스하려면 먼저 Hugging Face API 키가 필요합니다. 계정이 아직 없다면 만들어야 합니다. 계정이 생성되면 Settings<code>Access Tokens</code>을 클릭하고 "New token" 버튼을 누릅니다.</p>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_9.png" alt="hugging-face-image"></p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>토큰의 이름인 HF_TOKEN과 해당 토큰의 유형을 결정하세요. 이 유형은 read 또는 write 중 하나로 선택할 수 있습니다. 모델을 다운로드하거나 모델에서 추론을 실행하는 경우 read를 선택하면 가장 일반적인 선택지입니다. 모델을 훈련시키려면 write를 선택하는 것이 좋습니다.</p>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_10.png" alt="이미지"></p>
<p>그걸로 끝입니다! 우리는 Hugging Face에서 첫 번째 액세스 토큰을 생성했습니다. 액세스 토큰에 대해 더 깊이 알아보고 싶다면, Hugging Face 문서를 살펴보세요.</p>
<h2>Hugging Face와 놀기 시작</h2>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<img src="https://miro.medium.com/v2/resize:fit:1400/1*2AywAoMAEN5v8VG8wIFU7Q.gif">
<p>Hugging Face의 개념이 명확해지면, 이제는 자습서의 실제 부분으로 넘어가는 시간입니다. 영어에서 이탈리아어로 텍스트를 번역하는 모델을 찾고 싶다고 가정해 봅시다. 다음은 다음과 같은 단계입니다:</p>
<ul>
<li>모델 페이지로 이동</li>
<li>번역을 작업으로 선택</li>
<li>이탈리아어를 언어로 선택</li>
</ul>
<p>우리는 트렌딩 순으로 정렬된 첫 번째 결과 중에서 나타나는 모델 NLLB-200을 선택하기로 결정했습니다. 모델의 웹 페이지에는 프로젝트 목적에 따라 유용할 수 있는 다양한 버튼도 포함되어 있습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_11.png" alt="이미지"></p>
<p>이 경우에는 모델을 로드하는 코드 라인을 얻기 위해 "Transformers에서 사용" 버튼을 클릭하면 됩니다.</p>
<h2>Transformers 라이브러리 활용</h2>
<p>실험을 진행할 경우, Google Colab을 사용하는 것을 추천드립니다. Google Colab은 코드를 웹 브라우저에서 실행하며 CPU 또는 GPU 리소스에 액세스할 수 있는 클라우드 기반 플랫폼입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>또한, 이 환경은 이전에 얻은 허깅페이스의 액세스 키와 같은 환경 변수를 간단히 가져오는 것을 가능하게 합니다.</p>
<p>구글 코랩을 열고, Secrets로 이동하여 “새로운 비밀”을 클릭하고 허깅페이스 액세스 토큰의 이름과 값을 복사하면 됩니다. 또한, 노트북 액세스를 토글하는 것을 잊지 마세요!</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*Td3lFpVFua1VnP8vsogu3g.gif" alt="이미지"></p>
<p>설치해야 할 라이브러리가 있습니다:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">pip install transformers
</code></pre>
<p>이 Python 라이브러리를 시작하려면 파이프라인()을 사용하여 추론, 모델 로드, 및 학습을 하는 것이 좋습니다. 이 경우에는 모델 NLLB-200을 로드하려고 합니다.</p>
<p>간단히 "Transformers에서 사용하기" 버튼에서 찾은 코드를 복사하면 됩니다. 아래는 약간의 수정이 필요한 코드입니다:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> torch

translator = <span class="hljs-title function_">pipeline</span>(task=<span class="hljs-string">"translation"</span>,
                      model=<span class="hljs-string">"facebook/nllb-200-distilled-600M"</span>,
                      torch_dtype=torch.<span class="hljs-property">bfloat16</span>
                      )
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>pipeline()은 번역 작업용 모델 NLLB-200을 다운로드하고 캐시합니다. 이러한 매개변수들 외에도, 모델을 압축하는 데 성능이 감소하지 않는 torch의 유형을 지정합니다.</p>
<p>이제 이를 사용하여 텍스트를 번역할 수 있습니다:</p>
<pre><code class="hljs language-js">text = <span class="hljs-string">""</span><span class="hljs-string">"
ChatGPT 개발자 OpenAI는 단 한 번의 짧은 오디오 샘플만 있으면 인간의 목소리를 재현할 수 있는 새로운 도구를 소개했다.\
이 도구는 고도의 정확도로 음성을 복제하려는 기술 회사들이 개발한 여러 도구 중 하나이다.\
시스템의 이름은 Voice Engine입니다. OpenAI는 3월 29일 Voice Engine에 관한 세부 정보를 공개했다.\
"</span><span class="hljs-string">""</span>

text_translated = <span class="hljs-title function_">translator</span>(text,
                             src_lang=<span class="hljs-string">"eng_Latn"</span>,
                             tgt_lang=<span class="hljs-string">"ita_Latn"</span>)

<span class="hljs-title function_">print</span>(text_translated[<span class="hljs-number">0</span>][<span class="hljs-string">'translation_text'</span>])
</code></pre>
<p>이것이 출력 내용입니다:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-title class_">OpenAI</span>의 <span class="hljs-title class_">ChatGPT</span> 개발자가 새로운 도구를 소개했어요!
그 도구는 짧은 음성 샘플을 사용하여 인간의 목소리를 재현할 수 있다고 해요.
이 도구는 음성을 높은 정확도로 복제하기 위해 기술 기업들이 개발한 여러 도구 중 하나에요.
이 시스템의 이름은 <span class="hljs-title class_">Voice</span> <span class="hljs-title class_">Engine</span>이에요. <span class="hljs-title class_">OpenAI</span>는 <span class="hljs-number">3</span>월 <span class="hljs-number">29</span>일 <span class="hljs-title class_">Voice</span> <span class="hljs-title class_">Engine</span>에 대한 세부 정보를 공개했어요.
</code></pre>
<p>좋아요! 우리가 과제를 해결했네요. 쉬웠죠?</p>
<h2>최종 생각</h2>
<p>이것은 Hugging Face를 시작하는 데 도움이 되는 입문 가이드였어요. Transformers는 상위 모델, 특히 NLP 모델에 쉽게 액세스할 수 있게 해주는 파이썬 라이브러리에요.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 플랫폼과 파이썬 라이브러리에 대해 더 깊이 파고들고 싶다면, 아래에서 제안하는 리소스를 살펴보세요.</p>
<p>이 글이 유용하게 느껴졌으면 좋겠어요. 즐거운 하루 보내세요!</p>
<p>유용한 리소스:</p>
<ul>
<li>Hugging Face 문서</li>
<li>Hugging Face 무료 강좌</li>
<li>Hugging Face와 함께하는 오픈소스 모델 강좌</li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Hugging Face 시작을 위한 종합 가이드","description":"","date":"2024-07-09 21:02","slug":"2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace","content":"\n![Hugging Face](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png)\n\n대규모 언어 모델들의 급격한 발전으로 다양한 작업을 해결하기 위해 적용되는 경우가 많아졌으며, Hugging Face에 대한 지식은 반드시 알아둬야 할 필수요소가 되었습니다.\n\n왜 Hugging Face를 사용해야 할까요? Hugging Face는 다양한 오픈 소스 모델에 대한 접근성을 제공하는 데 중요한 역할을 합니다. 이 플랫폼 덕분에 데이터 과학자, 개발자 및 연구자들은 최신 모델을 쉽게 탐색하고 활용할 수 있습니다.\n\n본문에서는 Hugging Face의 잠재력, 이를 활용하는 방법 및 가능한 사용 사례에 대해 설명하겠습니다. 시작해봅시다!\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n목차:\n\n- Hugging Face란 무엇인가요?\n- Hugging Face의 기본 구성 요소\n- Open LLM Leaderboard란 무엇인가요?\n- Hugging Face에 접근하는 방법\n- Hugging Face로 놀기 시작하기\n- Transformers 라이브러리 활용하기\n\n## Hugging Face란 무엇인가요?\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_1.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n허깅페이스는 다양한 작업을 위한 사전 훈련 모델에 민주적인 접근을 제공하는 허브입니다. 번역, 요약, 질의응답, 객체 감지, 이미지 분할 등 다양한 작업에 사용됩니다. 사용자들이 오픈 소스 모델에 기여할 것을 장려합니다.\n\n이 중심화된 저장소의 매력은 허깅페이스 트랜스포머(Hugging Face Transformers)로, 모델을 쉽게 다운로드하고 불러오며 미세 조정할 수 있는 매우 인기 있는 파이썬 라이브러리입니다.\n\n모델뿐만 아니라 데이터셋과 기계 학습 데모인 허깅페이스 스페이스(Hugging Face Spaces)도 호스팅합니다.\n\n## 허깅페이스의 기본 구성요소\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n허깅페이스에는 모델, 데이터셋 및 스페이스 세 가지 주요 구성 요소가 있어요.\n\n![image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_2.png)\n\n모델 페이지에 들어가보면 수많은 오픈소스 모델로 인해 압도될 수 있지만 걱정 마세요. 먼저 해결하고자 하는 작업을 식별한 후 해당 작업으로 필터링하는 것이 권장됩니다. 작업을 선택한 후에는 인기도와 다운로드 횟수 같은 다양한 기준에 따라 모델을 정렬할 수 있어요.\n\n![image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_3.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델과 마찬가지로, 다양한 종류의 데이터셋이 있어서 다양한 작업에 활용할 수 있습니다. 이전과 마찬가지로 최종 목표에 따라 작업별로 필터링하고 결과를 정렬하는 것이 중요합니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_4.png)\n\n마지막으로, Hugging Face 스페이스라는 기계 학습 데모를 빠르게 살펴볼 수 있습니다. Hugging Face 스페이스에서는 Streamlit, Gradio, 그리고 FastAPI를 기반으로 한 대화형 애플리케이션을 통해 모델을 실행할 수 있습니다. 다시 말해, Hugging Face 스페이스를 통해 직관적인 인터페이스를 통해 간접적으로 모델과 상호 작용할 수 있습니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_5.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위에는 입력 텍스트로부터 이미지를 생성하는 전문 공간 예시가 있습니다. 이 데모인 PixArt-Sigma는 4K 해상도에서 이미지를 생성할 수 있는 PixArt-Sigma 1024px 확산 변환 모델을 활용합니다.\n\n## 오픈 LLM 리더보드란?\n\n![image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_6.png)\n\nHugging Face의 또 다른 중요한 기여는 오픈 LLM 리더보드입니다. 이는 오픈 소스 LLMs와 챗봇을 추적하고 평가할 수 있는 머신 러닝 데모 또는 Hugging Face 공간입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델 페이지와 마찬가지로 사용 가능한 모델이 너무 많습니다. 과업을 해결하기 위해 필요한 모델 유형을 식별한 후 이를 기반으로 결과를 필터링하는 것이 좋습니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_7.png)\n\n예를 들어, 처음부터 훈련된 모델만 추적하길 원한다고 가정해 봅시다. 이 경우 \"사전 훈련된 모델\"을 선택하여 필터링해야 합니다.\n\n필터를 수정하면 리더보드 상단의 모델 대부분이 Meta 및 Databricks와 같은 대규모 기술 회사에서 나온 것을 알 수 있을 것입니다. 이것은 모든 회사가 이러한 대규모 모델을 훈련시키기에 컴퓨팅 능력을 갖추지 못한 이유입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Hugging Face에 접속하는 방법\n\n![hugging-face-image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_8.png)\n\n노트북에서 Hugging Face의 모델과 데이터셋에 액세스하려면 먼저 Hugging Face API 키가 필요합니다. 계정이 아직 없다면 만들어야 합니다. 계정이 생성되면 Settings`Access Tokens`을 클릭하고 \"New token\" 버튼을 누릅니다.\n\n![hugging-face-image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_9.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n토큰의 이름인 HF_TOKEN과 해당 토큰의 유형을 결정하세요. 이 유형은 read 또는 write 중 하나로 선택할 수 있습니다. 모델을 다운로드하거나 모델에서 추론을 실행하는 경우 read를 선택하면 가장 일반적인 선택지입니다. 모델을 훈련시키려면 write를 선택하는 것이 좋습니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_10.png)\n\n그걸로 끝입니다! 우리는 Hugging Face에서 첫 번째 액세스 토큰을 생성했습니다. 액세스 토큰에 대해 더 깊이 알아보고 싶다면, Hugging Face 문서를 살펴보세요.\n\n## Hugging Face와 놀기 시작\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*2AywAoMAEN5v8VG8wIFU7Q.gif\" /\u003e\n\nHugging Face의 개념이 명확해지면, 이제는 자습서의 실제 부분으로 넘어가는 시간입니다. 영어에서 이탈리아어로 텍스트를 번역하는 모델을 찾고 싶다고 가정해 봅시다. 다음은 다음과 같은 단계입니다:\n\n- 모델 페이지로 이동\n- 번역을 작업으로 선택\n- 이탈리아어를 언어로 선택\n\n우리는 트렌딩 순으로 정렬된 첫 번째 결과 중에서 나타나는 모델 NLLB-200을 선택하기로 결정했습니다. 모델의 웹 페이지에는 프로젝트 목적에 따라 유용할 수 있는 다양한 버튼도 포함되어 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_11.png)\n\n이 경우에는 모델을 로드하는 코드 라인을 얻기 위해 \"Transformers에서 사용\" 버튼을 클릭하면 됩니다.\n\n## Transformers 라이브러리 활용\n\n실험을 진행할 경우, Google Colab을 사용하는 것을 추천드립니다. Google Colab은 코드를 웹 브라우저에서 실행하며 CPU 또는 GPU 리소스에 액세스할 수 있는 클라우드 기반 플랫폼입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한, 이 환경은 이전에 얻은 허깅페이스의 액세스 키와 같은 환경 변수를 간단히 가져오는 것을 가능하게 합니다.\n\n구글 코랩을 열고, Secrets로 이동하여 “새로운 비밀”을 클릭하고 허깅페이스 액세스 토큰의 이름과 값을 복사하면 됩니다. 또한, 노트북 액세스를 토글하는 것을 잊지 마세요!\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*Td3lFpVFua1VnP8vsogu3g.gif)\n\n설치해야 할 라이브러리가 있습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\npip install transformers\n```\n\n이 Python 라이브러리를 시작하려면 파이프라인()을 사용하여 추론, 모델 로드, 및 학습을 하는 것이 좋습니다. 이 경우에는 모델 NLLB-200을 로드하려고 합니다.\n\n간단히 \"Transformers에서 사용하기\" 버튼에서 찾은 코드를 복사하면 됩니다. 아래는 약간의 수정이 필요한 코드입니다:\n\n```js\nfrom transformers import pipeline\nimport torch\n\ntranslator = pipeline(task=\"translation\",\n                      model=\"facebook/nllb-200-distilled-600M\",\n                      torch_dtype=torch.bfloat16\n                      )\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\npipeline()은 번역 작업용 모델 NLLB-200을 다운로드하고 캐시합니다. 이러한 매개변수들 외에도, 모델을 압축하는 데 성능이 감소하지 않는 torch의 유형을 지정합니다.\n\n이제 이를 사용하여 텍스트를 번역할 수 있습니다:\n\n```js\ntext = \"\"\"\nChatGPT 개발자 OpenAI는 단 한 번의 짧은 오디오 샘플만 있으면 인간의 목소리를 재현할 수 있는 새로운 도구를 소개했다.\\\n이 도구는 고도의 정확도로 음성을 복제하려는 기술 회사들이 개발한 여러 도구 중 하나이다.\\\n시스템의 이름은 Voice Engine입니다. OpenAI는 3월 29일 Voice Engine에 관한 세부 정보를 공개했다.\\\n\"\"\"\n\ntext_translated = translator(text,\n                             src_lang=\"eng_Latn\",\n                             tgt_lang=\"ita_Latn\")\n\nprint(text_translated[0]['translation_text'])\n```\n\n이것이 출력 내용입니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nOpenAI의 ChatGPT 개발자가 새로운 도구를 소개했어요!\n그 도구는 짧은 음성 샘플을 사용하여 인간의 목소리를 재현할 수 있다고 해요.\n이 도구는 음성을 높은 정확도로 복제하기 위해 기술 기업들이 개발한 여러 도구 중 하나에요.\n이 시스템의 이름은 Voice Engine이에요. OpenAI는 3월 29일 Voice Engine에 대한 세부 정보를 공개했어요.\n```\n\n좋아요! 우리가 과제를 해결했네요. 쉬웠죠?\n\n## 최종 생각\n\n이것은 Hugging Face를 시작하는 데 도움이 되는 입문 가이드였어요. Transformers는 상위 모델, 특히 NLP 모델에 쉽게 액세스할 수 있게 해주는 파이썬 라이브러리에요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 플랫폼과 파이썬 라이브러리에 대해 더 깊이 파고들고 싶다면, 아래에서 제안하는 리소스를 살펴보세요.\n\n이 글이 유용하게 느껴졌으면 좋겠어요. 즐거운 하루 보내세요!\n\n유용한 리소스:\n\n- Hugging Face 문서\n- Hugging Face 무료 강좌\n- Hugging Face와 함께하는 오픈소스 모델 강좌\n","ogImage":{"url":"/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png","tag":["Tech"],"readingTime":11},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png\" alt=\"Hugging Face\"\u003e\u003c/p\u003e\n\u003cp\u003e대규모 언어 모델들의 급격한 발전으로 다양한 작업을 해결하기 위해 적용되는 경우가 많아졌으며, Hugging Face에 대한 지식은 반드시 알아둬야 할 필수요소가 되었습니다.\u003c/p\u003e\n\u003cp\u003e왜 Hugging Face를 사용해야 할까요? Hugging Face는 다양한 오픈 소스 모델에 대한 접근성을 제공하는 데 중요한 역할을 합니다. 이 플랫폼 덕분에 데이터 과학자, 개발자 및 연구자들은 최신 모델을 쉽게 탐색하고 활용할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e본문에서는 Hugging Face의 잠재력, 이를 활용하는 방법 및 가능한 사용 사례에 대해 설명하겠습니다. 시작해봅시다!\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e목차:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHugging Face란 무엇인가요?\u003c/li\u003e\n\u003cli\u003eHugging Face의 기본 구성 요소\u003c/li\u003e\n\u003cli\u003eOpen LLM Leaderboard란 무엇인가요?\u003c/li\u003e\n\u003cli\u003eHugging Face에 접근하는 방법\u003c/li\u003e\n\u003cli\u003eHugging Face로 놀기 시작하기\u003c/li\u003e\n\u003cli\u003eTransformers 라이브러리 활용하기\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eHugging Face란 무엇인가요?\u003c/h2\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_1.png\"\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e허깅페이스는 다양한 작업을 위한 사전 훈련 모델에 민주적인 접근을 제공하는 허브입니다. 번역, 요약, 질의응답, 객체 감지, 이미지 분할 등 다양한 작업에 사용됩니다. 사용자들이 오픈 소스 모델에 기여할 것을 장려합니다.\u003c/p\u003e\n\u003cp\u003e이 중심화된 저장소의 매력은 허깅페이스 트랜스포머(Hugging Face Transformers)로, 모델을 쉽게 다운로드하고 불러오며 미세 조정할 수 있는 매우 인기 있는 파이썬 라이브러리입니다.\u003c/p\u003e\n\u003cp\u003e모델뿐만 아니라 데이터셋과 기계 학습 데모인 허깅페이스 스페이스(Hugging Face Spaces)도 호스팅합니다.\u003c/p\u003e\n\u003ch2\u003e허깅페이스의 기본 구성요소\u003c/h2\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e허깅페이스에는 모델, 데이터셋 및 스페이스 세 가지 주요 구성 요소가 있어요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_2.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e모델 페이지에 들어가보면 수많은 오픈소스 모델로 인해 압도될 수 있지만 걱정 마세요. 먼저 해결하고자 하는 작업을 식별한 후 해당 작업으로 필터링하는 것이 권장됩니다. 작업을 선택한 후에는 인기도와 다운로드 횟수 같은 다양한 기준에 따라 모델을 정렬할 수 있어요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_3.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e모델과 마찬가지로, 다양한 종류의 데이터셋이 있어서 다양한 작업에 활용할 수 있습니다. 이전과 마찬가지로 최종 목표에 따라 작업별로 필터링하고 결과를 정렬하는 것이 중요합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_4.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e마지막으로, Hugging Face 스페이스라는 기계 학습 데모를 빠르게 살펴볼 수 있습니다. Hugging Face 스페이스에서는 Streamlit, Gradio, 그리고 FastAPI를 기반으로 한 대화형 애플리케이션을 통해 모델을 실행할 수 있습니다. 다시 말해, Hugging Face 스페이스를 통해 직관적인 인터페이스를 통해 간접적으로 모델과 상호 작용할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_5.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e위에는 입력 텍스트로부터 이미지를 생성하는 전문 공간 예시가 있습니다. 이 데모인 PixArt-Sigma는 4K 해상도에서 이미지를 생성할 수 있는 PixArt-Sigma 1024px 확산 변환 모델을 활용합니다.\u003c/p\u003e\n\u003ch2\u003e오픈 LLM 리더보드란?\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_6.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eHugging Face의 또 다른 중요한 기여는 오픈 LLM 리더보드입니다. 이는 오픈 소스 LLMs와 챗봇을 추적하고 평가할 수 있는 머신 러닝 데모 또는 Hugging Face 공간입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e모델 페이지와 마찬가지로 사용 가능한 모델이 너무 많습니다. 과업을 해결하기 위해 필요한 모델 유형을 식별한 후 이를 기반으로 결과를 필터링하는 것이 좋습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_7.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e예를 들어, 처음부터 훈련된 모델만 추적하길 원한다고 가정해 봅시다. 이 경우 \"사전 훈련된 모델\"을 선택하여 필터링해야 합니다.\u003c/p\u003e\n\u003cp\u003e필터를 수정하면 리더보드 상단의 모델 대부분이 Meta 및 Databricks와 같은 대규모 기술 회사에서 나온 것을 알 수 있을 것입니다. 이것은 모든 회사가 이러한 대규모 모델을 훈련시키기에 컴퓨팅 능력을 갖추지 못한 이유입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003eHugging Face에 접속하는 방법\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_8.png\" alt=\"hugging-face-image\"\u003e\u003c/p\u003e\n\u003cp\u003e노트북에서 Hugging Face의 모델과 데이터셋에 액세스하려면 먼저 Hugging Face API 키가 필요합니다. 계정이 아직 없다면 만들어야 합니다. 계정이 생성되면 Settings\u003ccode\u003eAccess Tokens\u003c/code\u003e을 클릭하고 \"New token\" 버튼을 누릅니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_9.png\" alt=\"hugging-face-image\"\u003e\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e토큰의 이름인 HF_TOKEN과 해당 토큰의 유형을 결정하세요. 이 유형은 read 또는 write 중 하나로 선택할 수 있습니다. 모델을 다운로드하거나 모델에서 추론을 실행하는 경우 read를 선택하면 가장 일반적인 선택지입니다. 모델을 훈련시키려면 write를 선택하는 것이 좋습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_10.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e그걸로 끝입니다! 우리는 Hugging Face에서 첫 번째 액세스 토큰을 생성했습니다. 액세스 토큰에 대해 더 깊이 알아보고 싶다면, Hugging Face 문서를 살펴보세요.\u003c/p\u003e\n\u003ch2\u003eHugging Face와 놀기 시작\u003c/h2\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*2AywAoMAEN5v8VG8wIFU7Q.gif\"\u003e\n\u003cp\u003eHugging Face의 개념이 명확해지면, 이제는 자습서의 실제 부분으로 넘어가는 시간입니다. 영어에서 이탈리아어로 텍스트를 번역하는 모델을 찾고 싶다고 가정해 봅시다. 다음은 다음과 같은 단계입니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e모델 페이지로 이동\u003c/li\u003e\n\u003cli\u003e번역을 작업으로 선택\u003c/li\u003e\n\u003cli\u003e이탈리아어를 언어로 선택\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e우리는 트렌딩 순으로 정렬된 첫 번째 결과 중에서 나타나는 모델 NLLB-200을 선택하기로 결정했습니다. 모델의 웹 페이지에는 프로젝트 목적에 따라 유용할 수 있는 다양한 버튼도 포함되어 있습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_11.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e이 경우에는 모델을 로드하는 코드 라인을 얻기 위해 \"Transformers에서 사용\" 버튼을 클릭하면 됩니다.\u003c/p\u003e\n\u003ch2\u003eTransformers 라이브러리 활용\u003c/h2\u003e\n\u003cp\u003e실험을 진행할 경우, Google Colab을 사용하는 것을 추천드립니다. Google Colab은 코드를 웹 브라우저에서 실행하며 CPU 또는 GPU 리소스에 액세스할 수 있는 클라우드 기반 플랫폼입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e또한, 이 환경은 이전에 얻은 허깅페이스의 액세스 키와 같은 환경 변수를 간단히 가져오는 것을 가능하게 합니다.\u003c/p\u003e\n\u003cp\u003e구글 코랩을 열고, Secrets로 이동하여 “새로운 비밀”을 클릭하고 허깅페이스 액세스 토큰의 이름과 값을 복사하면 됩니다. 또한, 노트북 액세스를 토글하는 것을 잊지 마세요!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*Td3lFpVFua1VnP8vsogu3g.gif\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e설치해야 할 라이브러리가 있습니다:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003epip install transformers\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 Python 라이브러리를 시작하려면 파이프라인()을 사용하여 추론, 모델 로드, 및 학습을 하는 것이 좋습니다. 이 경우에는 모델 NLLB-200을 로드하려고 합니다.\u003c/p\u003e\n\u003cp\u003e간단히 \"Transformers에서 사용하기\" 버튼에서 찾은 코드를 복사하면 됩니다. 아래는 약간의 수정이 필요한 코드입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pipeline\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch\n\ntranslator = \u003cspan class=\"hljs-title function_\"\u003epipeline\u003c/span\u003e(task=\u003cspan class=\"hljs-string\"\u003e\"translation\"\u003c/span\u003e,\n                      model=\u003cspan class=\"hljs-string\"\u003e\"facebook/nllb-200-distilled-600M\"\u003c/span\u003e,\n                      torch_dtype=torch.\u003cspan class=\"hljs-property\"\u003ebfloat16\u003c/span\u003e\n                      )\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003epipeline()은 번역 작업용 모델 NLLB-200을 다운로드하고 캐시합니다. 이러한 매개변수들 외에도, 모델을 압축하는 데 성능이 감소하지 않는 torch의 유형을 지정합니다.\u003c/p\u003e\n\u003cp\u003e이제 이를 사용하여 텍스트를 번역할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003etext = \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"hljs-string\"\u003e\"\nChatGPT 개발자 OpenAI는 단 한 번의 짧은 오디오 샘플만 있으면 인간의 목소리를 재현할 수 있는 새로운 도구를 소개했다.\\\n이 도구는 고도의 정확도로 음성을 복제하려는 기술 회사들이 개발한 여러 도구 중 하나이다.\\\n시스템의 이름은 Voice Engine입니다. OpenAI는 3월 29일 Voice Engine에 관한 세부 정보를 공개했다.\\\n\"\u003c/span\u003e\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n\ntext_translated = \u003cspan class=\"hljs-title function_\"\u003etranslator\u003c/span\u003e(text,\n                             src_lang=\u003cspan class=\"hljs-string\"\u003e\"eng_Latn\"\u003c/span\u003e,\n                             tgt_lang=\u003cspan class=\"hljs-string\"\u003e\"ita_Latn\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(text_translated[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e'translation_text'\u003c/span\u003e])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이것이 출력 내용입니다:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-title class_\"\u003eOpenAI\u003c/span\u003e의 \u003cspan class=\"hljs-title class_\"\u003eChatGPT\u003c/span\u003e 개발자가 새로운 도구를 소개했어요!\n그 도구는 짧은 음성 샘플을 사용하여 인간의 목소리를 재현할 수 있다고 해요.\n이 도구는 음성을 높은 정확도로 복제하기 위해 기술 기업들이 개발한 여러 도구 중 하나에요.\n이 시스템의 이름은 \u003cspan class=\"hljs-title class_\"\u003eVoice\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eEngine\u003c/span\u003e이에요. \u003cspan class=\"hljs-title class_\"\u003eOpenAI\u003c/span\u003e는 \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e월 \u003cspan class=\"hljs-number\"\u003e29\u003c/span\u003e일 \u003cspan class=\"hljs-title class_\"\u003eVoice\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eEngine\u003c/span\u003e에 대한 세부 정보를 공개했어요.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e좋아요! 우리가 과제를 해결했네요. 쉬웠죠?\u003c/p\u003e\n\u003ch2\u003e최종 생각\u003c/h2\u003e\n\u003cp\u003e이것은 Hugging Face를 시작하는 데 도움이 되는 입문 가이드였어요. Transformers는 상위 모델, 특히 NLP 모델에 쉽게 액세스할 수 있게 해주는 파이썬 라이브러리에요.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 플랫폼과 파이썬 라이브러리에 대해 더 깊이 파고들고 싶다면, 아래에서 제안하는 리소스를 살펴보세요.\u003c/p\u003e\n\u003cp\u003e이 글이 유용하게 느껴졌으면 좋겠어요. 즐거운 하루 보내세요!\u003c/p\u003e\n\u003cp\u003e유용한 리소스:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHugging Face 문서\u003c/li\u003e\n\u003cli\u003eHugging Face 무료 강좌\u003c/li\u003e\n\u003cli\u003eHugging Face와 함께하는 오픈소스 모델 강좌\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace"},"buildId":"xx51Gh_JNHDTBdDwrgykD","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>