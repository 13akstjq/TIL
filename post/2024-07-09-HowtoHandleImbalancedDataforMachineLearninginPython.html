<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Python으로 머신러닝에서 불균형 데이터 다루는 방법 | TIL</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://13akstjq.github.io/TIL//post/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Python으로 머신러닝에서 불균형 데이터 다루는 방법 | TIL" data-gatsby-head="true"/><meta property="og:title" content="Python으로 머신러닝에서 불균형 데이터 다루는 방법 | TIL" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://TIL.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://13akstjq.github.io/TIL//post/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython" data-gatsby-head="true"/><meta name="twitter:title" content="Python으로 머신러닝에서 불균형 데이터 다루는 방법 | TIL" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | TIL" data-gatsby-head="true"/><meta name="article:published_time" content="2024-07-09 14:33" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/TIL/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/TIL/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/TIL/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/TIL/favicons/favicon-96x96.png"/><link rel="icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/TIL/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/TIL/favicons/browserconfig.xml"/><link rel="preload" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/TIL/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/TIL/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/TIL/_next/static/chunks/webpack-21ffe88bdca56cba.js" defer=""></script><script src="/TIL/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/TIL/_next/static/chunks/main-a5eeabb286676ce6.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/TIL/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/TIL/_next/static/chunks/463-925361deb4cec4b1.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/post/%5Bslug%5D-9d7ebbd29b9e08ce.js" defer=""></script><script src="/TIL/_next/static/FuXRqV9h16krA5Mvtd6Dn/_buildManifest.js" defer=""></script><script src="/TIL/_next/static/FuXRqV9h16krA5Mvtd6Dn/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/TIL">TIL</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/TIL/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Python으로 머신러닝에서 불균형 데이터 다루는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Python으로 머신러닝에서 불균형 데이터 다루는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/TIL/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">TIL</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jul 9, 2024</span><span class="posts_reading_time__f7YPP">33<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>기계 학습의 분류 문제를 다룰 때 고려해야 할 중요한 요소 중 하나는 레이블을 정의하는 클래스의 균형입니다.</p>
<p>세 개의 클래스로 이루어진 상황을 상상해보세요. 초기 분석을 수행하여 정확도를 계산하면 93%를 얻을 수 있습니다. 그런 다음 더 깊게 들여다보는데, 데이터의 80%가 한 클래스에 속한다는 것을 알 수 있습니다. 이것이 좋은 징후인가요?</p>
<p>음, 그렇지 않습니다. 이 문서에서는 그 이유를 설명하고 있습니다.</p>
<h1>초보자를 위한 Jupyter 노트북 설정하기</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>기계 학습 초보자라면, ML 문제를 해결하기 위해 두 가지 소프트웨어를 사용할 수 있다는 것을 모를 수 있습니다:</p>
<ul>
<li>Anaconda</li>
<li>Google Colaboratory</li>
</ul>
<p>Anaconda는 데이터 분석 및 기계 학습으로 예측을 하는 데 필요한 모든 라이브러리를 제공하는 데이터 과학 플랫폼입니다. 또한 데이터 과학자들이 데이터를 분석하는 데 사용하는 Jupyter Notebooks를 제공합니다. 따라서 Anaconda를 설치하면 필요한 모든 것을 갖추게 됩니다.</p>
<p>반면에 Google Colaboratory는 설정이 필요 없는 호스팅된 Jupyter Notebook 서비스로, 무료로 컴퓨팅 리소스 및 필요한 모든 라이브러리에 대한 액세스를 제공합니다. 따라서 PC에 아무것도 설치하지 않고 데이터를 분석하려면 이 솔루션을 선택할 수 있습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>마침내, 이 글에서 찾을 수 있는 모든 코드를 포함하는 공개 저장소를 만들었습니다. 이 저장소는 하나의 Jupyter Notebook에 있어 데이터 과학자들이 데이터를 분석하는 방식을 확인하고자 할 때 참고할 수 있습니다.</p>
<h1>머신 러닝에서 불균형 데이터 소개</h1>
<p>이 섹션은 머신 러닝에서 클래스 불균형 문제를 소개하고, 불균형 클래스가 흔한 시나리오를 다룹니다. 그러나 계속하기 전에, "불균형" 또는 "균형이 맞지 않는" 용어를 무시하고 사용할 수 있다는 점을 얘기합시다.</p>
<h1>불균형 데이터 정의 및 모델 성능에 미치는 영향</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>상상해봐요. 당신이 100명의 학생들을 가르치는 수학 선생님인 상황을 상상해보세요. 이 학생들 중 90명은 수학을 잘하는 학생(Group A), 그리고 10명은 어려워하는 학생들(Group B)이라고 부를 수 있겠네요. 이 수업 구성은 기계 학습 세상에서 "불균형 데이터"로 알려져 있어요.</p>
<p>기계 학습에서 데이터는 컴퓨터에 예측이나 결정을 내리도록 가르치는 데 사용되는 교과서와 같아요. 불균형 데이터가 있다는 것은 컴퓨터가 배워야 하는 것들에 대한 예제 수에 큰 차이가 있다는 것을 의미해요. 우리의 수업 비유에 따르면, 과반이 되는 A 그룹보다 소수인 B 그룹의 학생 수가 적어요.</p>
<p>이제 우리의 기계 학습 모델의 성능은 불균형 데이터에 영향을 받아요. 예를 들어, 여기에는 몇 가지 영향들이 있어요:</p>
<ul>
<li>편향된 학습. 대부분의 학생들이 수학을 잘하는 이 불균형한 수업에서 컴퓨터를 가르치면, 약간 편향될 수 있어요. 마치 컴퓨터가 수학 천재들에게 둘러싸인 듯하니, 모두가 수학 천재인 것으로 생각할 수 있어요. 기계 학습 용어로는 모델이 과반수 클래스 쪽으로 편향될 수 있어요. 그것은 일반적인 것(Group A)을 예측하는 데 능숙해지지만 드문 것(Group B)을 이해하는 데 어려움을 겪을 수 있어요. 당신이 학생들의 투표를 사용하여 수학 가르치기에 얼마나 능숙한지를 평가한다면, 90%의 학생이 수학을 잘하는 것이기 때문에 편향된 결과를 받을 수 있어요. 그런데 이 90% 중 대부분이 사설 수업을 듣고 있다면 당신은 알 수 없어요.</li>
<li>잘못된 정확도. 컴퓨터의 성능을 평가하려면 컴퓨터가 수학을 잘하는 학생이나 어려워하는 학생을 올바르게 식별한 횟수를 확인하여야 해요. A 그룹이 많기 때문에 컴퓨터는 대부분의 학생을 올바르게 맞출 수 있을 거예요. 그래서 정확도가 높아 보인다면 컴퓨터가 훌륭한 일을 하는 것처럼 보일 수 있어요. 그러나 B 그룹이 적기 때문에 실제로는 B 그룹에는 엉망진창일 수 있어요. 기계 학습에서 이 높은 정확도는 컴퓨터가 소수 클래스에서 얼마나 잘 수행되고 있는지 알려주지 않아서 잘못된 정보일 수 있어요.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>간단히 말해서, 불균형 데이터는 컴퓨터에 학습시키려는 서로 다른 사례들에 대해 불균형한 예제 수가 있다는 것을 의미하며, 특히 드물게 발생하는 경우를 처리할 때 머신러닝 모델의 성능에 심각한 영향을 미칠 수 있습니다.</p>
<p>어쨌든, 데이터가 불균형할 것으로 예상되는 경우도 있습니다.</p>
<p>이것들에 대해 설명하기 전에 먼저 어떤 경우에 불균형 데이터가 일반적인지 살펴보겠습니다.</p>
<h1>불균형 데이터가 흔한 시나리오</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>현실적인 시나리오에서는 데이터가 불균형적인 경우가 많이 발생합니다. 만약 그렇지 않다면, 오류가 있는 것을 의미합니다.</p>
<p>예를 들어 의학 분야를 생각해보겠습니다. 대규모 인구 중에서 희귀 질병을 찾으려고 할 때, 데이터는 불균형해야 합니다. 그렇지 않으면 우리가 찾고 있는 질병이 희귀하지 않다는 것을 의미합니다.</p>
<p>사기 탐지의 경우도 마찬가지입니다. 금융 기관의 데이터 과학자로서 신용 카드에서 사기 거래를 분석하고 있을 때, 불균형한 데이터를 발견해야 합니다. 그렇지 않으면 사기 거래가 비-사기 거래만큼 자주 발생한다는 것을 의미합니다.</p>
<h1>불균형 문제 이해하기</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이제 Python 코드와 함께 실제 상황에 대해 알아볼까요? 이를 통해 다음을 보여줄 수 있습니다:</p>
<ul>
<li>그래픽을 기반으로 한 주요 및 소수 클래스 간의 차이.</li>
<li>불균형한 데이터에 영향을 받는 평가 지표들.</li>
<li>불균형한 데이터에 영향을 받지 않는 평가 지표들.</li>
</ul>
<h1>주요 및 소수 클래스 간의 차이</h1>
<p>수학 선생님인 당신이라고 가정해보겠습니다. 이번에는 1000명의 학생으로 이루어진 대규모 강의를 하고 있습니다. 머신러닝을 사용하여 어떠한 분류를 수행하기 전에, 데이터가 불균형인지 확인하기로 결정했습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>하나의 방법은 분포를 시각화하는 것입니다. 예를 들어, 다음과 같이:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.<span class="hljs-property">pyplot</span> <span class="hljs-keyword">as</span> plt
</code></pre>
<pre><code class="hljs language-js"># 재현 가능성을 위해 랜덤 시드 설정
np.<span class="hljs-property">random</span>.<span class="hljs-title function_">seed</span>(<span class="hljs-number">42</span>)
# 다수 클래스 (<span class="hljs-title class_">Class</span> <span class="hljs-number">0</span>)를 위한 데이터 생성
majority_class = np.<span class="hljs-property">random</span>.<span class="hljs-title function_">normal</span>(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">900</span>)
# 소수 클래스 (<span class="hljs-title class_">Class</span> <span class="hljs-number">1</span>)를 위한 데이터 생성
minority_class = np.<span class="hljs-property">random</span>.<span class="hljs-title function_">normal</span>(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">100</span>)
# 다수 클래스와 소수 클래스 데이터 결합
data = np.<span class="hljs-title function_">concatenate</span>((majority_class, minority_class))
# 클래스 레이블 생성
labels = np.<span class="hljs-title function_">concatenate</span>((np.<span class="hljs-title function_">zeros</span>(<span class="hljs-number">900</span>), np.<span class="hljs-title function_">ones</span>(<span class="hljs-number">100</span>)))
# 클래스 분포 플로팅
plt.<span class="hljs-title function_">figure</span>(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">6</span>))
plt.<span class="hljs-title function_">hist</span>(data[labels == <span class="hljs-number">0</span>], bins=<span class="hljs-number">20</span>, color=<span class="hljs-string">'blue'</span>, alpha=<span class="hljs-number">0.6</span>, label=<span class="hljs-string">'다수 클래스 (Class 0)'</span>)
plt.<span class="hljs-title function_">hist</span>(data[labels == <span class="hljs-number">1</span>], bins=<span class="hljs-number">20</span>, color=<span class="hljs-string">'red'</span>, alpha=<span class="hljs-number">0.6</span>, label=<span class="hljs-string">'소수 클래스 (Class 1)'</span>)
plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">'특성 값'</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">'빈도수'</span>)
plt.<span class="hljs-title function_">title</span>(<span class="hljs-string">'불균형 데이터셋의 클래스 분포'</span>)
plt.<span class="hljs-title function_">legend</span>()
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png">
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 Python 예제에서는 두 개의 클래스를 만들었습니다:</p>
<ul>
<li>주요 클래스 (클래스 0). 이 클래스는 데이터 포인트의 대다수를 나타냅니다. 평균이 0이고 표준 편차가 1인 정규 분포에서 900개의 데이터 포인트를 생성했습니다. 실제 시나리오에서는 매우 흔하거나 전형적인 것을 나타낼 수 있습니다.</li>
<li>소수 클래스 (클래스 1). 이 클래스는 데이터 포인트의 소수를 나타냅니다. 평균이 3이고 표준 편차가 1인 정규 분포에서 100개의 데이터 포인트를 생성했습니다. 이 클래스는 의도적으로 흔하지 않게 만들어져 불균형 데이터셋을 시뮬레이션합니다. 실제로는 드문 사건이나 이상을 나타낼 수 있습니다.</li>
</ul>
<p>다음으로, 이 두 클래스를 해당 레이블 (주요 클래스에 대한 0 및 소수 클래스에 대한 1)과 함께 단일 데이터셋으로 결합합니다. 마지막으로, 히스토그램을 사용하여 클래스 분포를 시각화합니다. 히스토그램에서:</p>
<ul>
<li>파란 막대는 주요 클래스 (클래스 0)를 나타내며, 좌측에 더 크고 더 빈번한 막대입니다.</li>
<li>빨간 막대는 소수 클래스 (클래스 1)를 나타내며, 우측에 더 작고 덜 빈번한 막대입니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 시각화는 불균형 데이터셋에서 주요 및 소수 클래스 간의 차이를 명확하게 보여줍니다. 주요 클래스는 소수 클래스보다 훨씬 많은 데이터 포인트를 가지고 있으며, 이는 불균형 데이터의 일반적인 특성입니다.</p>
<p>클래스 불균형을 다루는 또 다른 방법은 분포를 통해 직접적으로 빈도를 살펴보는 것입니다. 예를 들어, 다음과 같이 할 수 있습니다:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.<span class="hljs-property">pyplot</span> <span class="hljs-keyword">as</span> plt
</code></pre>
<pre><code class="hljs language-js"># 재현성을 위해 임의의 시드 설정
np.<span class="hljs-property">random</span>.<span class="hljs-title function_">seed</span>(<span class="hljs-number">42</span>)
# 주요 클래스 (클래스 <span class="hljs-number">0</span>)에 대한 데이터 생성
majority_class = np.<span class="hljs-property">random</span>.<span class="hljs-title function_">normal</span>(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">900</span>)
# 소수 클래스 (클래스 <span class="hljs-number">1</span>)에 대한 데이터 생성
minority_class = np.<span class="hljs-property">random</span>.<span class="hljs-title function_">normal</span>(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">100</span>)
# 주요 및 소수 클래스 데이터 결합
data = np.<span class="hljs-title function_">concatenate</span>((majority_class, minority_class))
# 클래스에 대한 레이블 생성
labels = np.<span class="hljs-title function_">concatenate</span>((np.<span class="hljs-title function_">zeros</span>(<span class="hljs-number">900</span>), np.<span class="hljs-title function_">ones</span>(<span class="hljs-number">100</span>))
# 각 클래스의 빈도 카운트
class_counts = [<span class="hljs-title function_">len</span>(labels[labels == <span class="hljs-number">0</span>]), <span class="hljs-title function_">len</span>(labels[labels == <span class="hljs-number">1</span>])]
# 막대 그래프를 사용하여 클래스 빈도 플로팅
plt.<span class="hljs-title function_">figure</span>(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">6</span>))
plt.<span class="hljs-title function_">bar</span>([<span class="hljs-string">'주요 클래스 (클래스 0)'</span>, <span class="hljs-string">'소수 클래스 (클래스 1)'</span>], class_counts, color=[<span class="hljs-string">'blue'</span>, <span class="hljs-string">'red'</span>])
plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">'클래스'</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">'빈도'</span>)
plt.<span class="hljs-title function_">title</span>(<span class="hljs-string">'불균형 데이터셋의 클래스 빈도'</span>)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>아래와 같이 테이블 태그를 마크다운 형식으로 변경해주세요.</p>
<p><img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_1.png" alt="image"></p>
<p>그러니까, 이 경우에는 클래스에 속하는 데이터의 모든 발생을 계산하는 내장 메소드 len()을 사용할 수 있습니다.</p>
<h1>이상 데이터로 영향을 받는 일반 평가 지표</h1>
<p>이상 데이터에 영향을 받는 모든 평가 지표를 설명하려면 먼저 다음을 정의해야 합니다:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>True positive (TP). 분류기가 조건이나 특성의 존재를 올바르게 예측한 값</li>
<li>True negative (TN). 분류기가 조건이나 특성의 부재를 올바르게 예측한 값</li>
<li>False positive (FP). 분류기가 특정 조건이나 속성이 존재하는 것으로 잘못 예측한 값</li>
<li>False negative (FN). 분류기가 특정 조건이나 속성이 존재하지 않는 것으로 잘못 예측한 값</li>
</ul>
<p>다음은 불균형 데이터가 영향을 미치는 일반적인 평가 지표입니다:</p>
<ul>
<li>정확도. 데이터 세트에서 올바르게 예측된 인스턴스의 비율을 측정합니다.</li>
</ul>
<p><img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_2.png" alt="이미지"></p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>파이썬에서 정확도 지표를 계산하는 방법에 대한 예제를 만들어보겠습니다:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score
</code></pre>
<pre><code class="hljs language-python"><span class="hljs-comment"># 실제 레이블</span>
true_labels = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
<span class="hljs-comment"># 모델이 예측한 레이블</span>
predicted_labels = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]
accuracy = accuracy_score(true_labels, predicted_labels)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"정확도:"</span>, accuracy)
</code></pre>
<p>결과는:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">정확도: <span class="hljs-number">0.5</span>;
</code></pre>
<p>정확도는 불균형한 데이터를 다룰 때 혼란을 줄 수 있습니다.</p>
<p>실제로 95%가 A 클래스에 속하고 5%만 B 클래스에 속하는 데이터 세트가 있다고 가정해 봅시다. 모델이 모든 인스턴스를 A 클래스로 예측한다면 95%의 정확도를 달성할 것입니다. 하지만 이는 반드시 모델이 좋다는 것을 의미하지는 않습니다. 이는 단지 클래스 불균형을 악용한 것뿐입니다. 다시 말해, 이 메트릭은 소수 클래스 (B 클래스)를 얼마나 잘 식별하는지를 고려하지 않습니다.</p>
<ul>
<li>정밀도. 이것은 모든 예측된 긍정 인스턴스 중 올바르게 예측된 긍정 인스턴스의 비율을 측정합니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_3.png" alt="How to Handle Imbalanced Data for Machine Learning in Python"></p>
<p>한 예제를 통해 Python에서 정밀도 지표를 계산하는 방법을 살펴보겠습니다:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> precision_score
</code></pre>
<pre><code class="hljs language-python"><span class="hljs-comment"># True labels</span>
true_labels = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
<span class="hljs-comment"># Predicted labels by a model</span>
predicted_labels = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
precision = precision_score(true_labels, predicted_labels)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Precision:"</span>, precision)
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>결과는 다음과 같습니다:</p>
<pre><code class="hljs language-js">정밀도: <span class="hljs-number">0.5</span>;
</code></pre>
<p>불균형 데이터 세트에서는 정밀도가 매우 오해를 일으킬 수 있습니다.</p>
<p>실제로, 모델이 하나의 인스턴스만을 긍정적(클래스 B)으로 분류하고 그게 맞는 경우, 정밀도는 100%가 될 것입니다. 그러나 이는 모델이 소수 클래스에서의 성능을 나타내는 것이 아닐 수 있습니다. 왜냐하면 많은 긍정적 인스턴스를 놓칠 수 있기 때문입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>재현율 (또는 민감도). 재현율은 또한 민감도 또는 진양성율로 알려져 있으며, 올바르게 예측된 긍정적 인스턴스의 비율을 측정합니다:</li>
</ul>
<p><img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_4.png" alt="Example"></p>
<p>파이썬을 사용하여 재현율 지표를 계산하는 예제를 만들어 보겠습니다:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">metrics</span> <span class="hljs-keyword">import</span> recall_score
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"># 실제 레이블
true_labels = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
# 모델이 예측한 레이블
predicted_labels = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
recall = <span class="hljs-title function_">recall_score</span>(true_labels, predicted_labels)
<span class="hljs-title function_">print</span>(<span class="hljs-string">"재현율:"</span>, recall)
</code></pre>
<p>결과는:</p>
<pre><code class="hljs language-js">재현율: <span class="hljs-number">1.0</span>;
</code></pre>
<p>재현율은 불균형한 데이터셋에서도 잘못된 정보를 줄 수 있습니다. 특히 모든 긍정적인 인스턴스를 포착하는 것이 중요할 때에는요.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>만약 모델이 더 많은 양의 양성 인스턴스가 있는 상황에서 한 인스턴스만을 양성(Class B)으로 예측할 경우, 재현율이 매우 낮을 수 있습니다. 이는 모델이 소수 클래스의 중요한 부분을 놓치고 있음을 나타낼 수 있습니다. 이는 이 메트릭이 false positives를 고려하지 않기 때문에 발생합니다.</p>
<ul>
<li>F1 스코어. F1 스코어는 정밀도와 재현율의 조화평균입니다. 정밀도와 재현율 사이의 균형을 제공합니다:</li>
</ul>
<p><img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_5.png" alt="image"></p>
<p>파이썬을 사용하여 F1 스코어 메트릭을 계산하는 예제를 만들어봅시다:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">metrics</span> <span class="hljs-keyword">import</span> f1_score
</code></pre>
<pre><code class="hljs language-js"># <span class="hljs-title class_">True</span> labels
true_labels = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
# <span class="hljs-title class_">Predicted</span> labels by a model
predicted_labels = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
# <span class="hljs-title class_">Calculate</span> and print <span class="hljs-variable constant_">F1</span>-score
f1 = <span class="hljs-title function_">f1_score</span>(true_labels, predicted_labels)
<span class="hljs-title function_">print</span>(<span class="hljs-string">"F1-Score:"</span>, f1)
</code></pre>
<p>결과는:</p>
<pre><code class="hljs language-js"><span class="hljs-variable constant_">F1</span>-<span class="hljs-title class_">Score</span>: <span class="hljs-number">0.6666666666666666</span>
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 메트릭은 정밀도와 재현율을 사용하여 생성되었기 때문에 데이터 불균형에 영향을 받을 수 있습니다.</p>
<p>하나의 클래스가 지배적이고 (다수 클래스인 경우), 그 모델이 해당 클래스를 편향으로 처리하는 경우, F1 점수는 소수 클래스의 낮은 재현율에도 높은 정밀도 때문에 상대적으로 높을 수 있습니다. 이는 모델의 전체 효과를 잘못 나타낼 수 있습니다.</p>
<h1>데이터 불균형에 영향을 받지 않는 가장 많이 사용되는 평가 지표</h1>
<p>이제 클래스 불균형에 영향을 받지 않는 평가 지표 중 가장 많이 사용되는 두 가지를 설명하겠습니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>혼동 행렬. 혼동 행렬은 분류 알고리즘의 성능을 요약하는 표입니다. 이는 True Positives (TP), True Negatives (TN), False Positives (FP) 및 False Negatives (FN)의 자세한 분석을 제공합니다. 특히, 주 대각선(왼쪽 위에서 오른쪽 아래)은 TP와 TN을 보여주며, 보조 대각선(왼쪽 아래에서 오른쪽 위)은 FP와 FN을 나타냅니다. 따라서, 머신 러닝 모델이 데이터를 올바르게 분류할 경우, 혼동 행렬의 주 대각선은 가장 높은 값을, 보조 대각선은 가장 낮은 값을 보고해야 합니다.</li>
</ul>
<p>파이썬에서 예제를 보여드리겠습니다:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix
</code></pre>
<pre><code class="hljs language-python"><span class="hljs-comment"># True and predicted labels</span>
true_labels = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
predicted_labels = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]
<span class="hljs-comment"># Create confusion matrix</span>
cm = confusion_matrix(true_labels, predicted_labels)
<span class="hljs-comment"># Print confusion matrix</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Confusion Matrix:"</span>)
<span class="hljs-built_in">print</span>(cm)
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>그리고 저희가 얻은 것은:</p>
<pre><code class="hljs language-js">혼동 행렬:
[[<span class="hljs-number">5</span> <span class="hljs-number">0</span>]
 [<span class="hljs-number">1</span> <span class="hljs-number">4</span>]]
</code></pre>
<p>이 혼동 행렬은 주 대각선에 결과가 가장 많기 때문에(10개 중 9개) 좋은 분류기를 나타냅니다. 이는 분류기가 5개의 TP와 4개의 TN을 예측했다는 것을 의미합니다.</p>
<p>그에 비해, 보조 대각선은 낮은 결과를 보여줍니다(10개 중 1개). 이는 분류기가 1개의 FP와 0개의 FN을 예측했음을 의미합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>그러므로 이것은 좋은 분류기로 이어집니다.</p>
<p>따라서 혼동 행렬은 모델 성능의 자세한 분석을 제공하여 각 클래스에 대해 올바르게 또는 잘못 분류된 인스턴스의 수를 몇 초 안에 알 수 있도록합니다.</p>
<ul>
<li>AUC/ROC 커브. ROC는 "Receiver Operating Characteristic"의 약자로, 참 긍정률 (TPR)을 다른 임계값에서 거짓 긍정률 (FPR)에 대비하여 그래픽 방식으로 그리는 분류기를 평가하는 방법입니다.</li>
</ul>
<p>우리는 다음과 같이 정의합니다:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>TPR을 민감도로(우리가 말했듯이 recall로도 불릴 수 있음).</li>
<li>FPR을 1-특이도로 정의합니다.</li>
</ul>
<p>특이도는 분류기가 모든 부정적인 샘플을 찾는 능력을 의미합니다:</p>
<p><img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_6.png" alt="이미지"></p>
<p>AUC는 ROC 곡선 아래 영역을 나타내며 "곡선 아래 영역"을 의미합니다. 이는 0에서 1사이의 전체적인 성능 지표로, 1은 분류기가 레이블의 100%를 실제 값으로 예측한다는 것을 의미하며, 서로 다른 분류기들을 비교할 때 더 적합합니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>만약 이진 분류 문제를 공부한다고 가정해봅시다. 파이썬에서 AUC 곡선을 그리는 방법은 다음과 같습니다:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_classification
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_curve, roc_auc_score
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
</code></pre>
<pre><code class="hljs language-python"><span class="hljs-comment"># 무작위로 이진 분류 데이터세트 생성</span>
X, y = make_classification(n_samples=<span class="hljs-number">1000</span>, n_features=<span class="hljs-number">10</span>, n_classes=<span class="hljs-number">2</span>, random_state=<span class="hljs-number">42</span>)
<span class="hljs-comment"># 데이터세트를 학습 및 테스트 세트로 분할</span>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>)
<span class="hljs-comment"># 학습 데이터에서 로지스틱 회귀 모델 학습</span>
model = LogisticRegression()
model.fit(X_train, y_train)
<span class="hljs-comment"># 테스트 데이터에 대해 확률 예측</span>
probs = model.predict_proba(X_test)
<span class="hljs-comment"># ROC 곡선 및 AUC 점수 계산</span>
fpr, tpr, thresholds = roc_curve(y_test, probs[:, <span class="hljs-number">1</span>])
auc_score = roc_auc_score(y_test, probs[:, <span class="hljs-number">1</span>])
<span class="hljs-comment"># ROC 곡선 그리기</span>
plt.plot(fpr, tpr, label=<span class="hljs-string">'AUC = {:.2f}'</span>.<span class="hljs-built_in">format</span>(auc_score))
plt.plot([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], <span class="hljs-string">'k--'</span>)
plt.xlabel(<span class="hljs-string">'False Positive Rate'</span>)
plt.ylabel(<span class="hljs-string">'True Positive Rate'</span>)
plt.title(<span class="hljs-string">'ROC Curve'</span>)
plt.legend(loc=<span class="hljs-string">'lower right'</span>)
plt.show()
</code></pre>
<img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_7.png">
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>그 코드로는 다음을 할 수 있어요:</p>
<ul>
<li>make_classification 메서드로 분류 데이터셋을 생성했어요.</li>
<li>데이터셋을 훈련 세트와 테스트 세트로 나눴어요.</li>
<li>Logistic Regression 분류기로 훈련 세트를 fit했어요.</li>
<li>predict_proba() 메서드로 테스트 데이터에 대한 예측을 만들었어요.</li>
<li>ROC 곡선과 AUC 점수를 계산했어요.</li>
<li>AUC 곡선을 그렸어요.</li>
</ul>
<h1>불균형 데이터 다루는 기술</h1>
<p>이 섹션에서는 불균형 데이터를 다루는 몇 가지 기술을 다루겠어요.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>다시 말해, 우리는 불균형 데이터를 다루는 방법에 대해 이야기할 것입니다.</p>
<h2>리샘플링</h2>
<p>불균형 데이터셋을 처리하는 데 널리 사용되는 방법론은 리샘플링입니다. 이 방법론은 두 가지 다른 프로세스로 나눌 수 있습니다:</p>
<ul>
<li>오버샘플링. 소수 클래스에 더 많은 예제를 추가하는 것을 의미합니다.</li>
<li>언더샘플링. 다수 클래스에서 샘플을 제거하는 것을 의미합니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>두 가지 방법에 대해 설명해 보겠습니다.</p>
<h2>Oversampling</h2>
<p>Oversampling은 소수 클래스의 인스턴스 수를 늘려 클래스 분포를 균형있게 만드는 재표본화 기술입니다. 주로 기존 인스턴스를 복제하거나 소수 클래스와 유사한 합성 데이터 포인트를 생성함으로써 수행됩니다. 목표는 모델이 훈련 중에 두 클래스의 더 균형 잡힌 표현을 볼 수 있도록 하는 것입니다.</p>
<p>장점:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>모델 성능 향상. Oversampling은 소수 클래스의 특성을 더 잘 학습할 수 있도록 도와주어 전체적인 분류 성능을 향상시킬 수 있습니다, 특히 소수 클래스에 대해서 더욱 효과적입니다.</li>
<li>정보 보존. 언더샘플링과는 달리, 오버샘플링은 과반 클래스의 모든 인스턴스를 보존하여 정보의 손실이 없도록 합니다.</li>
</ul>
<p>단점:</p>
<ul>
<li>과적합의 위험. 중복되거나 합성된 인스턴스는 적절하게 제어되지 않으면, 특히 합성 데이터가 기존 데이터와 너무 유사한 경우에는 과적합을 유발할 수 있습니다.</li>
<li>훈련 시간 증가. 오버샘플링으로 인한 더 큰 데이터셋은 머신러닝 알고리즘의 학습 시간이 더 오래 걸릴 수 있습니다.</li>
</ul>
<p>Python에서 불균형한 데이터셋에 대한 오버샘플링 기술을 어떻게 활용할 수 있는지 알아보겠습니다:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.<span class="hljs-property">pyplot</span> <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">datasets</span> <span class="hljs-keyword">import</span> make_classification
<span class="hljs-keyword">from</span> imblearn.<span class="hljs-property">over_sampling</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">RandomOverSampler</span>
<span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> <span class="hljs-title class_">Counter</span>
</code></pre>
<pre><code class="hljs language-js"># <span class="hljs-number">3</span>개 클래스를 가지는 불균형 데이터셋 생성
X, y = <span class="hljs-title function_">make_classification</span>(
    n_samples=<span class="hljs-number">1000</span>,
    n_features=<span class="hljs-number">20</span>,
    n_classes=<span class="hljs-number">3</span>,
    n_clusters_per_class=<span class="hljs-number">1</span>,
    weights=[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>],  # 클래스 불균형
    random_state=<span class="hljs-number">42</span>
)
# 초기 클래스들의 히스토그램 출력
plt.<span class="hljs-title function_">figure</span>(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))
plt.<span class="hljs-title function_">hist</span>(y, bins=<span class="hljs-title function_">range</span>(<span class="hljs-number">4</span>), align=<span class="hljs-string">'left'</span>, rwidth=<span class="hljs-number">0.8</span>, color=<span class="hljs-string">'blue'</span>, alpha=<span class="hljs-number">0.7</span>)
plt.<span class="hljs-title function_">title</span>(<span class="hljs-string">"초기 클래스들의 히스토그램"</span>)
plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">"클래스"</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">"인스턴스 개수"</span>)
plt.<span class="hljs-title function_">xticks</span>(<span class="hljs-title function_">range</span>(<span class="hljs-number">3</span>), [<span class="hljs-string">'클래스 0'</span>, <span class="hljs-string">'클래스 1'</span>, <span class="hljs-string">'클래스 2'</span>])
plt.<span class="hljs-title function_">show</span>()
# <span class="hljs-title class_">RandomOverSampler</span>를 사용하여 오버샘플링 적용
oversampler = <span class="hljs-title class_">RandomOverSampler</span>(sampling_strategy=<span class="hljs-string">'auto'</span>, random_state=<span class="hljs-number">42</span>)
X_resampled, y_resampled = oversampler.<span class="hljs-title function_">fit_resample</span>(X, y)
# 재샘플링된 클래스들의 히스토그램 출력
plt.<span class="hljs-title function_">figure</span>(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))
plt.<span class="hljs-title function_">hist</span>(y_resampled, bins=<span class="hljs-title function_">range</span>(<span class="hljs-number">4</span>), align=<span class="hljs-string">'left'</span>, rwidth=<span class="hljs-number">0.8</span>, color=<span class="hljs-string">'orange'</span>, alpha=<span class="hljs-number">0.7</span>)
plt.<span class="hljs-title function_">title</span>(<span class="hljs-string">"재샘플링된 클래스들의 히스토그램 (오버샘플링)"</span>)
plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">"클래스"</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">"인스턴스 개수"</span>)
plt.<span class="hljs-title function_">xticks</span>(<span class="hljs-title function_">range</span>(<span class="hljs-number">3</span>), [<span class="hljs-string">'클래스 0'</span>, <span class="hljs-string">'클래스 1'</span>, <span class="hljs-string">'클래스 2'</span>])
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_8.png">
<h2>언더샘플링</h2>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>언더샘플링은 머신 러닝에서 사용되는 샘플링 기술 중 하나로, 주요 클래스의 인스턴스 수를 줄여 클래스 분포를 균형있게 만드는 것에 초점을 맞춥니다. 주로 주요 클래스에서 인스턴스를 무작위로 제거해 두 클래스가 보다 균형 잡힌 표현이 되도록 하는 방식입니다. 여기에는 언더샘플링의 장단점이 있습니다.</p>
<p>장점:</p>
<ul>
<li>과적합 위험이 감소합니다. 언더샘플링은 오버샘플링과 비교하여 과적합 위험을 줄입니다. 주요 클래스의 인스턴스 수를 줄이면 모델이 학습 데이터를 외워버리는 경향이 줄어들고 새로운, 보이지 않는 데이터에 대해 더 잘 일반화할 수 있습니다.</li>
<li>빠른 학습 시간입니다. 언더샘플링을 거친 후 데이터셋에는 더 이상 적은 인스턴스가 있기 때문에 머신 러닝 알고리즘의 학습 시간을 줄일 수 있습니다. 보통 데이터가 적을수록 학습 시간이 더 빨라집니다.</li>
</ul>
<p>단점:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>정보 손실. 언더샘플링은 주요 클래스에서 인스턴스를 버림으로써 귀중한 정보 손실을 야기할 수 있습니다. 만일 버려진 인스턴스에 주요 클래스의 전반적인 이해에 기여하는 중요한 특성이 있다면 문제가 될 수 있습니다.</li>
<li>편향된 모델의 위험. 주요 클래스에서 인스턴스를 제거하면 편향된 모델을 유발할 수 있으며, 이는 실제 주요 클래스의 분포를 정확하게 포착하지 못할 수 있습니다. 이러한 편향은 모델이 실제 세계 상황에 일반화하는 능력에 영향을 줄 수 있습니다.</li>
<li>주요 클래스에서의 성능 저하 가능성. 언더샘플링은 주요 클래스에서 성능이 나쁜 모델을 유발할 수 있습니다. 왜냐하면 학습할 정보가 적기 때문입니다. 이는 주요 클래스의 인스턴스를 잘못 분류할 수 있게 됩니다.</li>
<li>샘플링 비율에 민감함. 언더샘플링 정도는 모델의 성능에 중대한 영향을 미칠 수 있습니다. 샘플링 비율이 과도하면 주요 클래스의 중요한 정보가 손실될 수 있고, 너무 보수적이면 클래스 불균형 문제가 계속 남을 수 있습니다.</li>
</ul>
<p>아래는 파이썬에서 불균형 데이터셋에 대해 언더샘플링 기술을 활용하는 방법입니다:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_classification
<span class="hljs-keyword">from</span> imblearn.under_sampling <span class="hljs-keyword">import</span> RandomUnderSampler
<span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter
</code></pre>
<pre><code class="hljs language-python"><span class="hljs-comment"># 3개 클래스를 갖는 불균형 데이터셋 생성</span>
X, y = make_classification(
    n_samples=<span class="hljs-number">1000</span>,
    n_features=<span class="hljs-number">20</span>,
    n_classes=<span class="hljs-number">3</span>,
    n_clusters_per_class=<span class="hljs-number">1</span>,
    weights=[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>],  <span class="hljs-comment"># 클래스 불균형</span>
    random_state=<span class="hljs-number">42</span>
)
<span class="hljs-comment"># 초기 클래스 히스토그램 출력</span>
plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))
plt.hist(y, bins=<span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>), align=<span class="hljs-string">'left'</span>, rwidth=<span class="hljs-number">0.8</span>, color=<span class="hljs-string">'blue'</span>, alpha=<span class="hljs-number">0.7</span>)
plt.title(<span class="hljs-string">"Initial Classes의 히스토그램"</span>)
plt.xlabel(<span class="hljs-string">"클래스"</span>)
plt.ylabel(<span class="hljs-string">"인스턴스 수"</span>)
plt.xticks(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>), [<span class="hljs-string">'클래스 0'</span>, <span class="hljs-string">'클래스 1'</span>, <span class="hljs-string">'클래스 2'</span>])
plt.show()
<span class="hljs-comment"># RandomUnderSampler를 사용하여 언더샘플링 적용</span>
undersampler = RandomUnderSampler(sampling_strategy=<span class="hljs-string">'auto'</span>, random_state=<span class="hljs-number">42</span>)
X_resampled, y_resampled = undersampler.fit_resample(X, y)
<span class="hljs-comment"># 재샘플링 클래스의 히스토그램 출력</span>
plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))
plt.hist(y_resampled, bins=<span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>), align=<span class="hljs-string">'left'</span>, rwidth=<span class="hljs-number">0.8</span>, color=<span class="hljs-string">'orange'</span>, alpha=<span class="hljs-number">0.7</span>)
plt.title(<span class="hljs-string">"Resampled Classes (언더샘플링)의 히스토그램"</span>)
plt.xlabel(<span class="hljs-string">"클래스"</span>)
plt.ylabel(<span class="hljs-string">"인스턴스 수"</span>)
plt.xticks(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>), [<span class="hljs-string">'클래스 0'</span>, <span class="hljs-string">'클래스 1'</span>, <span class="hljs-string">'클래스 2'</span>])
plt.show()
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>아래는 Markdown 형식으로 표를 변경한 것입니다.</p>
<p><img src="/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_9.png" alt="image"></p>
<h2>성능 비교</h2>
<p>다음은 Python 예제를 만들어보겠습니다.</p>
<ul>
<li>균형이 맞지 않은 데이터 세트를 만듭니다.</li>
<li>언더샘플링 및 오버샘플링을 진행합니다.</li>
<li>언더샘플링 및 오버샘플링된 데이터 세트에 대해 훈련 및 검증 세트를 만들고, KNN 분류기로 학습합니다.</li>
<li>언더샘플링 및 오버샘플링된 데이터 세트의 정확도를 비교합니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">datasets</span> <span class="hljs-keyword">import</span> make_classification
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">model_selection</span> <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">neighbors</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">KNeighborsClassifier</span>
<span class="hljs-keyword">from</span> imblearn.<span class="hljs-property">over_sampling</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">RandomOverSampler</span>
<span class="hljs-keyword">from</span> imblearn.<span class="hljs-property">under_sampling</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">RandomUnderSampler</span>
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">metrics</span> <span class="hljs-keyword">import</span> accuracy_score
</code></pre>
<pre><code class="hljs language-js"># <span class="hljs-number">3</span>개의 클래스를 가진 불균형 데이터셋 생성
X, y = <span class="hljs-title function_">make_classification</span>(
    n_samples=<span class="hljs-number">1000</span>,
    n_features=<span class="hljs-number">20</span>,
    n_classes=<span class="hljs-number">3</span>,
    n_clusters_per_class=<span class="hljs-number">1</span>,
    weights=[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>],  # 클래스 불균형
    random_state=<span class="hljs-number">42</span>
)
# 원본 데이터셋을 학습 및 테스트 세트로 분할
X_train, X_test, y_train, y_test = <span class="hljs-title function_">train_test_split</span>(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>)
# <span class="hljs-title class_">RandomOverSampler</span>를 사용하여 오버샘플링 적용
oversampler = <span class="hljs-title class_">RandomOverSampler</span>(sampling_strategy=<span class="hljs-string">'auto'</span>, random_state=<span class="hljs-number">42</span>)
X_train_oversampled, y_train_oversampled = oversampler.<span class="hljs-title function_">fit_resample</span>(X_train, y_train)
# <span class="hljs-title class_">RandomUnderSampler</span>를 사용하여 언더샘플링 적용
undersampler = <span class="hljs-title class_">RandomUnderSampler</span>(sampling_strategy=<span class="hljs-string">'auto'</span>, random_state=<span class="hljs-number">42</span>)
X_train_undersampled, y_train_undersampled = undersampler.<span class="hljs-title function_">fit_resample</span>(X_train, y_train)
# 원본 학습 세트에 <span class="hljs-variable constant_">KNN</span> 분류기 피팅
knn_original = <span class="hljs-title class_">KNeighborsClassifier</span>(n_neighbors=<span class="hljs-number">5</span>)
knn_original.<span class="hljs-title function_">fit</span>(X_train, y_train)
# 오버샘플링된 학습 세트에 <span class="hljs-variable constant_">KNN</span> 분류기 피팅
knn_oversampled = <span class="hljs-title class_">KNeighborsClassifier</span>(n_neighbors=<span class="hljs-number">5</span>)
knn_oversampled.<span class="hljs-title function_">fit</span>(X_train_oversampled, y_train_oversampled)
# 언더샘플링된 학습 세트에 <span class="hljs-variable constant_">KNN</span> 분류기 피팅
knn_undersampled = <span class="hljs-title class_">KNeighborsClassifier</span>(n_neighbors=<span class="hljs-number">5</span>)
knn_undersampled.<span class="hljs-title function_">fit</span>(X_train_undersampled, y_train_undersampled)
# 학습 세트에 대한 예측 수행
y_train_pred_original = knn_original.<span class="hljs-title function_">predict</span>(X_train)
y_train_pred_oversampled = knn_oversampled.<span class="hljs-title function_">predict</span>(X_train_oversampled)
y_train_pred_undersampled = knn_undersampled.<span class="hljs-title function_">predict</span>(X_train_undersampled)
# 테스트 세트에 대한 예측 수행
y_test_pred_original = knn_original.<span class="hljs-title function_">predict</span>(X_test)
y_test_pred_oversampled = knn_oversampled.<span class="hljs-title function_">predict</span>(X_test)
y_test_pred_undersampled = knn_undersampled.<span class="hljs-title function_">predict</span>(X_test)
# 학습 세트의 정확도 계산 및 출력
<span class="hljs-title function_">print</span>(<span class="hljs-string">"원본 학습 세트 정확도:"</span>, <span class="hljs-title function_">accuracy_score</span>(y_train, y_train_pred_original))
<span class="hljs-title function_">print</span>(<span class="hljs-string">"오버샘플링된 학습 세트 정확도:"</span>, <span class="hljs-title function_">accuracy_score</span>(y_train_oversampled, y_train_pred_oversampled))
<span class="hljs-title function_">print</span>(<span class="hljs-string">"언더샘플링된 학습 세트 정확도:"</span>, <span class="hljs-title function_">accuracy_score</span>(y_train_undersampled, y_train_pred_undersampled))
# 테스트 세트의 정확도 계산 및 출력
<span class="hljs-title function_">print</span>(<span class="hljs-string">"\n원본 테스트 세트 정확도:"</span>, <span class="hljs-title function_">accuracy_score</span>(y_test, y_test_pred_original))
<span class="hljs-title function_">print</span>(<span class="hljs-string">"오버샘플링된 테스트 세트 정확도:"</span>, <span class="hljs-title function_">accuracy_score</span>(y_test, y_test_pred_oversampled))
<span class="hljs-title function_">print</span>(<span class="hljs-string">"언더샘플링된 테스트 세트 정확도:"</span>, <span class="hljs-title function_">accuracy_score</span>(y_test, y_test_pred_undersampled))
</code></pre>
<p>결과:</p>
<pre><code class="hljs language-js">원본 학습 세트 정확도: <span class="hljs-number">0.9125</span>
오버샘플링된 학습 세트 정확도: <span class="hljs-number">0.9514767932489452</span>
언더샘플링된 학습 세트 정확도: <span class="hljs-number">0.85</span>
</code></pre>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">원본 테스트 세트 정확도: <span class="hljs-number">0.885</span>
오버샘플링된 테스트 세트 정확도: <span class="hljs-number">0.79</span>
언더샘플링된 테스트 세트 정확도: <span class="hljs-number">0.805</span>
</code></pre>
<p>정확도 지표 비교를 통해 이러한 방법론의 특징을 확인할 수 있습니다:</p>
<ul>
<li>오버샘플링 기술은 KNN 모델이 오버피팅되고 있는 것을 시사하며, 이는 오버샘플링 그 자체 때문입니다.</li>
<li>언더샘플링 기술은 KNN 모델이 편향될 수 있음을 시사하며, 이는 언더샘플링 그 자체 때문입니다.</li>
<li>리샘플링 없이 모델을 학습시킨 것은 데이터의 불균형으로 정확도가 잘못 이끌 수 있음을 보여줍니다.</li>
</ul>
<p>따라서 이 경우, 가능한 해결책은 오버샘플링을 사용하고 KNN의 하이퍼파라미터를 조정하여 오버피팅을 피할 수 있는지 확인해 보는 것입니다.</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>앙상블</h1>
<p>불균형 데이터를 다루는 또 다른 방법은 앙상블 학습을 사용하는 것입니다. 특히, 랜덤 포레스트(Random Forest, RF)는 여러 의사 결정 트리 모델의 앙상블인데, 주 클래스에 편향되지 않는 내재적 능력으로 널리 사용되는 머신 러닝 모델입니다.</p>
<p>그 이유는 다음과 같습니다:</p>
<ul>
<li>Bootstrap 샘플링. RF 모델은 무작위 샘플링을 사용하여 작동합니다. 즉, 다양한 의사 결정 트리 모델을 훈련하는 동안, 선택된 데이터는 전체 데이터 세트의 무작위 하위 집합을 사용하고, 데이터는 대체됩니다. 이는 평균적으로 각 의사 결정 트리가 원래 데이터의 약 2/3에 대해 훈련됩니다. 결과적으로 소수 클래스의 일부 인스턴스가 의사 결정 트리를 작성하는 데 사용된 하위 집합에 포함될 가능성이 높습니다. 샘플 선택의 이 랜덤성은 주요 및 소수 클래스의 영향을 균형있게 조정하는 데 도움이 됩니다.</li>
<li>무작위 특성 선택. 데이터를 무작위화하는 것 외에도, 랜덤 포레스트는 각 트리의 각 노드에 대해 무작위로 특성을 선택합니다. 즉, 분할할 때 고려할 특성의 무작위 하위 집합을 선택합니다. 이 특성의 무작위성은 대부분 주 클래스를 대표하는 특성에 대한 잠재적인 편향을 줄입니다.</li>
<li>오류 수정 메커니즘. 랜덤 포레스트는 그 자체의 앙상블 성격을 통해 오류 수정 메커니즘을 사용합니다. 앙상블에서 한 의사 결정 트리가 소수 클래스 인스턴스에서 오류를 발생시키면, 앙상블의 다른 트리들은 해당 인스턴스에 대해 정확한 예측을 함으로써 보상할 수 있습니다. 앙상블 기반의 오류 수정은 주요 클래스의 우세함을 완화하는 데 도움이 됩니다.</li>
</ul>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이전에 만든 데이터세트를 고려해 봅시다. 랜덤 포레스트 분류기를 사용하여 적합한 결과를 살펴봅시다:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">datasets</span> <span class="hljs-keyword">import</span> make_classification
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">model_selection</span> <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">ensemble</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">RandomForestClassifier</span>
<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">metrics</span> <span class="hljs-keyword">import</span> accuracy_score
</code></pre>
<pre><code class="hljs language-js"># <span class="hljs-number">3</span>개의 클래스로 불균형 데이터세트 생성
X, y = <span class="hljs-title function_">make_classification</span>(
    n_samples=<span class="hljs-number">1000</span>,
    n_features=<span class="hljs-number">20</span>,
    n_classes=<span class="hljs-number">3</span>,
    n_clusters_per_class=<span class="hljs-number">1</span>,
    weights=[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>],  # 클래스 불균형
    random_state=<span class="hljs-number">42</span>
)
# 데이터세트를 훈련 세트와 테스트 세트로 분할
X_train, X_test, y_train, y_test = <span class="hljs-title function_">train_test_split</span>(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>)
# 훈련 세트에 랜덤 포레스트 분류기를 적합
rf_classifier = <span class="hljs-title class_">RandomForestClassifier</span>(random_state=<span class="hljs-number">42</span>)
rf_classifier.<span class="hljs-title function_">fit</span>(X_train, y_train)
# 훈련 세트와 테스트 세트에 대한 예측 생성
y_train_pred = rf_classifier.<span class="hljs-title function_">predict</span>(X_train)
y_test_pred = rf_classifier.<span class="hljs-title function_">predict</span>(X_test)
# 훈련 세트의 정확도 계산 및 출력
train_accuracy = <span class="hljs-title function_">accuracy_score</span>(y_train, y_train_pred)
<span class="hljs-title function_">print</span>(<span class="hljs-string">"훈련 세트 정확도:"</span>, train_accuracy)
# 테스트 세트의 정확도 계산 및 출력
test_accuracy = <span class="hljs-title function_">accuracy_score</span>(y_test, y_test_pred)
<span class="hljs-title function_">print</span>(<span class="hljs-string">"테스트 세트 정확도:"</span>, test_accuracy)
</code></pre>
<p>그리고 우리는 다음과 같은 결과를 얻습니다:</p>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">학습 세트 정확도: <span class="hljs-number">1.0</span>
테스트 세트 정확도: <span class="hljs-number">0.97</span>
</code></pre>
<p>이 경우에는 랜덤 포레스트를 사용했기 때문에 데이터 세트를 다시 샘플링할 필요가 없었습니다. 그래도 결과는 모델이 과적합될 가능성을 시사합니다. 이는 랜덤 포레스트 특성 때문일 수 있으므로 하이퍼파라미터 튜닝을 위해 추가적인 조사가 필요할 것입니다.</p>
<p>어쨌든, 이 경우에는 하이퍼파라미터 튜닝 후 RF 모델을 사용하는 것이 KNN을 사용하고 데이터 세트를 언더샘플링하거나 오버샘플링하는 것보다 좋은 선택일 수 있습니다.</p>
<h1>결론</h1>
<!-- TIL 수평 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="1549334788" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 기사에서는 기계 학습(Machine Learning)에서 불균형 데이터를 다루는 방법에 대해 논의했습니다.</p>
<p>특히, 희귀한 사건을 연구하기 때문에 데이터가 불균형할 것으로 예상되는 상황이 있습니다.</p>
<p>반면에 데이터가 불균형해서는 안 되는 경우, 리샘플링(resampling)과 앙상블링(ensembling)과 같은 ML 모델을 다루는 방법에 대한 몇 가지 방법론을 소개했습니다.</p>
<p>원문은 2024년 3월 7일 <a href="https://semaphoreci.com" rel="nofollow" target="_blank">https://semaphoreci.com</a> 에서 게시되었습니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Python으로 머신러닝에서 불균형 데이터 다루는 방법","description":"","date":"2024-07-09 14:33","slug":"2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython","content":"\n기계 학습의 분류 문제를 다룰 때 고려해야 할 중요한 요소 중 하나는 레이블을 정의하는 클래스의 균형입니다.\n\n세 개의 클래스로 이루어진 상황을 상상해보세요. 초기 분석을 수행하여 정확도를 계산하면 93%를 얻을 수 있습니다. 그런 다음 더 깊게 들여다보는데, 데이터의 80%가 한 클래스에 속한다는 것을 알 수 있습니다. 이것이 좋은 징후인가요?\n\n음, 그렇지 않습니다. 이 문서에서는 그 이유를 설명하고 있습니다.\n\n# 초보자를 위한 Jupyter 노트북 설정하기\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기계 학습 초보자라면, ML 문제를 해결하기 위해 두 가지 소프트웨어를 사용할 수 있다는 것을 모를 수 있습니다:\n\n- Anaconda\n- Google Colaboratory\n\nAnaconda는 데이터 분석 및 기계 학습으로 예측을 하는 데 필요한 모든 라이브러리를 제공하는 데이터 과학 플랫폼입니다. 또한 데이터 과학자들이 데이터를 분석하는 데 사용하는 Jupyter Notebooks를 제공합니다. 따라서 Anaconda를 설치하면 필요한 모든 것을 갖추게 됩니다.\n\n반면에 Google Colaboratory는 설정이 필요 없는 호스팅된 Jupyter Notebook 서비스로, 무료로 컴퓨팅 리소스 및 필요한 모든 라이브러리에 대한 액세스를 제공합니다. 따라서 PC에 아무것도 설치하지 않고 데이터를 분석하려면 이 솔루션을 선택할 수 있습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마침내, 이 글에서 찾을 수 있는 모든 코드를 포함하는 공개 저장소를 만들었습니다. 이 저장소는 하나의 Jupyter Notebook에 있어 데이터 과학자들이 데이터를 분석하는 방식을 확인하고자 할 때 참고할 수 있습니다.\n\n# 머신 러닝에서 불균형 데이터 소개\n\n이 섹션은 머신 러닝에서 클래스 불균형 문제를 소개하고, 불균형 클래스가 흔한 시나리오를 다룹니다. 그러나 계속하기 전에, \"불균형\" 또는 \"균형이 맞지 않는\" 용어를 무시하고 사용할 수 있다는 점을 얘기합시다.\n\n# 불균형 데이터 정의 및 모델 성능에 미치는 영향\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n상상해봐요. 당신이 100명의 학생들을 가르치는 수학 선생님인 상황을 상상해보세요. 이 학생들 중 90명은 수학을 잘하는 학생(Group A), 그리고 10명은 어려워하는 학생들(Group B)이라고 부를 수 있겠네요. 이 수업 구성은 기계 학습 세상에서 \"불균형 데이터\"로 알려져 있어요.\n\n기계 학습에서 데이터는 컴퓨터에 예측이나 결정을 내리도록 가르치는 데 사용되는 교과서와 같아요. 불균형 데이터가 있다는 것은 컴퓨터가 배워야 하는 것들에 대한 예제 수에 큰 차이가 있다는 것을 의미해요. 우리의 수업 비유에 따르면, 과반이 되는 A 그룹보다 소수인 B 그룹의 학생 수가 적어요.\n\n이제 우리의 기계 학습 모델의 성능은 불균형 데이터에 영향을 받아요. 예를 들어, 여기에는 몇 가지 영향들이 있어요:\n\n- 편향된 학습. 대부분의 학생들이 수학을 잘하는 이 불균형한 수업에서 컴퓨터를 가르치면, 약간 편향될 수 있어요. 마치 컴퓨터가 수학 천재들에게 둘러싸인 듯하니, 모두가 수학 천재인 것으로 생각할 수 있어요. 기계 학습 용어로는 모델이 과반수 클래스 쪽으로 편향될 수 있어요. 그것은 일반적인 것(Group A)을 예측하는 데 능숙해지지만 드문 것(Group B)을 이해하는 데 어려움을 겪을 수 있어요. 당신이 학생들의 투표를 사용하여 수학 가르치기에 얼마나 능숙한지를 평가한다면, 90%의 학생이 수학을 잘하는 것이기 때문에 편향된 결과를 받을 수 있어요. 그런데 이 90% 중 대부분이 사설 수업을 듣고 있다면 당신은 알 수 없어요.\n- 잘못된 정확도. 컴퓨터의 성능을 평가하려면 컴퓨터가 수학을 잘하는 학생이나 어려워하는 학생을 올바르게 식별한 횟수를 확인하여야 해요. A 그룹이 많기 때문에 컴퓨터는 대부분의 학생을 올바르게 맞출 수 있을 거예요. 그래서 정확도가 높아 보인다면 컴퓨터가 훌륭한 일을 하는 것처럼 보일 수 있어요. 그러나 B 그룹이 적기 때문에 실제로는 B 그룹에는 엉망진창일 수 있어요. 기계 학습에서 이 높은 정확도는 컴퓨터가 소수 클래스에서 얼마나 잘 수행되고 있는지 알려주지 않아서 잘못된 정보일 수 있어요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n간단히 말해서, 불균형 데이터는 컴퓨터에 학습시키려는 서로 다른 사례들에 대해 불균형한 예제 수가 있다는 것을 의미하며, 특히 드물게 발생하는 경우를 처리할 때 머신러닝 모델의 성능에 심각한 영향을 미칠 수 있습니다.\n\n어쨌든, 데이터가 불균형할 것으로 예상되는 경우도 있습니다.\n\n이것들에 대해 설명하기 전에 먼저 어떤 경우에 불균형 데이터가 일반적인지 살펴보겠습니다.\n\n# 불균형 데이터가 흔한 시나리오\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현실적인 시나리오에서는 데이터가 불균형적인 경우가 많이 발생합니다. 만약 그렇지 않다면, 오류가 있는 것을 의미합니다.\n\n예를 들어 의학 분야를 생각해보겠습니다. 대규모 인구 중에서 희귀 질병을 찾으려고 할 때, 데이터는 불균형해야 합니다. 그렇지 않으면 우리가 찾고 있는 질병이 희귀하지 않다는 것을 의미합니다.\n\n사기 탐지의 경우도 마찬가지입니다. 금융 기관의 데이터 과학자로서 신용 카드에서 사기 거래를 분석하고 있을 때, 불균형한 데이터를 발견해야 합니다. 그렇지 않으면 사기 거래가 비-사기 거래만큼 자주 발생한다는 것을 의미합니다.\n\n# 불균형 문제 이해하기\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 Python 코드와 함께 실제 상황에 대해 알아볼까요? 이를 통해 다음을 보여줄 수 있습니다:\n\n- 그래픽을 기반으로 한 주요 및 소수 클래스 간의 차이.\n- 불균형한 데이터에 영향을 받는 평가 지표들.\n- 불균형한 데이터에 영향을 받지 않는 평가 지표들.\n\n# 주요 및 소수 클래스 간의 차이\n\n수학 선생님인 당신이라고 가정해보겠습니다. 이번에는 1000명의 학생으로 이루어진 대규모 강의를 하고 있습니다. 머신러닝을 사용하여 어떠한 분류를 수행하기 전에, 데이터가 불균형인지 확인하기로 결정했습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하나의 방법은 분포를 시각화하는 것입니다. 예를 들어, 다음과 같이:\n\n```js\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n```js\n# 재현 가능성을 위해 랜덤 시드 설정\nnp.random.seed(42)\n# 다수 클래스 (Class 0)를 위한 데이터 생성\nmajority_class = np.random.normal(0, 1, 900)\n# 소수 클래스 (Class 1)를 위한 데이터 생성\nminority_class = np.random.normal(3, 1, 100)\n# 다수 클래스와 소수 클래스 데이터 결합\ndata = np.concatenate((majority_class, minority_class))\n# 클래스 레이블 생성\nlabels = np.concatenate((np.zeros(900), np.ones(100)))\n# 클래스 분포 플로팅\nplt.figure(figsize=(8, 6))\nplt.hist(data[labels == 0], bins=20, color='blue', alpha=0.6, label='다수 클래스 (Class 0)')\nplt.hist(data[labels == 1], bins=20, color='red', alpha=0.6, label='소수 클래스 (Class 1)')\nplt.xlabel('특성 값')\nplt.ylabel('빈도수')\nplt.title('불균형 데이터셋의 클래스 분포')\nplt.legend()\nplt.show()\n```\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 Python 예제에서는 두 개의 클래스를 만들었습니다:\n\n- 주요 클래스 (클래스 0). 이 클래스는 데이터 포인트의 대다수를 나타냅니다. 평균이 0이고 표준 편차가 1인 정규 분포에서 900개의 데이터 포인트를 생성했습니다. 실제 시나리오에서는 매우 흔하거나 전형적인 것을 나타낼 수 있습니다.\n- 소수 클래스 (클래스 1). 이 클래스는 데이터 포인트의 소수를 나타냅니다. 평균이 3이고 표준 편차가 1인 정규 분포에서 100개의 데이터 포인트를 생성했습니다. 이 클래스는 의도적으로 흔하지 않게 만들어져 불균형 데이터셋을 시뮬레이션합니다. 실제로는 드문 사건이나 이상을 나타낼 수 있습니다.\n\n다음으로, 이 두 클래스를 해당 레이블 (주요 클래스에 대한 0 및 소수 클래스에 대한 1)과 함께 단일 데이터셋으로 결합합니다. 마지막으로, 히스토그램을 사용하여 클래스 분포를 시각화합니다. 히스토그램에서:\n\n- 파란 막대는 주요 클래스 (클래스 0)를 나타내며, 좌측에 더 크고 더 빈번한 막대입니다.\n- 빨간 막대는 소수 클래스 (클래스 1)를 나타내며, 우측에 더 작고 덜 빈번한 막대입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 시각화는 불균형 데이터셋에서 주요 및 소수 클래스 간의 차이를 명확하게 보여줍니다. 주요 클래스는 소수 클래스보다 훨씬 많은 데이터 포인트를 가지고 있으며, 이는 불균형 데이터의 일반적인 특성입니다.\n\n클래스 불균형을 다루는 또 다른 방법은 분포를 통해 직접적으로 빈도를 살펴보는 것입니다. 예를 들어, 다음과 같이 할 수 있습니다:\n\n```js\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n```js\n# 재현성을 위해 임의의 시드 설정\nnp.random.seed(42)\n# 주요 클래스 (클래스 0)에 대한 데이터 생성\nmajority_class = np.random.normal(0, 1, 900)\n# 소수 클래스 (클래스 1)에 대한 데이터 생성\nminority_class = np.random.normal(3, 1, 100)\n# 주요 및 소수 클래스 데이터 결합\ndata = np.concatenate((majority_class, minority_class))\n# 클래스에 대한 레이블 생성\nlabels = np.concatenate((np.zeros(900), np.ones(100))\n# 각 클래스의 빈도 카운트\nclass_counts = [len(labels[labels == 0]), len(labels[labels == 1])]\n# 막대 그래프를 사용하여 클래스 빈도 플로팅\nplt.figure(figsize=(8, 6))\nplt.bar(['주요 클래스 (클래스 0)', '소수 클래스 (클래스 1)'], class_counts, color=['blue', 'red'])\nplt.xlabel('클래스')\nplt.ylabel('빈도')\nplt.title('불균형 데이터셋의 클래스 빈도')\nplt.show()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같이 테이블 태그를 마크다운 형식으로 변경해주세요.\n\n![image](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_1.png)\n\n그러니까, 이 경우에는 클래스에 속하는 데이터의 모든 발생을 계산하는 내장 메소드 len()을 사용할 수 있습니다.\n\n# 이상 데이터로 영향을 받는 일반 평가 지표\n\n이상 데이터에 영향을 받는 모든 평가 지표를 설명하려면 먼저 다음을 정의해야 합니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- True positive (TP). 분류기가 조건이나 특성의 존재를 올바르게 예측한 값\n- True negative (TN). 분류기가 조건이나 특성의 부재를 올바르게 예측한 값\n- False positive (FP). 분류기가 특정 조건이나 속성이 존재하는 것으로 잘못 예측한 값\n- False negative (FN). 분류기가 특정 조건이나 속성이 존재하지 않는 것으로 잘못 예측한 값\n\n다음은 불균형 데이터가 영향을 미치는 일반적인 평가 지표입니다:\n\n- 정확도. 데이터 세트에서 올바르게 예측된 인스턴스의 비율을 측정합니다.\n\n![이미지](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_2.png)\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬에서 정확도 지표를 계산하는 방법에 대한 예제를 만들어보겠습니다:\n\n```python\nfrom sklearn.metrics import accuracy_score\n```\n\n```python\n# 실제 레이블\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n# 모델이 예측한 레이블\npredicted_labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(\"정확도:\", accuracy)\n```\n\n결과는:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n정확도: 0.5;\n```\n\n정확도는 불균형한 데이터를 다룰 때 혼란을 줄 수 있습니다.\n\n실제로 95%가 A 클래스에 속하고 5%만 B 클래스에 속하는 데이터 세트가 있다고 가정해 봅시다. 모델이 모든 인스턴스를 A 클래스로 예측한다면 95%의 정확도를 달성할 것입니다. 하지만 이는 반드시 모델이 좋다는 것을 의미하지는 않습니다. 이는 단지 클래스 불균형을 악용한 것뿐입니다. 다시 말해, 이 메트릭은 소수 클래스 (B 클래스)를 얼마나 잘 식별하는지를 고려하지 않습니다.\n\n- 정밀도. 이것은 모든 예측된 긍정 인스턴스 중 올바르게 예측된 긍정 인스턴스의 비율을 측정합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![How to Handle Imbalanced Data for Machine Learning in Python](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_3.png)\n\n한 예제를 통해 Python에서 정밀도 지표를 계산하는 방법을 살펴보겠습니다:\n\n```python\nfrom sklearn.metrics import precision_score\n```\n\n```python\n# True labels\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n# Predicted labels by a model\npredicted_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nprecision = precision_score(true_labels, predicted_labels)\nprint(\"Precision:\", precision)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n결과는 다음과 같습니다:\n\n```js\n정밀도: 0.5;\n```\n\n불균형 데이터 세트에서는 정밀도가 매우 오해를 일으킬 수 있습니다.\n\n실제로, 모델이 하나의 인스턴스만을 긍정적(클래스 B)으로 분류하고 그게 맞는 경우, 정밀도는 100%가 될 것입니다. 그러나 이는 모델이 소수 클래스에서의 성능을 나타내는 것이 아닐 수 있습니다. 왜냐하면 많은 긍정적 인스턴스를 놓칠 수 있기 때문입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 재현율 (또는 민감도). 재현율은 또한 민감도 또는 진양성율로 알려져 있으며, 올바르게 예측된 긍정적 인스턴스의 비율을 측정합니다:\n\n![Example](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_4.png)\n\n파이썬을 사용하여 재현율 지표를 계산하는 예제를 만들어 보겠습니다:\n\n```js\nfrom sklearn.metrics import recall_score\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 실제 레이블\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n# 모델이 예측한 레이블\npredicted_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nrecall = recall_score(true_labels, predicted_labels)\nprint(\"재현율:\", recall)\n```\n\n결과는:\n\n```js\n재현율: 1.0;\n```\n\n재현율은 불균형한 데이터셋에서도 잘못된 정보를 줄 수 있습니다. 특히 모든 긍정적인 인스턴스를 포착하는 것이 중요할 때에는요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 모델이 더 많은 양의 양성 인스턴스가 있는 상황에서 한 인스턴스만을 양성(Class B)으로 예측할 경우, 재현율이 매우 낮을 수 있습니다. 이는 모델이 소수 클래스의 중요한 부분을 놓치고 있음을 나타낼 수 있습니다. 이는 이 메트릭이 false positives를 고려하지 않기 때문에 발생합니다.\n\n- F1 스코어. F1 스코어는 정밀도와 재현율의 조화평균입니다. 정밀도와 재현율 사이의 균형을 제공합니다:\n\n![image](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_5.png)\n\n파이썬을 사용하여 F1 스코어 메트릭을 계산하는 예제를 만들어봅시다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfrom sklearn.metrics import f1_score\n```\n\n```js\n# True labels\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n# Predicted labels by a model\npredicted_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n# Calculate and print F1-score\nf1 = f1_score(true_labels, predicted_labels)\nprint(\"F1-Score:\", f1)\n```\n\n결과는:\n\n```js\nF1-Score: 0.6666666666666666\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 메트릭은 정밀도와 재현율을 사용하여 생성되었기 때문에 데이터 불균형에 영향을 받을 수 있습니다.\n\n하나의 클래스가 지배적이고 (다수 클래스인 경우), 그 모델이 해당 클래스를 편향으로 처리하는 경우, F1 점수는 소수 클래스의 낮은 재현율에도 높은 정밀도 때문에 상대적으로 높을 수 있습니다. 이는 모델의 전체 효과를 잘못 나타낼 수 있습니다.\n\n# 데이터 불균형에 영향을 받지 않는 가장 많이 사용되는 평가 지표\n\n이제 클래스 불균형에 영향을 받지 않는 평가 지표 중 가장 많이 사용되는 두 가지를 설명하겠습니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 혼동 행렬. 혼동 행렬은 분류 알고리즘의 성능을 요약하는 표입니다. 이는 True Positives (TP), True Negatives (TN), False Positives (FP) 및 False Negatives (FN)의 자세한 분석을 제공합니다. 특히, 주 대각선(왼쪽 위에서 오른쪽 아래)은 TP와 TN을 보여주며, 보조 대각선(왼쪽 아래에서 오른쪽 위)은 FP와 FN을 나타냅니다. 따라서, 머신 러닝 모델이 데이터를 올바르게 분류할 경우, 혼동 행렬의 주 대각선은 가장 높은 값을, 보조 대각선은 가장 낮은 값을 보고해야 합니다.\n\n파이썬에서 예제를 보여드리겠습니다:\n\n```python\nfrom sklearn.metrics import confusion_matrix\n```\n\n```python\n# True and predicted labels\ntrue_labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\npredicted_labels = [0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n# Create confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels)\n# Print confusion matrix\nprint(\"Confusion Matrix:\")\nprint(cm)\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 저희가 얻은 것은:\n\n```js\n혼동 행렬:\n[[5 0]\n [1 4]]\n```\n\n이 혼동 행렬은 주 대각선에 결과가 가장 많기 때문에(10개 중 9개) 좋은 분류기를 나타냅니다. 이는 분류기가 5개의 TP와 4개의 TN을 예측했다는 것을 의미합니다.\n\n그에 비해, 보조 대각선은 낮은 결과를 보여줍니다(10개 중 1개). 이는 분류기가 1개의 FP와 0개의 FN을 예측했음을 의미합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러므로 이것은 좋은 분류기로 이어집니다.\n\n따라서 혼동 행렬은 모델 성능의 자세한 분석을 제공하여 각 클래스에 대해 올바르게 또는 잘못 분류된 인스턴스의 수를 몇 초 안에 알 수 있도록합니다.\n\n- AUC/ROC 커브. ROC는 \"Receiver Operating Characteristic\"의 약자로, 참 긍정률 (TPR)을 다른 임계값에서 거짓 긍정률 (FPR)에 대비하여 그래픽 방식으로 그리는 분류기를 평가하는 방법입니다.\n\n우리는 다음과 같이 정의합니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- TPR을 민감도로(우리가 말했듯이 recall로도 불릴 수 있음).\n- FPR을 1-특이도로 정의합니다.\n\n특이도는 분류기가 모든 부정적인 샘플을 찾는 능력을 의미합니다:\n\n![이미지](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_6.png)\n\nAUC는 ROC 곡선 아래 영역을 나타내며 \"곡선 아래 영역\"을 의미합니다. 이는 0에서 1사이의 전체적인 성능 지표로, 1은 분류기가 레이블의 100%를 실제 값으로 예측한다는 것을 의미하며, 서로 다른 분류기들을 비교할 때 더 적합합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 이진 분류 문제를 공부한다고 가정해봅시다. 파이썬에서 AUC 곡선을 그리는 방법은 다음과 같습니다:\n\n```python\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\n```\n\n```python\n# 무작위로 이진 분류 데이터세트 생성\nX, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n# 데이터세트를 학습 및 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# 학습 데이터에서 로지스틱 회귀 모델 학습\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n# 테스트 데이터에 대해 확률 예측\nprobs = model.predict_proba(X_test)\n# ROC 곡선 및 AUC 점수 계산\nfpr, tpr, thresholds = roc_curve(y_test, probs[:, 1])\nauc_score = roc_auc_score(y_test, probs[:, 1])\n# ROC 곡선 그리기\nplt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_score))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc='lower right')\nplt.show()\n```\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_7.png\" /\u003e\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 코드로는 다음을 할 수 있어요:\n\n- make_classification 메서드로 분류 데이터셋을 생성했어요.\n- 데이터셋을 훈련 세트와 테스트 세트로 나눴어요.\n- Logistic Regression 분류기로 훈련 세트를 fit했어요.\n- predict_proba() 메서드로 테스트 데이터에 대한 예측을 만들었어요.\n- ROC 곡선과 AUC 점수를 계산했어요.\n- AUC 곡선을 그렸어요.\n\n# 불균형 데이터 다루는 기술\n\n이 섹션에서는 불균형 데이터를 다루는 몇 가지 기술을 다루겠어요.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다시 말해, 우리는 불균형 데이터를 다루는 방법에 대해 이야기할 것입니다.\n\n## 리샘플링\n\n불균형 데이터셋을 처리하는 데 널리 사용되는 방법론은 리샘플링입니다. 이 방법론은 두 가지 다른 프로세스로 나눌 수 있습니다:\n\n- 오버샘플링. 소수 클래스에 더 많은 예제를 추가하는 것을 의미합니다.\n- 언더샘플링. 다수 클래스에서 샘플을 제거하는 것을 의미합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 가지 방법에 대해 설명해 보겠습니다.\n\n## Oversampling\n\nOversampling은 소수 클래스의 인스턴스 수를 늘려 클래스 분포를 균형있게 만드는 재표본화 기술입니다. 주로 기존 인스턴스를 복제하거나 소수 클래스와 유사한 합성 데이터 포인트를 생성함으로써 수행됩니다. 목표는 모델이 훈련 중에 두 클래스의 더 균형 잡힌 표현을 볼 수 있도록 하는 것입니다.\n\n장점:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 모델 성능 향상. Oversampling은 소수 클래스의 특성을 더 잘 학습할 수 있도록 도와주어 전체적인 분류 성능을 향상시킬 수 있습니다, 특히 소수 클래스에 대해서 더욱 효과적입니다.\n- 정보 보존. 언더샘플링과는 달리, 오버샘플링은 과반 클래스의 모든 인스턴스를 보존하여 정보의 손실이 없도록 합니다.\n\n단점:\n\n- 과적합의 위험. 중복되거나 합성된 인스턴스는 적절하게 제어되지 않으면, 특히 합성 데이터가 기존 데이터와 너무 유사한 경우에는 과적합을 유발할 수 있습니다.\n- 훈련 시간 증가. 오버샘플링으로 인한 더 큰 데이터셋은 머신러닝 알고리즘의 학습 시간이 더 오래 걸릴 수 있습니다.\n\nPython에서 불균형한 데이터셋에 대한 오버샘플링 기술을 어떻게 활용할 수 있는지 알아보겠습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter\n```\n\n```js\n# 3개 클래스를 가지는 불균형 데이터셋 생성\nX, y = make_classification(\n    n_samples=1000,\n    n_features=20,\n    n_classes=3,\n    n_clusters_per_class=1,\n    weights=[0.1, 0.3, 0.6],  # 클래스 불균형\n    random_state=42\n)\n# 초기 클래스들의 히스토그램 출력\nplt.figure(figsize=(10, 6))\nplt.hist(y, bins=range(4), align='left', rwidth=0.8, color='blue', alpha=0.7)\nplt.title(\"초기 클래스들의 히스토그램\")\nplt.xlabel(\"클래스\")\nplt.ylabel(\"인스턴스 개수\")\nplt.xticks(range(3), ['클래스 0', '클래스 1', '클래스 2'])\nplt.show()\n# RandomOverSampler를 사용하여 오버샘플링 적용\noversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\nX_resampled, y_resampled = oversampler.fit_resample(X, y)\n# 재샘플링된 클래스들의 히스토그램 출력\nplt.figure(figsize=(10, 6))\nplt.hist(y_resampled, bins=range(4), align='left', rwidth=0.8, color='orange', alpha=0.7)\nplt.title(\"재샘플링된 클래스들의 히스토그램 (오버샘플링)\")\nplt.xlabel(\"클래스\")\nplt.ylabel(\"인스턴스 개수\")\nplt.xticks(range(3), ['클래스 0', '클래스 1', '클래스 2'])\nplt.show()\n```\n\n\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_8.png\" /\u003e\n\n## 언더샘플링\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n언더샘플링은 머신 러닝에서 사용되는 샘플링 기술 중 하나로, 주요 클래스의 인스턴스 수를 줄여 클래스 분포를 균형있게 만드는 것에 초점을 맞춥니다. 주로 주요 클래스에서 인스턴스를 무작위로 제거해 두 클래스가 보다 균형 잡힌 표현이 되도록 하는 방식입니다. 여기에는 언더샘플링의 장단점이 있습니다.\n\n장점:\n\n- 과적합 위험이 감소합니다. 언더샘플링은 오버샘플링과 비교하여 과적합 위험을 줄입니다. 주요 클래스의 인스턴스 수를 줄이면 모델이 학습 데이터를 외워버리는 경향이 줄어들고 새로운, 보이지 않는 데이터에 대해 더 잘 일반화할 수 있습니다.\n- 빠른 학습 시간입니다. 언더샘플링을 거친 후 데이터셋에는 더 이상 적은 인스턴스가 있기 때문에 머신 러닝 알고리즘의 학습 시간을 줄일 수 있습니다. 보통 데이터가 적을수록 학습 시간이 더 빨라집니다.\n\n단점:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 정보 손실. 언더샘플링은 주요 클래스에서 인스턴스를 버림으로써 귀중한 정보 손실을 야기할 수 있습니다. 만일 버려진 인스턴스에 주요 클래스의 전반적인 이해에 기여하는 중요한 특성이 있다면 문제가 될 수 있습니다.\n- 편향된 모델의 위험. 주요 클래스에서 인스턴스를 제거하면 편향된 모델을 유발할 수 있으며, 이는 실제 주요 클래스의 분포를 정확하게 포착하지 못할 수 있습니다. 이러한 편향은 모델이 실제 세계 상황에 일반화하는 능력에 영향을 줄 수 있습니다.\n- 주요 클래스에서의 성능 저하 가능성. 언더샘플링은 주요 클래스에서 성능이 나쁜 모델을 유발할 수 있습니다. 왜냐하면 학습할 정보가 적기 때문입니다. 이는 주요 클래스의 인스턴스를 잘못 분류할 수 있게 됩니다.\n- 샘플링 비율에 민감함. 언더샘플링 정도는 모델의 성능에 중대한 영향을 미칠 수 있습니다. 샘플링 비율이 과도하면 주요 클래스의 중요한 정보가 손실될 수 있고, 너무 보수적이면 클래스 불균형 문제가 계속 남을 수 있습니다.\n\n아래는 파이썬에서 불균형 데이터셋에 대해 언더샘플링 기술을 활용하는 방법입니다:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\n```\n\n```python\n# 3개 클래스를 갖는 불균형 데이터셋 생성\nX, y = make_classification(\n    n_samples=1000,\n    n_features=20,\n    n_classes=3,\n    n_clusters_per_class=1,\n    weights=[0.1, 0.3, 0.6],  # 클래스 불균형\n    random_state=42\n)\n# 초기 클래스 히스토그램 출력\nplt.figure(figsize=(10, 6))\nplt.hist(y, bins=range(4), align='left', rwidth=0.8, color='blue', alpha=0.7)\nplt.title(\"Initial Classes의 히스토그램\")\nplt.xlabel(\"클래스\")\nplt.ylabel(\"인스턴스 수\")\nplt.xticks(range(3), ['클래스 0', '클래스 1', '클래스 2'])\nplt.show()\n# RandomUnderSampler를 사용하여 언더샘플링 적용\nundersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\nX_resampled, y_resampled = undersampler.fit_resample(X, y)\n# 재샘플링 클래스의 히스토그램 출력\nplt.figure(figsize=(10, 6))\nplt.hist(y_resampled, bins=range(4), align='left', rwidth=0.8, color='orange', alpha=0.7)\nplt.title(\"Resampled Classes (언더샘플링)의 히스토그램\")\nplt.xlabel(\"클래스\")\nplt.ylabel(\"인스턴스 수\")\nplt.xticks(range(3), ['클래스 0', '클래스 1', '클래스 2'])\nplt.show()\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Markdown 형식으로 표를 변경한 것입니다.\n\n![image](/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_9.png)\n\n## 성능 비교\n\n다음은 Python 예제를 만들어보겠습니다.\n\n- 균형이 맞지 않은 데이터 세트를 만듭니다.\n- 언더샘플링 및 오버샘플링을 진행합니다.\n- 언더샘플링 및 오버샘플링된 데이터 세트에 대해 훈련 및 검증 세트를 만들고, KNN 분류기로 학습합니다.\n- 언더샘플링 및 오버샘플링된 데이터 세트의 정확도를 비교합니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import accuracy_score\n```\n\n```js\n# 3개의 클래스를 가진 불균형 데이터셋 생성\nX, y = make_classification(\n    n_samples=1000,\n    n_features=20,\n    n_classes=3,\n    n_clusters_per_class=1,\n    weights=[0.1, 0.3, 0.6],  # 클래스 불균형\n    random_state=42\n)\n# 원본 데이터셋을 학습 및 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# RandomOverSampler를 사용하여 오버샘플링 적용\noversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\nX_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n# RandomUnderSampler를 사용하여 언더샘플링 적용\nundersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\nX_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)\n# 원본 학습 세트에 KNN 분류기 피팅\nknn_original = KNeighborsClassifier(n_neighbors=5)\nknn_original.fit(X_train, y_train)\n# 오버샘플링된 학습 세트에 KNN 분류기 피팅\nknn_oversampled = KNeighborsClassifier(n_neighbors=5)\nknn_oversampled.fit(X_train_oversampled, y_train_oversampled)\n# 언더샘플링된 학습 세트에 KNN 분류기 피팅\nknn_undersampled = KNeighborsClassifier(n_neighbors=5)\nknn_undersampled.fit(X_train_undersampled, y_train_undersampled)\n# 학습 세트에 대한 예측 수행\ny_train_pred_original = knn_original.predict(X_train)\ny_train_pred_oversampled = knn_oversampled.predict(X_train_oversampled)\ny_train_pred_undersampled = knn_undersampled.predict(X_train_undersampled)\n# 테스트 세트에 대한 예측 수행\ny_test_pred_original = knn_original.predict(X_test)\ny_test_pred_oversampled = knn_oversampled.predict(X_test)\ny_test_pred_undersampled = knn_undersampled.predict(X_test)\n# 학습 세트의 정확도 계산 및 출력\nprint(\"원본 학습 세트 정확도:\", accuracy_score(y_train, y_train_pred_original))\nprint(\"오버샘플링된 학습 세트 정확도:\", accuracy_score(y_train_oversampled, y_train_pred_oversampled))\nprint(\"언더샘플링된 학습 세트 정확도:\", accuracy_score(y_train_undersampled, y_train_pred_undersampled))\n# 테스트 세트의 정확도 계산 및 출력\nprint(\"\\n원본 테스트 세트 정확도:\", accuracy_score(y_test, y_test_pred_original))\nprint(\"오버샘플링된 테스트 세트 정확도:\", accuracy_score(y_test, y_test_pred_oversampled))\nprint(\"언더샘플링된 테스트 세트 정확도:\", accuracy_score(y_test, y_test_pred_undersampled))\n```\n\n결과:\n\n```js\n원본 학습 세트 정확도: 0.9125\n오버샘플링된 학습 세트 정확도: 0.9514767932489452\n언더샘플링된 학습 세트 정확도: 0.85\n```\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n원본 테스트 세트 정확도: 0.885\n오버샘플링된 테스트 세트 정확도: 0.79\n언더샘플링된 테스트 세트 정확도: 0.805\n```\n\n정확도 지표 비교를 통해 이러한 방법론의 특징을 확인할 수 있습니다:\n\n- 오버샘플링 기술은 KNN 모델이 오버피팅되고 있는 것을 시사하며, 이는 오버샘플링 그 자체 때문입니다.\n- 언더샘플링 기술은 KNN 모델이 편향될 수 있음을 시사하며, 이는 언더샘플링 그 자체 때문입니다.\n- 리샘플링 없이 모델을 학습시킨 것은 데이터의 불균형으로 정확도가 잘못 이끌 수 있음을 보여줍니다.\n\n따라서 이 경우, 가능한 해결책은 오버샘플링을 사용하고 KNN의 하이퍼파라미터를 조정하여 오버피팅을 피할 수 있는지 확인해 보는 것입니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 앙상블\n\n불균형 데이터를 다루는 또 다른 방법은 앙상블 학습을 사용하는 것입니다. 특히, 랜덤 포레스트(Random Forest, RF)는 여러 의사 결정 트리 모델의 앙상블인데, 주 클래스에 편향되지 않는 내재적 능력으로 널리 사용되는 머신 러닝 모델입니다.\n\n그 이유는 다음과 같습니다:\n\n- Bootstrap 샘플링. RF 모델은 무작위 샘플링을 사용하여 작동합니다. 즉, 다양한 의사 결정 트리 모델을 훈련하는 동안, 선택된 데이터는 전체 데이터 세트의 무작위 하위 집합을 사용하고, 데이터는 대체됩니다. 이는 평균적으로 각 의사 결정 트리가 원래 데이터의 약 2/3에 대해 훈련됩니다. 결과적으로 소수 클래스의 일부 인스턴스가 의사 결정 트리를 작성하는 데 사용된 하위 집합에 포함될 가능성이 높습니다. 샘플 선택의 이 랜덤성은 주요 및 소수 클래스의 영향을 균형있게 조정하는 데 도움이 됩니다.\n- 무작위 특성 선택. 데이터를 무작위화하는 것 외에도, 랜덤 포레스트는 각 트리의 각 노드에 대해 무작위로 특성을 선택합니다. 즉, 분할할 때 고려할 특성의 무작위 하위 집합을 선택합니다. 이 특성의 무작위성은 대부분 주 클래스를 대표하는 특성에 대한 잠재적인 편향을 줄입니다.\n- 오류 수정 메커니즘. 랜덤 포레스트는 그 자체의 앙상블 성격을 통해 오류 수정 메커니즘을 사용합니다. 앙상블에서 한 의사 결정 트리가 소수 클래스 인스턴스에서 오류를 발생시키면, 앙상블의 다른 트리들은 해당 인스턴스에 대해 정확한 예측을 함으로써 보상할 수 있습니다. 앙상블 기반의 오류 수정은 주요 클래스의 우세함을 완화하는 데 도움이 됩니다.\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전에 만든 데이터세트를 고려해 봅시다. 랜덤 포레스트 분류기를 사용하여 적합한 결과를 살펴봅시다:\n\n```js\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n```\n\n```js\n# 3개의 클래스로 불균형 데이터세트 생성\nX, y = make_classification(\n    n_samples=1000,\n    n_features=20,\n    n_classes=3,\n    n_clusters_per_class=1,\n    weights=[0.1, 0.3, 0.6],  # 클래스 불균형\n    random_state=42\n)\n# 데이터세트를 훈련 세트와 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# 훈련 세트에 랜덤 포레스트 분류기를 적합\nrf_classifier = RandomForestClassifier(random_state=42)\nrf_classifier.fit(X_train, y_train)\n# 훈련 세트와 테스트 세트에 대한 예측 생성\ny_train_pred = rf_classifier.predict(X_train)\ny_test_pred = rf_classifier.predict(X_test)\n# 훈련 세트의 정확도 계산 및 출력\ntrain_accuracy = accuracy_score(y_train, y_train_pred)\nprint(\"훈련 세트 정확도:\", train_accuracy)\n# 테스트 세트의 정확도 계산 및 출력\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(\"테스트 세트 정확도:\", test_accuracy)\n```\n\n그리고 우리는 다음과 같은 결과를 얻습니다:\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n학습 세트 정확도: 1.0\n테스트 세트 정확도: 0.97\n```\n\n이 경우에는 랜덤 포레스트를 사용했기 때문에 데이터 세트를 다시 샘플링할 필요가 없었습니다. 그래도 결과는 모델이 과적합될 가능성을 시사합니다. 이는 랜덤 포레스트 특성 때문일 수 있으므로 하이퍼파라미터 튜닝을 위해 추가적인 조사가 필요할 것입니다.\n\n어쨌든, 이 경우에는 하이퍼파라미터 튜닝 후 RF 모델을 사용하는 것이 KNN을 사용하고 데이터 세트를 언더샘플링하거나 오버샘플링하는 것보다 좋은 선택일 수 있습니다.\n\n# 결론\n\n\u003c!-- TIL 수평 --\u003e\n\n\u003cins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 기계 학습(Machine Learning)에서 불균형 데이터를 다루는 방법에 대해 논의했습니다.\n\n특히, 희귀한 사건을 연구하기 때문에 데이터가 불균형할 것으로 예상되는 상황이 있습니다.\n\n반면에 데이터가 불균형해서는 안 되는 경우, 리샘플링(resampling)과 앙상블링(ensembling)과 같은 ML 모델을 다루는 방법에 대한 몇 가지 방법론을 소개했습니다.\n\n원문은 2024년 3월 7일 https://semaphoreci.com 에서 게시되었습니다.\n","ogImage":{"url":"/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png","tag":["Tech"],"readingTime":33},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e기계 학습의 분류 문제를 다룰 때 고려해야 할 중요한 요소 중 하나는 레이블을 정의하는 클래스의 균형입니다.\u003c/p\u003e\n\u003cp\u003e세 개의 클래스로 이루어진 상황을 상상해보세요. 초기 분석을 수행하여 정확도를 계산하면 93%를 얻을 수 있습니다. 그런 다음 더 깊게 들여다보는데, 데이터의 80%가 한 클래스에 속한다는 것을 알 수 있습니다. 이것이 좋은 징후인가요?\u003c/p\u003e\n\u003cp\u003e음, 그렇지 않습니다. 이 문서에서는 그 이유를 설명하고 있습니다.\u003c/p\u003e\n\u003ch1\u003e초보자를 위한 Jupyter 노트북 설정하기\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e기계 학습 초보자라면, ML 문제를 해결하기 위해 두 가지 소프트웨어를 사용할 수 있다는 것을 모를 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAnaconda\u003c/li\u003e\n\u003cli\u003eGoogle Colaboratory\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAnaconda는 데이터 분석 및 기계 학습으로 예측을 하는 데 필요한 모든 라이브러리를 제공하는 데이터 과학 플랫폼입니다. 또한 데이터 과학자들이 데이터를 분석하는 데 사용하는 Jupyter Notebooks를 제공합니다. 따라서 Anaconda를 설치하면 필요한 모든 것을 갖추게 됩니다.\u003c/p\u003e\n\u003cp\u003e반면에 Google Colaboratory는 설정이 필요 없는 호스팅된 Jupyter Notebook 서비스로, 무료로 컴퓨팅 리소스 및 필요한 모든 라이브러리에 대한 액세스를 제공합니다. 따라서 PC에 아무것도 설치하지 않고 데이터를 분석하려면 이 솔루션을 선택할 수 있습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e마침내, 이 글에서 찾을 수 있는 모든 코드를 포함하는 공개 저장소를 만들었습니다. 이 저장소는 하나의 Jupyter Notebook에 있어 데이터 과학자들이 데이터를 분석하는 방식을 확인하고자 할 때 참고할 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e머신 러닝에서 불균형 데이터 소개\u003c/h1\u003e\n\u003cp\u003e이 섹션은 머신 러닝에서 클래스 불균형 문제를 소개하고, 불균형 클래스가 흔한 시나리오를 다룹니다. 그러나 계속하기 전에, \"불균형\" 또는 \"균형이 맞지 않는\" 용어를 무시하고 사용할 수 있다는 점을 얘기합시다.\u003c/p\u003e\n\u003ch1\u003e불균형 데이터 정의 및 모델 성능에 미치는 영향\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e상상해봐요. 당신이 100명의 학생들을 가르치는 수학 선생님인 상황을 상상해보세요. 이 학생들 중 90명은 수학을 잘하는 학생(Group A), 그리고 10명은 어려워하는 학생들(Group B)이라고 부를 수 있겠네요. 이 수업 구성은 기계 학습 세상에서 \"불균형 데이터\"로 알려져 있어요.\u003c/p\u003e\n\u003cp\u003e기계 학습에서 데이터는 컴퓨터에 예측이나 결정을 내리도록 가르치는 데 사용되는 교과서와 같아요. 불균형 데이터가 있다는 것은 컴퓨터가 배워야 하는 것들에 대한 예제 수에 큰 차이가 있다는 것을 의미해요. 우리의 수업 비유에 따르면, 과반이 되는 A 그룹보다 소수인 B 그룹의 학생 수가 적어요.\u003c/p\u003e\n\u003cp\u003e이제 우리의 기계 학습 모델의 성능은 불균형 데이터에 영향을 받아요. 예를 들어, 여기에는 몇 가지 영향들이 있어요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e편향된 학습. 대부분의 학생들이 수학을 잘하는 이 불균형한 수업에서 컴퓨터를 가르치면, 약간 편향될 수 있어요. 마치 컴퓨터가 수학 천재들에게 둘러싸인 듯하니, 모두가 수학 천재인 것으로 생각할 수 있어요. 기계 학습 용어로는 모델이 과반수 클래스 쪽으로 편향될 수 있어요. 그것은 일반적인 것(Group A)을 예측하는 데 능숙해지지만 드문 것(Group B)을 이해하는 데 어려움을 겪을 수 있어요. 당신이 학생들의 투표를 사용하여 수학 가르치기에 얼마나 능숙한지를 평가한다면, 90%의 학생이 수학을 잘하는 것이기 때문에 편향된 결과를 받을 수 있어요. 그런데 이 90% 중 대부분이 사설 수업을 듣고 있다면 당신은 알 수 없어요.\u003c/li\u003e\n\u003cli\u003e잘못된 정확도. 컴퓨터의 성능을 평가하려면 컴퓨터가 수학을 잘하는 학생이나 어려워하는 학생을 올바르게 식별한 횟수를 확인하여야 해요. A 그룹이 많기 때문에 컴퓨터는 대부분의 학생을 올바르게 맞출 수 있을 거예요. 그래서 정확도가 높아 보인다면 컴퓨터가 훌륭한 일을 하는 것처럼 보일 수 있어요. 그러나 B 그룹이 적기 때문에 실제로는 B 그룹에는 엉망진창일 수 있어요. 기계 학습에서 이 높은 정확도는 컴퓨터가 소수 클래스에서 얼마나 잘 수행되고 있는지 알려주지 않아서 잘못된 정보일 수 있어요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e간단히 말해서, 불균형 데이터는 컴퓨터에 학습시키려는 서로 다른 사례들에 대해 불균형한 예제 수가 있다는 것을 의미하며, 특히 드물게 발생하는 경우를 처리할 때 머신러닝 모델의 성능에 심각한 영향을 미칠 수 있습니다.\u003c/p\u003e\n\u003cp\u003e어쨌든, 데이터가 불균형할 것으로 예상되는 경우도 있습니다.\u003c/p\u003e\n\u003cp\u003e이것들에 대해 설명하기 전에 먼저 어떤 경우에 불균형 데이터가 일반적인지 살펴보겠습니다.\u003c/p\u003e\n\u003ch1\u003e불균형 데이터가 흔한 시나리오\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e현실적인 시나리오에서는 데이터가 불균형적인 경우가 많이 발생합니다. 만약 그렇지 않다면, 오류가 있는 것을 의미합니다.\u003c/p\u003e\n\u003cp\u003e예를 들어 의학 분야를 생각해보겠습니다. 대규모 인구 중에서 희귀 질병을 찾으려고 할 때, 데이터는 불균형해야 합니다. 그렇지 않으면 우리가 찾고 있는 질병이 희귀하지 않다는 것을 의미합니다.\u003c/p\u003e\n\u003cp\u003e사기 탐지의 경우도 마찬가지입니다. 금융 기관의 데이터 과학자로서 신용 카드에서 사기 거래를 분석하고 있을 때, 불균형한 데이터를 발견해야 합니다. 그렇지 않으면 사기 거래가 비-사기 거래만큼 자주 발생한다는 것을 의미합니다.\u003c/p\u003e\n\u003ch1\u003e불균형 문제 이해하기\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이제 Python 코드와 함께 실제 상황에 대해 알아볼까요? 이를 통해 다음을 보여줄 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e그래픽을 기반으로 한 주요 및 소수 클래스 간의 차이.\u003c/li\u003e\n\u003cli\u003e불균형한 데이터에 영향을 받는 평가 지표들.\u003c/li\u003e\n\u003cli\u003e불균형한 데이터에 영향을 받지 않는 평가 지표들.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e주요 및 소수 클래스 간의 차이\u003c/h1\u003e\n\u003cp\u003e수학 선생님인 당신이라고 가정해보겠습니다. 이번에는 1000명의 학생으로 이루어진 대규모 강의를 하고 있습니다. 머신러닝을 사용하여 어떠한 분류를 수행하기 전에, 데이터가 불균형인지 확인하기로 결정했습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e하나의 방법은 분포를 시각화하는 것입니다. 예를 들어, 다음과 같이:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.\u003cspan class=\"hljs-property\"\u003epyplot\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 재현 가능성을 위해 랜덤 시드 설정\nnp.\u003cspan class=\"hljs-property\"\u003erandom\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eseed\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n# 다수 클래스 (\u003cspan class=\"hljs-title class_\"\u003eClass\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)를 위한 데이터 생성\nmajority_class = np.\u003cspan class=\"hljs-property\"\u003erandom\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enormal\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e900\u003c/span\u003e)\n# 소수 클래스 (\u003cspan class=\"hljs-title class_\"\u003eClass\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)를 위한 데이터 생성\nminority_class = np.\u003cspan class=\"hljs-property\"\u003erandom\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enormal\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e)\n# 다수 클래스와 소수 클래스 데이터 결합\ndata = np.\u003cspan class=\"hljs-title function_\"\u003econcatenate\u003c/span\u003e((majority_class, minority_class))\n# 클래스 레이블 생성\nlabels = np.\u003cspan class=\"hljs-title function_\"\u003econcatenate\u003c/span\u003e((np.\u003cspan class=\"hljs-title function_\"\u003ezeros\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e900\u003c/span\u003e), np.\u003cspan class=\"hljs-title function_\"\u003eones\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e)))\n# 클래스 분포 플로팅\nplt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e(figsize=(\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\nplt.\u003cspan class=\"hljs-title function_\"\u003ehist\u003c/span\u003e(data[labels == \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], bins=\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'blue'\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.6\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e'다수 클래스 (Class 0)'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003ehist\u003c/span\u003e(data[labels == \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], bins=\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'red'\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.6\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e'소수 클래스 (Class 1)'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'특성 값'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'빈도수'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etitle\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'불균형 데이터셋의 클래스 분포'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003elegend\u003c/span\u003e()\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_0.png\"\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 Python 예제에서는 두 개의 클래스를 만들었습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e주요 클래스 (클래스 0). 이 클래스는 데이터 포인트의 대다수를 나타냅니다. 평균이 0이고 표준 편차가 1인 정규 분포에서 900개의 데이터 포인트를 생성했습니다. 실제 시나리오에서는 매우 흔하거나 전형적인 것을 나타낼 수 있습니다.\u003c/li\u003e\n\u003cli\u003e소수 클래스 (클래스 1). 이 클래스는 데이터 포인트의 소수를 나타냅니다. 평균이 3이고 표준 편차가 1인 정규 분포에서 100개의 데이터 포인트를 생성했습니다. 이 클래스는 의도적으로 흔하지 않게 만들어져 불균형 데이터셋을 시뮬레이션합니다. 실제로는 드문 사건이나 이상을 나타낼 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e다음으로, 이 두 클래스를 해당 레이블 (주요 클래스에 대한 0 및 소수 클래스에 대한 1)과 함께 단일 데이터셋으로 결합합니다. 마지막으로, 히스토그램을 사용하여 클래스 분포를 시각화합니다. 히스토그램에서:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e파란 막대는 주요 클래스 (클래스 0)를 나타내며, 좌측에 더 크고 더 빈번한 막대입니다.\u003c/li\u003e\n\u003cli\u003e빨간 막대는 소수 클래스 (클래스 1)를 나타내며, 우측에 더 작고 덜 빈번한 막대입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 시각화는 불균형 데이터셋에서 주요 및 소수 클래스 간의 차이를 명확하게 보여줍니다. 주요 클래스는 소수 클래스보다 훨씬 많은 데이터 포인트를 가지고 있으며, 이는 불균형 데이터의 일반적인 특성입니다.\u003c/p\u003e\n\u003cp\u003e클래스 불균형을 다루는 또 다른 방법은 분포를 통해 직접적으로 빈도를 살펴보는 것입니다. 예를 들어, 다음과 같이 할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.\u003cspan class=\"hljs-property\"\u003epyplot\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 재현성을 위해 임의의 시드 설정\nnp.\u003cspan class=\"hljs-property\"\u003erandom\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eseed\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n# 주요 클래스 (클래스 \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)에 대한 데이터 생성\nmajority_class = np.\u003cspan class=\"hljs-property\"\u003erandom\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enormal\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e900\u003c/span\u003e)\n# 소수 클래스 (클래스 \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)에 대한 데이터 생성\nminority_class = np.\u003cspan class=\"hljs-property\"\u003erandom\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enormal\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e)\n# 주요 및 소수 클래스 데이터 결합\ndata = np.\u003cspan class=\"hljs-title function_\"\u003econcatenate\u003c/span\u003e((majority_class, minority_class))\n# 클래스에 대한 레이블 생성\nlabels = np.\u003cspan class=\"hljs-title function_\"\u003econcatenate\u003c/span\u003e((np.\u003cspan class=\"hljs-title function_\"\u003ezeros\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e900\u003c/span\u003e), np.\u003cspan class=\"hljs-title function_\"\u003eones\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e))\n# 각 클래스의 빈도 카운트\nclass_counts = [\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(labels[labels == \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]), \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(labels[labels == \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e])]\n# 막대 그래프를 사용하여 클래스 빈도 플로팅\nplt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e(figsize=(\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\nplt.\u003cspan class=\"hljs-title function_\"\u003ebar\u003c/span\u003e([\u003cspan class=\"hljs-string\"\u003e'주요 클래스 (클래스 0)'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'소수 클래스 (클래스 1)'\u003c/span\u003e], class_counts, color=[\u003cspan class=\"hljs-string\"\u003e'blue'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'red'\u003c/span\u003e])\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'클래스'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'빈도'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etitle\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'불균형 데이터셋의 클래스 빈도'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e아래와 같이 테이블 태그를 마크다운 형식으로 변경해주세요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_1.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e그러니까, 이 경우에는 클래스에 속하는 데이터의 모든 발생을 계산하는 내장 메소드 len()을 사용할 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e이상 데이터로 영향을 받는 일반 평가 지표\u003c/h1\u003e\n\u003cp\u003e이상 데이터에 영향을 받는 모든 평가 지표를 설명하려면 먼저 다음을 정의해야 합니다:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003eTrue positive (TP). 분류기가 조건이나 특성의 존재를 올바르게 예측한 값\u003c/li\u003e\n\u003cli\u003eTrue negative (TN). 분류기가 조건이나 특성의 부재를 올바르게 예측한 값\u003c/li\u003e\n\u003cli\u003eFalse positive (FP). 분류기가 특정 조건이나 속성이 존재하는 것으로 잘못 예측한 값\u003c/li\u003e\n\u003cli\u003eFalse negative (FN). 분류기가 특정 조건이나 속성이 존재하지 않는 것으로 잘못 예측한 값\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e다음은 불균형 데이터가 영향을 미치는 일반적인 평가 지표입니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e정확도. 데이터 세트에서 올바르게 예측된 인스턴스의 비율을 측정합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e파이썬에서 정확도 지표를 계산하는 방법에 대한 예제를 만들어보겠습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e accuracy_score\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# 실제 레이블\u003c/span\u003e\ntrue_labels = [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n\u003cspan class=\"hljs-comment\"\u003e# 모델이 예측한 레이블\u003c/span\u003e\npredicted_labels = [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\naccuracy = accuracy_score(true_labels, predicted_labels)\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"정확도:\"\u003c/span\u003e, accuracy)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e결과는:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e정확도: \u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e정확도는 불균형한 데이터를 다룰 때 혼란을 줄 수 있습니다.\u003c/p\u003e\n\u003cp\u003e실제로 95%가 A 클래스에 속하고 5%만 B 클래스에 속하는 데이터 세트가 있다고 가정해 봅시다. 모델이 모든 인스턴스를 A 클래스로 예측한다면 95%의 정확도를 달성할 것입니다. 하지만 이는 반드시 모델이 좋다는 것을 의미하지는 않습니다. 이는 단지 클래스 불균형을 악용한 것뿐입니다. 다시 말해, 이 메트릭은 소수 클래스 (B 클래스)를 얼마나 잘 식별하는지를 고려하지 않습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e정밀도. 이것은 모든 예측된 긍정 인스턴스 중 올바르게 예측된 긍정 인스턴스의 비율을 측정합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_3.png\" alt=\"How to Handle Imbalanced Data for Machine Learning in Python\"\u003e\u003c/p\u003e\n\u003cp\u003e한 예제를 통해 Python에서 정밀도 지표를 계산하는 방법을 살펴보겠습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e precision_score\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# True labels\u003c/span\u003e\ntrue_labels = [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n\u003cspan class=\"hljs-comment\"\u003e# Predicted labels by a model\u003c/span\u003e\npredicted_labels = [\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\nprecision = precision_score(true_labels, predicted_labels)\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Precision:\"\u003c/span\u003e, precision)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e결과는 다음과 같습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e정밀도: \u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e불균형 데이터 세트에서는 정밀도가 매우 오해를 일으킬 수 있습니다.\u003c/p\u003e\n\u003cp\u003e실제로, 모델이 하나의 인스턴스만을 긍정적(클래스 B)으로 분류하고 그게 맞는 경우, 정밀도는 100%가 될 것입니다. 그러나 이는 모델이 소수 클래스에서의 성능을 나타내는 것이 아닐 수 있습니다. 왜냐하면 많은 긍정적 인스턴스를 놓칠 수 있기 때문입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e재현율 (또는 민감도). 재현율은 또한 민감도 또는 진양성율로 알려져 있으며, 올바르게 예측된 긍정적 인스턴스의 비율을 측정합니다:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_4.png\" alt=\"Example\"\u003e\u003c/p\u003e\n\u003cp\u003e파이썬을 사용하여 재현율 지표를 계산하는 예제를 만들어 보겠습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e recall_score\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 실제 레이블\ntrue_labels = [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n# 모델이 예측한 레이블\npredicted_labels = [\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\nrecall = \u003cspan class=\"hljs-title function_\"\u003erecall_score\u003c/span\u003e(true_labels, predicted_labels)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"재현율:\"\u003c/span\u003e, recall)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e결과는:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e재현율: \u003cspan class=\"hljs-number\"\u003e1.0\u003c/span\u003e;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e재현율은 불균형한 데이터셋에서도 잘못된 정보를 줄 수 있습니다. 특히 모든 긍정적인 인스턴스를 포착하는 것이 중요할 때에는요.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e만약 모델이 더 많은 양의 양성 인스턴스가 있는 상황에서 한 인스턴스만을 양성(Class B)으로 예측할 경우, 재현율이 매우 낮을 수 있습니다. 이는 모델이 소수 클래스의 중요한 부분을 놓치고 있음을 나타낼 수 있습니다. 이는 이 메트릭이 false positives를 고려하지 않기 때문에 발생합니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eF1 스코어. F1 스코어는 정밀도와 재현율의 조화평균입니다. 정밀도와 재현율 사이의 균형을 제공합니다:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_5.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e파이썬을 사용하여 F1 스코어 메트릭을 계산하는 예제를 만들어봅시다:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e f1_score\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e labels\ntrue_labels = [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n# \u003cspan class=\"hljs-title class_\"\u003ePredicted\u003c/span\u003e labels by a model\npredicted_labels = [\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n# \u003cspan class=\"hljs-title class_\"\u003eCalculate\u003c/span\u003e and print \u003cspan class=\"hljs-variable constant_\"\u003eF1\u003c/span\u003e-score\nf1 = \u003cspan class=\"hljs-title function_\"\u003ef1_score\u003c/span\u003e(true_labels, predicted_labels)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"F1-Score:\"\u003c/span\u003e, f1)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e결과는:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-variable constant_\"\u003eF1\u003c/span\u003e-\u003cspan class=\"hljs-title class_\"\u003eScore\u003c/span\u003e: \u003cspan class=\"hljs-number\"\u003e0.6666666666666666\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 메트릭은 정밀도와 재현율을 사용하여 생성되었기 때문에 데이터 불균형에 영향을 받을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e하나의 클래스가 지배적이고 (다수 클래스인 경우), 그 모델이 해당 클래스를 편향으로 처리하는 경우, F1 점수는 소수 클래스의 낮은 재현율에도 높은 정밀도 때문에 상대적으로 높을 수 있습니다. 이는 모델의 전체 효과를 잘못 나타낼 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e데이터 불균형에 영향을 받지 않는 가장 많이 사용되는 평가 지표\u003c/h1\u003e\n\u003cp\u003e이제 클래스 불균형에 영향을 받지 않는 평가 지표 중 가장 많이 사용되는 두 가지를 설명하겠습니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e혼동 행렬. 혼동 행렬은 분류 알고리즘의 성능을 요약하는 표입니다. 이는 True Positives (TP), True Negatives (TN), False Positives (FP) 및 False Negatives (FN)의 자세한 분석을 제공합니다. 특히, 주 대각선(왼쪽 위에서 오른쪽 아래)은 TP와 TN을 보여주며, 보조 대각선(왼쪽 아래에서 오른쪽 위)은 FP와 FN을 나타냅니다. 따라서, 머신 러닝 모델이 데이터를 올바르게 분류할 경우, 혼동 행렬의 주 대각선은 가장 높은 값을, 보조 대각선은 가장 낮은 값을 보고해야 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e파이썬에서 예제를 보여드리겠습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e confusion_matrix\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# True and predicted labels\u003c/span\u003e\ntrue_labels = [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\npredicted_labels = [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n\u003cspan class=\"hljs-comment\"\u003e# Create confusion matrix\u003c/span\u003e\ncm = confusion_matrix(true_labels, predicted_labels)\n\u003cspan class=\"hljs-comment\"\u003e# Print confusion matrix\u003c/span\u003e\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Confusion Matrix:\"\u003c/span\u003e)\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(cm)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e그리고 저희가 얻은 것은:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e혼동 행렬:\n[[\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\n [\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e]]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 혼동 행렬은 주 대각선에 결과가 가장 많기 때문에(10개 중 9개) 좋은 분류기를 나타냅니다. 이는 분류기가 5개의 TP와 4개의 TN을 예측했다는 것을 의미합니다.\u003c/p\u003e\n\u003cp\u003e그에 비해, 보조 대각선은 낮은 결과를 보여줍니다(10개 중 1개). 이는 분류기가 1개의 FP와 0개의 FN을 예측했음을 의미합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e그러므로 이것은 좋은 분류기로 이어집니다.\u003c/p\u003e\n\u003cp\u003e따라서 혼동 행렬은 모델 성능의 자세한 분석을 제공하여 각 클래스에 대해 올바르게 또는 잘못 분류된 인스턴스의 수를 몇 초 안에 알 수 있도록합니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAUC/ROC 커브. ROC는 \"Receiver Operating Characteristic\"의 약자로, 참 긍정률 (TPR)을 다른 임계값에서 거짓 긍정률 (FPR)에 대비하여 그래픽 방식으로 그리는 분류기를 평가하는 방법입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e우리는 다음과 같이 정의합니다:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003eTPR을 민감도로(우리가 말했듯이 recall로도 불릴 수 있음).\u003c/li\u003e\n\u003cli\u003eFPR을 1-특이도로 정의합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e특이도는 분류기가 모든 부정적인 샘플을 찾는 능력을 의미합니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_6.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003eAUC는 ROC 곡선 아래 영역을 나타내며 \"곡선 아래 영역\"을 의미합니다. 이는 0에서 1사이의 전체적인 성능 지표로, 1은 분류기가 레이블의 100%를 실제 값으로 예측한다는 것을 의미하며, 서로 다른 분류기들을 비교할 때 더 적합합니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e만약 이진 분류 문제를 공부한다고 가정해봅시다. 파이썬에서 AUC 곡선을 그리는 방법은 다음과 같습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.datasets \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e make_classification\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.model_selection \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e train_test_split\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.linear_model \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e LogisticRegression\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e roc_curve, roc_auc_score\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.pyplot \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# 무작위로 이진 분류 데이터세트 생성\u003c/span\u003e\nX, y = make_classification(n_samples=\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e, n_features=\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, n_classes=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n\u003cspan class=\"hljs-comment\"\u003e# 데이터세트를 학습 및 테스트 세트로 분할\u003c/span\u003e\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n\u003cspan class=\"hljs-comment\"\u003e# 학습 데이터에서 로지스틱 회귀 모델 학습\u003c/span\u003e\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\u003cspan class=\"hljs-comment\"\u003e# 테스트 데이터에 대해 확률 예측\u003c/span\u003e\nprobs = model.predict_proba(X_test)\n\u003cspan class=\"hljs-comment\"\u003e# ROC 곡선 및 AUC 점수 계산\u003c/span\u003e\nfpr, tpr, thresholds = roc_curve(y_test, probs[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e])\nauc_score = roc_auc_score(y_test, probs[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e])\n\u003cspan class=\"hljs-comment\"\u003e# ROC 곡선 그리기\u003c/span\u003e\nplt.plot(fpr, tpr, label=\u003cspan class=\"hljs-string\"\u003e'AUC = {:.2f}'\u003c/span\u003e.\u003cspan class=\"hljs-built_in\"\u003eformat\u003c/span\u003e(auc_score))\nplt.plot([\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], \u003cspan class=\"hljs-string\"\u003e'k--'\u003c/span\u003e)\nplt.xlabel(\u003cspan class=\"hljs-string\"\u003e'False Positive Rate'\u003c/span\u003e)\nplt.ylabel(\u003cspan class=\"hljs-string\"\u003e'True Positive Rate'\u003c/span\u003e)\nplt.title(\u003cspan class=\"hljs-string\"\u003e'ROC Curve'\u003c/span\u003e)\nplt.legend(loc=\u003cspan class=\"hljs-string\"\u003e'lower right'\u003c/span\u003e)\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_7.png\"\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e그 코드로는 다음을 할 수 있어요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003emake_classification 메서드로 분류 데이터셋을 생성했어요.\u003c/li\u003e\n\u003cli\u003e데이터셋을 훈련 세트와 테스트 세트로 나눴어요.\u003c/li\u003e\n\u003cli\u003eLogistic Regression 분류기로 훈련 세트를 fit했어요.\u003c/li\u003e\n\u003cli\u003epredict_proba() 메서드로 테스트 데이터에 대한 예측을 만들었어요.\u003c/li\u003e\n\u003cli\u003eROC 곡선과 AUC 점수를 계산했어요.\u003c/li\u003e\n\u003cli\u003eAUC 곡선을 그렸어요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e불균형 데이터 다루는 기술\u003c/h1\u003e\n\u003cp\u003e이 섹션에서는 불균형 데이터를 다루는 몇 가지 기술을 다루겠어요.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e다시 말해, 우리는 불균형 데이터를 다루는 방법에 대해 이야기할 것입니다.\u003c/p\u003e\n\u003ch2\u003e리샘플링\u003c/h2\u003e\n\u003cp\u003e불균형 데이터셋을 처리하는 데 널리 사용되는 방법론은 리샘플링입니다. 이 방법론은 두 가지 다른 프로세스로 나눌 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e오버샘플링. 소수 클래스에 더 많은 예제를 추가하는 것을 의미합니다.\u003c/li\u003e\n\u003cli\u003e언더샘플링. 다수 클래스에서 샘플을 제거하는 것을 의미합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e두 가지 방법에 대해 설명해 보겠습니다.\u003c/p\u003e\n\u003ch2\u003eOversampling\u003c/h2\u003e\n\u003cp\u003eOversampling은 소수 클래스의 인스턴스 수를 늘려 클래스 분포를 균형있게 만드는 재표본화 기술입니다. 주로 기존 인스턴스를 복제하거나 소수 클래스와 유사한 합성 데이터 포인트를 생성함으로써 수행됩니다. 목표는 모델이 훈련 중에 두 클래스의 더 균형 잡힌 표현을 볼 수 있도록 하는 것입니다.\u003c/p\u003e\n\u003cp\u003e장점:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e모델 성능 향상. Oversampling은 소수 클래스의 특성을 더 잘 학습할 수 있도록 도와주어 전체적인 분류 성능을 향상시킬 수 있습니다, 특히 소수 클래스에 대해서 더욱 효과적입니다.\u003c/li\u003e\n\u003cli\u003e정보 보존. 언더샘플링과는 달리, 오버샘플링은 과반 클래스의 모든 인스턴스를 보존하여 정보의 손실이 없도록 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e단점:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e과적합의 위험. 중복되거나 합성된 인스턴스는 적절하게 제어되지 않으면, 특히 합성 데이터가 기존 데이터와 너무 유사한 경우에는 과적합을 유발할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e훈련 시간 증가. 오버샘플링으로 인한 더 큰 데이터셋은 머신러닝 알고리즘의 학습 시간이 더 오래 걸릴 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePython에서 불균형한 데이터셋에 대한 오버샘플링 기술을 어떻게 활용할 수 있는지 알아보겠습니다:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.\u003cspan class=\"hljs-property\"\u003epyplot\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003edatasets\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e make_classification\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e imblearn.\u003cspan class=\"hljs-property\"\u003eover_sampling\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eRandomOverSampler\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e collections \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eCounter\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e개 클래스를 가지는 불균형 데이터셋 생성\nX, y = \u003cspan class=\"hljs-title function_\"\u003emake_classification\u003c/span\u003e(\n    n_samples=\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e,\n    n_features=\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e,\n    n_classes=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e,\n    n_clusters_per_class=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n    weights=[\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.6\u003c/span\u003e],  # 클래스 불균형\n    random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e\n)\n# 초기 클래스들의 히스토그램 출력\nplt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e(figsize=(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\nplt.\u003cspan class=\"hljs-title function_\"\u003ehist\u003c/span\u003e(y, bins=\u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e), align=\u003cspan class=\"hljs-string\"\u003e'left'\u003c/span\u003e, rwidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'blue'\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etitle\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"초기 클래스들의 히스토그램\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"클래스\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"인스턴스 개수\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003exticks\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e), [\u003cspan class=\"hljs-string\"\u003e'클래스 0'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'클래스 1'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'클래스 2'\u003c/span\u003e])\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n# \u003cspan class=\"hljs-title class_\"\u003eRandomOverSampler\u003c/span\u003e를 사용하여 오버샘플링 적용\noversampler = \u003cspan class=\"hljs-title class_\"\u003eRandomOverSampler\u003c/span\u003e(sampling_strategy=\u003cspan class=\"hljs-string\"\u003e'auto'\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\nX_resampled, y_resampled = oversampler.\u003cspan class=\"hljs-title function_\"\u003efit_resample\u003c/span\u003e(X, y)\n# 재샘플링된 클래스들의 히스토그램 출력\nplt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e(figsize=(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\nplt.\u003cspan class=\"hljs-title function_\"\u003ehist\u003c/span\u003e(y_resampled, bins=\u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e), align=\u003cspan class=\"hljs-string\"\u003e'left'\u003c/span\u003e, rwidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'orange'\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etitle\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"재샘플링된 클래스들의 히스토그램 (오버샘플링)\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"클래스\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"인스턴스 개수\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003exticks\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e), [\u003cspan class=\"hljs-string\"\u003e'클래스 0'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'클래스 1'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'클래스 2'\u003c/span\u003e])\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_8.png\"\u003e\n\u003ch2\u003e언더샘플링\u003c/h2\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e언더샘플링은 머신 러닝에서 사용되는 샘플링 기술 중 하나로, 주요 클래스의 인스턴스 수를 줄여 클래스 분포를 균형있게 만드는 것에 초점을 맞춥니다. 주로 주요 클래스에서 인스턴스를 무작위로 제거해 두 클래스가 보다 균형 잡힌 표현이 되도록 하는 방식입니다. 여기에는 언더샘플링의 장단점이 있습니다.\u003c/p\u003e\n\u003cp\u003e장점:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e과적합 위험이 감소합니다. 언더샘플링은 오버샘플링과 비교하여 과적합 위험을 줄입니다. 주요 클래스의 인스턴스 수를 줄이면 모델이 학습 데이터를 외워버리는 경향이 줄어들고 새로운, 보이지 않는 데이터에 대해 더 잘 일반화할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e빠른 학습 시간입니다. 언더샘플링을 거친 후 데이터셋에는 더 이상 적은 인스턴스가 있기 때문에 머신 러닝 알고리즘의 학습 시간을 줄일 수 있습니다. 보통 데이터가 적을수록 학습 시간이 더 빨라집니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e단점:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e정보 손실. 언더샘플링은 주요 클래스에서 인스턴스를 버림으로써 귀중한 정보 손실을 야기할 수 있습니다. 만일 버려진 인스턴스에 주요 클래스의 전반적인 이해에 기여하는 중요한 특성이 있다면 문제가 될 수 있습니다.\u003c/li\u003e\n\u003cli\u003e편향된 모델의 위험. 주요 클래스에서 인스턴스를 제거하면 편향된 모델을 유발할 수 있으며, 이는 실제 주요 클래스의 분포를 정확하게 포착하지 못할 수 있습니다. 이러한 편향은 모델이 실제 세계 상황에 일반화하는 능력에 영향을 줄 수 있습니다.\u003c/li\u003e\n\u003cli\u003e주요 클래스에서의 성능 저하 가능성. 언더샘플링은 주요 클래스에서 성능이 나쁜 모델을 유발할 수 있습니다. 왜냐하면 학습할 정보가 적기 때문입니다. 이는 주요 클래스의 인스턴스를 잘못 분류할 수 있게 됩니다.\u003c/li\u003e\n\u003cli\u003e샘플링 비율에 민감함. 언더샘플링 정도는 모델의 성능에 중대한 영향을 미칠 수 있습니다. 샘플링 비율이 과도하면 주요 클래스의 중요한 정보가 손실될 수 있고, 너무 보수적이면 클래스 불균형 문제가 계속 남을 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e아래는 파이썬에서 불균형 데이터셋에 대해 언더샘플링 기술을 활용하는 방법입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.pyplot \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.datasets \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e make_classification\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e imblearn.under_sampling \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e RandomUnderSampler\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e collections \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Counter\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# 3개 클래스를 갖는 불균형 데이터셋 생성\u003c/span\u003e\nX, y = make_classification(\n    n_samples=\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e,\n    n_features=\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e,\n    n_classes=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e,\n    n_clusters_per_class=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n    weights=[\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.6\u003c/span\u003e],  \u003cspan class=\"hljs-comment\"\u003e# 클래스 불균형\u003c/span\u003e\n    random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e\n)\n\u003cspan class=\"hljs-comment\"\u003e# 초기 클래스 히스토그램 출력\u003c/span\u003e\nplt.figure(figsize=(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\nplt.hist(y, bins=\u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e), align=\u003cspan class=\"hljs-string\"\u003e'left'\u003c/span\u003e, rwidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'blue'\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e)\nplt.title(\u003cspan class=\"hljs-string\"\u003e\"Initial Classes의 히스토그램\"\u003c/span\u003e)\nplt.xlabel(\u003cspan class=\"hljs-string\"\u003e\"클래스\"\u003c/span\u003e)\nplt.ylabel(\u003cspan class=\"hljs-string\"\u003e\"인스턴스 수\"\u003c/span\u003e)\nplt.xticks(\u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e), [\u003cspan class=\"hljs-string\"\u003e'클래스 0'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'클래스 1'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'클래스 2'\u003c/span\u003e])\nplt.show()\n\u003cspan class=\"hljs-comment\"\u003e# RandomUnderSampler를 사용하여 언더샘플링 적용\u003c/span\u003e\nundersampler = RandomUnderSampler(sampling_strategy=\u003cspan class=\"hljs-string\"\u003e'auto'\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\nX_resampled, y_resampled = undersampler.fit_resample(X, y)\n\u003cspan class=\"hljs-comment\"\u003e# 재샘플링 클래스의 히스토그램 출력\u003c/span\u003e\nplt.figure(figsize=(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\nplt.hist(y_resampled, bins=\u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e), align=\u003cspan class=\"hljs-string\"\u003e'left'\u003c/span\u003e, rwidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'orange'\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e)\nplt.title(\u003cspan class=\"hljs-string\"\u003e\"Resampled Classes (언더샘플링)의 히스토그램\"\u003c/span\u003e)\nplt.xlabel(\u003cspan class=\"hljs-string\"\u003e\"클래스\"\u003c/span\u003e)\nplt.ylabel(\u003cspan class=\"hljs-string\"\u003e\"인스턴스 수\"\u003c/span\u003e)\nplt.xticks(\u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e), [\u003cspan class=\"hljs-string\"\u003e'클래스 0'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'클래스 1'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'클래스 2'\u003c/span\u003e])\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e아래는 Markdown 형식으로 표를 변경한 것입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/TIL/assets/img/2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython_9.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003ch2\u003e성능 비교\u003c/h2\u003e\n\u003cp\u003e다음은 Python 예제를 만들어보겠습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e균형이 맞지 않은 데이터 세트를 만듭니다.\u003c/li\u003e\n\u003cli\u003e언더샘플링 및 오버샘플링을 진행합니다.\u003c/li\u003e\n\u003cli\u003e언더샘플링 및 오버샘플링된 데이터 세트에 대해 훈련 및 검증 세트를 만들고, KNN 분류기로 학습합니다.\u003c/li\u003e\n\u003cli\u003e언더샘플링 및 오버샘플링된 데이터 세트의 정확도를 비교합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003edatasets\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e make_classification\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emodel_selection\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e train_test_split\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003eneighbors\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eKNeighborsClassifier\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e imblearn.\u003cspan class=\"hljs-property\"\u003eover_sampling\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eRandomOverSampler\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e imblearn.\u003cspan class=\"hljs-property\"\u003eunder_sampling\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eRandomUnderSampler\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e accuracy_score\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e개의 클래스를 가진 불균형 데이터셋 생성\nX, y = \u003cspan class=\"hljs-title function_\"\u003emake_classification\u003c/span\u003e(\n    n_samples=\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e,\n    n_features=\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e,\n    n_classes=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e,\n    n_clusters_per_class=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n    weights=[\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.6\u003c/span\u003e],  # 클래스 불균형\n    random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e\n)\n# 원본 데이터셋을 학습 및 테스트 세트로 분할\nX_train, X_test, y_train, y_test = \u003cspan class=\"hljs-title function_\"\u003etrain_test_split\u003c/span\u003e(X, y, test_size=\u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n# \u003cspan class=\"hljs-title class_\"\u003eRandomOverSampler\u003c/span\u003e를 사용하여 오버샘플링 적용\noversampler = \u003cspan class=\"hljs-title class_\"\u003eRandomOverSampler\u003c/span\u003e(sampling_strategy=\u003cspan class=\"hljs-string\"\u003e'auto'\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\nX_train_oversampled, y_train_oversampled = oversampler.\u003cspan class=\"hljs-title function_\"\u003efit_resample\u003c/span\u003e(X_train, y_train)\n# \u003cspan class=\"hljs-title class_\"\u003eRandomUnderSampler\u003c/span\u003e를 사용하여 언더샘플링 적용\nundersampler = \u003cspan class=\"hljs-title class_\"\u003eRandomUnderSampler\u003c/span\u003e(sampling_strategy=\u003cspan class=\"hljs-string\"\u003e'auto'\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\nX_train_undersampled, y_train_undersampled = undersampler.\u003cspan class=\"hljs-title function_\"\u003efit_resample\u003c/span\u003e(X_train, y_train)\n# 원본 학습 세트에 \u003cspan class=\"hljs-variable constant_\"\u003eKNN\u003c/span\u003e 분류기 피팅\nknn_original = \u003cspan class=\"hljs-title class_\"\u003eKNeighborsClassifier\u003c/span\u003e(n_neighbors=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\nknn_original.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X_train, y_train)\n# 오버샘플링된 학습 세트에 \u003cspan class=\"hljs-variable constant_\"\u003eKNN\u003c/span\u003e 분류기 피팅\nknn_oversampled = \u003cspan class=\"hljs-title class_\"\u003eKNeighborsClassifier\u003c/span\u003e(n_neighbors=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\nknn_oversampled.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X_train_oversampled, y_train_oversampled)\n# 언더샘플링된 학습 세트에 \u003cspan class=\"hljs-variable constant_\"\u003eKNN\u003c/span\u003e 분류기 피팅\nknn_undersampled = \u003cspan class=\"hljs-title class_\"\u003eKNeighborsClassifier\u003c/span\u003e(n_neighbors=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\nknn_undersampled.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X_train_undersampled, y_train_undersampled)\n# 학습 세트에 대한 예측 수행\ny_train_pred_original = knn_original.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_train)\ny_train_pred_oversampled = knn_oversampled.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_train_oversampled)\ny_train_pred_undersampled = knn_undersampled.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_train_undersampled)\n# 테스트 세트에 대한 예측 수행\ny_test_pred_original = knn_original.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_test)\ny_test_pred_oversampled = knn_oversampled.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_test)\ny_test_pred_undersampled = knn_undersampled.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_test)\n# 학습 세트의 정확도 계산 및 출력\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"원본 학습 세트 정확도:\"\u003c/span\u003e, \u003cspan class=\"hljs-title function_\"\u003eaccuracy_score\u003c/span\u003e(y_train, y_train_pred_original))\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"오버샘플링된 학습 세트 정확도:\"\u003c/span\u003e, \u003cspan class=\"hljs-title function_\"\u003eaccuracy_score\u003c/span\u003e(y_train_oversampled, y_train_pred_oversampled))\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"언더샘플링된 학습 세트 정확도:\"\u003c/span\u003e, \u003cspan class=\"hljs-title function_\"\u003eaccuracy_score\u003c/span\u003e(y_train_undersampled, y_train_pred_undersampled))\n# 테스트 세트의 정확도 계산 및 출력\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"\\n원본 테스트 세트 정확도:\"\u003c/span\u003e, \u003cspan class=\"hljs-title function_\"\u003eaccuracy_score\u003c/span\u003e(y_test, y_test_pred_original))\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"오버샘플링된 테스트 세트 정확도:\"\u003c/span\u003e, \u003cspan class=\"hljs-title function_\"\u003eaccuracy_score\u003c/span\u003e(y_test, y_test_pred_oversampled))\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"언더샘플링된 테스트 세트 정확도:\"\u003c/span\u003e, \u003cspan class=\"hljs-title function_\"\u003eaccuracy_score\u003c/span\u003e(y_test, y_test_pred_undersampled))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e결과:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e원본 학습 세트 정확도: \u003cspan class=\"hljs-number\"\u003e0.9125\u003c/span\u003e\n오버샘플링된 학습 세트 정확도: \u003cspan class=\"hljs-number\"\u003e0.9514767932489452\u003c/span\u003e\n언더샘플링된 학습 세트 정확도: \u003cspan class=\"hljs-number\"\u003e0.85\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e원본 테스트 세트 정확도: \u003cspan class=\"hljs-number\"\u003e0.885\u003c/span\u003e\n오버샘플링된 테스트 세트 정확도: \u003cspan class=\"hljs-number\"\u003e0.79\u003c/span\u003e\n언더샘플링된 테스트 세트 정확도: \u003cspan class=\"hljs-number\"\u003e0.805\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e정확도 지표 비교를 통해 이러한 방법론의 특징을 확인할 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e오버샘플링 기술은 KNN 모델이 오버피팅되고 있는 것을 시사하며, 이는 오버샘플링 그 자체 때문입니다.\u003c/li\u003e\n\u003cli\u003e언더샘플링 기술은 KNN 모델이 편향될 수 있음을 시사하며, 이는 언더샘플링 그 자체 때문입니다.\u003c/li\u003e\n\u003cli\u003e리샘플링 없이 모델을 학습시킨 것은 데이터의 불균형으로 정확도가 잘못 이끌 수 있음을 보여줍니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e따라서 이 경우, 가능한 해결책은 오버샘플링을 사용하고 KNN의 하이퍼파라미터를 조정하여 오버피팅을 피할 수 있는지 확인해 보는 것입니다.\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e앙상블\u003c/h1\u003e\n\u003cp\u003e불균형 데이터를 다루는 또 다른 방법은 앙상블 학습을 사용하는 것입니다. 특히, 랜덤 포레스트(Random Forest, RF)는 여러 의사 결정 트리 모델의 앙상블인데, 주 클래스에 편향되지 않는 내재적 능력으로 널리 사용되는 머신 러닝 모델입니다.\u003c/p\u003e\n\u003cp\u003e그 이유는 다음과 같습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBootstrap 샘플링. RF 모델은 무작위 샘플링을 사용하여 작동합니다. 즉, 다양한 의사 결정 트리 모델을 훈련하는 동안, 선택된 데이터는 전체 데이터 세트의 무작위 하위 집합을 사용하고, 데이터는 대체됩니다. 이는 평균적으로 각 의사 결정 트리가 원래 데이터의 약 2/3에 대해 훈련됩니다. 결과적으로 소수 클래스의 일부 인스턴스가 의사 결정 트리를 작성하는 데 사용된 하위 집합에 포함될 가능성이 높습니다. 샘플 선택의 이 랜덤성은 주요 및 소수 클래스의 영향을 균형있게 조정하는 데 도움이 됩니다.\u003c/li\u003e\n\u003cli\u003e무작위 특성 선택. 데이터를 무작위화하는 것 외에도, 랜덤 포레스트는 각 트리의 각 노드에 대해 무작위로 특성을 선택합니다. 즉, 분할할 때 고려할 특성의 무작위 하위 집합을 선택합니다. 이 특성의 무작위성은 대부분 주 클래스를 대표하는 특성에 대한 잠재적인 편향을 줄입니다.\u003c/li\u003e\n\u003cli\u003e오류 수정 메커니즘. 랜덤 포레스트는 그 자체의 앙상블 성격을 통해 오류 수정 메커니즘을 사용합니다. 앙상블에서 한 의사 결정 트리가 소수 클래스 인스턴스에서 오류를 발생시키면, 앙상블의 다른 트리들은 해당 인스턴스에 대해 정확한 예측을 함으로써 보상할 수 있습니다. 앙상블 기반의 오류 수정은 주요 클래스의 우세함을 완화하는 데 도움이 됩니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이전에 만든 데이터세트를 고려해 봅시다. 랜덤 포레스트 분류기를 사용하여 적합한 결과를 살펴봅시다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003edatasets\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e make_classification\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emodel_selection\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e train_test_split\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003eensemble\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eRandomForestClassifier\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003emetrics\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e accuracy_score\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e개의 클래스로 불균형 데이터세트 생성\nX, y = \u003cspan class=\"hljs-title function_\"\u003emake_classification\u003c/span\u003e(\n    n_samples=\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e,\n    n_features=\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e,\n    n_classes=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e,\n    n_clusters_per_class=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n    weights=[\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.6\u003c/span\u003e],  # 클래스 불균형\n    random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e\n)\n# 데이터세트를 훈련 세트와 테스트 세트로 분할\nX_train, X_test, y_train, y_test = \u003cspan class=\"hljs-title function_\"\u003etrain_test_split\u003c/span\u003e(X, y, test_size=\u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\n# 훈련 세트에 랜덤 포레스트 분류기를 적합\nrf_classifier = \u003cspan class=\"hljs-title class_\"\u003eRandomForestClassifier\u003c/span\u003e(random_state=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e)\nrf_classifier.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X_train, y_train)\n# 훈련 세트와 테스트 세트에 대한 예측 생성\ny_train_pred = rf_classifier.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_train)\ny_test_pred = rf_classifier.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_test)\n# 훈련 세트의 정확도 계산 및 출력\ntrain_accuracy = \u003cspan class=\"hljs-title function_\"\u003eaccuracy_score\u003c/span\u003e(y_train, y_train_pred)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"훈련 세트 정확도:\"\u003c/span\u003e, train_accuracy)\n# 테스트 세트의 정확도 계산 및 출력\ntest_accuracy = \u003cspan class=\"hljs-title function_\"\u003eaccuracy_score\u003c/span\u003e(y_test, y_test_pred)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"테스트 세트 정확도:\"\u003c/span\u003e, test_accuracy)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e그리고 우리는 다음과 같은 결과를 얻습니다:\u003c/p\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e학습 세트 정확도: \u003cspan class=\"hljs-number\"\u003e1.0\u003c/span\u003e\n테스트 세트 정확도: \u003cspan class=\"hljs-number\"\u003e0.97\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 경우에는 랜덤 포레스트를 사용했기 때문에 데이터 세트를 다시 샘플링할 필요가 없었습니다. 그래도 결과는 모델이 과적합될 가능성을 시사합니다. 이는 랜덤 포레스트 특성 때문일 수 있으므로 하이퍼파라미터 튜닝을 위해 추가적인 조사가 필요할 것입니다.\u003c/p\u003e\n\u003cp\u003e어쨌든, 이 경우에는 하이퍼파라미터 튜닝 후 RF 모델을 사용하는 것이 KNN을 사용하고 데이터 세트를 언더샘플링하거나 오버샘플링하는 것보다 좋은 선택일 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003c!-- TIL 수평 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 기사에서는 기계 학습(Machine Learning)에서 불균형 데이터를 다루는 방법에 대해 논의했습니다.\u003c/p\u003e\n\u003cp\u003e특히, 희귀한 사건을 연구하기 때문에 데이터가 불균형할 것으로 예상되는 상황이 있습니다.\u003c/p\u003e\n\u003cp\u003e반면에 데이터가 불균형해서는 안 되는 경우, 리샘플링(resampling)과 앙상블링(ensembling)과 같은 ML 모델을 다루는 방법에 대한 몇 가지 방법론을 소개했습니다.\u003c/p\u003e\n\u003cp\u003e원문은 2024년 3월 7일 \u003ca href=\"https://semaphoreci.com\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://semaphoreci.com\u003c/a\u003e 에서 게시되었습니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-07-09-HowtoHandleImbalancedDataforMachineLearninginPython"},"buildId":"FuXRqV9h16krA5Mvtd6Dn","assetPrefix":"/TIL","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>