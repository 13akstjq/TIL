{"pageProps":{"posts":[{"title":"비용 없이 AI 도구만으로 ChatGPT를 능가하는 챗봇을 구축한 방법","description":"","date":"2024-07-13 19:52","slug":"2024-07-13-HowIBuiltaChatbotthatCrushedChatGPTwithZeroCostAITools","content":"\n\n챗봇은 고객과 상호작용하고 정보를 제공하며 사용자를 즐겁게 해주는 방법으로 점점 더 인기를 얻고 있습니다. 그러나 자연스럽고 매력적인 대화를 나눌 수 있는 AI 애플리케이션을 구축하는 것은 쉬운 일이 아닙니다.\n\n많은 챗봇 개발자들이 ChatGPT와 같은 비싼 독점 AI 모델을 활용하고 있습니다.\n\n하지만 무료 및 오픈 소스 AI 도구를 사용하여 ChatGPT와 어울리는 챗봇을 만들 수 있다면 어떨까요?\n\n저는 그것을 해냈고, 이 글에서 그 방법을 공유하려고 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 도전과 탐험\n\n이 도전에 도전하게 된 이유에 대해 궁금해 할 수도 있어요. 그 이유는 모두 오픈 소스 언어 모델의 성능에 대해 회의적인 중도 독자로부터 받은 메시지에서 시작되었어요.\n\n중도 독자가 ChatGPT를 사용한 질문/답변 세션을 보내줬고, 오픈 소스 도구를 사용하여 동일한 수준의 품질과 일관성을 실현할 수 있는지 물었어요.\n\n그 질문에 흥미를 느껴서 도전해보기로 결정했어요. 몇 일 동안 Hugging Face의 다양한 오픈 소스 AI 도구를 연구하고 실험하며 조정하는 시간을 보냈어요. 나만의 소규모 전문가 팀을 결성하여 ChatGPT를 넘어서거나 심지어 뛰어넘길 수 있기를 바랬는데, 결과가 궁금하게요?\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nWell done! You've done amazing work by creating a chatbot that can engage in fluent and diverse conversations. What's even more impressive is that you accomplished this on your own computer without relying on external cloud services or APIs. This allowed you to maintain full control and privacy over your data and model.\n\n![Image](/TIL/assets/img/2024-07-13-HowIBuiltaChatbotthatCrushedChatGPTwithZeroCostAITools_0.png)\n\n## The Issue\n\nWith the article \"Apple's iOS App Store announces sweeping changes in the EU,\" the objective is to identify the key question implied by the headline (or let the user ask it) and then provide a concise answer based on the article text.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기 ChatGPT에서 받은 결과입니다...\n\n# ChatGPT 결과\n\n![이미지](/TIL/assets/img/2024-07-13-HowIBuiltaChatbotthatCrushedChatGPTwithZeroCostAITools_1.png)\n\n# 우리의 개인 AI가 지역에서 이것을 어떻게 할까요?\n\n음, 당신은 아마도 이것에는 최소한 Mistral-7B만큼 좋은 수퍼 모델이 필요할 것이라고 생각할 수 있습니다. 물론 당신이 좋은 NVidia GPU나 16GB의 메모리, 그리고 양자화된 버전을 갖고 있지 않는 이상 일반 노트북에서 실행할 수 없습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그런 일은 없어요. 내가 구글 콜랩에서 실행하는 Mixtures of Experts (SoMoE)를 만들기로 결정했어. 또한 내 미니PC(130 달러짜리 팬리스 컴퓨터로 윈도우 11이 돌아가며 16GB RAM과 7세대 Intel 4코어 4스레드를 가지고 있는)에서도 테스트했어. 그래서 결론적으로 누구나 내 SoMoE를 실행할 수 있어.\n\n![이미지](/TIL/assets/img/2024-07-13-HowIBuiltaChatbotthatCrushedChatGPTwithZeroCostAITools_2.png)\n\n비밀 조리법? 작은 T5 모델이 텍스트를 요약하고 문서의 주요 질문을 제안하며, StableLM-Zephyr-3B의 양자화 버전이 질문에 대답하고 해당 문서에 대한 챗봇 역할을 한다는 것. 모든 것을 연결하기 위해 영어에만 BAAI/bge-base-en-v1.5 임베딩을 사용해서 벡터 데이터베이스를 만들고 유사성 검색 및 관련성 재랭킹에 작동시키고 있어.\n\n![이미지](/TIL/assets/img/2024-07-13-HowIBuiltaChatbotthatCrushedChatGPTwithZeroCostAITools_3.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 쉬운 방법\n\n간단히 말하면, 기사의 텍스트 길이는 꽤 짧습니다. 4k 토큰 콘텍스트 길이를 가진 모델은 쉽게 전체 로드를 처리하고 텍스트를 처리할 수 있습니다.\n\nGoogle Colab의 무료 티어(오직 CPU와 12GB RAM만 사용 가능)에서 다음을 수행할 수 있습니다:\n\n```js\n#Dependencies 설치 및 stablelm-zephyr-3b-GGUF 다운로드\n!pip install transformers -U --no-cache-dir\n!pip install llama-cpp-python==0.2.34\n!pip install rich\n!huggingface-cli download TheBloke/stablelm-zephyr-3b-GGUF stablelm-zephyr-3b.Q5_K_S.gguf --local-dir . --local-dir-use-symlinks False\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\neditedtext = \"\"\"Apple의 iOS 앱 스토어가 EU에서 대대적인 변화를 발표했습니다.\nhttps://www.axios.com/2024/01/25/apple-app-store-eu-changes\n저자: Ashley Gold, Axios Pro의 저자\nApple은 유럽의 디지털 시장 법안을 준수하기 위해 알 터 내 앱 스토어 및 앱 개발자를 위한 다른 새로운 옵션을 허용할 것이라고 회사가 목요일 밝혔습니다.\n뉴스 주도: 3월 7일에 발효될 예정인 유럽의 주요 기술 경쟁 법은 개발자들이 배포 및 결제 처리를 위해 앱 스토어에 의존해야 하는 엄격한 규정을 완화하기를 Apple에 요구합니다.\nApple은 오랫동안 ...\"\"\"\n```\n\n```js\nfrom rich.panel import Panel\nimport datetime\nfrom rich.console import Console\nconsole = Console(width=110)\nwith console.status(\"Loading ✅✅✅✅ stablelm-zephyr-3b with LLAMA.CPP...\",\n                    spinner=\"dots12\"):\n    llm = Llama(\n        model_path=\"/content/stablelm-zephyr-3b.Q5_K_S.gguf\",  # 먼저 모델 파일을 다운로드하세요\n        n_ctx=4096,  # 사용할 최대 시퀀스 길이 - 더 긴 시퀀스 길이는 더 많은 리소스를 필요로 함을 참고하세요\n        n_threads=2,  # 사용할 CPU 스레드 수, 시스템 및 결과 성능에 맞게 조정하세요\n    )\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n안녕하세요! 아래 텍스트를 참고해주세요:\n\n```js\ncontext = editedtext # 주로 전체 문서입니다\nquery = \"유럽 디지털 시장법에 대응하여 EU 앱 스토어에서 Apple이 시행하는 주요 변경 사항은 무엇인가요?\"\ntemplate = f\"\"\"<|user|>\\n주어진 텍스트 일부는 다음과 같습니다:\\n-----\n              {context}\\n-----\\n\n              질문에 대한 답변을 해주세요. 답변은 정보를 제공하고 목록 형식으로 구성되어야 합니다. 답변할 수 없는 경우, \"답변 불가\"라고 말해주세요.\\n\n              질문: {query}\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```\n![Image](/TIL/assets/img/2024-07-13-HowIBuiltaChatbotthatCrushedChatGPTwithZeroCostAITools_4.png)\n\n# The SoMoE way\n\nI think that the best way to approach a text we don’t know anything about consists at least of 2 steps:\n\n- read a summary\n- get an idea of the main questions about that text\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이러한 이유로 우리는 2개의 함수가 필요합니다: 하나는 텍스트를 요약하는 함수이고, 다른 하나는 텍스트에 대해 통찰력있는 질문을 제공하여 추천 시스템을 구축할 것입니다.\n\n# 🦙 LaMini-Flan-T5–77M — 요약\n\nFlan-T5 패밀리는 인코더-디코더 모델 그룹입니다. 이들은 텍스트 조작과 이해에서 뛰어나게 빠릅니다. 자세한 내용은 여기에서 확인할 수 있어요...\n\n제한 사항은 문맥 크기에 있습니다: 모두 512개의 토큰 이상을 처리할 수 없습니다. 그래서 우리는 Langchain을 사용할 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 단계에서는 텍스트 스플릿터만 사용할 것입니다: 큰 텍스트 말뭉치를 작은 조각들로 나누는 도구와 전략입니다. 일반적으로 문단 수준으로 분할하라고 가르치는 자습서를 찾을 수 있지만, 여기서는 토큰만 사용할 것입니다(512 글자 제한이 있기 때문에).\n\n```js\n# 텍스트 파일 읽기\nwith open(\"/content/Article-edited.txt\") as f:\n  editedtext = f.read()\nf.close()\n# 토큰별로 나누기\nfrom langchain.text_splitter import TokenTextSplitter\nTOKENtext_splitter = TokenTextSplitter(chunk_size=430, chunk_overlap=20)\nsplitted_text_sum = TOKENtext_splitter.split_text(editedtext)  # 리스트 생성\n```\n\n이제 LaMini 모델에게 각 조각에 대한 간단한 요약을 생성해 달라고 요청하고 모든 요약을 결합할 수 있습니다.\n\n```js\n# 모델을 파이프라인으로 로드하기\nfrom transformers import pipeline\nmodel77 = pipeline('text2text-generation',model=\"MBZUAI/LaMini-Flan-T5-77M\")\nsummary =\"요약:\\n\"\n# 조각을 순환하며\nfor item in splitted_text_sum:\n  text = item\n  template_summary = f'''텍스트: {text}\n\n위 텍스트에 대한 명확한 요약을 작성하세요.\n'''\n  res = model77(template_summary, temperature=0.3, repetition_penalty=1.3, max_length=300, do_sample=True)[0]['generated_text']\n  summary = summary + res + '\\n'\nprint(summary)\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n매우 쉬워요! 몇 가지 테스트를 진행해 보시는 걸 권장해요.\n\n# 🦙 LaMini-Flan-T5–77M — 질문 생성기\n\n다음 단계는 주요 질문들을 추출하는 것이에요: 이것은 학교 교과서에서 일반적으로 찾을 수 있는 질문들과 동일한 것이죠 (좋은 교과서들에요): 챕터나 섹션 뒤에 작가들이 공부하는 데 도움이 되는 몇 가지 질문을 제공해요.\n\nLaMini를 사용하면 매우 쉬워요, 프롬프트에 몇 가지 속임수만 있으면 돼요. 차별화된 점은 Text-Splitter의 정밀도를 높이는 것이에요. 우리는 크고 일반적인 질문만 원하는 게 아니에요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nTOKENtext_splitter = TokenTextSplitter(chunk_size=280, chunk_overlap=20)\nsplitted_text_qg = TOKENtext_splitter.split_text(editedtext) # 리스트 생성\n\nfor item in splitted_text_qg:\n  text = item\n  template_qg = f'''{text}\\n\\n\n위의 텍스트에 대한 중요한 두 가지 질문을 작성하세요.\n질문:\n1.\n2.\n'''\n  res = model(template_qg, temperature=0.3, repetition_penalty=1.3, max_length=250, do_sample=True)[0]['generated_text']\n  ed_res = res.replace('? ','?#')\n  list_res = ed_res.split('#')\n  for i in list_res:\n     quest2.append(i[3:])\n```\n\n280 토큰 단위로 청크가 생성되었습니다. 요약에 사용된 430 토큰과는 다릅니다.\n\n# 최종 결과\n\nGitHub 저장소에서 Google Colab 노트북 2개를 찾을 수 있습니다. 하나는 CPU만으로 실행되고, 다른 하나는 무료 T4 인스턴스(GPU)를 사용할 수 있는 노트북입니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오픈 소스 LLM이 여기 있고, 당신이 그것을 사용할 때 꼭 고루가 아니어도 됩니다.\n\n가장 많이 사용하는 작업에 대한 몇 가지 함수를 만들면, 어떤 사용 사례에도 사용할 수 있는 스위스 아미 나이프를 갖게 됩니다.\n\n그저 시작하는 용기만 있으면 됩니다!\n\n이 기사를 즐겼기를 바랍니다. 만약 이 이야기가 가치를 제공하고 조금이라도 지원을 보여주고 싶다면 다음과 같은 방법을 사용할 수 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 이 이야기에 대해 많이 박수를 치세요\n- 기억할 가치가 있는 부분을 강조하세요 (나중에 찾기 쉽고 더 나은 기사를 쓰기 위해)\n- 직접 AI를 만들어보기 시작하는 방법을 배운다면, 무료 eBook을 다운로드하세요\n- 무제한 Medium 이야기를 읽기 위해 월 $5를 내고 Medium 멤버십에 가입하세요\n- Medium에서 나를 팔로우하세요\n- 내 최신 기사를 읽어보세요 https://medium.com/@fabio.matricardi\n\n더 많은 정보를 원한다면, 다음은 로컬 AI를 문서와 함께 사용하는 아이디어입니다:\n\nWRITER at MLearning.ai / Midjourney ALPHA / 180K+ AI Art Prompts","ogImage":{"url":"/TIL/assets/img/2024-07-13-HowIBuiltaChatbotthatCrushedChatGPTwithZeroCostAITools_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-HowIBuiltaChatbotthatCrushedChatGPTwithZeroCostAITools_0.png","tag":["Tech"],"readingTime":11},{"title":"딥러닝 메모리 관리 혁명 Torch Memoryadaptive Algorithms TOMA의 비밀","description":"","date":"2024-07-13 19:50","slug":"2024-07-13-TorchMemoryadaptiveAlgorithmsTOMARevolutionizingMemoryManagementinDeepLearning","content":"\n\n# 요약\n\n배경: 딥러닝에서는 메모리를 효율적으로 관리하는 것이 중요합니다. 특히 대규모이고 복잡한 신경망을 훈련할 때 이는 중요합니다. 자원 제약으로 인해 메모리 부족 오류가 발생하고 모델의 확장성이 제한될 수 있습니다.\n\n문제: 전통적인 메모리 관리 방법은 종종 정적이고 비효율적이며 훈련 중에 불안정성을 초래하고 세련된 모델의 개발을 방해할 수 있습니다. 이 병목현상은 동적으로 메모리 사용량을 최적화하기 위한 혁신적인 솔루션을 필수로 합니다.\n\n접근 방식: 본 에세이는 PyTorch를 기반으로 구축된 Torch Memoryadaptive Algorithms (TOMA)를 소개합니다. TOMA는 훈련 및 추론 중 메모리 할당을 동적으로 조정하는 것을 목적으로 설계되었습니다. TOMA는 적응형 기울기 체크포인팅, 최적화된 데이터 로딩, 그리고 모델 가지치기 및 양자화를 활용하여 메모리 효율성을 향상시킵니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n결과: 합성 데이터세트를 사용하여 TOMA의 적용은 우수한 성능을 보여주었습니다. 최상의 교차 확인 RMSE가 0.1138이고 R2 점수가 0.9844였습니다. 이 모델은 테스트 RMSE가 0.1129이고 R2 점수가 0.9848로 안정적인 일반화와 높은 예측 정확도를 보여주었습니다. 실제 값 대 예측값의 산점도는 강한 선형 관계를 나타내며 모델의 효과를 더욱 확증했습니다.\n\n결론: TOMA는 딥 러닝에서 메모리 관리를 혁신적으로 향상시켜, 자원에 제한된 하드웨어에서 더 큰 모델을 학습할 수 있도록 합니다. 결과는 TOMA가 모델의 안정성, 확장성, 효율성을 향상시키는 잠재력을 강조하며, AI 커뮤니티의 연구원과 실무자들에게 가치 있는 도구로 자리잡을 수 있다는 것을 보여줍니다.\n\n키워드: 동적 메모리 관리; 신경망 최적화; PyTorch TOMA 프레임워크; 효율적인 딥 러닝; 적응형 그래디언트 체크포인팅.\n\n# 소개\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n상상해보세요. 당신의 최첨단 GPU 메모리에 맞기 어려운 정도로 방대한 신경망을 훈련한다고 상상해봅시다. 훈련 중에 메모리 부족 오류가 발생하여 진행이 멈추고 모델을 축소하거나 하드웨어를 업그레이드해야 하는 상황입니다. 그러나 메모리를 적응적으로 관리하여 가장 복잡한 모델들에도 원만하고 효율적인 훈련을 보장할 수 있는 방법이 있다면 어떨까요? Torch Memoryadaptive Algorithms (TOMA) [1]가 바로 그 메모리 최적화의 게임 체인저입니다.\n\n![이미지](/TIL/assets/img/2024-07-13-TorchMemoryadaptiveAlgorithmsTOMARevolutionizingMemoryManagementinDeepLearning_0.png)\n\n# 메모리 병목 현상: 흔한 장애물\n\n딥러닝 모델은 점점 더 복잡해지면서 더 많은 계산 성능과 메모리를 요구합니다. AI가 어디까지 가능한지의 한계를 끌어올리는 동시에, 이러한 경향은 상당한 어려움을 야기합니다. 기존 방법론은 종종 고성능 GPU에 제한된 연구원과 실무자들이 계속해서 따라잡기 어렵도록 만들어버립니다. 메모리 병목 현상은 흔하게 발생하며 훈련 과정을 충돌시키거나 상당히 느리게 만들어버립니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# TOMA: 적응형 메모리 관리\n\nTorch Memoryadaptive Algorithms (TOMA)은 이러한 도전에 직면하여 대응합니다. 다재다능한 PyTorch 프레임워크 위에 구축된 TOMA는 훈련과 추론 중에 메모리 사용량을 동적으로 조정합니다. 이러한 적응성은 자원이 효율적으로 할당되어 메모리 부족 오류가 발생할 가능성을 줄이며 모델의 전반적인 안정성과 확장성을 향상시킵니다.\n\n## 동적 메모리 할당: 효율성 극대화\n\nTOMA의 핵심 기능 중 하나는 현재 훈련 상태를 기반으로 메모리를 동적으로 할당하는 능력입니다. 낭비되고 비효율적일 수 있는 정적 할당 방법과 달리 TOMA는 메모리 사용량을 지속적으로 모니터하고 할당을 실시간으로 조정합니다. 이 방법은 자원 활용률을 최적화하고 기존 하드웨어에서 더 큰 모델을 훈련할 수 있도록 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 적응형 그래디언트 체크포인팅: 메모리와 계산의 균형 유지\n\nTOMA의 또 다른 혁신적인 측면은 적응형 그래디언트 체크포인팅 기술입니다. TOMA는 중간 활성화값을 선택적으로 저장하고 다시 계산함으로써 계산 효율성을 훼손하지 않으면서 메모리 소비를 크게 줄입니다. 이 균형은 메모리 절약이 성능과 확장성을 크게 향상시킬 수 있는 딥 뉴럴 네트워크 학습에 중요합니다.\n\n## 최적화된 데이터로딩: 안정적인 데이터 흐름 보장\n\n데이터 로딩은 딥러닝 훈련에서 종종 간과되는 부분입니다. 비효율적인 데이터 전송이 병목 현상을 일으켜 전체 프로세스를 늦추는 경우가 있습니다. TOMA는 사전 로딩 및 데이터 일괄 처리를 위한 최적화된 데이터 로딩 전략을 통합함으로써 이 문제에 대처합니다. 이를 통해 GPU로 안정적인 데이터 흐름을 보장하고 지연을 최소화하여 전반적인 훈련 효율성을 향상시킵니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 모델 가지치기 및 양자화: 풋프린트 축소\n\nTOMA는 메모리 사용량을 더욱 최적화하기 위해 모델 가지치기 및 양자화 기술을 포함하고 있습니다. 가지치기는 중복 매개변수를 제거하며, 양자화는 가중치의 정밀도를 감소시킵니다. 이러한 방법들은 모델의 정확도를 유지하면서 메모리 풋프린트를 크게 줄여줌으로써, 자원이 제한된 기기에 복잡한 모델을 배포하는 것이 가능해집니다.\n\n## 실시간 모니터링 및 프로파일링: 투명성 및 제어\n\n효율적인 메모리 관리에는 투명성과 제어가 중요합니다. TOMA는 실시간 메모리 모니터링 및 프로파일링 도구를 제공하여, 개발자들이 교육 과정 전반에 걸쳐 사용량을 추적할 수 있도록 합니다. 이러한 가시성은 메모리 병목 현상을 식별하고 해결함으로써, 더 효율적이고 신뢰할 수 있는 교육 실행을 이끌어냅니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 실용적인 응용: 연구부터 엣지 컴퓨팅까지\n\nTOMA의 장점은 다양한 분야에 걸쳐 확장됩니다. 연구에서는 새로운 신경망 구조의 신속한 프로토타이핑과 테스트를 지원합니다. 엣지 컴퓨팅 및 사물 인터넷(IoT) 장치를 다루는 실무자들에게는, TOMA가 제한된 메모리와 처리 능력을 갖춘 장치에 정교한 AI 모델을 배포하는 것을 가능하게 합니다. TOMA는 메모리 사용량을 최적화하고 엣지에서 실시간 추론과 의사 결정을 용이하게 해주어, 지능적인 응용 프로그램에 대한 새로운 가능성을 열어줍니다.\n\n# 실용적인 예제\n\n아래는 합성 데이터셋을 사용하여 Torch Memoryadaptive Algorithms (TOMA)를 시연하는 완전한 Python 코드 예제입니다. 이 예제는 데이터 생성, 피처 엔지니어링, 초모수 조정을 통한 모델 훈련, 교차 검증, 예측 및 평가를 다룹니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 합성 데이터셋 생성\ndef generate_synthetic_data(n_samples=1000, n_features=10):\n    X = np.random.rand(n_samples, n_features)\n    y = np.sum(X, axis=1) + np.random.randn(n_samples) * 0.1  # 단순한 선형 관계에 노이즈 추가\n    return X, y\n\n# 특성 엔지니어링 (다항 특성 추가)\ndef feature_engineering(X):\n    poly_features = X ** 2\n    return np.hstack([X, poly_features])\n\n# 간단한 신경망 모델\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.fc3 = nn.Linear(32, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n# 훈련 함수\ndef train_model(model, train_loader, criterion, optimizer, n_epochs=100):\n    model.train()\n    for epoch in range(n_epochs):\n        for data, target in train_loader:\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target.view(-1, 1))\n            loss.backward()\n            optimizer.step()\n\n# 교차 검증과 하이퍼파라미터 튜닝\ndef cross_validate(X, y, k=5, lr=0.001, n_epochs=100):\n    kf = KFold(n_splits=k)\n    rmses = []\n    r2s = []\n\n    for train_index, val_index in kf.split(X):\n        X_train, X_val = X[train_index], X[val_index]\n        y_train, y_val = y[train_index], y[val_index]\n\n        train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n        val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n\n        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n        model = SimpleNN(X_train.shape[1])\n        criterion = nn.MSELoss()\n        optimizer = optim.Adam(model.parameters(), lr=lr)\n\n        train_model(model, train_loader, criterion, optimizer, n_epochs)\n\n        model.eval()\n        val_preds = []\n        val_targets = []\n\n        with torch.no_grad():\n            for data, target in val_loader:\n                output = model(data)\n                val_preds.extend(output.view(-1).tolist())\n                val_targets.extend(target.tolist())\n\n        rmse = mean_squared_error(val_targets, val_preds, squared=False)\n        r2 = r2_score(val_targets, val_preds)\n        rmses.append(rmse)\n        r2s.append(r2)\n\n    return np.mean(rmses), np.mean(r2s)\n\n# 주 스크립트\nif __name__ == \"__main__\":\n    X, y = generate_synthetic_data()\n    X = feature_engineering(X)\n\n    # 데이터를 훈련 및 테스트 세트로 분할\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # 하이퍼파라미터 튜닝\n    best_lr = 0.001\n    best_rmse, best_r2 = cross_validate(X_train, y_train, k=5, lr=best_lr, n_epochs=100)\n\n    # 전체 훈련 세트에서 최종 모델 훈련\n    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n    final_model = SimpleNN(X_train.shape[1])\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(final_model.parameters(), lr=best_lr)\n\n    train_model(final_model, train_loader, criterion, optimizer, n_epochs=100)\n\n    # 테스트 세트에서 평가\n    final_model.eval()\n    test_preds = []\n    with torch.no_grad():\n        test_preds = final_model(torch.tensor(X_test, dtype=torch.float32)).view(-1).tolist()\n\n    rmse = mean_squared_error(y_test, test_preds, squared=False)\n    r2 = r2_score(y_test, test_preds)\n\n    # 결과 및 해석\n    print(f\"최고 교차 확인 RMSE: {best_rmse:.4f}\")\n    print(f\"최고 교차 확인 R2: {best_r2:.4f}\")\n    print(f\"테스트 RMSE: {rmse:.4f}\")\n    print(f\"테스트 R2: {r2:.4f}\")\n\n    # 결과 그래프\n    plt.figure(figsize=(10, 5))\n    plt.scatter(y_test, test_preds, alpha=0.7)\n    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')\n    plt.xlabel(\"실제 값\")\n    plt.ylabel(\"예측 값\")\n    plt.title(\"실제 값 대 예측 값\")\n    plt.show()\n```\n\n## 설명\n\n- 데이터 생성: 선형 관계와 노이즈가 포함된 가상 데이터셋 생성\n- 특성 엔지니어링: 모델 용량을 높이기 위해 다항 특성 추가\n- 모델 정의: PyTorch를 사용하여 간단한 신경망 모델 정의\n- 훈련 함수: 주어진 데이터셋과 옵티마이저를 사용하여 모델 훈련\n- 교차 검증 및 하이퍼파라미터 튜닝: K-Fold 교차 검증을 통해 하이퍼파라미터를 튜닝하고 모델 성능 평가\n- 주 스크립트: 데이터 분할, 하이퍼파라미터 튜닝, 최종 모델 훈련, 테스트 세트 평가 등을 실행하는 스크립트\n- 결과 및 그래프: 성능 지표 (RMSE, R2)를 출력하고 실제 값과 예측값을 비교하는 산점도 그래프 표시\n\nTorch Memoryadaptive Algorithms (TOMA)을 활용하여 신경망을 효율적으로 훈련하고 평가하는 포괄적인 예제 코드입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-13-TorchMemoryadaptiveAlgorithmsTOMARevolutionizingMemoryManagementinDeepLearning_1.png\" />\n\n모델의 성능 지표와 산점도 결과는 모델의 성능을 얼마나 잘 평가했는지에 대한 소중한 통찰력을 제공합니다. 여기에 결과에 대한 해석이 있습니다:\n\n## 성능 지표\n\n- Best Cross-Validated RMSE: 0.1138: Root Mean Squared Error (RMSE)는 모델이 예측한 값과 실제 값 사이의 차이를 측정합니다. 낮은 RMSE는 더 좋은 성능을 나타냅니다. 여기서 교차 확인을 통해 0.1138의 값은 검증 데이터에서 모델이 잘 수행되고 예측이 실제 값에 가깝다는 것을 시사합니다.\n- Best Cross-Validated R2: 0.9844: R-squared (R2) 점수는 모델이 대상 변수의 분산을 얼마나 잘 설명하는지를 나타냅니다. R2 점수가 1에 가까울수록 모델이 대상 변수의 분산의 많은 부분을 설명한다는 것을 의미합니다. 0.9844의 교차 확인된 R2 점수는 모델이 데이터의 기저 패턴을 매우 잘 포착한다는 것을 시사합니다.\n- Test RMSE: 0.1129: 시험 RMSE가 교차 확인된 RMSE보다 약간 낮은 것은 모델이 보이지 않은 데이터에도 잘 일반화된다는 것을 나타냅니다. 이는 훈련 과정 중에 과적합이 심하지 않았으며, 시험 세트에서의 모델 성능이 교차 확인 중에 보인 성능과 일관성이 있다는 것을 시사합니다.\n- Test R2: 0.9848: 0.9848의 시험 R2 점수는 교차 확인된 R2 점수에 매우 가까운 것으로, 모델이 견고하고 새로운 데이터에도 잘 일반화된다는 것을 확인합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 산점도 해석\n\n\"True Values vs Predictions\"라는 제목이 붙은 산점도는 실제 값과 모델이 예측한 값 사이의 관계를 보여줍니다.\n\n- 최적 선 (빨간 선): 빨간 선은 예측이 실제 값과 완벽하게 일치하는 이상적인 상황을 나타냅니다 (즉, 원점을 통과하는 45도 직선). 파란 점들이 빨간 선에 가까울수록 모델의 예측이 더 좋습니다.\n- 데이터 점 (파란 점): 파란 점들은 모델이 한 실제 예측을 나타냅니다. 이러한 점들이 빨간 선 주변에 밀집되어 있음은 모델의 예측이 높은 정확도를 가지고 있다는 것을 나타냅니다.\n- 실제 값과 예측값 사이의 일관된 선형 관계는 모델이 합성 데이터셋의 기본 선형 패턴을 효과적으로 포착했다는 것을 시사합니다.\n\n```js\n최적 교차 확인 RMSE: 0.1138\n최적 교차 확인 R2: 0.9844\n테스트 RMSE: 0.1129\n테스트 R2: 0.9848\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 전반적 해석\n\n교차 검증 및 테스트 세트에서 낮은 RMSE 값과 높은 R2 점수의 조합은 모델이 매우 우수한 성능을 발휘했음을 나타냅니다. 산점도는 예측값이 실제 값과 매우 가까운 것을 보여주어 이를 더욱 뒷받침합니다.\n\n- 모델 정확도: 높은 R2 점수와 낮은 RMSE 값은 모델이 특성으로부터 대상 변수를 매우 정확하게 예측한다는 것을 시사합니다.\n- 일반화: 교차 확인 및 테스트 지표 간의 일관성은 모델이 보이지 않은 데이터에도 잘 일반화되며, 이는 실용적인 응용 프로그램에 매우 중요합니다.\n- 실용적 영향: 실용적 시나리오에서 이러한 강력한 성능은 모델이 비슷한 맥락에서 예측 작업에 신뢰할 수 있게 사용될 수 있음을 의미하며, 예측이 실제 결과에 근접하게 하여 더 나은 의사 결정이 가능합니다.\n\n결론적으로, Torch Memoryadaptive Algorithms (TOMA)은 합성 데이터셋에서 메모리 관리와 신경망 성능 향상의 효과를 입증했습니다. 결과는 TOMA가 실제 응용 분야에서 효율적이고 정확한 예측 모델 개발에 유용한 도구가 될 수 있다는 것을 보여줍니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론: 딥 러닝의 경계를 넓히는 TOMA\n\nTorch Memoryadaptive Algorithms (TOMA)는 메모리 관리의 중요한 과제를 해결하는 딥 러닝의 중요한 진전입니다. TOMA는 메모리 할당을 동적으로 조정하고 적응형 그래디언트 체크포인팅을 이용하며 데이터 로딩을 최적화하고 가지치기 및 양자화 기술을 통합함으로써 신경망의 효율성, 확장성 및 안정성을 향상시킵니다. 연구원과 실무자들에게 TOMA는 가능한 한계를 초월할 수 있는 강력한 도구로 작용하며, 메모리 제약이 있는 환경에서도 고급 AI를 활용할 수 있도록 합니다. 딥 러닝이 발전함에 따라, TOMA와 같은 혁신은 진전을 이끄는 데 중요하며 기술적 돌파구를 가능하게 합니다.\n\n딥 러닝에서 동적 메모리 관리의 영향에 대한 생각이 있으신가요? 프로젝트에서 메모리 제약이 있었나요? 아래 댓글에 여러분의 경험과 의견을 공유해 주세요! 도움이 되었다면 이 글을 꼭 여러분의 네트워크와 공유하세요!\n\n# 참고문헌","ogImage":{"url":"/TIL/assets/img/2024-07-13-TorchMemoryadaptiveAlgorithmsTOMARevolutionizingMemoryManagementinDeepLearning_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-TorchMemoryadaptiveAlgorithmsTOMARevolutionizingMemoryManagementinDeepLearning_0.png","tag":["Tech"],"readingTime":14},{"title":"몰랐던 Jupyter의 숨겨진 해킹 5가지","description":"","date":"2024-07-13 19:49","slug":"2024-07-13-5JupyterHacksThatYouNeverKnewEvenExisted","content":"\n\n아래는 이 기사의 코드입니다.\n\nJupyter Notebook은 데이터 과학, 머신 러닝, 과학 계산 및 기타 Python 중심 프로그래밍 작업에 가장 인기 있는 IDE 중 하나입니다.\n\n대화식 코딩 기능으로 초심자뿐만 아니라 전문가들에게도 가장 많이 사용되는 도구로 자리 잡고 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n하지만 널리 사용되고 있지만, 많은 사용자들이 그 가능성을 충분히 활용하지 못하고 있습니다.\n\n결과적으로, 그들은 주피터를 기본 인터페이스/기능을 이용하여 사용하는데, 내 의견으로는 이를 향상시켜 더욱 풍부한 경험을 제공할 수 있습니다.\n\n그래서 이 글에서는 아마 당신이 전혀 몰랐을 것으로 생각되는 5가지 멋진 주피터 해킹을 소개하겠습니다.\n\n이를 통해 당신은 이 강력한 도구로 새로운 생산성과 창의력을 발휘할 수 있을 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n시작해봅시다 🚀!\n\n## 1. 데이터프레임의 원시 데이터 미리보기 중지\n\nJupyter에서 데이터프레임을 로드할 때 종종 출력을 통해 미리보기합니다. 아래의 내용을 확인할 수 있습니다: \n\n![데이터프레임 미리보기](/TIL/assets/img/2024-07-13-5JupyterHacksThatYouNeverKnewEvenExisted_1.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러나 이것은 이 데이터에 내장된 내용에 대해 거의 어떤 정보도 전달하지 않습니다.\n\n결과적으로 분석을 통해 더 깊이 파고들어야 할 필요가 있습니다. 그리고 이는 간단하면서 반복적인 코드를 포함합니다.\n\n대신 Jupyter-DataTables을 사용하세요. 다음과 같이 설치할 수 있습니다:\n\n사용하려면 Jupyter에서 다음 코드를 실행하세요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDataFrame의 기본 미리보기를 많은 유용한 기능으로 확장합니다.\n\n결과적으로 DataFrame을 출력할 때 아래와 같이 훨씬 더 우아하게 나타납니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*vtDNomuoHOnqE46HGF61rA.gif)\n\n이 풍부한 미리보기는 정렬, 필터링, 내보내기 및 페이지네이션 작업을 제공하며 열 분포 및 데이터 유형도 제공합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 데이터에 레이블을 붙이는 클릭 한 번으로!\n\n모든 데이터가 미리 레이블이 달려 온 것은 아닙니다.\n\n따라서 레이블이 없는 데이터의 경우, 주로 약간의 시간을 들여 주석을 다는 작업을 해야 할 수도 있습니다.\n\n파일을 외부에서 미리보고 레이블을 붙이거나 복잡한 주석 생성 파이프라인을 만드는 대신, **ipynnotate**를 사용하여 몇 줄의 코드로 주석을 달 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위의 문구를 번역하면 다음과 같습니다:\n\n데이터 주석을 위한 특별한 Jupyter 위젯을 제공합니다.\n\n다음 명령을 실행하여 설치합니다:\n\n버튼을 클릭하여 데이터 주석을 쉽게 할 수 있습니다. 따라서 ipyannotate를 사용하면 버튼에 데이터 레이블을 부착할 수 있습니다.\n\n고양이와 개의 이미지가 있는 경우(라벨이 없음) 주석 처리 파이프라인을 다음과 같이 생성할 수 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*HyBsbKP8jtnB-srveBSDwA.gif\" />\n\n위에 표시된 것처럼 해당 버튼을 클릭하기만 하면 데이터를 주석으로 달 수 있습니다.\n\n더불어, 레이블을 검색하고 필요에 따라 데이터 파이프라인에 사용할 수도 있습니다.\n\n# #3 주피터에서 문서 보기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nJupyter에서 작업할 때 함수의 매개변수를 잊기 쉽고 공식 문서(또는 StackOverflow)를 방문하는 것이 일반적입니다.\n\n그러나 노트북 자체에서 문서를 볼 수 있습니다.\n\nShift-Tab 키를 누르면 문서 패널이 열립니다. 이 기능은 매우 유용하며 공식 문서를 매번 열 필요가 없어 시간을 절약할 수 있습니다.\n\n아래에서 데모를 보여드립니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*BoRuu6MfmFfjACuXrPpjrg.gif)\n\nThis feature also works for your custom functions.\n\n## 4. Get Notified When Jupyter Cell Has Executed\n\nAfter running some code in a Jupyter cell, we often navigate away to do some other work in the meantime.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기에서는 셀이 실행되었는지 여부를 확인하기 위해 반복적으로 주피터 탭으로 돌아가야 합니다.\n\n이를 피하기 위해, 주피터 노트북 확장 기능인 %%notify 매직 명령어를 사용할 수 있습니다.\n\n이름에서 알 수 있듯이, 이 매직 명령은 Jupyter 셀의 완료(성공 또는 실패) 시에 브라우저 알림을 통해 사용자에게 알려줍니다.\n\n설치하려면 다음 명령을 실행하세요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음으로, 확장 기능을 로드하세요:\n\n그리고 끝났어요!\n\n이제 원하는 경우 알림을 받으려면 셀 맨 위에 다음의 매직 명령어를 입력하십시오:\n\n해당 셀이 실행을 완료하면 다음과 같은 알림을 받게 됩니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 마크다운 형식으로 된 테이블입니다.\n\n클릭하면 알림이 발생하여 Jupyter 탭으로 돌아갑니다.\n\n# #5 Jupyter Notebook에서 런타임 중 셀 출력 지우기\n\nJupyter를 사용하면 코드 진행 상황을 추적하기 위해 일반적으로 많은 세부 정보를 출력합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러나 출력 패널에 많은 세부 정보가 누적된 경우, 가장 최근의 출력만 관심이 있는 경우가 있기 때문에 짜증이 날 수 있습니다.\n\n게다가 매번 출력 맨 아래로 스크롤하는 것도 짜증스러울 수 있어요.\n\n셀의 출력을 지우려면 IPython 패키지에서 clear_output 메서드를 사용할 수 있어요.\n\nPython에 IPython이 미리 설치되어 있기 때문에 설치가 필요하지 않아요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래와 같이 해당 메서드를 가져올 수 있습니다:\n\n호출하면 셀의 현재 출력이 제거되며, 그 후에 최신 세부 정보를 출력할 수 있습니다.\n\n다음은 데모가 표시됩니다:\n\n![데모](https://miro.medium.com/v2/resize:fit:1400/1*HLiihJXmkIXB0vZg2DbTtA.gif)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위에서 보여드린 대로, 우리는 셀에서 가장 최근 출력만 볼 수 있습니다. 이전 출력물들은 지워집니다.\n\n# 보너스 팁\n\n위에서 언급한 팁들은 주피터를 더욱 풍요롭게 만들어줄 것이지만, 주피터에서 아직까지 해결하기 어려운 부분들이 많습니다.\n\n예를 들어, 주피터는 협업에 적합하지 않습니다. 로컬에서 실행되기 때문에, 실시간 협업 기능을 주피터에 내장하는 것이 불가능하며, 팀원들이 함께 작업하고, 댓글을 추가하고, 진행 상황을 추적하는 등의 작업을 할 수 없습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n게다가, 공유하기도 똑같이 까다로워요. 노트북을 누군가와 공유해야 한다면, 그럴 수 있는 방법은 그들에게 이메일을 보내거나 GitHub와 같은 온라인 서비스에 호스팅하여 링크를 공유하는 것뿐입니다.\n\n마지막으로, 많은 데이터 과학 작업은 파이썬으로만 제한되지 않아요. 그 작업에는 SQL도 불가피하게 관련되어 있는데, 이는 주로 조직의 데이터베이스와 상호작용하는 데 사용돼요.\n\n하지만, Jupyter에 SQL을 통합하는 것은 가능하지만 번거로운 과정이에요.\n\n## 해결책\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 한계에 좌절하며 대안을 찾기 시작했는데, Deepnote를 발견해서 정말 다행이었습니다.\n\nDeepnote는 제이퍼의 모든 한계를 쉽게 해결해 주었고, 기존의 제이퍼와 유사한 풍부한 경험을 제공해 주었습니다. 새로운 것을 배우지 않아도 되는 Deepnote를 사용하면, SQL 사용, 코드 없이 차트 생성, 데이터베이스 연결 등 모든 것이 원활하게 통합되어 있습니다.\n\n제이퍼가 모든 파이썬 사용자에게 일반화된 경험을 제공하려고 하는 것을 이해하지만, 데이터 과학자들의 고통 포인트를 전혀 해결하지 못한다는 사실을 이해합니다. 특히 팀으로 작업하는 데이터 과학자들에게는 더 그렇습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDeepnote은 내 의견으로는 모든 데이터 주도 프로젝트에 대한 Jupyter의 초고속 버전입니다. 꼭 확인해보세요.\n\n# 결론\n\n이로써, 이 블로그의 끝에 도달했습니다.\n\nJupyter 노트북을 위한 멋진 팁 몇 가지를 배워 축하드립니다. 이 정보들이 여러분의 Python 프로그래밍 생산성을 높여줄 것이라고 확신합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저도 여러분이 주피터 노트북을 사용할 때 어떤 좋은 팁이 있나요? \n\n언제나 읽어 주셔서 감사합니다!\n\n🚀 오늘 구독하시면 320개 이상의 게시물과 550페이지 이상의 무료 데이터 과학 PDF를 받을 수 있습니다:\n\n![image](https://miro.medium.com/v2/resize:fit:1400/0*oW2adl2lbMY8ZplS.gif)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDataDrivenInvestor.com에서 저희를 방문해 주세요.\n\nDDIntel을 여기에서 구독하실 수 있습니다.\n\n공유하고 싶은 독특한 이야기가 있나요? DDIntel로 제출해 주세요.\n\n저희 창조자 생태계에 여기서 참여해 보세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDDIntel은 우리의 주요 사이트와 인기 있는 DDI Medium 출판물에서 주목할 만한 기사를 소개합니다. 우리 커뮤니티로부터 더 많은 통찰력 있는 작품을 확인해보세요.\n\nDDI 공식 텔레그램 채널: [링크](https://t.me/+tafUp6ecEys4YjQ1)\n\nLinkedIn, Twitter, YouTube, 그리고 Facebook에서 팔로우해주세요.","ogImage":{"url":"/TIL/assets/img/2024-07-13-5JupyterHacksThatYouNeverKnewEvenExisted_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-5JupyterHacksThatYouNeverKnewEvenExisted_0.png","tag":["Tech"],"readingTime":11},{"title":"라즈베리 파이에서 Mistral과 LLaVA로 AI와 함께 중국 설날 즐기는 팁 10가지","description":"","date":"2024-07-13 19:47","slug":"2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi","content":"\n\n# 소개\n\n전통 축제가 첨단 기술과 만나는 이 기사에 오신 것을 환영합니다. 우리가 중국 음력 새해를 접하면서, Mistral AI의 대형 언어 모델이나 LLaVA와 같은 멀티 모달 모델과 같은 문화적 조언들과 함께 축제 기간을 즐기기에 완벽한 순간입니다.\n\n이 기사의 특별한 점은 언급된 모델을 저렴한 소형 엣지 장치인 라즈베리 파이에 배포한다는 것입니다. 이를 통해 주방을 비롯한 다른 가정용 가전 제품에서도 첨단 인공지능 기술을 접근할 수 있습니다.\n\n용감하게 우리가 용의 해에 발을 디딜 때, 상품 장치에 작은 AI 모델을 활용하고 축제 분위기를 즐기는 것이 흥미로운 순간입니다. 라즈베리 파이나 생성적 AI를 사용해본 적이 없더라도 걱정하지 마세요. 이 기사에서는 이 프로젝트의 모든 단계를 영웅이 될 때까지 안내해 드리겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n시작해 봅시다!\n\n![image](/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_0.png)\n\n## 하드웨어 전제 조건\n\n이해하셨듯이, 이 문서에는 몇 가지 기본 하드웨어가 필요합니다. 필요한 것은 다음과 같습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Raspberry Pi 5–8 GB: 라즈베리 파이를 129유로에 개별 구매했어요. 아래 나열된 모든 구성품이 포함된 스타터 키트를 구입할 수도 있어요.\n- 마이크로 메모리 카드: 메모리 카드가 클수록 빠를수록 좋아요. 저는 \"SanDisk 128GB MicroSDXC + SD 어댑터 A2 앱 성능 최대 190MB/s, 클래스 10, U3, V30\"을 선택했어요. 이 마이크로 SD 카드 비용은 27유로 했어요.\n- 마이크로 HDMI 변환기: 디스플레이를 위해 필요해요. 저는 약 4유로에 가장 저렴한 옵션을 구매했어요.\n- 팬 (선택 사항): CPU를 냉각하기 위해. 처음에는 팬을 사지 않았지만, CPU가 지나치게 뜨거워지고 AI 모델이 더 느리게 실행되기 시작하자, 냉각 팬이 성능을 향상시킬 수 있을 것 같았어요. 오늘 아침 20유로에 하나를 구입했고, 다음 기사에서 제 귀여운 팬을 볼 수 있을 거예요. :)\n- 27W USB-C 전원 공급 장치: 이 건 20유로에 구매했어요.\n\n이 프로젝트를 시작하려면 유럽에서 약 160유로에서 180유로 정도를 투자할 것으로 예상돼요. 이제 라즈베리 파이와 하드웨어, 필요한 모든 장비를 빠르게 살펴봐요.\n\n주변기기에 대한 자세한 내용은 아래 이미지를 참조해주세요. 라즈베리 파이에는 4개의 USB 포트가 있어요: 5Gbps 전송 속도를 지원하는 2개의 USB 3.0 포트로 빠른 장치에 이상적이고, 마우스와 키보드를 연결하기에 완벽한 2개의 USB 2.0 포트가 있어요.\n\n라즈베리 파이에는 두 개의 마이크로 HDMI 포트도 제공돼요. 이를 통해 두 개의 디스플레이를 동시에 연결할 수 있어요. 전원 공급을 위한 전용 전원 공급 포트도 있어요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n라즈베리파이 5의 반대쪽에는 microSD 카드를 넣을 수 있는 슬롯이 있습니다. 거기에 운영 체제를 다운로드하고 설치할 것입니다.\n\n# 라즈베리 OS 이미지 준비\n\nSD 카드를 통해 라즈베리 파이를 부팅하려면, 우선 라즈베리 파이에서 제공하는 이미지 소프트웨어를 다운로드해야 합니다. 해당 소프트웨어는 https://www.raspberrypi.com/software/에서 제공됩니다.\n\n이 소프트웨어는 사용자 친화적이며 사용하기 쉽습니다. 노트북에 다운로드하고 설치한 후, SD 카드를 노트북의 카드 리더기에 삽입하십시오. 그런 다음 소프트웨어를 사용하여 라즈베리 OS를 SD 카드에 플래시 할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우선, Raspberry Pi 장치, 운영 체제 및 저장 공간을 선택해야 합니다. 다음 화면 캡처에서 제공된 옵션을 선택할 수 있어요.\n\n그런 다음 몇 가지 사용자 정의 설정을 설정하기 위해 다음을 클릭할 수 있어요. 아래 화면 캡처에서 보여주는 대로요.\n\n그 사용자 정의 설정을 마무리하면 아래에서 보여주는 대로 SD 카드를 플래시할 수 있어요.\n\n![화면 캡처](/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_1.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n# 라즈베리 파이 시작 및 필수 도구 설치하기\n\nSD 카드를 준비한 후 라즈베리 파이에 삽입할 수 있습니다. 전원을 켜고 몇 분을 기다리면 익숙한 리눅스 (데비안) 데스크톱 화면이 화면에 나타납니다. 사용하기 쉬운 깨끗하고 간단한 UI로 이 점을 감사히 여깁니다.\n\n<img src=\"/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_3.png\" />\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n내 Raspberry Pi가 시작되면 다음 몤령을 실행하여 Raspberry Pi의 IP 주소를 알 수 있고, 그런 다음 노트북을 사용하여 SSH를 통해 Raspberry Pi에 연결합니다.\n\nSSH 연결 없이 Raspberry Pi에서 아래 모든 몤령을 직접 실행하려면 가능합니다.\n\n```js\n# Raspberry Pi에서 실행\nifconfig\n```\n\n![이미지](/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_4.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n# 내 노트북에서 실행\nssh 내_사용자_이름@라즈베리_파이_IP_주소\n\n\n# 라즈베리 파이에 Docker 설치하기\n\nSSH를 통해 라즈베리 파이에 연결한 후 다음 명령을 실행하여 Docker를 설치할 것입니다. 웹 UI를 설치하기 위해 Docker가 필요한데, 이를 통해 AI 어시스턴트와 상호작용할 수 있습니다.\n\n\nsudo apt-get update && sudo apt-get upgrade\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![이미지](/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_5.png)\n\n도커 설치를 몇 가지 간단한 명령어로 안내해 드리겠습니다. 먼저 라즈베리 파이에 Docker를 설치할 적절한 스크립트를 다운로드합니다. 다음 명령어를 사용하여 설치 스크립트를 다운로드하세요:\n\n```js\ncurl -fsSL https://get.docker.com -o get-docker.sh\n```\n\n그런 다음 다음 명령어로 스크립트를 실행하세요:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nsudo sh get-docker.sh\n```\n\n![image](/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_6.png)\n\n설치 후에는 일반 사용자를 Docker 그룹에 추가하는 것이 좋습니다. 이렇게하면 루트 액세스 없이도 Docker 명령을 실행할 수 있습니다.\n\n사용자를 Docker 그룹에 추가하는 방법은 다음과 같습니다. 변경 사항이 적용되려면 Raspberry Pi에서 로그아웃하고 SSH로 다시 로그인해야 합니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\nsudo usermod -aG docker [user_name]\n\nexit\n\n\n라즈베리 파이에 SSH로 다시 연결하세요:\n\n\nssh my_user_name@raspberry_pi_ip_adress\n\n\n이제 다음을 실행하여 루트 권한이 아닌 사용자가 Docker를 실행할 수 있는지 테스트하세요:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n도커 실행 hello-world\n```\n\n다음 스크린 캡처에서 확인할 수 있듯이 도커가 올바르게 설치되었으며 루트 권한이 없는 사용자에 대해 실행됩니다.\n\n<img src=\"/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_7.png\" />\n\n# Ollama, Mistral AI 및 LLaVA 설치하기\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 재미있는 부분을 시작해봅시다: 우리의 AI 모델을 설치하는 것입니다. 먼저, Ollama를 설치할 것입니다.\n\nOllama는 사용자가 개인 컴퓨터나 Raspberry Pi와 같은 기기에서 대규모 언어 모델 (LLMs)을 직접 작동할 수 있는 기술적인 솔루션이에요. 이 플랫폼은 사용자가 모델을 맞춤화하고 훈련할 수 있도록 해주며, 외부 서버에 의존하는 것이 아니라 정보를 로컬에서 처리하여 데이터 프라이버시를 보호합니다. Llama 2와 Code Llama을 비롯한 다양한 모델을 지원하며, 민감한 정보를 제3자 서비스와 공유할 필요 없이 고급 AI 도구를 사용할 수 있습니다.\n\n이 프로젝트에서는 Mistral과 LLaVA 두 모델을 설치할 것입니다.\n\n## Ollama 설치\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nOllama를 설치하려면 먼저 다음 명령을 실행하여 Ollama를 다운로드하고 설치합니다.\n\n```js\ncurl https://ollama.ai/install.sh | sh\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_8.png\" />\n\nOllama를 설치한 후에는 Raspberry의 웹 브라우저에서 http://127.0.0.1:11434/을 방문하여 작동 여부를 확인하세요. 기본적으로 포트 번호를 사용하는데, 사용자 설정에 따라 다를 수 있습니다. 기본 포트 번호는 11434입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![이미지](/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_9.png)\n\n## Mistral AI 설치하기\n\nOllama를 설치한 후에 다양한 AI 모델을 다운로드해봅시다. 먼저 다음 명령어를 사용하여 Mistral을 다운로드했습니다. Ollama 웹사이트에서 Mistral 모델에 대한 더 많은 옵션을 찾을 수 있습니다.\n\n```js\nollama run mistral\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![링크 텍스트](/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_10.png)\n\n미스트럴 AI 모델 다운로드를 완료하면 명령줄에서 LLM 모델에 직접 질문할 수 있습니다. 여기서 제가 물었던 질문은 \"2024년 중국 새해는 언제인가요?\" 이었고, 중국 새해가 2월 10일 토요일에 시작됨을 정확히 알아냈습니다.\n\n![링크 텍스트](/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_11.png)\n\n## LLaVA 설치\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희가 관심 있는 두 번째 모델은 LLaVA입니다. LLaVA는 비전 인코더를 사용하여 Vicuna와 결합한 새로운 엔드 투 엔드 학습 대형 멀티모달 모델로, 일반적인 시각 및 언어 이해를 위해 설계되었습니다. Mistral을 다운로드한 방식과 유사하게 LLaVA를 다운로드하는 과정을 진행해 보겠습니다.\n\n```js\nollama run llava\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_12.png\" />\n\n## Ollama 웹 UI 설치\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAI 어시스턴트와의 상호 작용을 더 시각적이고 직접적으로 만들기 위해 Ollama 웹 UI를 사용하기로 결정했어요.\n\nOllama 웹 UI는 개인 기기 전반에서 대형 언어 모델(LLMs)과의 상호 작용을 향상시키기 위해 설계된 완벽한 인터페이스에요. ChatGPT에 영감을 받은 이 사용자 친화적인 디자인은 사용자가 여러 AI 모델을 쉽게 관리하고 전환할 수 있도록 하며 멀티모달 상호 작용에서 채팅하고, 고급 대화 매개변수로 경험을 사용자 정의할 수 있어요.\n\nOllama를 설치하려면 다음 명령을 실행하기만 하면 돼요. 이미 Docker를 설치했기 때문에요.\n\n```js\ndocker run -d --network=host -v ollama-webui:/app/backend/data -e OLLAMA_API_BASE_URL=http://127.0.0.1:11434/api --name ollama-webui --restart always ghcr.io/ollama-webui/ollama-webui:main\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_13.png\" />\n\n웹 UI 도커가 실행되면 이제 라즈베리 파이 UI로 돌아가서, 도커에서 웹 UI를 시작한 후 http://localhost:8080을 방문할 수 있습니다.\n\n# 라즈베리 파이에서 AI 어시스턴트 실행\n\nOllama 웹 UI를 http://localhost:8080을 통해 열었을 때, 처음 해야 할 일은 가입하는 것입니다. 이 단계는 AI 모델과의 채팅 내역을 기록하고 보안상의 이유로 중요합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_14.png\" />\n\nOllama 웹 UI에 로그인하고 처음 화면을 확인해 보았습니다. 이미 Mistal AI와 LLaVA 두 개의 AI 모델을 다운로드했기 때문에 원하는 모델을 직접 선택할 수 있습니다.\n\n## Mistral AI 질문과 답변\n\nMistral AI의 기능 탐색 중에 다음 질문을 하였습니다: “중국 정월에는 무엇을 먹나요?”\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMistral AI를 통해 액세스하는 Ollama 웹 UI는 나에게 중국 새해와 관련된 전통 요리 목록을 상세히 보여주었어.\n\n이를 통해 Mistral AI가 쿼리를 이해하고 처리할 뿐만 아니라 넓은 지식 베이스를 가지고 있다는 것을 보여줬어. 응답에는 부자를 상징하는 만두와 풍요를 나타내는 생선 등과 같은 클래식한 요리들이 포함되어 있었어. 각 요리 옆에 문화적 의미에 대한 간단한 설명이 포함되어 있어, 중국 새해와 같은 중요한 축제 기간에 교육 및 요리를 위한 도구로서의 Mistral AI의 잠재력을 보여줬어.\n\n## LLaVA 질문과 답변\n\nMistral AI와 이야기한 뒤에, 나는 중국 전통 요리를 요리해보는 아이디어에서 영감을 받았어. 그러나 냉장고에 있는 재료로 무엇을 할 수 있을까? 바로 여기서 LLaVA가 그의 실력과 마법을 보여줄 때야.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n냉장고 사진을 찍어 \"새해 맞이 중국 요리 무엇을 요리할까요?\" 라고 물었습니다. LLaVA는 먼저 사진을 분석하고, 냉장고 속 재료로 새해 맞이 중국 요리로 요리할 수 있는 몇 가지 요리를 제안했습니다. 나는 고기만두와 만두를 가장 좋아해요.\n\n# 결론\n\n이 문서는 AI 기술의 진전을 보여주며, 라즈베리 파이와 같은 기본 하드웨어도 Mistral AI 및 LLaVA와 같은 최첨단 AI 모델을 실행할 수 있다는 것을 보여줍니다.\n\n이 쉬운 단계별 안내서를 통해, 누구나 라즈베리 파이나 AI 지식에 상관없이 1시간 이내에 자신만의 AI 조수를 설정할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n중국의 새해를 축하하는 동안, 이 안내서를 살펴보세요. 인공 지능의 요소를 더해 이 휴일을 환영할 수 있는 방법을 알아보세요. 이 기술적인 경이로움과 함께 새해를 맞아 지혜, 행복, 그리고 번영을 축하하세요.\n\n\n# 떠나기 전에! 🦸🏻‍♀️\n\n- 이 글에서 가치를 발견하고 지원을 원한다면, 이 LinkedIn 게시물에 '좋아요'를 눌러주세요. LinkedIn 게시물에서 무료 친구 링크도 찾을 수 있습니다. 여러분의 참여는 이 글의 영향력을 확장하는 데 도움이 되며, 지원은 저에 대한 큰 동기부여가 됩니다. ✍🏻🦾❤️\n- 제 글에 50번 박수를 보내주세요. 이것은 저를 돕고 다른 사람들에게 이 글을 알리는 데 큰 도움이 됩니다. 👏\n- Medium에서 저를 팔로우하고, LinkedIn에서 나를 팔로우하고, 최신 글을 받아보기 위해 구독하세요. 🫶\n\n# 이 주제에 관심이 있다면, 읽을 수 있는 더 많은 기사들이 있습니다.","ogImage":{"url":"/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-CelebratewithAIChineseNewYearTipsfromMistralandLLaVAonRaspberryPi_0.png","tag":["Tech"],"readingTime":15},{"title":"파이썬으로 셀러 파이낸싱 계산기 만들기 창의적 금융의 힘을 활용하는 방법 ","description":"","date":"2024-07-13 19:45","slug":"2024-07-13-UnlockthePowerofCreativeFinancingBuildYourOwnSellerFinancingCalculatorinPython","content":"\n\n<img src=\"/TIL/assets/img/2024-07-13-UnlockthePowerofCreativeFinancingBuildYourOwnSellerFinancingCalculatorinPython_0.png\" />\n\n# 크리에이티브 파이낸스 소개 📊\n\n크리에이티브 파이낸스는 전통적인 은행 대출과 모기지를 넘어 부동산을 사고 판매하는 혁신적인 방법을 가리킵니다. 이러한 방법들은 종종 구매자와 판매자 양쪽에 유연성과 혜택을 제공하여 부동산 투자에서 특히 매력적입니다.\n\n높은 가격, 높은 이자율, 그리고 낮은 재고로 특징 지어지는 현재 시장에서는, 크리에이티브 파이낸싱 전략은 이러한 도전에 대처하고자 하는 부동산 투자자에게 특히 가치 있는 솔루션일 수 있습니다 🚀.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 판매자 융자란 무엇인가요? 🤔\n\n![이미지](/TIL/assets/img/2024-07-13-UnlockthePowerofCreativeFinancingBuildYourOwnSellerFinancingCalculatorinPython_1.png)\n\n판매자 융자는 판매자가 구매자를 위해 구매를 융자하는 거래로, 은행 대출을 받는 대신 구매자가 직접 판매자에게 지불하는 방식을 말합니다 🤝.\n\n이는 구매자가 부동산을 쉽게 구입하고, 판매자가 그렇지 않으면 어려운 부동산을 판매하는 데 도움을 줄 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 왜 판매자 금융이 부동산 투자자에게 가장 좋은 선택인가요?\n\n- 유연한 조건 📝: 투자자는 이자율, 계약금 및 지불 일정 등 양쪽 모두에게 가장 적합한 조건을 협상할 수 있습니다.\n- 쉬운 자격 요건 ✔️: 전통 은행 대출에 자격이 없는 구매자도 부동산을 구매할 수 있습니다.\n- 판매자에게 더 높은 수익률 📈: 판매자들은 금융된 금액에 대한 이자를 받아 더 높은 수익을 올릴 수 있습니다.\n- 현재 시장 상황 🌟: 높은 가격, 높은 이자율 및 낮은 재고가 특징인 현재 기후 속에서 판매자 금융은 중요한 장점을 제공할 수 있습니다. 이는 투자자들이 여전히 수익성 있는 부동산을 찾고 자금을 조달할 수 있도록 거래를 창의적으로 구조화할 수 있게 해줍니다.\n\n# 실시간 판매자 금융 계산기 ⏱️\n\n파이썬으로 직접 판매자 금융 계산기를 작성하기에 들어가기 전에, Streamlit 앱을 소개하고 싶습니다 💻.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 앱은 여기에서 이용할 수 있으며, 우리가 살펴볼 동일한 코드를 실시간으로 사용할 수 있게 해줍니다. 매개변수를 입력하고 결과를 즉시 확인할 수 있어 잠재적 거래를 분석하는 강력한 도구가 될 것입니다.\n\n# Python으로 판매자 금융 계산기 만들기 🐍\n\n단계별로 판매자 금융 계산기를 만드는 과정을 살펴보겠습니다. Python을 사용하여 기능을 구현할 것입니다. 사용 사례의 매개변수는 다음과 같습니다:\n\n- sale_price = 379900\n- down_payment_rate = 10\n- annual_interest_rate = 3.5\n- loan_term_years = 30\n- balloon_due_years = 5\n- interest_only_years = False\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 1: 초기 대출 금액 설정 💵\n\n우선, 계산해야 하는 것은 계약금 및 초기 대출 금액입니다.\n\n```js\n# 매개변수\nsale_price = 379900\ndown_payment_rate = 10\n\n# 초기 대출 금액 계산\ndown_payment = int(sale_price * (down_payment_rate / 100))\nloan_amount = sale_price - down_payment\n\n# 결과 출력\nprint(f\"계약금: ${down_payment:0,.0f}\")\nprint(f\"대출 금액: ${loan_amount:0,.0f}\")\n```\n\n설명: 우리는 판매 가격과 계약금 비율에 기반하여 계약금을 계산하고, 판매 가격에서 계약금을 뺀 결과를 통해 대출 금액을 결정합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 2: 매월 상환액 계산하기 📅\n\n이제, 매월 지불해야 하는 주택담보 대출 상환액을 계산합니다.\n\n```js\n# 추가 매개변수\n연간 이자율 = 3.5\n대출 기간(년) = 30\n\n# 월 이자율\n월 이자율 = 연간 이자율 / 100 / 12\n# 총 상환 횟수\n총 상환 횟수 = 대출 기간(년) * 12\n\n# 완전 상환 대출의 매월 상환액 계산\nif 월 이자율 > 0:\n    매월 상환액 = 대출금액 * 월 이자율 / (1 - (1 + 월 이자율) ** -총 상환 횟수)\nelse:\n    매월 상환액 = 대출금액 / 총 상환 횟수\n\n# 결과 출력\nprint(f\"매월 상환액: ${매월 상환액:0,.2f}\")\n```\n\n해설: 대출금액, 연간 이자율 및 대출 기간을 사용하여 매월 상환액을 계산합니다. 이 단계에서는 월 이자율을 결정하고 완전 상환 대출의 매월 상환액 공식을 사용합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 3: 분할 상환 표 작성하기 📊\n\n이제 대출 기간 동안 지불을 추적하기 위한 분할 상환 표를 생성합니다.\n\n```js\nimport pandas as pd\n\n# 분할 상환 표 생성\namortization_table = []\nbalance = loan_amount\nfor month in range(1, total_payments + 1):\n    interest_payment = balance * monthly_interest_rate\n    principal_payment = monthly_payment - interest_payment\n    balance -= principal_payment\n    amortization_table.append([month, round(monthly_payment, 2), round(interest_payment, 2), round(principal_payment, 2), max(round(balance, 2), 0)]\n\n# DataFrame으로 변환하여 분할 상환 표 표시\ndf_amortization_table = pd.DataFrame(amortization_table, columns=[\"월\", \"매월 상환액\", \"이자\", \"원금\", \"잔여 대출 잔액\"])\n\n# 분할 상환 표의 처음 몇 행을 출력\ndf_amortization_table.head()\n```\n\n설명: 월별 지불의 이자 및 원금 부분을 계산하고 남은 대출 잔액을 업데이트합니다. 이 정보는 분할 상환 표에 저장되며 DataFrame을 사용하여 표시됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 4: 풍선 상환 및 이자 전만기 처리하기 🎈\n\n풍선 상환 또는 이자 전만기가 있는 시나리오를 처리해야 합니다.\n\n```js\n# 추가 매개변수\nballoon_due_years = 5\ninterest_only_years = False\n\n# 풍선 상환을 위해 분할상환표 조정\nif balloon_due_years:\n    total_payments_balloon = balloon_due_years * 12\n    amortization_table_balloon = amortization_table[:total_payments_balloon]\n    balloon_payment = amortization_table_balloon[-1][-1]\n    amortization_table_balloon[-1][-1] = 0  # 풍선 상환 후 잔액은 0으로 설정\n\n    # DataFrame으로 변환\n    df_amortization_table = pd.DataFrame(amortization_table_balloon, columns=[\"월\", \"월 상환액\", \"이자\", \"원금\", \"잔여 잔액\"])\n\n    # 조정된 분할상환표의 처음 몇 행 출력\n    print(df_amortization_table.head())\n    print(f\"풍선 상환금: ${balloon_payment:0,.2f}\")\n\n# 총 지급 이자\ntotal_interest_paid = df_amortization_table[\"이자\"].sum()\nprint(f\"총 이자 지급액: ${total_interest_paid:0,.2f}\")\n\n# 총 지급액\ntotal_payments_made = df_amortization_table[\"월 상환액\"].sum() + (balloon_payment if balloon_due_years else 0)\nprint(f\"총 지급액: ${total_payments_made:0,.2f}\")\n```\n\n설명: 풍선 상환금이 있을 경우, 분할상환표를 이에 맞게 조정합니다. 풍선 상환 후 잔금은 0으로 설정됩니다. 또한 총 지급 이자와 총 지급액을 계산합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 완성된 코드 구현 🖥️\n\n판매자 금융 계산기의 전체 코드입니다:\n\n```js\nimport pandas as pd\n\n# 매개변수\nsale_price = 379900\ndown_payment_rate = 10\nannual_interest_rate = 3.5\nloan_term_years = 30\nballoon_due_years = 5\ninterest_only_years = False\n\n# 초기 대출액 계산\ndown_payment = int(sale_price * (down_payment_rate / 100))\nloan_amount = sale_price - down_payment\n\n# 월 이자율\nmonthly_interest_rate = annual_interest_rate / 100 / 12\n# 총 상환 횟수\ntotal_payments = loan_term_years * 12\n\n# 완전상환 대출의 월 상환액 계산\nif monthly_interest_rate > 0:\n    monthly_payment = loan_amount * monthly_interest_rate / (1 - (1 + monthly_interest_rate) ** -total_payments)\nelse:\n    monthly_payment = loan_amount / total_payments\n\n# 분할 상환 테이블 생성\namortization_table = []\nbalance = loan_amount\nfor month in range(1, total_payments + 1):\n    interest_payment = balance * monthly_interest_rate\n    if interest_only_years and month <= interest_only_years * 12:\n        principal_payment = 0\n        monthly_payment_during_interest_only = loan_amount * monthly_interest_rate\n        amortization_table.append([month, monthly_payment_during_interest_only, interest_payment, principal_payment, balance])\n    else:\n        principal_payment = monthly_payment - interest_payment\n        balance -= principal_payment\n        amortization_table.append([month, round(monthly_payment, 2), round(interest_payment, 2), round(principal_payment, 2), max(round(balance, 2), 0)])\n    if balloon_due_years and month == balloon_due_years * 12:\n        balloon_payment = balance\n        amortization_table.append([month, round(monthly_payment, 2), round(interest_payment, 2), round(principal_payment, 2), 0])\n        break\n\n# 표시를 위해 분할 상환 테이블을 DataFrame으로 변환\ndf_amortization_table = pd.DataFrame(amortization_table, columns=[\"Month\", \"Monthly Payment\", \"Interest\", \"Principal\", \"Remaining Balance\"])\n\n# 결과 출력\nprint(df_amortization_table.head())\n\n# 지불된 총 이자\ntotal_interest_paid = df_amortization_table[\"Interest\"].sum()\nprint(f\"지불된 총 이자: ${round(total_interest_paid, 2)}\")\n\n# 총 지불액\ntotal_payments_made = df_amortization_table[\"Monthly Payment\"].sum() + (balloon_payment if balloon_due_years else 0)\nprint(f\"총 지불 금액: ${round(total_payments_made, 2)}\")\n```\n\n# 결론\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 단계를 따라가면 Python에서 강력한 판매자 금융 계산기를 만들 수 있어요.\n\n이 도구는 여러 금융 시나리오를 분석하고 부동산 투자에 있어 판단력 있는 결정을 내릴 수 있게 도와줄 거예요.\n\n# Cash Flowing Seller Finance 거래 찾기\n\n창조적인 금융 전략을 활용할 기회를 찾고 다음 투자를 성공적으로 이루는 Coffee Clozers Creative을 확인해보세요! 👉\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 노트북 복제\n\n# 커뮤니티에 참여하세요\n\n부동산 기술 페이스북 그룹에 가입하여 기술, 데이터 및 부동산 관련 토론에 참여해 보세요.","ogImage":{"url":"/TIL/assets/img/2024-07-13-UnlockthePowerofCreativeFinancingBuildYourOwnSellerFinancingCalculatorinPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-UnlockthePowerofCreativeFinancingBuildYourOwnSellerFinancingCalculatorinPython_0.png","tag":["Tech"],"readingTime":10},{"title":"Moirai 모든 예측을 위한 시계열 기초 모델","description":"","date":"2024-07-13 19:42","slug":"2024-07-13-MoiraiTimeSeriesFoundationModelsforUniversalForecasting","content":"\n\n이 게시물은 Rafael Guedes와 함께 작성되었습니다.\n\n# 소개\n\n시계열 기초 모델의 개발이 지난 두 분기 동안 가속화되고 있으며 매달 새로운 모델이 출시되고 있는 것을 목격하고 있습니다. 2023년 마지막 분기에 TimeGPT [1]가 출시되었으며 그 이후로 Lag-Llama [2], 구글의 TimesFM [3], 아마존의 Chronos [4], Salesforce의 Moirai [5] 등이 출시되었습니다.\n\n기초 모델에 대한 증가하는 관심을 이해하기 위해 핵심 능력인 제로샷 추론을 정의해야 합니다. 이는 이러한 모델이 훈련 단계에서 만나보지 못한 데이터에서 작업을 정확하게 수행하거나 예측하는 능력을 가리킵니다. 이 능력은 자연어 처리(NLP), 컴퓨터 비전, 텍스트와 이미지를 결합하는 다중 모달 작업 등 다양한 영역에 적용된 모델에서 탐구되었습니다. \"제로샷\"이라는 용어는 모델이 특정 작업이나 데이터 도메인에서 훈련 중에 \"제로\" 예제를 보지만 그 영역에서 효과적으로 작업을 수행하려하는 능력에서 나왔습니다. 이 용어는 2009년 Hinton 등에 의해 저술된 \"시맨틱 출력 코드를 사용한 제로샷 학습\" 논문에서 소개되었으며 같은 해 NIPS 컨퍼런스에서 발표되었습니다. 그 이후로 가장 중요한 연구 주제 중 하나로 등장하여 이제는 시계열 분석 분야로 진입하고 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사에서는 Salesforce가 제공하는 Moirai라는 새로운 시계열 예측을 위한 기반 모델을 탐구합니다. 이는 시계열 예측을 위한 기반 모델에 대한 시리즈 기사들을 기반으로 하며, TimeGPT 및 Chronos와 같은 모델의 성능을 실제 데이터셋에서 자세히 설명하고 보여준 기사들을 바탕으로 합니다.\n\nMoirai 뒤의 아키텍처와 제로샷 추론을 가능하게 하는 주요 구성 요소에 대한 심층적인 설명을 제공합니다. 우리는 또한 지금까지 조사한 Moirai와 다른 두 기반 모델 간의 차이점을 요약합니다. 예를 들어, 훈련 데이터의 크기, 모델 매개변수 수, 그리고 다변량 예측을 허용하는지 여부를 비교합니다.\n\n이론적 개요를 마친 후에는 Moirai를 특정 사용 사례와 데이터셋에 적용합니다. 우리는 구체적인 실행 세부 사항을 다루고 모델의 성능을 철저히 분석합니다. 마지막으로, Moirai의 성능을 TiDE와 Chronos와 공개 데이터셋을 사용하여 비교합니다.\n\n![이미지](/TIL/assets/img/2024-07-13-MoiraiTimeSeriesFoundationModelsforUniversalForecasting_0.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n항상 코드는 GitHub에서 확인하실 수 있습니다.\n\n# 배경\n\n시계열 예측에서 주요 개념을 정의하여 Moirai가 다루는 시계열 문제를 이해하기 쉽도록 설명합니다.\n\n단일 변수 시계열 예측은 과거 값만을 사용하여 단일 시계열 변수의 미래 값을 예측하는 것에 초점을 맞춥니다. 예측 모델은 단일 변수의 과거 데이터를 활용하여 미래 예측을 위한 패턴, 추세 및 주기를 식별합니다. 예를 들어, 과거 온도 기록만을 기반으로 내일의 온도를 예측하는 것이 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다변량 시계열 예측은 과거 데이터를 기반으로 관련된 여러 시계열 변수의 미래 값을 예측하는 것을 의미합니다. 이 맥락에서 예측 모델은 여러 변수 간의 상호의존성과 상호작용을 고려하여 예측을 수행합니다. 예를 들어 제품의 미래 판매량을 예측할 때, 과거 판매뿐만 아니라 마케팅 비용, 계절적 추세, 경쟁사 가격과 같은 관련 요인도 고려될 수 있습니다.\n\n시계열 예측에서의 공변량은 예측 결과에 영향을 미칠 수 있는 변수를 말합니다. 이러한 변수들은 사전에 알려진 것이거나 예측 기간 동안 추정될 수 있습니다. 단변량 및 다변량 예측 모델에서 공변량은 대상 변수의 과거 데이터를 넘어 추가적인 통찰을 도입합니다. 예를 들어 공휴일, 특별 이벤트, 경제 지표와 같은 요소들이 있습니다. 더불어 다변량 예측에서는 공변량이 관련 시계열 데이터로 확장될 수 있는데, 이는 미래 값이 알려진 변수들이거나 예측이 필요한 변수들을 설명합니다.\n\n시계열 빈도는 시계열 데이터 점들이 기록되거나 관찰되는 간격을 나타내며, 시간에 따른 데이터의 규칙성과 세분화를 대표합니다. 이 빈도는 금융 시장의 분 단위 거래와 같이 높은 주파수 데이터부터 연간 경제 지표와 같은 저주파수 데이터까지 다양할 수 있습니다. 또한 다른 빈도는 다양한 추세, 패턴 및 계절성을 포착할 수 있습니다. 예를 들어 일일 판매 데이터는 월별 집계에서 보이지 않는 주간 주기나 특정 요일의 영향과 같은 패턴을 드러낼 수 있습니다.\n\n확률적 예측은 가능한 미래 결과의 분포를 제공하여 점 예측을 넘어 확장합니다. 이 출력 분포는 다양한 미래 값이 발생할 확률을 나타내며, 불확실성 하에서 더 통찰력 있는 의사결정을 가능케 합니다. 예를 들어 판매량이나 에너지 소비와 같이 관측 값이 엄격히 양수인 경우, 확률적 예측은 가능한 결과 값 범위를 모델링하기 위해 로그-정규분포나 감마 분포를 활용할 수 있습니다. 확률적 예측은 위험 관리와 계획에 특히 유용하며, 가장 비관적적부터 가장 낙관적인 시나리오까지 다양한 상황의 발생 가능성을 이해할 수 있도록 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Moirai: Salesforce의 시계열 기반 모델\n\n모이라이(Moirai)는 Salesforce에서 개발한 시계열 예측을 위한 기본 모델입니다. 이 모델은 다양한 시계열을 예측할 수 있는 범용 모델로서 설계되었습니다. 이 유연성을 달성하기 위해 해당 모델은 시계열 데이터와 관련된 여러 가지 문제를 다룹니다. 예를 들어, 다음과 같은 능력을 갖추고 있습니다:\n\n- 모든 종류의 데이터 주파수(시간당, 일일, 주간 등) 다루기;\n- 미래에 알려지지 않은 경우에도 어떠한 종류의 공변수도 수용하기;\n- 유연한 분포를 사용하여 여러 상황에 적응할 수 있는 확률적 예측 생성.\n\n데이터셋은 기초 모델의 주요 구성 요소 중 하나입니다. 저자들은 9개의 다양한 시계열 도메인에 걸쳐 270억 건의 관측치로 이루어진 대규모이자 다양한 데이터셋을 구축했습니다. (*예시 활용, 다양성, 확신 정도*) 게다가, 저자들은 세 가지 주요 혁신적 개념을 도입했습니다: Multi Patch Size Projection Layers(다중 패치 크기 투영 레이어), Any-Variate Attention(모든 공변수 관심), 그리고 Mixture Distribution(혼합 분포)각각에 대해 다음 섹션에서 자세히 설명합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Multi Patch Size Projection Layers\n\n시계열에 패치 개념이 처음 소개된 것은 PatchTST [7]였습니다. 이것의 목표는 시계열 데이터를 크기 P의 패치로 나누는 것이었습니다. 즉, 이는 원래 시리즈의 짧은 하위 집합인 패치로 나누는 것이죠. 그렇다면 시계열 예측의 기본 모델에서 패치를 사용하는 것이 왜 유용한 걸까요?\n\n시계열 예측은 각 다른 시간 단계의 데이터 간 상관 관계를 이해하려는 목표를 가지고 있습니다. 기본 모델은 주로 트랜스포머(Transformer) 기반의 아키텍처를 사용합니다. NLP 애플리케이션에는 트랜스포머가 잘 작동하지만, 시간 단계 하나는 문장의 단어처럼 의미가 없습니다. 그래서 우리는 주의 메커니즘을 적용하기 위해 지역 의미 정보를 추출할 방법이 필요합니다. 시리즈를 패치로 나누면 시간 단계를 리치한 의미 표현을 가진 서브시리즈 수준 구성 요소로 종합할 수 있습니다.\n\n더 간단히 말하면, 단어 임베딩이 단어를 고차원 공간에서 표현하는 것처럼, 시계열 패치는 그들의 특징에 의해 정의된 다차원 공간에서 시리즈 세그먼트의 표현으로 간주할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 프로세스는 여러 이점을 제공합니다:\n\n- 싱글 타임 스텝이 아닌 시계열 그룹을 살펴 지역적 의미를 추출하기 위한 주의 메커니즘 활성화;\n- 인코더에 공급되는 토큰 수를 줄이고, 이에 따라 필요한 메모리를 줄여 모델에 더 긴 입력 시퀀스를 공급할 수 있는 것;\n- 더 긴 시퀀스로 인해 모델은 처리해야 할 정보가 더 많아지고 의미 있는 시간적 관계를 추출할 수 있어 더 정확한 예측을 할 수 있습니다.\n\n저자들이 사용하는 패치 크기는 데이터 빈도에 따라 다르며, 저주파수 데이터일수록 작은 패치 크기를 갖고 고주파수 데이터일수록 큰 패치 크기를 갖습니다:\n\n- 연간 및 분기별 → 패치 크기 8\n- 월간 → 패치 크기 8, 16, 32\n- 주간 및 일일 → 패치 크기 16, 32\n- 시간 단위 → 패치 크기 32, 64\n- 분 단위 → 패치 크기 32, 64, 128\n- 초 단위 → 패치 크기 64, 128\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모델 아키텍처에 대해 저자들은 입력 및 출력 패치 레이어를 사용했습니다. 데이터를 패치로 변환한 후, 입력 패치 레이어인 간단한 선형 레이어가 시계열 서브셋을 패치 임베딩으로 매핑하여 엔코더 전용 트랜스포머 레이어로 전달합니다. 나중에 두 번째 패치 레이어가 사용되어 엔코더의 출력을 처리합니다. 출력 토큰은 다중 패치 크기 출력 프로젝션을 통해 디코딩됩니다. 다섯 가지 다른 패치 크기가 있기 때문에 모델은 입력 데이터를 처리하는 데 사용된 패치 크기에 따라 활성화되는 다섯 가지 다른 입력 패치 레이어와 다섯 가지 다른 출력 패치 레이어가 있습니다.\n\n더 명확히 설명하기 위해 특정 예시를 살펴보겠습니다. 분기별 시계열을 예측하고자 한다고 가정해봅시다. 데이터는 크기가 8인 P개의 패치로 세분화됩니다. 이러한 패치는 이후 8 크기의 패치에 대해 설계된 입력 패치 레이어에 의해 처리됩니다. 이 레이어에서 생성된 패치 임베딩은 엔코더 전용 트랜스포머로 전달되어 임베딩을 처리합니다. 마지막으로, 처리된 임베딩은 다시 8 크기의 패치 레이어를 통해 출력됩니다.\n\n# 다변량 어텐션\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n전통적인 Transformer 아키텍처는 단일 시퀀스의 대상 값만 받아 들이도록 설계되어 있습니다. 그러나 이 모델은 다변량 시계열 시나리오에서 여러 시퀀스의 대상 값 및 동적 공변량을 다루기를 기대합니다. 따라서 저자들은 Moirai가 여러 시퀀스를 처리할 수 있도록 \"Any-Variate Attention\"을 도입했습니다.\n\n이 프로세스는 여러 시계열(변수)을 값의 단일 시퀀스로 평평하게 만드는 것으로 시작합니다. 그런 다음, 모델이 주의 점수를 계산할 때 중요한 서로 다른 변수들을 구별할 수 있도록 변수 인코딩이 적용됩니다.\n\n\"Any-Variate Attention\"에는 두 가지 기본 특성이 있습니다: 변수 순서에 대한 순열 등변성과 변수 지수에 대한 순열 무변성을 달성합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nPermutation Equivariance in relation to variate ordering means that if the observation sequence within a variate is rearranged, the model's output for that variate will reflect the same rearrangement. This property is essential as we are dealing with time series data, and the chronological order must be maintained within each variate. As a result, the model's comprehension of time series dynamics remains consistent regardless of the input sequence.\n\nPermutation Invariance concerning variate indices implies that the model's output remains unchanged even if the variates are reordered. For example, suppose we are processing temperature and humidity data as two variates in a multivariate time series framework. If we choose to change the sequence in which these variates are fed into the model (e.g., presenting humidity first and then temperature instead of temperature first and then humidity), it should not impact the final result. The model treats variate indices as interchangeable, focusing on the encoded relationships instead.\n\nTo achieve permutation equivariance/invariance, Moirai employs two different techniques:\n\n- Rotary Positional Embeddings (RoPE) [8] enforce permutation equivariance through their encoding mechanism. They represent positional information by rotating tokens in the embedding space based on their positions in the sequence. This allows the model to retain the absolute positions of tokens while preserving the relative distances between any pair of tokens.\n- Binary attention bias helps the model achieve invariance by treating variates as if they are not ordered. The model dynamically adjusts its focus by applying various attention biases (learnable scalars) depending on whether elements belong to the same variate (m=n) or different variates (m≠n). This empowers the Any-variate Attention mechanism to accommodate diverse numbers of variates and their permutations.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Moirai Time Series Foundation Models for Universal Forecasting](/TIL/assets/img/2024-07-13-MoiraiTimeSeriesFoundationModelsforUniversalForecasting_3.png)\n\n# 혼합 분포\n\nMoirai는 확률적 예측 모델로, 단순히 하나의 점 예측을 제공하는 대신 분포의 매개변수를 학습합니다. 분포로 출력되는 결과는 예측의 불확실성을 결정자가 낮은 간격은 모델의 예측에서 큰 불확실성을 나타냅니다.\n\nDeepAR과 같은 다른 확률 모델들처럼, Moirai의 목적은 손실 함수, 특히 음의 로그-우도를 최소화하여 확률 분포의 매개변수를 추정하는 것입니다. 최적화를 위해 여러 가능한 분포가 있습니다. 예를 들어, DeepAR은 가우시안, 베타, 음이항 또는 스튜던트 t-분포의 매개변수를 추정하도록 구성할 수 있습니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMoirai는 토대 모델이기 때문에 다양한 데이터 도메인을 예측할 수 있도록 설계되었으며, 따라서 단일 분포로 제한될 수 없습니다. 가능한 모든 시나리오를 수용하기 위해 모델은 다양한 종류의 데이터에 적합한 혼합 분포의 매개변수를 학습합니다:\n\n- Student의 t-분포는 꼬리가 무거운 데이터나 이상치를 처리할 수 있는 능력으로 대부분의 시계열 데이터에 대해 견고한 옵션입니다.\n- 음이항 분포는 음수 값을 예측하지 않기 때문에 엄격히 양의 카운트 데이터에 유용합니다.\n- 로그-정규 분포는 경제 지표나 자연 현상과 같이 오른쪽으로 치우친 데이터를 효과적으로 예측합니다.\n- 낮은 분산 정규 분포는 평균 주변에 군집된 데이터에 사용되며, 높은 신뢰도의 예측에 적합합니다.\n\n# TimeGPT 대 Chronos 대 Moirai: 비교\n\n이 섹션은 이전 글들에서 다룬 토대 모델들 간의 유사점과 차이점을 제시합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Table 1](https://your-website.com/assets/img/2024-07-13-MoiraiTimeSeriesFoundationModelsforUniversalForecasting_4.png)\n\n테이블 1은 기초 모델들의 주요 특성을 비교합니다. 이 단계에서는 성능을 비교하는 데 초점을 맞추지 않았으며, 그 내용은 다음 섹션에서 다룰 것입니다. 우리는 Chronos와 Moirai가 오픈 소스 모델이며 커뮤니티 기여를 통해 발전할 것이라고 이야기해드려야 합니다. 그러므로, 결정을 내리는 데 의구심이 든다면 오픈 소스 모델을 선택하고, 시간이 지남에 따라 개선되는 잠재력과 커뮤니티 지원이 큰 모델로 가는 것을 권장합니다. 중요한 결론은 Chronos가 훨씬 더 효율적인 데이터를 보여주는데, 훈련 데이터가 훨씬 적게 필요하다는 점입니다. 그러나, 이 모델은 아직 다변량적이지는 않습니다. 마지막으로, 매개 변수의 수를 살펴보면 시계열 모델이 LLMs보다 상당히 더 작아서 사용자 친화적이며 배포하기가 더 쉽다는 것을 알 수 있습니다.\n\n# Moirai vs. Chronos: 공개 데이터셋에서의 비교\n\n이 섹션에서는 Moirai를 사용하여 실제로 공개적으로 이용 가능한 cc-by-4.0 라이선스하에 있는 호주 관광객을 예측할 것입니다. 이후에 Moirai의 예측 성능을 Chronos (큰 버전) 및 TiDE와 비교할 것입니다 (Chronos 및 TiDE로 생성된 예측 코드를 얻으려면, 저희의 마지막 기사를 확인해주세요).\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n경제 변수(CPI, 인플레이션율, GDP 등)를 Trading Economics에서 추출한 것으로 강화된 데이터셋을 소개합니다. Trading Economics는 공식 소스를 기반으로 한 경제 지표를 사용합니다. 데이터셋의 사용성을 높이기 위해 전처리 작업을 수행했습니다. 우리는 전처리된 데이터셋 버전을 저장하여 실험을 쉽게 재현할 수 있도록 했습니다.\n\n먼저 라이브러리를 가져와 전역 변수를 설정합니다. 날짜 열, 대상 열, 동적 변수, 시리즈 빈도 및 예측 기간을 설정합니다.\n\n```js\n%load_ext autoreload\n%autoreload 2\nimport torch\nimport pandas as pd\nimport numpy as np\nimport utils\n\nfrom datasets import load_dataset\nfrom gluonts.dataset.pandas import PandasDataset\nfrom huggingface_hub import hf_hub_download\n\nfrom uni2ts.model.moirai import MoiraiForecast\n\n\nTIME_COL = \"Date\"\nTARGET = \"visits\"\nDYNAMIC_COV = ['CPI', 'Inflation_Rate', 'GDP']\nSEAS_COV=['month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7','month_8', 'month_9', 'month_10', 'month_11', 'month_12']\nFORECAST_HORIZON = 8 # 개월\nFREQ = \"M\"\n```\n\n그런 다음, 데이터셋을 불러옵니다. 데이터셋 설명에 언급된 외부 기능을 이미 포함하고 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# 데이터 및 외생적 특징 로드\ndf = pd.DataFrame(load_dataset(\"zaai-ai/time_series_datasets\", data_files={'train': 'data.csv'})['train']).drop(columns=['Unnamed: 0'])\ndf[TIME_COL] = pd.to_datetime(df[TIME_COL])\n\n# 월을 원핫 인코딩\ndf['month'] = df[TIME_COL].dt.month\ndf = pd.get_dummies(df, columns=['month'], dtype=int)\n\nprint(f\"고유 ID의 시계열 수: {len(df['unique_id'].unique())}\")\ndf.head()\r\n```\n\n데이터 세트를로드 한 후, 데이터를 훈련 및 테스트로 분할 할 수 있습니다 (우리는 테스트 세트로 데이터의 마지막 8 개월을 사용하기로 결정했습니다).\n\n```python\n# 8 개월 동안 테스트\ntrain = df[df[TIME_COL] <= (max(df[TIME_COL])-pd.DateOffset(months=FORECAST_HORIZON)]\ntest = df[df[TIME_COL] > (max(df[TIME_COL])-pd.DateOffset(months=FORECAST_HORIZON)]\n\nprint(f\"훈련을 위한 개월: {len(train[TIME_COL].unique())} from {min(train[TIME_COL]).date()} to {max(train[TIME_COL]).date()}\")\nprint(f\"테스트를 위한 개월: {len(test[TIME_COL].unique())} from {min(test[TIME_COL]).date()} to {max(test[TIME_COL]).date()}\")\n```\n\n마지막으로, 판다 데이터 프레임을 GluonTS 데이터 세트로 변환하여 모델에 공급해야합니다:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 훈련 데이터셋(타겟 및 동적 공변량)을 테스트 세트(예측 시간대의 타겟은 null이 됨)의 동적 공변량만을 연결합니다. 그런 다음 팬더스 데이터 프레임의 인덱스를 날짜 열로 바꿉니다.\n- 서로 다른 시계열을 구별할 수 있게 해주는 열을 설정합니다(unique_id).\n- 미래에 알려진 동적 공변량을 나타내는 열을 정의합니다(feat_dynamic_real).\n- 타겟 열(target)과 시계열 주파수(freq)를 정의합니다.\n- 모델이 내부적으로 처리하기 때문에 데이터를 스케일링할 필요가 없다는 점을 유의해주세요.\n\n```js\n# 팬더스로부터 GluonTS 데이터셋 생성\nds = PandasDataset.from_long_dataframe(\n    pd.concat([train, test[[\"unique_id\", TIME_COL]+DYNAMIC_COV+SEAS_COV]]).set_index(TIME_COL), # 테스트 동적 공변량과 연결\n    item_id=\"unique_id\",\n    feat_dynamic_real=DYNAMIC_COV+SEAS_COV,\n    target=TARGET,\n    freq=FREQ\n)\n```\n\n데이터셋이 준비되었으니, Moirai를 사용하여 예측할 수 있습니다. 이를 위해 Hugging Face에서 모델을 로드하고 다음 매개변수를 설정해야 합니다:\n\n- prediction_length — 이전에 정의한 예측 시간대입니다.\n- context_length — 모델이 주의를 기울일 수 있는 시퀀스의 항목 수(양의 정수).\n- patch_size — 각 패치의 길이. 이전에 본 바와 같이 작성자는 빈도에 따라 다른 패치 크기를 설정했습니다. 사전 정의된 값을 사용하려면 patch_size를 'auto'로 설정해야 합니다. 'auto, 8, 16, 32, 64, 128' 중의 하나로 설정할 수도 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# 사전 훈련된 모델을 준비하기 위해 huggingface hub에서 모델 가중치를 다운로드합니다.\nmodel = MoiraiForecast.load_from_checkpoint(\n    checkpoint_path=hf_hub_download(\n        repo_id=\"Salesforce/moirai-R-large\", filename=\"model.ckpt\"\n    ),\n    prediction_length=FORECAST_HORIZON,\n    context_length=24,\n    patch_size='auto',\n    num_samples=100,\n    target_dim=1,\n    feat_dynamic_real_dim=ds.num_feat_dynamic_real,\n    past_feat_dynamic_real_dim=ds.num_past_feat_dynamic_real,\n    map_location=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n)\n\npredictor = model.create_predictor(batch_size=32)\nforecasts = predictor.predict(ds)\n\n# 예측을 판다스로 변환합니다.\nforecast_df = utils.moirai_forecast_to_pandas(forecasts, test, FORECAST_HORIZON, TIME_COL)\n```\n\n예측이 완료되면 실제 값과 예측값을 그래프로 나타낼 수 있습니다.\n\n![Plot](/TIL/assets/img/2024-07-13-MoiraiTimeSeriesFoundationModelsforUniversalForecasting_5.png)\n\n그림 7은 Moirai가 시계열을 예측하는 데 어려움을 겪고 안정적인 예측을 생성하지 못했음을 보여줍니다. 대신, 예상보다 더 높은 크기의 연속적인 점프를 예측했습니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMoirai에서 수신한 예측을 기반으로 TiDE 및 Chronos에서 생성된 예측을 불러와서 비교를 위해 예측 성능 지표를 계산할 수 있습니다. 더 잘 이해하기 위해 평균 절대 백분율 오차(MAPE)를 비교 메트릭으로 사용했습니다.\n\n그림 8에서 확인할 수 있듯이 Moirai는 전체 예측 기간에서 가장 높은 MAPE를 가지고 있습니다. 한 달에 있어 TiDE를 약간 능가했지만 결코 Chronos를 능가하지는 못했습니다. 우리는 몇 가지의 비공개 데이터셋에서 유사한 실험을 진행했고 결과는 일관되게 그림 8에 제시된 결과와 일치합니다. 이 일관성은 교육 데이터셋이 공개적으로 공개되지 않았다는 점에서 기초 모델을 분석할 때 관련이 있습니다. 공개 도메인에서 어떤 데이터셋이 그들의 교육 데이터로 사용되었을 수 있다는 것은 가능성이 있습니다. 그러한 상황에서 모델은 단순히 교육 데이터에 오버피팅된 것이었을 수 있습니다.\n\nChronos는 공변량의 사용을 허용하지 않으며 시계열 간의 독립성을 가정합니다. 이는 Chronos의 접근 방식이 현저히 더 나은 것이며 미래에 발전 가능성이 크다는 것을 보여줍니다.\n\n# 결론\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 글에서는 시계열 예측을 위한 가장 최근의 재단 모델 중 하나 인 Moirai를 탐구했습니다. 이는 제로샷 추론을 생성할 수 있는 모델의 한 예입니다. 우리는 Chronos와 TimeGPT를 자세히 다뤘는데, Moirai의 접근 방식과 모델 아키텍처는 매우 다릅니다. 따라서 이 모델은 과학적 가치를 지니고 있으며 오픈 소스임에 감사합니다.\n\n우리의 실험 결과는 Moirai가 TiDE와 Chronos를 능가하지 못했음을 나타냈습니다. TiDE의 경우, 그들은 동일한 정보에 액세스하고 TiDE가 특별히 이 데이터에 대해 훈련되었습니다. 그러나 Moirai의 성능을 Chronos와 비교할 때, Moirai로부터 더 비교 가능하거나 심지어 더 나은 성능을 예상했습니다. 왜냐하면 Moirai는 동적 공변량을 통해 외부 정보에 액세스 할 수 있는 이점을 가지고 있으며 서로 다른 시계열 간의 상호 관계에서 이득을 얻을 수 있는 다변량 시계열 모델입니다.\n\n시계열 예측을 위한 기초 모델 개발을 위한 AI 경쟁은 시작에 불과하며, 우리는 그 진행을 주의 깊게 지켜볼 것입니다. 기대해 주세요.\n\n# 나에 대해\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n시리얼 기업가이자 AI 분야의 리더입니다. 저는 기업을 위한 AI 제품을 개발하고 AI 중심의 스타트업에 투자합니다.\n\nZAAI 창립자 | LinkedIn | X/Twitter\n\n# 참고 자료\n\n[1] Garza, A., & Mergenthaler-Canseco, M. (2023). TimeGPT-1. arXiv. https://arxiv.org/abs/2310.03589\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n[2] 라술, K., 아쇼크, A., 윌리엄스, A. R., 고니아, H., 바그와트카, R., 코라사니, A., 다르비시 바야지, M. J., 아다모푸로스, G., 리아키, R., 하센, N., 비로쉬, M., 가르그, S., 슈나이더, A., 채파도스, N., 드루앙, A., 잔테데스키, V., 너브리바카, Y., & 리쉬, I. (2024). Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting. arXiv. https://arxiv.org/abs/2310.08278\n\n[3] 다스, A., 공, W., 센, R., & 조우, Y. (2024). A decoder-only foundation model for time-series forecasting. arXiv. https://arxiv.org/abs/2310.10688\n\n[4] 안사리, A. F., 스텔라, L., 터크멘, C., 장, X., 메르카도, P., 셴, H., 셰르, O., 랑가푸람, S. S., 아랑고, S. P., 카푸어, S., 즈시그너, J., 매딕스, D. C., 마호니, M. W., 토르콜라, K., 윌슨, A. G., 보르케-슈나이더, M., & 왕, Y. (2024). Chronos: Learning the Language of Time Series. arXiv. https://arxiv.org/abs/2403.07815\n\n[5] 우, G., 리우, C., 쿠마르, A., 씽, C., 사바레세, S., & 사후, D. (2024). Unified Training of Universal Time Series Forecasting Transformers. arXiv. https://arxiv.org/abs/2402.02592\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n[6] Palatucci, M., Pomerleau, D., Hinton, G. E., & Mitchell, T. M. (2009). Zero-shot Learning with Semantic Output Codes. In Y. Bengio, D. Schuurmans, J. Lafferty, C. Williams, & A. Culotta (Eds.), Advances in Neural Information Processing Systems (Vol. 22). Curran Associates, Inc. Retrieved from [here](https://proceedings.neurips.cc/paper_files/paper/2009/file/1543843a4723ed2ab08e18053ae6dc5b-Paper.pdf)\n\n[7] Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, Jayant Kalagnanam. A Time Series is Worth 64 Words: Long-term Forecasting with Transformers. arXiv:2211.14730, 2022.\n\n[8] Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, Yunfeng Liu. RoFormer: Enhanced Transformer with Rotary Position Embedding. arXiv:2104.09864, 2021.\n\n[9] David Salinas, Valentin Flunkert, Jan Gasthaus. DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks. arXiv:1704.04110, 2017.","ogImage":{"url":"/TIL/assets/img/2024-07-13-MoiraiTimeSeriesFoundationModelsforUniversalForecasting_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-MoiraiTimeSeriesFoundationModelsforUniversalForecasting_0.png","tag":["Tech"],"readingTime":22},{"title":"SOLID 원칙으로 테니스 리팩토링 도전 과제 해결하기 Python 사용","description":"","date":"2024-07-13 19:41","slug":"2024-07-13-SolvingaTennisRefactoringChallengeinPythonusingSOLID","content":"\n\n<img src=\"/TIL/assets/img/2024-07-13-SolvingaTennisRefactoringChallengeinPythonusingSOLID_0.png\" />\n\n## 소개\n\n코드 리팩터링 도전 과제는 소프트웨어 엔지니어들에게 잘 알려져 있지만, 데이터 과학자들에게는 그렇지 않을 수도 있습니다. 그러나 데이터 과학자들 또한 이러한 도전들을 연습함으로써 상당한 혜택을 받을 수 있습니다. 특히 SOLID 원칙을 적용할 때, 이를 연습함으로써 모듈화되고 품질이 높으며 객체지향적인 훨씬 나은 코드를 작성하는 방법을 배울 수 있습니다. 데이터 과학자로서 SOLID 원칙을 습득하면 데이터 과학 프로젝트의 품질과 관리 용이성을 상당히 향상시킬 수 있습니다. 이는 특히 대부분의 데이터 과학자가 통계학자 및 수학자 출신으로, 소프트웨어 엔지니어보다 프로그래밍 기본 원리에 대한 익숙함이 적은 팀에서 중요합니다.\n\n온라인에서는 많은 리팩터링 도전 과제가 제공되고 있습니다. 아마 가장 유명한 것 중 하나는 길드 로즈 카타일 것입니다. 또 다른 재미있는 리팩터링 카타는 테니스 리팩터링 카타인데, 이를 이 글에서 다루겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![이미지](/TIL/assets/img/2024-07-13-SolvingaTennisRefactoringChallengeinPythonusingSOLID_1.png)\n\n[여기](https://github.com/emilybache/Tennis-Refactoring-Kata)로 이동하여 녹색 상단 오른쪽 버튼에서 \"템플릿으로 사용\"을 선택해주세요.\n\n템플릿을 클론하고 터미널에서 해당 저장소로 이동하세요. 그런 다음 python 디렉토리로 이동하여 가상 환경을 생성하고 필수 의존성을 설치해주세요. 모든 것이 정상적으로 작동하는지 테스트하려면 pytest를 실행하세요. 아래 명령어를 터미널에 복사하여 붙여넣을 수 있습니다.\n\n```js\ncd python\npython -m venv .venv\nsource .venv/bin/activate # 맥 또는 리눅스에서\n# .venv\\Scripts\\activate # 윈도우에서\npip install -r requirements.txt\npytest\n``` \n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Tennis Refactoring Challenge](/TIL/assets/img/2024-07-13-SolvingaTennisRefactoringChallengeinPythonusingSOLID_2.png)\n\n터미널의 출력 결과는 위의 스크린샷과 유사해야 합니다.\n\n시작 시, 총 6개의 tennis.py 파일이 있습니다. 각 파일은 테니스 경기의 점수를 표시하는 다른 솔루션을 나타냅니다. 테니스는 약간 독특한 점수 표현 방식을 갖고 있습니다. 테니스 경기는 세트로 이루어지며, 세트는 게임으로 이루어지며, 게임에서는 점수를 획득할 수 있습니다. 이 도전 과제는 단일 게임 내에서 점수를 나타내는 것에 관한 것입니다.\n\n- 점수를 획득하지 않은 상태에서는 '러브'라고 부릅니다.\n- 한 점을 획득한 후에는 '피프틴'이 됩니다.\n- 두 점을 획득한 후에는 '서티'가 됩니다.\n- 세 점을 획득한 후에는 '포티'가 되며, 상대방이 세 점을 획득한 경우에는 '듀스'라고 부릅니다.\n- 네 점 이상을 획득했을 때, 상대와 2점 이상 차이가 나면 게임에 승리합니다.\n- 네 점 이상을 획득했을 때, 상대와 1점 차이가 나면 어드밴티지를 얻습니다.\n- 네 점 이상을 획득했을 때, 상대와 같은 점수를 가지면 '듀스'라고 부릅니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테니스 테스트를 확인할 수 있는 tennis_test.py 및 tennis_unittest.py 두 파일도 있습니다. 이 파일들은 tennis.py 파일의 로직이 올바른지 확인하는 테스트를 제공합니다. 처음에는 모든 테스트가 통과해야 합니다 (이전에 pytest를 실행했을 때 본 것과 같이).\n\n일반적으로는 각 tennis.py 파일을 다시 설계하는 것이 목표입니다. 그러나 한 문서에서 여섯 개의 Python 파일을 다시 설계하는 것은 너무 방대하기 때문에, 적절한 코딩 구조의 기반인 SOLID 원칙을 준수하는 하나의 해결책을 다룰 것입니다.\n\n## 테니스 게임 정의\n\n테니스 게임을 높은 추상화로 정의해 봅시다. 테니스 게임은 두 팀 게임의 형태입니다. 여기서는 두 플레이어가 아닌 두 팀을 사용합니다. 왜냐하면 테니스는 더블즈로도 (예: 패들은 기본적으로 두 팀으로 플레이되는) 할 수 있기 때문입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 테이블 태그를 마크다운 형식으로 변경하세요:\n\n\nWe can define a two-team game as follows:\n\n```js\nfrom abc import ABC, abstractmethod\n\n\nclass TwoTeamGame(ABC):\n    def __init__(\n        self,\n        team1_name: str,\n        team2_name: str,\n        team1_points: float = 0,\n        team2_points: float = 0,\n    ):\n        self.team1_name = team1_name\n        self.team2_name = team2_name\n        self.team1_points = team1_points\n        self.team2_points = team2_points\n```\n\nNext, let’s define a tennis game:\n\n```js\nclass TennisGame1(TwoTeamGame):\n    def __init__(self, team1_name: str, team2_name: str):\n        super().__init__(team1_name, team2_name)\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테니스 경기에는 won_point(team_name: str)과 score() 두 가지 메서드가 있어야 합니다.\n\n```js\nclass TennisGame1(TwoTeamGame):\n    def __init__(self, team1_name: str, team2_name: str):\n        super().__init__(team1_name, team2_name)\n\n    def won_point(self, team_name: str):\n        ...\n\n    def score(self) -> str:\n        ...\n```\n\n## 점수 계산 전략 구현\n\nwon_points(team_name)부터 시작해보죠. 이 메서드는 매우 간단합니다. team_name으로 팀 이름을 전달하면 해당 플레이어의 점수가 하나 증가해야 합니다. 그러나 SOLID 원칙을 적용하기 위해 더 높은 추상화 수준에 대해 고려해야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\nwon_points를 스코어링 전략을 사용하는 것으로 생각할 수 있습니다.\n\n```python\nfrom abc import ABC, abstractmethod\n\nclass TwoTeamScoringStrategy(ABC):\n    @abstractmethod\n    def update_score(\n        self, game: TwoTeamGame, team_name: str,\n    ):\n        pass\n```\n\nwon_points에서 스코어링 전략을 추출한 이유는 SOLID의 개방/폐쇄 원칙을 지키기 위한 것입니다. won_points에서 스코어링 전략을 분리함으로써, won_points 자체를 수정하지 않고도 스코어링 전략을 쉽게 교체하거나 변경할 수 있습니다.\n\n이제 StandardTennisScoring을 만들어봅시다:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nclass StandardTennisScoring(TwoTeamScoringStrategy):\n    def update_score(\n        self,\n        game: TwoTeamGame,\n        team_name: str,\n    ):\n        if game.team1_name == team_name:\n            game.team1_points += 1\n        elif game.team2_name == team_name:\n            game.team2_points += 1\n        else:\n            raise ValueError(\"Invalid team name\")\n```\n\n위의 코드를 won_point 메서드에 구현하려면 TennisGame 클래스에 스코링 전략을 전달하고 won_point에서 StandardTennisScoring의 update_score 메서드를 호출해야 합니다:\n\n```js\n# 주의:\n# 절대로 클래스 인스턴스를 기본 인수로 초기화해서는 안 됩니다.\n# 기사에서는 이 문제를 수정하지 않고 주어진 테스트를 통과하기 위해 이를 수행합니다.\n\nclass TennisGame1(TwoTeamGame):\n    def __init__(\n        self,\n        team1_name: str,\n        team2_name: str,\n        score_strategy: TwoTeamScoringStrategy = StandardTennisScoring(),\n        score_reperesentation: TwoTeamScoreRepresentation = TennisScoreRepresentation(),\n    ):\n        super().__init__(team1_name, team2_name)\n        self.score_strategy = score_strategy\n        self.score_representation = score_representation\n\n    def won_point(\n        self,\n        team_name: str,\n    ):\n        if team_name == self.team1_name:\n            self.score_strategy.update_score(game=self, team_name=team_name)\n        elif team_name == self.team2_name:\n            self.score_strategy.update_score(game=self, team_name=team_name)\n        else:\n            raise ValueError(\"Invalid team name\")\n\n     def score(self):\n        ...\n```\n\n## 스코어 표현 구현하기\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금 남은 작업은 score() 메서드를 구현하는 것뿐입니다. 먼저 두 팀 게임의 점수를 표현하는 추상 클래스를 생각해 봅시다. 점수를 나타내려면 게임의 점수에 액세스할 수 있어야 하므로 represent_score 메서드의 game이 매개변수인지 확인해 봅시다.\n\n```js\nclass TwoTeamScoreRepresentation(ABC):\n    @abstractmethod\n    def represent_score(self, game: TwoTeamGame) -> str:\n        pass\n```\n\n빠르게 어떤 단어가 어떤 점수에 관련된지 요약해보겠습니다:\n\n- 0: Love\n- 1: Fifteen\n- 2: Thirty\n- 3: Forty or Deuce\n- 4: Deuce, Advantage or win (최다 점수를 획득한 플레이어의 점수만 나타내기 때문에)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테니스 게임을 생각해볼 때, 점수를 나타내는 세 가지 유형의 상황이 있습니다:\n\n- 두 플레이어가 동일한 점수를 가지고 있는 경우.\n- 두 플레이어가 동일한 점수를 가지고 있거나 한 플레이어가 더 많은 점수를 가지고 있지만 적어도 한 플레이어가 세 점보다 많은 점수를 가지고 있다 (그러면 우승 가능성이 있고, 이기거나 지는 장단점이 있을 수 있다).\n- 한 플레이어가 다른 플레이어보다 더 많은 점수를 가지고 있지만 두 플레이어 모두 세 점보다 많은 점수를 가지고 있지 않은 경우\n\n```js\nclass TennisScoreRepresentation(TwoTeamScoreRepresentation):\n    def represent_score(self, game: TwoTeamGame) -> str:\n        if game.team1_points == game.team2_points:\n            return ...\n        if max(game.team1_points, game.team2_points) >= 4:\n            return ...\n        return ...\n```\n\n우리가 지정한 세 가지 상황에 대해 클래스를 만들어 봅시다. 어떻게 점수를 나타내는지 확인하려면 tennis_unittest.py에서 테스트가 어떻게 지정되어 있는지 살펴봐야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n#(team1_score, team2_score, score_representation, team1_name, team2_name)\n(2, 2, \"Thirty-All\", 'player1', 'player2'),\n(3, 3, \"Deuce\", 'player1', 'player2'),\n(4, 4, \"Deuce\", 'player1', 'player2'),\n(1, 0, \"Fifteen-Love\", 'player1', 'player2'),\n(4, 2, \"Win for player1\", 'player1', 'player2')\n(4, 3, \"Advantage player1\", 'player1', 'player2'),\n(14, 15, \"Advantage player2\", 'player1', 'player2'),\n(14, 16, \"Win for player2\", 'player1', 'player2'),\n```\n\n```js\nclass TennisTieRepresentation(TwoTeamScoreRepresentation):\n    def __init__(self, score_names: set[str] = (\"Love\", \"Fifteen\", \"Thirty\")):\n        super().__init__()\n        self.score_names = score_names\n\n    def represent_score(self, game: TwoTeamGame) -> str:\n        return {\n            0: f\"{self.score_names[0]}-All\",\n            1: f\"{self.score_names[1]}-All\",\n            2: f\"{self.score_names[2]}-All\",\n        }.get(game.team1_points, \"Deuce\")\n\n\nclass TennisEndGameRepresentation(TwoTeamScoreRepresentation):\n    def represent_score(self, game: TwoTeamGame) -> str:\n        point_difference = game.team1_points - game.team2_points\n        leader = game.team1_name if point_difference > 0 else game.team2_name\n        if abs(point_difference) == 1:\n            return f\"Advantage {leader}\"\n        else:\n            return f\"Win for {leader}\"\n\n\nclass TennisNormalRepresentation(TwoTeamScoreRepresentation):\n    def __init__(self, score_names: set[str] = (\"Love\", \"Fifteen\", \"Thirty\", \"Forty\")):\n        super().__init__()\n        self.score_names = score_names\n\n    def represent_score(self, game: TwoTeamGame) -> str:\n        return f\"{self.score_names[game.team1_points]}-{self.score_names[game.team2_points]}\"\n```\n\nIf we implement these classes in the TennisScoreRepresentation we’ll get the following code:\n\n```js\nclass TennisScoreRepresentation(TwoTeamScoreRepresentation):\n    def __init__(\n        self,\n        tie_score: TwoTeamScoreRepresentation = TennisTieRepresentation(),\n        end_game_score: TwoTeamScoreRepresentation = TennisEndGameRepresentation(),\n        normal_score: TwoTeamScoreRepresentation = TennisNormalRepresentation(),\n    ):\n        self.tie_score = tie_score\n        self.end_game_score = end_game_score\n        self.normal_score = normal_score\n\n    def represent_score(self, game: TwoTeamGame) -> str:\n        if game.team1_points == game.team2_points:\n            return self.tie_score.represent_score(game)\n        if max(game.team1_points, game.team2_points) >= 4:\n            return self.end_game_score.represent_score(game)\n        return self.normal_score.represent_score(game)\n```\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 모든 것을 합쳐보기\n\n이제 완료했어요! 코드를 모두 결합한 것을 살펴봅시다. 만약 이 코드를 tennis1.py 파일에 넣고 터미널에서 pytest를 실행하면 모든 테스트가 여전히 통과해야 합니다.\n\n아마 궁금할 것입니다. tennis_unittest.py에 쓰인 테스트를 준수하는 모든 기능과 규칙을 구현한 한 클래스를 작성할 수 있는데, 왜 이런 클래스들이 필요한 걸까요? 이유는, SOLID 원칙을 준수함으로써, 전체 구현의 어떤 부분이든 손쉽게 교체할 수 있고 기존 코드를 변경하거나 망가뜨리지 않을 수 있습니다. 우리가 바꾸고 싶은 부분에 대해 약간의 새 코드만 작성하면 됩니다. 이는 거의 모든 코드 부분에 적용되며, 각 클래스가 교체 가능하기 때문입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n# 새로운 점수 표현 방식\nclass FrenchScoreRepresentation(TwoTeamScoreRepresentation):\n    # 프랑스어 점수 표현에 대한 구현\n    ...\n\n# 게임에 새 전략 주입\nfrench_game = TennisGame1(\n                    team1_name=\"T1\", \n                    team2_name=\"T2\", \n                    score_representation=FrenchScoreRepresentation()\n)\n\n\n## 결론\n\nSOLID 원칙을 적용하여, 우리는 프로덕션 수준의 코드 구조를 사용하여 이 리팩터링 카타를 해결했습니다. 이제 SOLID 원칙을 어떻게 적용해야 하는지 더 잘 이해할 수 있을 것입니다. 클래스의 더 높은 추상화를 정의하여 시작하고, 각 클래스의 서브클래스를 교환 가능하도록 만들어 의존성 주입을 사용하여 새 기능을 쉽게 조정하고 적용할 수 있도록 했습니다.\n\n높은 품질의 Python 코드에 대해 더 배우고 싶으세요? 이 다른 기사들도 꼭 확인하세요!\n","ogImage":{"url":"/TIL/assets/img/2024-07-13-SolvingaTennisRefactoringChallengeinPythonusingSOLID_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-SolvingaTennisRefactoringChallengeinPythonusingSOLID_0.png","tag":["Tech"],"readingTime":14},{"title":"파이썬으로 AI 노래 목소리 클로닝 하는 방법","description":"","date":"2024-07-13 19:38","slug":"2024-07-13-AISingingVoiceCloninginPython","content":"\n\n<img src=\"/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_0.png\" />\n\n음성이 어떤 음조와 조화를 이루거나 어떤 사투리를 쓰거나 전설적인 가수들의 특이한 음색을 복제할 수 있는 세계를 상상해보세요. 이것은 AI 노래 음성 복제를 통해 가능해진 현실입니다.\n\n이 혁신적인 기술은 음악의 예술을 기계 학습의 정밀성과 결합하여 우리가 원하는 어떤 목소리로도 새로운 노래를 만들거나 고전적인 곡을 재해석할 수 있게 해줍니다.\n\nAI 음성 복제는 특이한 음성의 특성을 포착하고 놀라운 정확도로 재현하는 기술입니다. 이 디지털 연금술을 통해 우리는 기존의 목소리를 복제하는 것뿐만 아니라 완전히 새로운 목소리를 만들어내는 것도 가능해집니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n컨텐츠 생성을 혁신한 도구입니다. 맞춤 노래부터 사용자 정의 보이스 오버까지 다양한 크리에이티브 가능성을 열어줍니다. 이는 언어와 문화적인 장벽을 초월하는 세계를 제공합니다.\n\n본 글의 목적은 기술적인 독자들을 대상으로 AI 보이스 클로닝 기술을 활용하는 포괄적인 Python 가이드를 제공하는 것입니다. 이 기술은 선택한 아티스트의 음조로 또는 사용자 자신의 목소리로 어떠한 오디오든 변환할 수 있는 종단 간 솔루션입니다.\n\n이 튜토리얼 글은 다음과 같이 구성되어 있습니다:\n\n# 1. 기술적 배경\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사에서 사용할 기술은 Singing Voice Conversion (SVC)이라는 시스템인 SO-VITS-SVC입니다. SO-VITS-SVC는 \"SoftVC VITS Singing Voice Conversion\"의 약어로, SVC의 정교한 구현을 나타냅니다.\n\nSO-VITS-SVC 시스템은 심층 학습 기술을 사용하여 노래 목소리 변환(SVC)을 복잡하게 구현한 것입니다. 이 시스템을 이해하려면 사용된 특정 기계 학습 아키텍처와 알고리즘에 대한 이해가 필요합니다.\n\n## 1.1 변분 추론과 생성 적대 네트워크\n\n- SO-VITS-SVC의 중심에는 Text-to-Speech (VITS) 아키텍처에 대한 변분 추론이 있습니다. 이 시스템은 변분 오토인코더(VAEs)와 생성 적대 네트워크(GANs)를 빈틈없이 결합하고 있습니다.\n- VAEs는 SVC에서 오디오 신호의 중요한 표현인 멜 스펙트로그램 분포를 모델링하는 데 사용됩니다. VAE 구성 요소는 음성의 잠재 변수를 캡처하는 데 도움이 됩니다.\n- VAE 손실 함수는 아래 수식과 같이 표현됩니다. 여기서 x는 입력 멜 스펙트로그램, z는 잠재 변수이며 KL은 Kullback-Leibler 발산을 나타냅니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![image](/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_1.png)\n\n- GANs enhance the realism of the synthesized audio. The discriminator in the GAN critiques the output of the generator, improving its accuracy. The GAN loss function is given by:\n\n![image](/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_2.png)\n\nFor a comprehensive understanding of Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), you might want to refer to the original papers introducing these concepts:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- VAEs: Kingma, D. P., and Welling, M. \"Auto-Encoding Variational Bayes.\" arXiv:1312.6114, 2013.\n- GANs: Goodfellow, I. J., et al. \"Generative Adversarial Nets.\" arXiv:1406.2661, 2014.\n\n## 1.2 얕은 확산 프로세스\n\n- 인접 다이어그램에 나와 있는 것처럼, 얕은 확산 프로세스는 소음 샘플로 시작되어 일련의 변환을 통해 구조화된 멜 스펙트로그램으로 점진적으로 정제됩니다.\n\n<img src=\"/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_3.png\" />\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n1. 초기 노이즈 샘플: 확산 프로세스의 시작점으로 작용하는 노이즈의 시각적 표현입니다.\n\n2. 변환 단계: 노이즈는 확산 모델 내에서 일련의 단계를 거치며 비구조적인 상태에서 구조화된 멜 스펙트로그램으로 전환됩니다. 아래와 같이 설명할 수 있으며, 여기서 xt는 t단계에서의 데이터를 나타내고 ϵ은 가우시안 노이즈를 나타냅니다.\n\n![이미지](/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_4.png)\n\n- SO-VITS-SVC의 맥락에서 '얕은'이라고 할 때는 아마도 계층이나 단계가 적은 것을 의미하며, 계산 효율성과 오디오 품질 사이의 균형을 맞출 것으로 예상됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 멜 스펙트로그램 정제: 이 과정의 결과는 노래하는 목소리의 오디오 콘텐츠를 담은 멜 스펙트로그램으로, 다음 합성 단계에 사용할 준비가 된 상태입니다.\n\n4. 보코딩: 최종 보코딩 단계에서 멜 스펙트로그램을 오디오 웨이브폼으로 변환하여, 그것이 들리는 노래하는 목소리가 됩니다.\n\n확산 모델에 대한 깊은 탐구를 위해 다음 자료들이 상세한 설명과 연구 맥락을 제공합니다:\n\n- Sohl-Dickstein, J., et al. “Deep Unsupervised Learning using Nonequilibrium Thermodynamics.” arXiv:1503.03585, 2015.\n- Ho, J., et al. “Denoising Diffusion Probabilistic Models.” arXiv:2006.11239, 2020.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 1.3 SVC 시스템과 합성 프로세스의 통합\n\n- 멜-스펙트로그램 정제:\n\n얕은 확산 모델이 소음을 더 응집된 형태로 구조화한 후에, 이전에 언급된 다이어그램에서 시각화된 대로 결과 멜-스펙트로그램은 노래하는 목소리의 세세한 오디오 콘텐츠를 포착합니다. 이 멜-스펙트로그램은 초기 구조가 없는 데이터와 최종 음성 출력 사이의 중요한 다리 역할을 합니다.\n\n2. 보코딩:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n보코더는 그 후 정제된 멜 스펙트로그램을 오디오 웨이브폼으로 변환하는 데 사용됩니다. 이 단계는 시각 데이터가 청각적인 노래 목소리로 변환되는 과정입니다. 보코더의 역할은 멜 스펙트로그램에서 포착된 음높이, 음색 및 리듬의 미묘한 점을 합성하여 최종 노래 목소리를 생성하는 것입니다.\n\n3. 훈련 및 최적화:\n\n이 고품질 음성 합성을 달성하기 위해 SO-VITS-SVC 시스템은 엄격한 훈련과 최적화를 거칩니다. 훈련에는 VAE, GAN 및 확산 모델 구성 요소의 기여를 균형있게 조절하는 병합 손실 함수를 최적화하는 과정이 포함됩니다.\n\n이 최적화는 확률적 경사 하강법이나 Adam과 같은 알고리즘을 사용하여 진행되며, 전반적인 손실을 최소화하는 것을 최종 목표로 합니다. 이 과정을 통해 최종 출력이 음색, 음높이 및 리듬 측면에서 목표 노래 목소리와 유사하게 되도록 보장합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n4. 최종 산출물:\n\n이 프로세스의 최종 산출물은 대상 노래하는 목소리와 매우 유사한 합성음성입니다. 소스의 음악성과 표현의 미묘함을 유지하면서 대상의 음조 특성을 채택하는 능력은 SO-VITS-SVC 시스템의 정교함을 증명합니다.\n\n머신러닝과 딥러닝에 처음 접하는 사람들을 위해 교육 플랫폼에서 제공하는 기초 자료와 코스는 필요한 배경 지식을 쌓는 데 초석이 될 수 있습니다:\n\n- Coursera — 딥러닝 전문화: https://www.coursera.org/specializations/deep-learning\n- MIT OpenCourseWare — 딥러닝 입문: https://ocw.mit.edu/courses/6-036-introduction-to-deep-learning-spring-2021/\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 1.4 IPython 라이브러리 사용\n\nGitHub에서 호스팅되는 SO-VITS-SVC Fork는 실시간 노래 음성 변환을 위해 특별히 설계된 전문 도구입니다. 원본 SO-VITS-SVC 프로젝트의 이 Fork는 CREPE를 사용하여 더 정확한 음높이 추정을 제공하는 등 강화된 기능을 제공합니다. 또한 GUI(Graphical User Interface), 더 빠른 학습 시간, pip를 사용하여 도구를 쉽게 설치할 수 있는 편의성을 제공합니다.\n\n또한 QuickVC를 통합하고 원본 저장소에서 발견된 일부 문제를 수정합니다. 이 Fork는 실시간 음성 변환을 지원하여 목소리 복제 작업에 사용할 수 있는 다목적 도구입니다. 또한 설치 및 설정 과정을 단순화하여 목소리 복제 기술을 실험하고 싶은 사용자들에게 더 쉽게 접근할 수 있습니다.\n\n# 2. 추론: 어떤 아티스트의 AI 목소리로 노래하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n추론은 신경망 모델이 특정 음성을 이해하기 위해 데이터 세트에서 훈련된 후, 해당 학습된 음성으로 새로운 콘텐츠를 생성하는 과정을 의미합니다.\n\n이 단계에서는 사전 훈련된 모델에 새로운 입력(원시 가창 음성 오디오)을 제공하여 해당 아티스트의 AI 음성과 함께 '노래'할 수 있는 시기입니다. 그 모델은 이후 해당 원시 음성 오디오에서 아티스트의 가창 스타일을 모방하는 출력을 생성합니다.\n\n## 2.1 SO-VITS-SVC 환경 설정하기\n\n간편하게 가상 환경을 갖춘 Jupyter Notebook을 사용할 것입니다. 그러므로 그곳에서 스타팅하는 것을 권장합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Anaconda 설치하기: 시스템에 Anaconda를 다운로드하고 설치하세요. 이를 통해 다른 프로젝트를 위한 격리된 환경을 만들 수 있습니다.\n- Anaconda 터미널을 열고 다음 명령을 실행하여 새 환경을 생성하세요.\n\n```js\nconda create -n sovits-svc\n```\n\n- 만약 VS Code를 사용한다면 커널 선택에서 환경을 참조할 수 있습니다. 그렇지 않으면 Anaconda를 계속 사용할 경우 conda activate로 환경을 활성화하고 Jupyter notebook을 실행하세요.\n\n```js\nconda activate sovits-svc\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 노트북 내에서 환경에 필요한 라이브러리를 설치하세요.\n\n```js\n!python -m pip install -U pip wheel\n%pip install -U ipython\n%pip install -U so-vits-svc-fork\n```\n\n- 나중에 !svc 명령을 실행할 때 아래와 같은 문제를 피하기 위해 아나콘다 환경으로 이동하여 torchaudio를 pip uninstall torchaudio로 제거하고 pip install torchaudio로 다시 설치해야 합니다.\n\n이제 깨끗한 보컬(즉, 배경 소음이 없는)에 사전 훈련된 모델을 사용하여 '노래 음성 변환'을 수행할 준비가 되었습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 2.1 사전 훈련된 모델을 사용하여 노래 목소리 생성하기\n\n## 1) 사전 훈련된 모델 선택하기\n\n환경이 준비되었으면, 다음 단계는 사전 훈련된 모델을 얻는 것입니다. 여러 사전 훈련된 모델이 제공되어 사용할 수 있습니다. Drake부터 Michael Jackson까지! 옵션은 다음과 같습니다:\n\n어떤 모델을 사용할지 결정되면, .pth Pytorch 모델 파일과 관련된 config.json을 검색하고 다운로드해야 합니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nfrom huggingface_hub import hf_hub_download\nimport os\n\n# 저장소 ID와 로컬 디렉터리를 설정합니다. Drake의 모델을 사용할 것입니다.\nrepo_id = 'Entreprenerdly/drake-so-vits-svc'\nlocal_directory = '.'\n\n# config.json 파일을 다운로드합니다.\nconfig_file = hf_hub_download(\n    repo_id=repo_id,\n    filename='config.json',\n    local_dir=local_directory,\n    local_dir_use_symlinks=False\n)\n\n# 현재 디렉터리에 config 파일 경로를 만듭니다.\nlocal_config_path = os.path.join(local_directory, 'config.json')\nprint(f\"config 파일 다운로드 완료: {local_config_path}\")\n\n# 모델 파일을 다운로드합니다.\nmodel_file = hf_hub_download(\n    repo_id=repo_id,\n    filename='G_106000.pth',\n    local_dir=local_directory,\n    local_dir_use_symlinks=False\n)\n\n# 현재 디렉터리에 모델 파일 경로를 만듭니다.\nlocal_model_path = os.path.join(local_directory, 'G_83000.pth')\nprint(f\"모델 파일 다운로드 완료: {local_model_path}\")\n```\n\n## 2) 깨끗한 오디오 파일 선택\n\n다음으로, 변환을 위해 깨끗한 오디오 파일을 다운로드할 것입니다. 사용할 오디오 파일은 Google 드라이브를 통해 액세스하고 다운로드할 수 있습니다.\n\nJustin Bieber의 깨끗한 보컬 트랙이며, 선택한 모델을 사용하여 음성 변환을 위해 SO-VITS-SVC 시스템에 입력할 수 있습니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이것은 가장 깔끔하지 않을 수 있지만, 오디오 파일을 변환하기 전에 자체 오디오 파일을 준비할 때는 생성된 오디오에서 의도하지 않은 아티팩트나 품질 문제를 피하기 위해 가능한 깨끗하게 유지하는 것이 매우 중요합니다.\n\n원본 오디오의 품질은 목소리 변환의 충실도에 큰 영향을 미치므로 항상 고품질의 깨끗한 녹음을 권장합니다.\n\n```js\nimport requests\n\nvocals_url = 'https://drive.google.com/uc?id=154awrw0VxIZKQ2jQpHQQSt__cOUdM__y'\nresponse = requests.get(vocals_url)\nwith open('vocals.wav', \"wb\") as file:\n    file.write(response.content)\n\ndisplay(Audio('vocals.wav', autoplay=True))\n```\n\n## 3) 추론 실행하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSO-VITS-SVC 모델을 사용하여 음성 변환을 수행하려면 오디오 파일, 모델 체크포인트 및 구성 파일의 경로를 지정해야 합니다. 아래는 경로를 설정하고 추론을 실행하는 방법입니다.\n\n이 명령을 실행하는 환경이 SO-VITS-SVC 도구가 설치된 환경에서 !svc 명령에 액세스할 수 있는 환경에서 실행되는지 확인하세요. 예를 들어 명령 프롬프트나 SO-VITS-SVC 도구가 설치된 환경에서 실행되는 스크립트와 같은 환경입니다.\n\n```js\nfrom IPython.display import Audio, display\nimport os\n\n# 파일 이름\naudio_filename = 'vocals.wav'\nmodel_filename = 'G_106000.pth'\nconfig_filename = 'config.json'\n\n# 전체 로컬 경로 구성\naudio_file = f\"\\\"{os.path.join('.', audio_filename)}\\\"\"\nmodel_path = f\"\\\"{os.path.join('.', model_filename)}\\\"\"\nconfig_path = f\"\\\"{os.path.join('.', config_filename)}\\\"\"\n\n# 추론 명령 실행\n!svc infer {audio_file} -m {model_path} -c {config_path}\n```\n\n## 4) 출력 표시\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n추론을 실행한 후에는 Jupyter 노트북이나 IPython 인터페이스에서 바로 출력 오디오를 표시할 수 있습니다. 다음의 코드 스니펫을 사용하면 결과 오디오 파일을 재생할 수 있습니다:\n\n```js\nfrom IPython.display import Audio, display\n\n# 출력 오디오 파일의 경로\noutput_audio_path = \"vocals.out.wav\"\n\n# 결과 오디오를 표시\ndisplay(Audio(output_audio_path, autoplay=True))\n```\n\n## 5) 선택 사항 — GUI 사용하여 추론 수행하기\n\n그래픽 인터페이스를 선호하는 사용자들을 위해, SO-VITS-SVC 시스템은 음성 변환을 수행하기 위한 선택적 GUI를 제공합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기능이 풍부한 GUI는 명령 줄 작업의 대안을 제공하여 추론 프로세스를 간소화합니다. 다음을 사용하여 시작할 수 있습니다.\n\n```js\nsvcg\n```\n\n![이미지](/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_5.png)\n\n- 설정: GUI를 실행하고 모델, 구성 및 오디오 파일의 필요한 경로를 '찾아보기' 버튼을 사용하여 구성합니다.\n- 모델 선택: 'Model path' 필드를 통해 적절한 사전 훈련된 모델을 선택합니다.\n- 구성: 모델에 해당하는 구성 파일을 'Config path' 필드에서 선택합니다.\n- 오디오 입력: 'Input audio path'를 사용하여 변환할 대상 오디오 파일을 로드합니다.\n- 추론: 필요한 경우 추가 매개변수를 조정하여 변환 프로세스를 시작하려면 'Infer' 버튼을 클릭합니다.\n- 출력: GUI를 통해 직접 생성된 출력을 저장하고 듣어보며 품질이 예상과 일치하는지 확인합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nGUI는 실시간 추론 기능도 제공하여 조정을 즉시 하고 즉각적인 청각적 피드백도 받을 수 있습니다.\n\n스크립팅이나 명령 줄 도구에 익숙하지 않은 사용자들을 고려하여 사용하기 쉽게 설계되었습니다.\n\n# 2. 모델 훈련: 당신처럼 노래하는 방법을 AI에게 가르치기\n\n이제 SO-VITS-SVC 시스템을 사용하여 사용자 지정 노래 목소리 변환 모델을 훈련하는 데 필요한 단계들을 보여드리겠습니다. 데이터셋 준비부터 환경 설정 및 모델 훈련, 기존 오디오 클립에서 노래하는 목소리를 생성하는 추론까지 순서대로 진행하겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모델 훈련 과정에 착수하기 전에 중요한 점이 있습니다. 이 작업은 컴퓨팅이 많이 필요하며, 높은 성능의 GPU와 상당한 VRAM이 필요합니다. 보통 10GB 이상이 필요합니다.\n\n이러한 요구 사항을 충족하지 못하는 개인용 하드웨어를 사용하는 분들을 위해, Google Colab은 강력한 GPU와 충분한 메모리에 접근할 수 있는 대안을 제공합니다. T4 GPU가 충분합니다. 추론은 그렇게 많은 VRAM이 필요하지 않습니다.\n\n## 2.1 데이터 준비\n\nHugging Face에서 제공되는 다양한 음성 데이터셋을 활용하여 사용자 정의 so-vits-svc 모델을 훈련할 수 있습니다. 그러나 고유한 음성 특성으로 모델을 개인화하고자 한다면, 자신의 목소리를 녹음하는 것이 더 흥미로운 방법일 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n당신만의 목소리 샘플 녹음하기\n\n- 샘플 길이: 가능하다면 최적의 길이인 10초씩 말하고 노래하는 자신을 녹음해보세요. 이 길이는 당신의 목소리의 세세한 특징을 캡처하기에 적합하며 처리하는 데 너무 많은 요구를 안 합니다.\n- 샘플의 양: 데이터가 많을수록 더 좋습니다. 적어도 200개의 목소리 샘플을 목표로 해보세요. 50개의 노래 샘플과 150개의 말하기 샘플이 적절한 혼합입니다.\n- 총 오디오 길이: 적어도 5분의 총 오디오를 모으는 것이 목표입니다. 이것은 모델이 학습할 튼튼한 기반을 제공합니다.\n- 다양한 콘텐츠: 발음학적으로 균형 잡힌 문장들을 읽어 다양한 음운을 다루세요. IEEE는 말 음질 측정을 위한 권장 사항으로 이러한 문장들의 목록을 제공하며 이는 다양성 있는 데이터셋에 기여할 수 있습니다.\n- 녹음 도구: Audacity는 당신의 샘플 녹음에 완벽한 무료 오픈 소스 소프트웨어입니다. 이것은 WAV 파일의 쉬운 녹음, 편집 및 내보내기를 가능하게 합니다.\n\n목소리 샘플 더욱 준비하기\n\n- 배경 소음 제거: 오디오 트랙에서 배경 소음을 제거해야 할 수 있습니다. Spleeter는 이를 위한 우수한 파이썬 라이브러리입니다. 아래 예시를 참고하세요. 그러나 반드시 WAV 파일로 저장해야 합니다. 더 자세한 내용은 깃허브 저장소를 참조해주세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n!pip install spleeter\n\nfrom spleeter.separator import Separator\n\n# 주어진 구성으로 분리기를 초기화합니다.\n# 여기서 'spleeter:2stems'는 음성을 보컬과 반주 두 부분으로 분리하려고 한다는 것을 의미합니다.\nseparator = Separator('spleeter:2stems')\n\n# 분리기를 오디오 파일에 적용합니다.\n# 이 함수는 오디오 파일을 두 개의 파일로 분리합니다: 보컬이 포함된 파일과 배경 음악이 포함된 파일입니다.\nseparator.separate_to_file('audiofile.wav', './')\n```\n\n2. 15초 단위로 오디오 트랙 분할하기: AudioSlicer를 사용하여 광범위한 오디오 파일을 10-15초 단위로 나눠 모델 학습에 적합한 스니펫으로 만들 수 있습니다.\n\n```js\nfrom audioslicer import slice_audio\n\n# 입력 오디오 파일 경로\ninput_audio_path = 'long_audio_file.wav'\n\n# 스니펫이 저장될 출력 디렉토리 경로\noutput_directory = 'output/snippets/'\n\n# 각 오디오 스니펫의 길이(초)\nsnippet_length = 15\n\n# 오디오 파일을 스니펫으로 나눕니다.\nslice_audio(input_audio_path, output_directory, snippet_length)\n```\n\n## 2.2 자동 전처리\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n현재 디렉토리에 dataset_raw 폴더가 생성되었고, 녹음 파일은 dataset_raw/'speaker_id' 디렉토리에 저장되어 있습니다. 아래 폴더 구조에 설명된 대로, 노래 목소리 변환 모델을 위한 전처리 및 학습 단계를 시작할 준비가 되었습니다.\n\n```js\n.\n├── dataset_raw\n│   └── {speaker_id}\n│       └── {wav_file}.wav\n```\n\n전 처리 단계에는 오디오 데이터를 모델 학습을 위해 준비하는 3가지 주요 단계가 포함됩니다 — !svc pre-resample, !svc pre-config, !svc pre-hubert로 최종적으로 !svc train을 실행합니다.\n\n전체 훈련 코드는 entprenerdly.com을 방문해주시기 바랍니다. Entrprenerdly는 튜토리얼, 코드 및 전략을 모두 제공합니다. 이러한 리소스들은 실용적인 지식을 얻을 수 있도록 설계되었습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Training Configuration](/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_6.png)\n\n## 2.3 Training Configuration\n\n학습을 시작하기 전에 모델을 구성하여 최적의 학습 조건을 확보하는 것이 중요합니다. 이는 전처리 중에 생성된 config.json 파일을 편집하는 작업을 포함합니다. 이 구성 파일 내의 주요 매개변수는 다음과 같습니다: log_interval, eval_interval, epochs, batch_size:\n\n![Config Parameters](/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_7.png)\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n데이터셋은 200개의 샘플이 있고 배치 크기는 20입니다. 따라서 각 에포크는 10단계와 같습니다. 100 에포크를 목표로 한다면 1,000단계가 됩니다. 에포크 수에 1을 추가하는 것이 좋습니다. 마지막 단계가 저장되도록 하기 위해서입니다.\n\n기본 설정은 10,000 에포크를 제안할 수 있지만, 하드웨어와 데이터셋 크기에 따라 조정해야 할 수도 있습니다. 실용적인 접근법은 20,000단계를 목표로 삼고 훈련을 계속하기 전에 성능을 평가하는 것입니다.\n\n## 2.4 훈련 시작\n\nsvc train 명령어로 실제 모델 훈련을 시작하세요. 이 명령은 dataset/44k/'speaker_id' 디렉토리에서 전처리된 데이터와 config/44k/config.json의 설정을 활용하여 머신러닝 프로세스를 시작합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n전체 교육 코드는 entreprenerdly.com을 방문해주세요. Entrprenerdly는 튜토리얼, 코드, 그리고 전략을 모두 담은 호스팅 서비스입니다. 이러한 자료들은 실용적인 지식을 전해줄 수 있도록 설계되었습니다.\n\n## 2.5 모델 추론\n\n모델을 학습하고 세밀하게 조정하며 유효성을 검증한 후, 다음 단계는 이전 섹션에 따라 소스 오디오를 대상 음성으로 변환하는 추론을 실행하는 것입니다.\n\n```js\nfrom IPython.display import Audio, display\nimport os\n\n# 파일 이름\naudio_filename = 'vocals.wav' # 훈련된 모델을 적용할 보컬\nmodel_filename = 'model.pth' # 생성된 모델 파일\nconfig_filename = 'config.json' # 생성된 구성 파일\n\n# 전체 로컬 경로 구성\naudio_file = f\"\\\"{os.path.join('.', audio_filename)}\\\"\"\nmodel_path = f\"\\\"{os.path.join('.', model_filename)}\\\"\"\nconfig_path = f\"\\\"{os.path.join('.', config_filename)}\\\"\"\n\n# 추론 명령 실행\n!svc infer {audio_file} -m {model_path} -c {config_path}\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n추론을 실행한 후에는 더 나은 결과물을 더 섬세하게 조정하고 싶을 수 있습니다. 예를 들어, 소스 오디오가 노래였고 배경 음악과 혼합해야 하는 경우나 음정을 조정하고 싶은 경우, Audacity나 다른 디지털 오디오 워크스테이션과 같은 오디오 처리 도구를 사용하여 선호에 맞게 트랙을 혼합하고 조정할 수 있습니다.\n\n# 4. 해결책의 실용적 응용\n\n- 음악 제작 향상 — 프로듀서들은 가수의 다른 음성 질감과 스타일을 실험해볼 수 있으며 아티스트의 물리적 존재 없이도 이를 시도할 수 있습니다. 새로운 트랙을 개념화하거나 다양한 음 높이와 음색으로 배경 보컬을 추가하는 데 특히 유용할 수 있습니다.\n- 맞춤형 음악 체험 — 팬들이 다른 아티스트의 목소리로 즐겨 듣는 노래의 버전을 받거나 사용자 정의 모델을 사용하여 자신의 목소리로 노래하게끔 받는 서비스를 상상해보세요.\n- 영화 및 애니메이션 더빙 — SO-VITS-SVC를 통해 영화, 만화, 게임의 더빙은 특히 원래 배우가 사용 불가능할 때 다양한 캐릭터 목소리로 보이스 오버를 생성하여 이점을 얻을 수 있습니다. 다양한 언어 버전 간 일관된 보컬 성능을 만들어낼 수 있습니다.\n- 교육 도구 — 언어 학습에서 SO-VITS-SVC를 사용하면 학습자가 여러 언어의 올바른 악센트와 억양으로 읽힌 텍스트를 자신의 목소리로들을 수 있어 이해력을 향상시킬 수 있습니다. 청취 및 말하기 기술을 발전시키는 데 도움이 됩니다.\n- 목소리 복원 — 말하는 능력을 잃은 개인들을 위해 SO-VITS-SVC는 그들의 목소리 레코딩을 기반으로 훈련을 받아 원래 목소리의 본질을 유지하면서 의사소통 능력을 회복할 수 있습니다.\n- 역사적 목소리 부활 — 지난 시대의 연설을 살려내어 박물관이나 교육 콘텐츠에서 흥미로운 청각 경험을 제공할 수 있습니다.\n\n# 결론\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기술의 함의는 깊고 넓은 영향을 미치고 있습니다. 가까운 미래에는 독립 아티스트가 AI를 활용하여 역사적인 어떤 목소리와도 듀엣할 수 있는 음악 제작의 민주화를 볼 수도 있을 것입니다. 또는 교육자들이 언어 장벽을 세계적으로 제거하는 데 활용할 수도 있을 것입니다. 그러나 SO-VITS-SVC의 참된 잠재력은 우리가 아직 완전히 이해하거나 상상조차 못한 장기적인 응용 분야에 있습니다.\n\n시각적 취향에만 맞추는 것이 아니라 청각적 편안함에도 개인화된 모든 디지털 상호 작용이 세계를 상상해보세요. 시각적인 광경뿐만 아니라 청각적인 축제가 되는 가상 현실 세계를 상상해보세요. 모든 캐릭터, 모든 존재가 실제 사람의 목소리와 구분이 안 가는 목소리로 당신과 대화할 수 있는 세계입니다. SO-VITS-SVC는 고유한 음성 아이덴티티를 가진 가상 존재를 위한 선구자가 될 수 있습니다. 이들은 다양한 언어와 스타일에서 노래하고 말하며 상호 작용할 수 있는 능력을 가질 것입니다.\n\n이러한 프로젝트와 더불어 AI, 데이터 과학, 기술 분야의 또 다른 혁신적인 데이터 기반 개발을 위해 독자 여러분이 www.entreprenerdly.com의 다양한 정보 자원을 탐험할 것을 장려합니다.\n\n![이미지](/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_8.png)","ogImage":{"url":"/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-AISingingVoiceCloninginPython_0.png","tag":["Tech"],"readingTime":23},{"title":"1줄짜리 SQL로 스테이징 테이블 데이터를 프로덕션 데이터로 이동하는 방법","description":"","date":"2024-07-13 19:37","slug":"2024-07-13-GoFromStagingTableToProductionDataWith1StupidSimpleSQLLine","content":"\n\n취업을 찾고 계신가요? 무료 5페이지 프로젝트 아이데이션 가이드를 활용하여 개인 프로젝트를 개발하여 경쟁력을 확보하세요.\n\n데이터 엔지니어링 튜토리얼에서 s-단어에 대해 충분히 다루지 않습니다. 제안을 제출하고 잘못 처리되면 반사적으로 터지는 네 글자의 욕설을 말하는 것이 아닙니다. 또는 스키마가 대상 테이블과 일치하지 않을 때 중얼거리는 말을 의미하지 않습니다.\n\n저는 스테이징에 대해 이야기합니다.\n\n왜냐하면 \"언제 (데이터 소스)가 프로덕션에서 이용 가능해질까요?\" 라는 스테이크홀더들로부터 받는 모든 질문에 대해 멈추고 \"먼저 스테이징 테이블로 로드되어야 합니다.\" 라고 말하기 때문입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그리고 지나치게 명료해질 위험이 있지만, 스테이징 환경이란 단순히 당신의 코드를 테스트하는 모래 상자가 아닙니다. 이것은 데이터 페이로드가 \"스위치를 누르고\" 제품 끝점, 테이블 및 대시보드를 가리키는 우리의 파이프 라인을 향하는 마지막 과정입니다.\n\n이상적으로, 당신의 스테이징 환경은 생산 테이블을 흉내 내며 다음과 같은 높은 데이터 엔지니어링 표준을 유지해야 합니다:\n\n- 클러스터링\n- 파티셔닝\n- 중복 제거\n\n이런 식으로 스테이징 테이블은 당신의 관리자, 팀 리더 또는 이해 관계자가 \"이 데이터가 이 형식으로 제공될 수 있다고 자신 있습니다.\" 라고 말하기 전에 검토할 최종 초안을 나타냅니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n무대 테이블을 세심하게 조사하는 동안에는 스키마와 파이프라인 기준을 세련된 상태로 개선하는 기회가 될 수 있지만, 그보다 중요한 것은 스위치를 뒤집는 시점에 발생하는 오류를 최소화하는 시간입니다.\n\n무대 테이블에 대해 800단어를 더 읽고 싶어할지도 모르겠지만, 저의 목표는 스테이징→프로덕션 전환을 원활하게 만들 수 있는 전략을 공유하는 것입니다.\n\n그리고 당신이 아마 존재한다는 명령어와 함께 빅쿼리 SQL의 1줄만 있을 뿐입니다.\n\n참고: 아래 과정은 특정 시나리오에 해당합니다 - 기존 테이블의 스키마를 편집하여 어떤 이유로든 끝에 추가할 수 없는 필드를 추가하는 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n<img src=\"/TIL/assets/img/2024-07-13-GoFromStagingTableToProductionDataWith1StupidSimpleSQLLine_0.png\" />\n\n저는 새로운 직업에서 3년이 지난 지금도 데이터 엔지니어링 분야에 관심을 가지고 있는 행운아라 생각합니다. 이야기하고자 하는 것은 앞으로 하지 않으면 안 될 작업이 없다는 것은 아니라는 점입니다.\n\n그 중 한 가지 작업이 데이터 엔지니어링의 기초에 관련되어 있습니다: 프로덕션 테이블을 덮어씌우는 것입니다.\n\n명확하게 말하면, 저는 테이블에 DML을 사용하는 것을 두렵게 여기지는 않습니다. 단지 파괴를 최소화하는 방법을 사용하려고 노력하는 것 뿐입니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n일반적으로 테이블 중간에 새 열을 삽입해야 한다면, 다음 단계를 따릅니다:\n\n- 기존 열을 모두 선택합니다.\n- 모든 열이 포함되었는지 확인하기 위해 UNION ALL 문을 작성합니다.\n- 새 열(또는 유형 변경을 위해 기존 열을 CAST())을 SELECT 문에 추가합니다.\n- BigQuery UI의 설정으로 전환합니다.\n- \"테이블 덮어쓰기\"를 선택합니다.\n- 원본 테이블의 데이터셋/이름을 입력합니다.\n- 실행합니다.\n- 변경 사항을 확인합니다.\n\n이렇게 들리겠지만, 조금의 연습을 통해 이 과정은 5분 이하로 완료할 수 있습니다.\n\n하지만, 전 상사에 따르면 더 짧게 할 수 있다고 하네요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n생산 테이블의 구조를 편집하는 대신에는 위험이 따르므로 스테이징 테이블을 만들고 그 스테이징 테이블을 생산 테이블의 이름으로 다시 별칭을 지정해야 합니다.\n\n만약 이 최종 결과물을 생성하기 위해 테이블을 생성/대체하거나 삭제해야 한다고 생각한다면, 예의를 갖추어 말씀드리면 틀린 판단일 것입니다.\n\nBigQuery는 다양한 유용한 DML 함수를 제공하는데, 그 중에서도 잘 알려지지 않은 함수 중 하나는 ALTER와 함께 사용되는 RENAME 명령입니다.\n\n이것을 함께 사용하면 다음과 같습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\nALTER TABLE `dataset.table` RENAME TO table\n\n스키마를 건드리지 않은 채 이 프로세스는 다음과 같습니다:\n\n- 스테이징 테이블을 생성합니다 (이미 생성된 경우 제외)\n- 전환할 준비가 되면 원본 테이블의 이름을 다르게 변경하여 두 개의 테이블을 가지고 있도록 합니다. 두 테이블 중 하나도 원본 테이블 이름을 가지지 않도록 합니다. 일반적으로 \"og\"를 추가하여 태그를 달아요. 예를 들어, financial_data_eom 테이블의 경우 financial_data_eom_og 및 financial_data_eom_test를 사용하겠습니다.\n\n3. 변경사항에 대해 자신감을 갖고 (이와 같이 이해 관계자들도) 된다면 ALTER TABLE 문을 실행합니다:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\nALTER TABLE financial_data_eom_test RENAME TO financial_data_eom\n\n4. Run a few quality assurance (QA) queries and merge the PR that contains a pipeline with the updated schema\n\nFunctionally, this provides you the ability to not only assure you’ve tested your changes, but also to preserve your original data and schema, should you need to revert to the “_og” table.\n\nThink of it like a save point or respawn in a video game. Or, if you want a more developer-centric explanation: The “_og” table contains your version history.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n스테이징 테이블에서 전환하는 것이 위험이 적지만, 위험이 없다는 뜻은 아닙니다.\n\n다음 사항을 염두에 두시기 바랍니다:\n\n- 스테이징 테이블을 생성할 때, 프로덕션 테이블과 동일한 클러스터링/파티셔닝 사양이 있어야 합니다.\n- 원본 테이블에서 데이터를 보존했더라도 업데이트된 테이블은 새로운 테이블입니다. 생성 시 메타데이터에는 새로운 생성 날짜와 최종 수정 날짜가 표시됩니다.\n- 새 테이블을 생성하면 추가 비용이 발생합니다. 이 방법을 시도할 경우 크기와 보관 기간을 고려해야 합니다.\n\n이 방법은 꽤 복잡한 것에 초보적으로 보일 수 있지만, 제 경험 상 스테이징 테이블을 통해 주요 변경 사항을 푸시하는 것이 프로덕션 편집보다 훨씬 편하고 확실하다고 느꼈습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 팁을 배운 지 얼마 지나지 않아서 역으로 해야 할 일이 발생했습니다. 코드가 불완전한 스키마를 포함하여 받은 후에 밤늦게 이전 버전의 테이블로 되돌려야 했죠.\n\n제출 마감이 몇 분 남았음에도 압박을 느꼈지만, 백업할 스테이징 테이블 덕분에 전환이 매우 원활하게 진행되었습니다. 테이블 이름 변경과 레포지토리의 커밋 이력에서 코드를 다시 커밋하는 사이에 3분만에 작업이 완료되었습니다.\n\n생산 스위치를 뒤집을 때는 두 가지 위치가 있는 것이 정말 다행입니다.\n\n도와주셔야 해요. 이 블로그 외에 어떻게 도와드릴 수 있는지 말씀해 주실 3가지 질문 설문에 응해주세요. 응답한 모든 분들께 무료 선물을 보내드릴게요.","ogImage":{"url":"/TIL/assets/img/2024-07-13-GoFromStagingTableToProductionDataWith1StupidSimpleSQLLine_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-GoFromStagingTableToProductionDataWith1StupidSimpleSQLLine_0.png","tag":["Tech"],"readingTime":7},{"title":"데이터 과학을 위한 Python 완벽 가이드","description":"","date":"2024-07-13 19:36","slug":"2024-07-13-PythonforDataScience","content":"\n\n<table>\n    <tr>\n        <td><img src=\"/TIL/assets/img/2024-07-13-PythonforDataScience_0.png\" /></td>\n    </tr>\n</table>\n\n데이터 과학 분야에서 Python이 인기 있는 이유를 살펴보겠습니다. Python은 그 간결함과 강력한 라이브러리로 인해 데이터 과학 분야에서 가장 많이 사용되는 언어 중 하나가 되었습니다.\n\n# 데이터 과학을 위한 Python의 장점\n\n- 학습 용이성: Python의 문법은 간단하고 가독성이 좋아 초심자부터 숙련된 프로그래머까지 모두 사용할 수 있습니다.\n- 다양한 라이브러리: 데이터 과학을 위해 특별히 설계된 다양한 라이브러리가 존재합니다.\n- 커뮤니티 지원: 큰 활성화된 커뮤니티가 많은 자료, 튜토리얼, 문제 해결 및 새로운 기술 습득을 지원해줍니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 데이터 과학을 위한 주요 라이브러리\n\n- NumPy: 대규모 다차원 배열과 행렬을 지원하며, 이러한 배열에 작용하는 수학 함수 모음을 제공합니다.\n\n```python\nimport numpy as np\narr = np.array([1, 2, 3, 4])\n```\n\n- Pandas: 데이터 조작과 분석에 꼭 필요한 DataFrames와 같은 데이터 구조를 제공하여 탭 형식의 데이터를 처리합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nimport pandas as pd\ndf = pd.read_csv('data.csv')\n```\n\n3. Matplotlib: 정적, 대화식 및 애니메이션 시각화를 생성하는 데 사용되는 도표 라이브러리입니다.\n\n```python\nimport matplotlib.pyplot as plt\nplt.plot([1, 2, 3, 4])\nplt.show()\n```\n\n4. Seaborn: Matplotlib을 기반으로 한 Seaborn은 매력적인 통계 그래픽을 그리기 위한 고수준 인터페이스를 제공합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n```\n\n5. SciPy: 과학 및 기술 계산에 사용되며 NumPy의 기능을 확장합니다.\n\n```js\nfrom scipy import stats\n```\n\n6. Scikit-Learn: 데이터 마이닝 및 데이터 분석에 유용한 간단하고 효율적인 도구를 제공하는 머신러닝 라이브러리입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nfrom sklearn.ensemble import RandomForestClassifier\n```\n\n# 예시 워크플로우\n\n파이썬에서의 전형적인 데이터 과학 워크플로우는 다음과 같은 단계를 포함할 수 있습니다:\n\n- 데이터 수집: Pandas를 사용하여 CSV, 데이터베이스 또는 API에서 데이터를 읽기\n- 데이터 정제: Pandas를 사용하여 결측값 및 중복 처리 및 데이터 변환\n- 탐색적 데이터 분석 (EDA): Pandas, Matplotlib 및 Seaborn을 사용하여 데이터 시각화 및 요약\n- 모델 구축: Scikit-Learn을 사용하여 머신러닝 알고리즘 적용\n- 평가: Scikit-Learn에서 제공하는 메트릭을 사용하여 모델 성능 평가\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n파이썬은 가독성, 라이브러리 다양성 및 강력한 커뮤니티 지원이 결합되어 데이터 과학에 이상적인 선택지입니다. 처음 시작하거나 경험 많은 데이터 과학자이든, 파이썬은 다양한 데이터 관련 문제에 대처할 도구와 유연성을 제공합니다.","ogImage":{"url":"/TIL/assets/img/2024-07-13-PythonforDataScience_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-PythonforDataScience_0.png","tag":["Tech"],"readingTime":4}],"page":"9","totalPageCount":35,"totalPageGroupCount":2,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}