{"pageProps":{"post":{"title":"로컬에서 Florence 2 시작하는 방법","description":"","date":"2024-07-12 20:11","slug":"2024-07-12-StartingwithFlorence2locally","content":"\n\n플로렌스-2는 Microsoft의 고급 비전 기반 모델로, 프롬프트 기반 방식을 사용하여 다양한 비전 및 비전-언어 작업을 처리하기 위해 설계되었습니다. 로컬에서 플로렌스-2를 설정하고 실행하는 데 도움이 되는 시작 스크립트가 여기 있어요.\n\n![이미지](/TIL/assets/img/2024-07-12-StartingwithFlorence2locally_0.png)\n\n# 시작 스크립트\n\n플로렌스-2를 실행하는 데 사용할 수 있는 시작 스크립트입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nimport os\nfrom transformers import AutoProcessor, AutoModelForCausalLM  \nfrom PIL import Image\nimport requests\nfrom unittest.mock import patch\nfrom transformers.dynamic_module_utils import get_imports\n\ndef run_example(task_prompt, text_input=None):\n    if text_input is None:\n        prompt = task_prompt\n    else:\n        prompt = task_prompt + text_input\n    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n    generated_ids = model.generate(\n        input_ids=inputs[\"input_ids\"].cuda(),\n        pixel_values=inputs[\"pixel_values\"].cuda(),\n        max_new_tokens=1024,\n        early_stopping=False,\n        do_sample=False,\n        num_beams=3,\n    )\n    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n    parsed_answer = processor.post_process_generation(\n        generated_text, \n        task=task_prompt, \n        image_size=(image.width, image.height),\n    )\n    return parsed_answer\n\n# Example usage\nfn = 'ray_ban_meta.jpeg'\nimage = Image.open(fn)\ntask_prompt = '<MORE_DETAILED_CAPTION>'\nret = run_example(task_prompt)\nprint(ret)\n```\n\n## 너무 괴롭히지 마세요\n\n만약 지역에서 실행하는 모든 시도 끝에도 이 예외를 받게 된다면: `pip install flash_attn`를 실행해 보세요.\n\n```python\nFile \"C:\\Users\\alex_\\aichat\\florence2_vision\\myenv\\lib\\site-packages\\transformers\\dynamic_module_utils.py\", line 182, in check_imports\n    raise ImportError(\nImportError: 이 모델링 파일은 환경에 없는 다음 패키지가 필요합니다: flash_attn. `pip install flash_attn`을 실행해 보세요.\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n상태 코드를 Markdown 형식으로 변경하십시오.\n\n```js\nFile \"C:\\Users\\alex_\\aichat\\florence2_vision\\myenv\\lib\\site-packages\\flash_attn\\flash_attn_interface.py\", line 10, in <module>\n    import flash_attn_2_cuda as flash_attn_cuda\nImportError: DLL load failed while importing flash_attn_2_cuda: The specified procedure could not be found.\n```\n\n청소한 상태에서 Miniconda를 사용하여 시작해 보세요.\n\n# 깔끔한 환경 설정\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음과 같이 새로운 conda 환경을 만들어 보세요:\n\n```js\nconda create -n florence2 python=3.11 -y\nconda activate florence2\n```\n\nCUDA 설치 여부 확인:\n\nCUDA가 설치되어 있는지 확인해주세요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\r\nnvcc --version\n\nnvcc: NVIDIA (R) Cuda 컴파일러 드라이버\nCopyright (c) 2005-2024 NVIDIA Corporation\n2024년 4월 17일 수요일에 빌드됨\nCuda 컴파일 도구, 릴리즈 12.5, V12.5.40\n빌드 cuda_12.5.r12.5/compiler.34177558_0\r\n```\n\nCUDA 경로 설정:\n\n```js\r\nset \"CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.5\"\nset \"CUDA_HOME=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.5\"\r\n```\n\nPyTorch 및 종속성 설치하기:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\npip install transformers einops timm\n```\n\n# Flash 어텐션 불필요\n\ntransformers 의존성에서 요구되지도 않고 알려진 문제입니다.\n\n이것이 해결책이에요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# With Python 3.11.7, transformers==4.36.2\nimport os\nfrom unittest.mock import patch\n\nfrom transformers import AutoModelForCausalLM\nfrom transformers.dynamic_module_utils import get_imports\n\n\ndef fixed_get_imports(filename: str | os.PathLike) -> list[str]:\n    \"\"\"https://huggingface.co/microsoft/phi-1_5/discussions/72을 위한 해결책.\"\"\"\n    if not str(filename).endswith(\"/modeling_phi.py\"):\n        return get_imports(filename)\n    imports = get_imports(filename)\n    imports.remove(\"flash_attn\")\n    return imports\n\n\nwith patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports):\n    model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\r\n```\n\n# OCR 테스트\n\n## 입력 이미지\n\n<img src=\"/TIL/assets/img/2024-07-12-StartingwithFlorence2locally_1.png\" />\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 스크립트를 실행한 후의 업데이트 내용입니다:\n\n```js\nD:\\DEV\\MODELS\\modules\\transformers_modules\\microsoft\\Florence-2-large-ft\\3112cd2e25c969cfdcb600a01489c56737d943d3\\modeling_florence2.py:1209: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n  attn_output = torch.nn.functional.scaled_dot_product_attention(\n{'<OCR>': '2310Z8MOOWN - RW4008 6015IC 26243-4003RCID 2AYOA-403'}\n```\n\n잘 작동합니다! 좀 그렇지만요. 일부 숫자가 누락되었지만, 그건 다음에 다시 이야기할 주제입니다.\n\n# 마지막으로\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 단계를 따르면 어려움 없이 Florence-2를 로컬에서 실행할 수 있을 것입니다. 다른 문제가 발생하면 모든 의존성이 올바르게 설치되어 있는지, 환경이 올바르게 구성되어 있는지 확인해주세요.\n\n# Hugging Face Spaces\n\n환경을 로컬로 설정하기를 원치 않는다면 Hugging Face Spaces를 사용하여 Florence-2를 실행할 수도 있습니다. 이는 로컬 구성이 필요 없이 모델에 액세스할 수 있는 클라우드 기반 솔루션을 제공합니다. Hugging Face의 Florence-2 스페이스를 확인해보세요: Hugging Face Spaces\n\n# 출처","ogImage":{"url":"/TIL/assets/img/2024-07-12-StartingwithFlorence2locally_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-StartingwithFlorence2locally_0.png","tag":["Tech"],"readingTime":7},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>플로렌스-2는 Microsoft의 고급 비전 기반 모델로, 프롬프트 기반 방식을 사용하여 다양한 비전 및 비전-언어 작업을 처리하기 위해 설계되었습니다. 로컬에서 플로렌스-2를 설정하고 실행하는 데 도움이 되는 시작 스크립트가 여기 있어요.</p>\n<p><img src=\"/TIL/assets/img/2024-07-12-StartingwithFlorence2locally_0.png\" alt=\"이미지\"></p>\n<h1>시작 스크립트</h1>\n<p>플로렌스-2를 실행하는 데 사용할 수 있는 시작 스크립트입니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoProcessor, AutoModelForCausalLM  \n<span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image\n<span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">from</span> unittest.mock <span class=\"hljs-keyword\">import</span> patch\n<span class=\"hljs-keyword\">from</span> transformers.dynamic_module_utils <span class=\"hljs-keyword\">import</span> get_imports\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run_example</span>(<span class=\"hljs-params\">task_prompt, text_input=<span class=\"hljs-literal\">None</span></span>):\n    <span class=\"hljs-keyword\">if</span> text_input <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n        prompt = task_prompt\n    <span class=\"hljs-keyword\">else</span>:\n        prompt = task_prompt + text_input\n    inputs = processor(text=prompt, images=image, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\n    generated_ids = model.generate(\n        input_ids=inputs[<span class=\"hljs-string\">\"input_ids\"</span>].cuda(),\n        pixel_values=inputs[<span class=\"hljs-string\">\"pixel_values\"</span>].cuda(),\n        max_new_tokens=<span class=\"hljs-number\">1024</span>,\n        early_stopping=<span class=\"hljs-literal\">False</span>,\n        do_sample=<span class=\"hljs-literal\">False</span>,\n        num_beams=<span class=\"hljs-number\">3</span>,\n    )\n    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=<span class=\"hljs-literal\">False</span>)[<span class=\"hljs-number\">0</span>]\n    parsed_answer = processor.post_process_generation(\n        generated_text, \n        task=task_prompt, \n        image_size=(image.width, image.height),\n    )\n    <span class=\"hljs-keyword\">return</span> parsed_answer\n\n<span class=\"hljs-comment\"># Example usage</span>\nfn = <span class=\"hljs-string\">'ray_ban_meta.jpeg'</span>\nimage = Image.<span class=\"hljs-built_in\">open</span>(fn)\ntask_prompt = <span class=\"hljs-string\">'&#x3C;MORE_DETAILED_CAPTION>'</span>\nret = run_example(task_prompt)\n<span class=\"hljs-built_in\">print</span>(ret)\n</code></pre>\n<h2>너무 괴롭히지 마세요</h2>\n<p>만약 지역에서 실행하는 모든 시도 끝에도 이 예외를 받게 된다면: <code>pip install flash_attn</code>를 실행해 보세요.</p>\n<pre><code class=\"hljs language-python\">File <span class=\"hljs-string\">\"C:\\Users\\alex_\\aichat\\florence2_vision\\myenv\\lib\\site-packages\\transformers\\dynamic_module_utils.py\"</span>, line <span class=\"hljs-number\">182</span>, <span class=\"hljs-keyword\">in</span> check_imports\n    <span class=\"hljs-keyword\">raise</span> ImportError(\nImportError: 이 모델링 파일은 환경에 없는 다음 패키지가 필요합니다: flash_attn. `pip install flash_attn`을 실행해 보세요.\n</code></pre>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>상태 코드를 Markdown 형식으로 변경하십시오.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-title class_\">File</span> <span class=\"hljs-string\">\"C:\\Users\\alex_\\aichat\\florence2_vision\\myenv\\lib\\site-packages\\flash_attn\\flash_attn_interface.py\"</span>, line <span class=\"hljs-number\">10</span>, <span class=\"hljs-keyword\">in</span> &#x3C;<span class=\"hljs-variable language_\">module</span>>\n    <span class=\"hljs-keyword\">import</span> flash_attn_2_cuda <span class=\"hljs-keyword\">as</span> flash_attn_cuda\n<span class=\"hljs-title class_\">ImportError</span>: <span class=\"hljs-variable constant_\">DLL</span> load failed <span class=\"hljs-keyword\">while</span> importing <span class=\"hljs-attr\">flash_attn_2_cuda</span>: <span class=\"hljs-title class_\">The</span> specified procedure could not be found.\n</code></pre>\n<p>청소한 상태에서 Miniconda를 사용하여 시작해 보세요.</p>\n<h1>깔끔한 환경 설정</h1>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>다음과 같이 새로운 conda 환경을 만들어 보세요:</p>\n<pre><code class=\"hljs language-js\">conda create -n florence2 python=<span class=\"hljs-number\">3.11</span> -y\nconda activate florence2\n</code></pre>\n<p>CUDA 설치 여부 확인:</p>\n<p>CUDA가 설치되어 있는지 확인해주세요:</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-js\">nvcc --version\n\n<span class=\"hljs-attr\">nvcc</span>: <span class=\"hljs-variable constant_\">NVIDIA</span> (R) <span class=\"hljs-title class_\">Cuda</span> 컴파일러 드라이버\n<span class=\"hljs-title class_\">Copyright</span> (c) <span class=\"hljs-number\">2005</span>-<span class=\"hljs-number\">2024</span> <span class=\"hljs-variable constant_\">NVIDIA</span> <span class=\"hljs-title class_\">Corporation</span>\n<span class=\"hljs-number\">2024</span>년 <span class=\"hljs-number\">4</span>월 <span class=\"hljs-number\">17</span>일 수요일에 빌드됨\n<span class=\"hljs-title class_\">Cuda</span> 컴파일 도구, 릴리즈 <span class=\"hljs-number\">12.5</span>, <span class=\"hljs-variable constant_\">V12</span><span class=\"hljs-number\">.5</span><span class=\"hljs-number\">.40</span>\n빌드 cuda_12<span class=\"hljs-number\">.5</span>.<span class=\"hljs-property\">r12</span><span class=\"hljs-number\">.5</span>/compiler<span class=\"hljs-number\">.34177558_0</span>\n</code></pre>\n<p>CUDA 경로 설정:</p>\n<pre><code class=\"hljs language-js\">set <span class=\"hljs-string\">\"CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.5\"</span>\nset <span class=\"hljs-string\">\"CUDA_HOME=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.5\"</span>\n</code></pre>\n<p>PyTorch 및 종속성 설치하기:</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-js\">pip install torch torchvision torchaudio --index-url <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//download.pytorch.org/whl/cu121</span>\npip install transformers einops timm\n</code></pre>\n<h1>Flash 어텐션 불필요</h1>\n<p>transformers 의존성에서 요구되지도 않고 알려진 문제입니다.</p>\n<p>이것이 해결책이에요:</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-title class_\">With</span> <span class=\"hljs-title class_\">Python</span> <span class=\"hljs-number\">3.11</span><span class=\"hljs-number\">.7</span>, transformers==<span class=\"hljs-number\">4.36</span><span class=\"hljs-number\">.2</span>\n<span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">from</span> unittest.<span class=\"hljs-property\">mock</span> <span class=\"hljs-keyword\">import</span> patch\n\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">AutoModelForCausalLM</span>\n<span class=\"hljs-keyword\">from</span> transformers.<span class=\"hljs-property\">dynamic_module_utils</span> <span class=\"hljs-keyword\">import</span> get_imports\n\n\ndef <span class=\"hljs-title function_\">fixed_get_imports</span>(<span class=\"hljs-attr\">filename</span>: str | os.<span class=\"hljs-property\">PathLike</span>) -> list[str]:\n    <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"https://huggingface.co/microsoft/phi-1_5/discussions/72을 위한 해결책.\"</span><span class=\"hljs-string\">\"\"</span>\n    <span class=\"hljs-keyword\">if</span> not <span class=\"hljs-title function_\">str</span>(filename).<span class=\"hljs-title function_\">endswith</span>(<span class=\"hljs-string\">\"/modeling_phi.py\"</span>):\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-title function_\">get_imports</span>(filename)\n    imports = <span class=\"hljs-title function_\">get_imports</span>(filename)\n    imports.<span class=\"hljs-title function_\">remove</span>(<span class=\"hljs-string\">\"flash_attn\"</span>)\n    <span class=\"hljs-keyword\">return</span> imports\n\n\n<span class=\"hljs-keyword\">with</span> <span class=\"hljs-title function_\">patch</span>(<span class=\"hljs-string\">\"transformers.dynamic_module_utils.get_imports\"</span>, fixed_get_imports):\n    model = <span class=\"hljs-title class_\">AutoModelForCausalLM</span>.<span class=\"hljs-title function_\">from_pretrained</span>(<span class=\"hljs-string\">\"microsoft/phi-1_5\"</span>, trust_remote_code=<span class=\"hljs-title class_\">True</span>)\n</code></pre>\n<h1>OCR 테스트</h1>\n<h2>입력 이미지</h2>\n<img src=\"/TIL/assets/img/2024-07-12-StartingwithFlorence2locally_1.png\">\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>다음은 스크립트를 실행한 후의 업데이트 내용입니다:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-attr\">D</span>:\\<span class=\"hljs-variable constant_\">DEV</span>\\<span class=\"hljs-variable constant_\">MODELS</span>\\modules\\transformers_modules\\microsoft\\<span class=\"hljs-title class_\">Florence</span>-<span class=\"hljs-number\">2</span>-large-ft\\3112cd2e25c969cfdcb600a01489c56737d943d3\\modeling_florence2.<span class=\"hljs-property\">py</span>:<span class=\"hljs-number\">1209</span>: <span class=\"hljs-title class_\">UserWarning</span>: 1Torch was not compiled <span class=\"hljs-keyword\">with</span> flash attention. (<span class=\"hljs-title class_\">Triggered</span> internally at ..\\aten\\src\\<span class=\"hljs-title class_\">ATen</span>\\native\\transformers\\cuda\\sdp_utils.<span class=\"hljs-property\">cpp</span>:<span class=\"hljs-number\">455.</span>)\n  attn_output = torch.<span class=\"hljs-property\">nn</span>.<span class=\"hljs-property\">functional</span>.<span class=\"hljs-title function_\">scaled_dot_product_attention</span>(\n{<span class=\"hljs-string\">'&#x3C;OCR>'</span>: <span class=\"hljs-string\">'2310Z8MOOWN - RW4008 6015IC 26243-4003RCID 2AYOA-403'</span>}\n</code></pre>\n<p>잘 작동합니다! 좀 그렇지만요. 일부 숫자가 누락되었지만, 그건 다음에 다시 이야기할 주제입니다.</p>\n<h1>마지막으로</h1>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>이 단계를 따르면 어려움 없이 Florence-2를 로컬에서 실행할 수 있을 것입니다. 다른 문제가 발생하면 모든 의존성이 올바르게 설치되어 있는지, 환경이 올바르게 구성되어 있는지 확인해주세요.</p>\n<h1>Hugging Face Spaces</h1>\n<p>환경을 로컬로 설정하기를 원치 않는다면 Hugging Face Spaces를 사용하여 Florence-2를 실행할 수도 있습니다. 이는 로컬 구성이 필요 없이 모델에 액세스할 수 있는 클라우드 기반 솔루션을 제공합니다. Hugging Face의 Florence-2 스페이스를 확인해보세요: Hugging Face Spaces</p>\n<h1>출처</h1>\n</body>\n</html>\n"},"__N_SSG":true}