{"pageProps":{"posts":[{"title":"코드 변경을 안전하게 하는 커스텀 pre-commit 훅 사용하는 방법","description":"","date":"2024-07-09 21:03","slug":"2024-07-09-Custompre-commithooksforsafercodechanges","content":"\n\n## 첫 번째 pre-commit 훅을 작성하는 단계별 가이드\n\n![이미지](/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_0.png)\n\n대부분의 소프트웨어는 코드를 업데이트하고 배포하기 위해 git 버전 관리 시스템을 사용하여 개발됩니다. 코드를 협업하여 작성하는 한 가지 어려움은 각 참여자가 깨끗한 코드로 간주되는 것에 대한 자기 스타일과 의견이 있을 때 특정한 표준을 보장하는 것입니다.\n\npre-commit 훅은 코드 변경을 커밋하기 전에 자동으로 실행되는 스크립트나 명령어입니다. 이들은 스타일 가이드를 강제하고 커밋되기 전에 오류를 잡을 수 있으며 더 다양하게 배포할 수 있습니다. 주요한 훅은 구문 오류를 확인하고, import를 정렬하며, 따옴표를 정규화하는 것이 있습니다. 이러한 훅들은 많은 참여자가 있는 오픈 소스 프로젝트를 포함한 모든 프로젝트에 필수적인 도구입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 사용자 정의 pre-commit 훅을 만드는 이유\n\n저는 Python 라이브러리 Hamilton을 위해 데이터플로우 정의를 검증하기 위한 pre-commit 훅을 만드려고 했지만, 대부분의 온라인 자료가 분산되어 있고 기본 사용법에 한정되어 있다는 것을 발견했습니다.\n\n이 게시물에서는 다음을 찾아볼 수 있습니다:\n\n- 프로젝트에서 pre-commit 훅을 사용하기 시작하는 방법\n- 사용자 정의 pre-commit 훅을 개발하기 위한 단계별 튜토리얼\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n토론을 바탕으로, Hamilton을 위해 개발한 사전 커밋 후크를 포함하는 이 GitHub 저장소를 살펴보겠습니다.\n\n# 사전 커밋 후크 사용 시작하기\n\n후크(Hooks)는 git 버전 관리 시스템에 직접 내장된 메커니즘입니다. .git/hooks 디렉토리 아래에서 프로젝트의 후크를 찾을 수 있습니다(기본적으로 숨겨질 수 있습니다). 일반적으로 \"사전 커밋 후크\"라고 불리지만, git 후크는 전체 git 수명 주기를 다룹니다. 예를 들어, 커밋 직후나 푸시하기 직전에 후크를 트리거할 수 있습니다. 또한, 후크는 어떤 프로그래밍 언어로도 작성할 수 있습니다. 흥미롭게도, Ruff 라이브러리는 성능 향상을 위해 많은 Python 기반 후크를 Rust로 재구현했습니다.\n\n코드 동작에 집중하는 소프트웨어 테스트와 비교해볼 때, 후크는 각 파일 저장 시 수행하는 가벼운 체크로 생각할 수 있습니다. 테스트가 코드베이스와 함께 변화하고 진화하는 것을 기대할 수 있는 반면, 코드 작성 가이드라인과 사전 커밋 후크는 고정될 가능성이 높습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 프로젝트 설정\n\n새로운 파이썬 프로젝트를 시작하거나 기존 프로젝트를 사용하는 것으로 가정해 봅시다. 디렉토리 /my-project 에서 작업하려면 pre-commit 후크를 사용하는 선호하는 방법은 pre-commit Python 라이브러리를 사용하는 것입니다. 다음 단계로 설정할 수 있습니다:\n\n- 프로젝트를 위해 git init으로 git 저장소를 만듭니다.\n- pre-commit 라이브러리를 설치하려면 pip install pre-commit을 사용합니다.\n- 저장소에 .pre-commit-config.yaml 파일을 추가합니다. 다음은 예시입니다:\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n    # 후크 정의가 있는 저장소\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v2.3.0  # 저장소의 릴리스 버전\n    hooks:  # 이 프로젝트에 포함할 저장소의 후크 목록\n    -   id: end-of-file-fixer\n    -   id: trailing-whitespace\n    -   id: check-yaml\n        args: ['--unsafe']  # `check-yaml`에 인수 추가\n\n    # 후크가 있는 다른 저장소 다운로드\n-   repo: https://github.com/psf/black\n    rev: 22.10.0\n    hooks:\n    -   id: black\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n4. `pre-commit install` 명령어를 사용하여 훅을 설치하세요. 이 몤령어는 .pre-commit-config.yaml 파일에서 지시 사항을 읽고, .git/hooks/pre-commit 폴더 아래 로컬로 훅을 설치합니다.\n\n5. 커밋을 만들거나 `pre-commit run --all-files` 명령어를 수동으로 실행하여 훅을 작동시킬 수 있습니다.\n\n### 사용자 정의 pre-commit 훅 만들기\n\n커뮤니티가 유지보수하는 훅은 유연성을 제공하며 선호하는 코딩 가이드라인에 맞게 맞춤화할 수 있습니다. 이러한 훅은 대부분의 경우 98%의 요구를 충족해야 할 것입니다. 그러나 기본 제공 솔루션은 사용 중인 도구나 팀의 내부 규칙을 알지 못합니다. 예를 들어, 내부 구성을 유효성 검사하거나 프로젝트의 디렉토리 구조를 강제로 지정하는 것과 같은 조치를 취하려고 할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리 케이스에서는, 그들의 Hamilton 데이터 플로우 정의에 대한 Python 코드를 검증하기 위한 후크를 생성하려고 합니다. 우리의 후크 스크립트는 검증을 수행하기 위해 hamilton CLI 도구를 활용하여 간단한 코드 예제를 따라할 수 있게 됩니다.\n\n## 1. pre-commit 후크 저장소 설정\n\n프로젝트 설정 섹션에서 소개된 대로, pre-commit 후크는 .pre-commit-config.yaml에 있어야 하며, 프로젝트가 해당 후크를 참조하고 pre-commit install로 로컬에 설치할 수 있도록 공개 저장소에 존재해야 합니다.\n\n이전에는 프로젝트 디렉토리 /my-project에 있었으며 .pre-commit-config.yaml을 정의하고 후크를 설치했습니다. 이제, /my-hooks 디렉토리를 생성하여 사용자 정의 후크를 정의할 것입니다. 우리의 hamilton-pre-commit 저장소를 참조하여 일반적인 구조를 확인할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_1.png\" />\n\n## 2. 훅 로직 작성\n\nhooks/ 디렉토리 아래에는 해당 디렉토리를 파이썬 모듈로 찾을 수 있도록 하는 파일 __init__.py와 cli_command.py 스크립트가 있습니다. cli_command.py에는 하나의 main() 함수가 포함되어 있으며, 이 함수는 sys.argv에서 햄릴턴 CLI 명령의 목록을 읽습니다. 그런 다음, 예외 처리가 적용된 서브프로세스로 감싸져 하나씩 실행합니다.\n\n```js\n# hooks/cli_command.py\nimport sys\nimport json\nimport subprocess\n\nPASS = 0\nFAIL = 1\n\ndef main() -> int:\n    \"\"\"햄릴턴 CLI를 사용하여 명령 목록 실행\"\"\"    \n    commands = sys.argv[1:]\n\n    if len(commands) == 0:\n        return PASS\n        \n    exit_code = PASS\n    for command in commands:\n        try:\n            args = command.split(\" \")\n            # `--json-out`를 삽입하여 적절한 stdout 구문 분석\n            args.insert(1, \"--json-out\")\n            result = subprocess.run(args, stdout=subprocess.PIPE, text=True)\n            response = json.loads(result.stdout)\n            \n            if response[\"success\"] is False:\n                raise ValueError\n                \n        except Exception:\n            exit_code |= FAIL\n\n    return exit_code\n\nif __name__ == \"__main__\":\n    raise SystemExit(main())\r\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n처음에는 exit_code를 PASS로 설정하지만, 어떤 예외나 실행되지 못한 명령이 있다면 exit_code를 FAIL로 설정합니다. main() 함수는 exit 코드를 SystemExit 예외에 반환합니다. pre-commit 훅이 성공하려면 모든 명령이 성공한 후에 PASS를 반환해야 합니다. PASS가 0이고 FAIL이 1인 것이 직관적이지 않을 수 있지만, 이 값들은 표준 시스템의 종료 코드를 가리킵니다.\n\n우리는 편의성을 위해 Python을 사용했지만, 이 간단한 논리는 Bash와 같은 가벼운 스크립팅 언어에서도 적용될 수 있습니다. pre-commit 팀이 유지 관리하는 후크를 방문하여 더 많은 예제를 확인할 수 있습니다.\n\n## 3. 후크 진입점 정의하기\n\n이제, 당신의 후크 저장소(/my-hooks)는 설치된 후에 사용할 수 있는 후크들과 그 실행 방법을 지정하는 .pre-commit-hooks.yaml 파일을 포함해야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n- id: cli-command\n  name: '`hamilton` CLI 명령 실행'\n  description: '이 후크는 `hamilton` CLI를 사용하여 명령을 실행합니다.'\n  entry: cli-command\n  language: python\n  types: [python]\n  stages: [pre-commit, pre-merge-commit, manual]\n  pass_filenames: false\n\n\n우리의 경우, id: cli-command 및 entry: cli-command를 설정하고 몇 가지 메타데이터를 추가하며 프로그래밍 언어는 Python으로 지정했습니다. 중요한 점은 파일 속성이 설정되어 있지 않아 후크가 커밋 당 한 번 실행되게하려면 파일: \"*.py\"를 설정해야합니다. 예를 들어 각 수정된 Python 파일에서 후크를 실행하도록 할 수 있습니다 (사용 가능한 옵션에 대해 알아보세요).\n\n지금까지 hooks/cli_command.py 아래 Python 스크립트를 만들고 .pre-commit-hooks.yaml에 cli-command 진입점이있는 후크를 추가했습니다. 그러나 Python 프로젝트 파일 pyproject.toml에서 명시적으로 두 가지를 연결해야합니다.\n\n\n[project.scripts]\ncli-command = \"hooks.cli_command:main\"\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 줄은 \"입력 지점 cli-command은 hooks.cli_command의 main 함수를 가리킵니다.\"라고 읽습니다.\n\n## 4. 로컬에서 훅을 테스트하는 방법\n\n먼저, 단위 테스트로 훅의 로직을 유효성 검사해야 합니다. 그러나 테스팅에 대해 자세히 다루지는 않겠습니다. 현재 hamilton-pre-commit 저장소에는 이 main Hamilton 저장소에서 테스트 된 기본 CLI가 없기 때문에 테스트가 없습니다. 테스트 예제용으로 공식으로 유지되는 pre-commit 훅을 방문할 수 있습니다.\n\n두 번째로, .pre-commit-hooks.yaml 및 입력 지점이 올바르게 구성되었는지 확인하기 위해 로컬에서 pre-commit 훅을 시도해야 합니다. 이상적으로는 변경 사항을 테스트하기 위해 훅을 실행할 때마다 커밋을 추가하는 것을 피하고 싶습니다. pre-commit 라이브러리는 이 프로세스를 용이하게 하기 위한 유틸리티를 제공하지만 pre-commit GitHub 문제에서 자세히 설명 된 몇 가지 수동 단계가 필요합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 훅을 테스트하고 싶은 디렉토리 /my-project로 이동하세요.\n- pre-commit try-repo ../LOCAL/PATH/TO/my-hooks 명령을 실행하고, 로컬 초기화 메시지가 표시되어야 합니다.\n\n![이미지](/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_2.png)\n\n한 가지 제한 사항은이 명령을 통해 훅에 직접 매개변수를 전달할 수 없다는 것입니다.\n\n3. Using config: 하위의 구성을 복사하여 로컬 파일에 추가하고 args 섹션을 추가하세요. 우리는 .local-pre-commit-config.yaml를 생성했지만 원하는 이름을 사용할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\nrepos:\n  - repo: ../../dagworks/hamilton-pre-commit\n    rev: e4b77a499ba0ff3446a86ebbe4c2cbca82eb54f8\n    hooks:\n    - id: cli-command\n      args: [\n        hamilton build my_func2.py\n      ]\n```\n\n4. `pre-commit run --config .local-pre-commit-config.yaml --all-files` 명령어를 사용하여 로컬 후크를 실행하세요. `--all-files` 플래그를 사용하면 현재 스테이징된 파일뿐만 아니라 저장소의 모든 파일에 후크가 적용됩니다.\n\n![Custom Pre-Commit Hooks](/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_3.png)\n\n## 5. Pre-Commit 후크 공개하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n거의 다 왔어요! 동작하는 후크 스크립트를 테스트하고 git 저장소에 패키징했군요. 이제 그것을 온라인으로 사용할 수 있도록 만들어야 합니다. GitHub 호스팅 프로젝트를 위한 단계를 보여드리겠지만, 당신의 pre-commit 후크는 git clone을 통해 접근 가능한 어디에나 저장할 수 있어요.\n\n- GitHub 저장소에서 Releases 섹션으로 이동하세요\n\n![image](/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_4.png)\n\n2. 새 릴리스 초안 작성을 클릭하세요\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![이미지](/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_5.png)\n\n3. 새 릴리스 페이지에서는 버전 태그, 제목 및 설명을 추가해야 합니다. 첫 번째 릴리스인 경우, GitHub에서 권장하는 시맨틱 버전을 따르기 위해 태그를 v0.1.0으로 설정하는 것이 좋습니다.\n\n변경 사항을 만들고 실험 버전을 배포하려는 경우 버전을 v0.1.1-rc로 설정하고 \"릴리스 후보\"로 표시하려면 확인란을 사용하세요.\n\n![이미지](/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_6.png)\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n.pre-commit-config.yaml 파일에서 rev 값은 설정한 버전 태그와 일치해야 합니다.\n\n```js\nrepos:\n- repo: https://github.com/DAGWorks-Inc/hamilton-pre-commit\n  rev: v0.1.3rc\n  hooks:\n    - id: cli-command\n      # ...\n```\n\n# 마무리 맺기\n\n축하합니다! 이 글을 읽어나가셨군요! 이제 프로젝트에서 코드 품질을 향상시키기 위해 pre-commit 훅을 사용할 수 있게 되었습니다. 그 내부 원리를 이해했으니 이제 여러분만의 훅을 작성할 수 있습니다!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n바퀴를 다시 발명하기 전에 커뮤니티에서 유지보수하는 많은 후크들을 확인하시기 바랍니다: [https://pre-commit.com/hooks.html](https://pre-commit.com/hooks.html)\n\n파이썬에서 데이터플로우를 작성하기 위해 Hamilton 라이브러리를 확인해보세요!\nLinkedIn에서 저를 찾아보고 DAGWorks 블로그에서 더 많은 포스트를 읽어보세요","ogImage":{"url":"/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_0.png"},"coverImage":"/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_0.png","tag":["Tech"],"readingTime":13},{"title":"Hugging Face 시작을 위한 종합 가이드","description":"","date":"2024-07-09 21:02","slug":"2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace","content":"\n\n![Hugging Face](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png)\n\n대규모 언어 모델들의 급격한 발전으로 다양한 작업을 해결하기 위해 적용되는 경우가 많아졌으며, Hugging Face에 대한 지식은 반드시 알아둬야 할 필수요소가 되었습니다.\n\n왜 Hugging Face를 사용해야 할까요? Hugging Face는 다양한 오픈 소스 모델에 대한 접근성을 제공하는 데 중요한 역할을 합니다. 이 플랫폼 덕분에 데이터 과학자, 개발자 및 연구자들은 최신 모델을 쉽게 탐색하고 활용할 수 있습니다.\n\n본문에서는 Hugging Face의 잠재력, 이를 활용하는 방법 및 가능한 사용 사례에 대해 설명하겠습니다. 시작해봅시다!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n목차:\n\n- Hugging Face란 무엇인가요?\n- Hugging Face의 기본 구성 요소\n- Open LLM Leaderboard란 무엇인가요?\n- Hugging Face에 접근하는 방법\n- Hugging Face로 놀기 시작하기\n- Transformers 라이브러리 활용하기\n\n## Hugging Face란 무엇인가요?\n\n<img src=\"/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_1.png\" />\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n허깅페이스는 다양한 작업을 위한 사전 훈련 모델에 민주적인 접근을 제공하는 허브입니다. 번역, 요약, 질의응답, 객체 감지, 이미지 분할 등 다양한 작업에 사용됩니다. 사용자들이 오픈 소스 모델에 기여할 것을 장려합니다.\n\n이 중심화된 저장소의 매력은 허깅페이스 트랜스포머(Hugging Face Transformers)로, 모델을 쉽게 다운로드하고 불러오며 미세 조정할 수 있는 매우 인기 있는 파이썬 라이브러리입니다.\n\n모델뿐만 아니라 데이터셋과 기계 학습 데모인 허깅페이스 스페이스(Hugging Face Spaces)도 호스팅합니다.\n\n## 허깅페이스의 기본 구성요소\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n허깅페이스에는 모델, 데이터셋 및 스페이스 세 가지 주요 구성 요소가 있어요.\n\n![image](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_2.png)\n\n모델 페이지에 들어가보면 수많은 오픈소스 모델로 인해 압도될 수 있지만 걱정 마세요. 먼저 해결하고자 하는 작업을 식별한 후 해당 작업으로 필터링하는 것이 권장됩니다. 작업을 선택한 후에는 인기도와 다운로드 횟수 같은 다양한 기준에 따라 모델을 정렬할 수 있어요.\n\n![image](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_3.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모델과 마찬가지로, 다양한 종류의 데이터셋이 있어서 다양한 작업에 활용할 수 있습니다. 이전과 마찬가지로 최종 목표에 따라 작업별로 필터링하고 결과를 정렬하는 것이 중요합니다.\n\n![이미지](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_4.png)\n\n마지막으로, Hugging Face 스페이스라는 기계 학습 데모를 빠르게 살펴볼 수 있습니다. Hugging Face 스페이스에서는 Streamlit, Gradio, 그리고 FastAPI를 기반으로 한 대화형 애플리케이션을 통해 모델을 실행할 수 있습니다. 다시 말해, Hugging Face 스페이스를 통해 직관적인 인터페이스를 통해 간접적으로 모델과 상호 작용할 수 있습니다.\n\n![이미지](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_5.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위에는 입력 텍스트로부터 이미지를 생성하는 전문 공간 예시가 있습니다. 이 데모인 PixArt-Sigma는 4K 해상도에서 이미지를 생성할 수 있는 PixArt-Sigma 1024px 확산 변환 모델을 활용합니다.\n\n## 오픈 LLM 리더보드란?\n\n![image](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_6.png)\n\nHugging Face의 또 다른 중요한 기여는 오픈 LLM 리더보드입니다. 이는 오픈 소스 LLMs와 챗봇을 추적하고 평가할 수 있는 머신 러닝 데모 또는 Hugging Face 공간입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모델 페이지와 마찬가지로 사용 가능한 모델이 너무 많습니다. 과업을 해결하기 위해 필요한 모델 유형을 식별한 후 이를 기반으로 결과를 필터링하는 것이 좋습니다.\n\n![이미지](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_7.png)\n\n예를 들어, 처음부터 훈련된 모델만 추적하길 원한다고 가정해 봅시다. 이 경우 \"사전 훈련된 모델\"을 선택하여 필터링해야 합니다.\n\n필터를 수정하면 리더보드 상단의 모델 대부분이 Meta 및 Databricks와 같은 대규모 기술 회사에서 나온 것을 알 수 있을 것입니다. 이것은 모든 회사가 이러한 대규모 모델을 훈련시키기에 컴퓨팅 능력을 갖추지 못한 이유입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Hugging Face에 접속하는 방법\n\n![hugging-face-image](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_8.png)\n\n노트북에서 Hugging Face의 모델과 데이터셋에 액세스하려면 먼저 Hugging Face API 키가 필요합니다. 계정이 아직 없다면 만들어야 합니다. 계정이 생성되면 Settings`Access Tokens`을 클릭하고 \"New token\" 버튼을 누릅니다.\n\n![hugging-face-image](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_9.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n토큰의 이름인 HF_TOKEN과 해당 토큰의 유형을 결정하세요. 이 유형은 read 또는 write 중 하나로 선택할 수 있습니다. 모델을 다운로드하거나 모델에서 추론을 실행하는 경우 read를 선택하면 가장 일반적인 선택지입니다. 모델을 훈련시키려면 write를 선택하는 것이 좋습니다.\n\n![이미지](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_10.png)\n\n그걸로 끝입니다! 우리는 Hugging Face에서 첫 번째 액세스 토큰을 생성했습니다. 액세스 토큰에 대해 더 깊이 알아보고 싶다면, Hugging Face 문서를 살펴보세요.\n\n## Hugging Face와 놀기 시작\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*2AywAoMAEN5v8VG8wIFU7Q.gif\" />\n\nHugging Face의 개념이 명확해지면, 이제는 자습서의 실제 부분으로 넘어가는 시간입니다. 영어에서 이탈리아어로 텍스트를 번역하는 모델을 찾고 싶다고 가정해 봅시다. 다음은 다음과 같은 단계입니다:\n\n- 모델 페이지로 이동\n- 번역을 작업으로 선택\n- 이탈리아어를 언어로 선택\n\n우리는 트렌딩 순으로 정렬된 첫 번째 결과 중에서 나타나는 모델 NLLB-200을 선택하기로 결정했습니다. 모델의 웹 페이지에는 프로젝트 목적에 따라 유용할 수 있는 다양한 버튼도 포함되어 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![이미지](/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_11.png)\n\n이 경우에는 모델을 로드하는 코드 라인을 얻기 위해 \"Transformers에서 사용\" 버튼을 클릭하면 됩니다.\n\n## Transformers 라이브러리 활용\n\n실험을 진행할 경우, Google Colab을 사용하는 것을 추천드립니다. Google Colab은 코드를 웹 브라우저에서 실행하며 CPU 또는 GPU 리소스에 액세스할 수 있는 클라우드 기반 플랫폼입니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n또한, 이 환경은 이전에 얻은 허깅페이스의 액세스 키와 같은 환경 변수를 간단히 가져오는 것을 가능하게 합니다.\n\n구글 코랩을 열고, Secrets로 이동하여 “새로운 비밀”을 클릭하고 허깅페이스 액세스 토큰의 이름과 값을 복사하면 됩니다. 또한, 노트북 액세스를 토글하는 것을 잊지 마세요!\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*Td3lFpVFua1VnP8vsogu3g.gif)\n\n설치해야 할 라이브러리가 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n```js\npip install transformers\n```\n\n이 Python 라이브러리를 시작하려면 파이프라인()을 사용하여 추론, 모델 로드, 및 학습을 하는 것이 좋습니다. 이 경우에는 모델 NLLB-200을 로드하려고 합니다.\n\n간단히 \"Transformers에서 사용하기\" 버튼에서 찾은 코드를 복사하면 됩니다. 아래는 약간의 수정이 필요한 코드입니다:\n\n```js\nfrom transformers import pipeline\nimport torch\n\ntranslator = pipeline(task=\"translation\",\n                      model=\"facebook/nllb-200-distilled-600M\",\n                      torch_dtype=torch.bfloat16 \n                      )\n``` \n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\npipeline()은 번역 작업용 모델 NLLB-200을 다운로드하고 캐시합니다. 이러한 매개변수들 외에도, 모델을 압축하는 데 성능이 감소하지 않는 torch의 유형을 지정합니다.\n\n이제 이를 사용하여 텍스트를 번역할 수 있습니다:\n\n```js\ntext = \"\"\"\nChatGPT 개발자 OpenAI는 단 한 번의 짧은 오디오 샘플만 있으면 인간의 목소리를 재현할 수 있는 새로운 도구를 소개했다.\\\n이 도구는 고도의 정확도로 음성을 복제하려는 기술 회사들이 개발한 여러 도구 중 하나이다.\\\n시스템의 이름은 Voice Engine입니다. OpenAI는 3월 29일 Voice Engine에 관한 세부 정보를 공개했다.\\\n\"\"\"\n\ntext_translated = translator(text,\n                             src_lang=\"eng_Latn\",\n                             tgt_lang=\"ita_Latn\")\n\nprint(text_translated[0]['translation_text'])\r\n```\n\n이것이 출력 내용입니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nOpenAI의 ChatGPT 개발자가 새로운 도구를 소개했어요! \n그 도구는 짧은 음성 샘플을 사용하여 인간의 목소리를 재현할 수 있다고 해요. \n이 도구는 음성을 높은 정확도로 복제하기 위해 기술 기업들이 개발한 여러 도구 중 하나에요. \n이 시스템의 이름은 Voice Engine이에요. OpenAI는 3월 29일 Voice Engine에 대한 세부 정보를 공개했어요.\n```\n\n좋아요! 우리가 과제를 해결했네요. 쉬웠죠?\n\n## 최종 생각\n\n이것은 Hugging Face를 시작하는 데 도움이 되는 입문 가이드였어요. Transformers는 상위 모델, 특히 NLP 모델에 쉽게 액세스할 수 있게 해주는 파이썬 라이브러리에요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 플랫폼과 파이썬 라이브러리에 대해 더 깊이 파고들고 싶다면, 아래에서 제안하는 리소스를 살펴보세요.\n\n이 글이 유용하게 느껴졌으면 좋겠어요. 즐거운 하루 보내세요!\n\n유용한 리소스:\n\n- Hugging Face 문서\n- Hugging Face 무료 강좌\n- Hugging Face와 함께하는 오픈소스 모델 강좌","ogImage":{"url":"/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png"},"coverImage":"/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png","tag":["Tech"],"readingTime":11},{"title":"2024년 최신 LangChain, Python, Heroku 사용 방법 실제 사용 사례와 팁","description":"","date":"2024-07-09 20:59","slug":"2024-07-09-LangChainPythonandHeroku","content":"\n\n<img src=\"/assets/img/2024-07-09-LangChainPythonandHeroku_0.png\" />\n\n## 커피숍에서 코딩하기\n\n2022년 말 이후 ChatGPT의 출시 및 널리 사용되면서 대형 언어 모델(LLM) 및 생성적 AI(GenAI)에서 비롯된 도구, 제품 및 혁신에 대한 뉴스 폭풍이 몰려왔습니다. 많은 기술 유행이 몇 년 내에 사라지는 반면, LLM 및 GenAI가 여기에 남아있음이 분명합니다.\n\n이러한 새로운 도구와 제품의 배경에 이어지는 다양한 도구들과 제품들에 대해 궁금한 적이 있나요? 또한 개발자와 최종 사용자 모두가 활용하는 이러한 도구들이 어떻게 운영되는지 궁금해할 수도 있습니다. 이러한 도구와 응용 프로그램 중 많은 경우, LangChain, Python 및 Heroku를 알 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 문서에서는 다룰 조각들입니다. 인공 지능/기계 학습 개발자들이 이들을 사용하여 복잡한 LLM 파이프라인 구성 요소를 구축하고 쉽게 배포하는 실제 예시를 살펴보겠습니다.\n\n# LLM 워크플로우와 파이프라인 해독하기\n\n기계 학습 파이프라인과 워크플로우는 AI 세계에 입문한 이들에게는 불투명해 보일 수 있습니다. 특히 LLM과 그와 관련된 도구에서는 더 그렇습니다. 왜냐하면 이들은 (비교적으로) 새로운 기술들이기 때문입니다. LLM을 처리하는 것은 도전적일 수 있습니다. 특히 엔지니어링이 강화되고 제품용으로 준비된 파이프라인, 워크플로 및 배포를 만들려고 할 때입니다. 새로운 도구들, 빠르게 변화하는 문서 및 제한된 지침들로 인해 어디서부터 시작하거나 무엇을 사용해야 할지를 알기 어려울 수 있습니다. 그래서 LangChain과 Heroku의 기본부터 시작해 봅시다.\n\nLangChain의 문서에는 다음과 같이 나와 있습니다: \"LangChain은 언어 모델을 기반으로 한 애플리케이션을 개발할 수 있는 프레임워크입니다.\"\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n한편, Heroku는 다음과 같이 자신을 설명합니다: \"Heroku는 회사가 앱을 구축, 전달, 모니터링 및 확장할 수 있는 클라우드 플랫폼입니다. 아이디어에서 URL로 이동하는 가장 빠른 방법입니다. 모든 인프라 문제를 우회합니다.\"\n\n이를 LLM 애플리케이션 구축의 맥락으로 놓으면, LangChain과 Heroku는 최고의 조합입니다. 우리는 LLM 애플리케이션을 구축하기 위해 테스트된 쉬운 프레임워크(LangChain)가 필요하고, 그 애플리케이션을 배포하고 호스팅할 방법(Heroku)이 필요합니다.\n\n이제 각 기술에 대해 자세히 살펴보겠습니다.\n\n## LangChain 탐구하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLangChain을 사용하는 방법에 대해 간단히 이야기해 봅시다. LangChain은 LLM 모델과 사용 사례를 기반으로 한 애플리케이션을 개발하는 개발자들을 지원하는 프레임워크입니다. Python, JavaScript, TypeScript를 지원합니다. 예를 들어, 사용자 입력에 기반을 둔 보고서를 생성하거나 고객 지원 응답을 자동화하는 도구를 개발 중이라고 가정해 봅시다. LangChain은 프로젝트의 골조로 작용하여 언어 모델을 효율적으로 솔루션에 통합할 수 있는 도구와 구조를 제공합니다.\n\nLangChain 내에는 몇 가지 주요 구성 요소가 있습니다:\n\n- 에이전트: 에이전트는 우리의 요구 사항에 따라 작업을 수행하기 위해 언어 모델과 상호 작용하는 구성 요소입니다. 이것은 우리 애플리케이션의 두뇌로, 언어 모델의 기능을 활용하여 텍스트를 이해하고 생성합니다.\n- 체인: 에이전트가 작업을 수행하는 데 따르는 동작이나 프로세스의 시퀀스입니다. 예를 들어, 고객 지원을 자동화한다면 체인은 고객 질문 수락, 관련 정보 찾기, 그리고 응답 작성 등의 단계를 포함할 수 있습니다.\n- 템플릿: 템플릿은 언어 모델의 출력을 구조화하는 방법을 제공합니다. 예를 들어, 애플리케이션이 보고서를 생성하는 경우, 모델의 출력을 기반으로 이러한 보고서를 일관되게 포맷하는 데 도움이 되는 템플릿을 활용할 것입니다.\n- LangServe: 개발자가 LangChain 애플리케이션을 REST API로 배포하고 제공할 수 있도록 합니다.\n- LangSmith: 이 도구는 언어 모델 애플리케이션의 상호 작용을 평가, 테스트 및 정제하여 제품을 상용화할 준비를 얻도록 도와줍니다.\n\nLangChain은 인기 있는 AI 및 LLM 애플리케이션을 구축하기 위한 프레임워크이며, 그 이유를 쉽게 이해할 수 있습니다. LangChain은 제품을 끝까지 구축하고 배포하는 데 필요한 기능을 제공합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Heroku를 탐험해보세요\n\nHeroku는 클라우드 플랫폼 서비스(PaaS)로서 애플리케이션을 클라우드에 간단하게 배포할 수 있게 해주어 가장 잘 알려져 있습니다. 개발자들은 주로 코드와 구현에만 집중하고 싶어합니다. 이미 복잡한 데이터 파이프라인과 LLM 기반 애플리케이션을 다루고 있을 때는 서버, 네트워크, 지속적인 저장소와 같은 인프라 문제를 다루는데 필요한 자원이나 전문지식이 부족할 수 있습니다.\n\nHeroku를 통해 애플리케이션을 쉽게 배포할 수 있기 때문에 프로젝트를 제품화하는 주요 장벽이 손쉽게 처리됩니다.\n\n# LangChain으로 빌드하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLangChain이 LLM 애플리케이션에서 어떻게 사용되는지 더 잘 이해하기 위해 몇 가지 예제 문제를 통해 과정을 명확하게 알아보겠습니다. 일반적으로, LLM 체인을 구성하기 위해 다음 항목을 연결하여 단일 워크플로우를 형성합니다:\n\n- 사용자의 매개 변수를 기반으로 프롬프트를 생성하는 프롬프트 템플릿으로 시작합니다.\n- 언어 모델이 원래 훈련되지 않은 데이터를 검색하는 리트리버를 체인에 추가합니다(예: 문서 데이터베이스에서).\n- 더 나은 응답을 형성하기 위해 언어 모델에 맥락을 제공하기 위해 채팅 기록을 포함하는 회화 검색 체이닝을 추가합니다.\n- 실제 LLM과 상호 작용하는 에이전트를 추가합니다.\n\nLangChain을 사용하면 LLM 애플리케이션의 기본을 형성하는 프로세스를 연결할 수 있습니다. 이는 우리의 구현을 쉽고 친근하게 만듭니다. 간단한 예제를 통해 함께 살펴보겠습니다.\n\n이 예시에서는 OpenAI와 함께 작업하겠습니다. 프롬프트를 이렇게 작성해 보겠습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n안녕하세요! LangChain을 사용하고 계시다니 멋지네요! 여기 저희 훌륭한 가상 트레이너, OpenAI에게 문의하시면 됩니다. 사용자의 질문을 입력해 주세요. 요청하신 내용에 따라 OpenAI가 도움을 들어드리겠습니다. 함께 성공적인 코딩 여정을 시작해봐요!\n\nMarkdown 형식을 사용해 표를 만들어보세요:\n\n\n| 컬럼1 | 컬럼2 |\n|-------|-------|\n| 데이터1 | 데이터2 |\n\n\n그럼 좋은 하루 보내세요!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nmain.py라는 새 파일을 만들겠습니다. 우리의 기본 Python 코드는 다음과 같습니다:\n\n```python\nimport os\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\nmy_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a friendly and encouraging fitness trainer.\"),\n    (\"user\", \"{input}\")\n])\n\nllm = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"])\n\nchain = my_prompt | llm\n```\n\n여기서 그만입니다! 이 기본 예제에서는 LangChain을 사용하여 프롬프트 템플릿과 OpenAI 에이전트를 연결했습니다.\n\n이를 명령줄에서 사용하려면 다음 코드를 추가해야합니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\r\nuser_input = input(\"피트니스 목표와 관련된 질문을 하세요.\\n\")\r\nresponse = chain.invoke({\r\n  \"input\": user_input\r\n})\r\n\r\nprint(response)\r\n```\r\n\r\n위에서 코드블록을 보면 우리 애플리케이션을 명령줄에서 테스트할 수 있습니다.\r\n\r\n```js\r\n(venv) $ OPENAI_API_KEY=insert-key-here python3 main.py \r\n피트니스 목표와 관련된 질문을 하세요.\r\n60초 동안 플랭크를 유지하는 방법은 무엇인가요?\r\ncontent=\"60초 동안 플랭크를 유지하는 것은 좋은 목표입니다! 60초 동안 플랭크를 유지하기 위해선 올바른 자세로 시작하고 천천히 플랭크를 유지하는 시간을 늘려나가는 것이 중요합니다. 진행하는 데 도움이 될 몇 가지 팁을 드리겠습니다:\\n\\n1. 짧은 시간으로 시작하기: 자세를 잘 유지한 채로 플랭크를 유지할 수 있는 시간부터 시작해보세요. 몇 초만이라도 괜찮으니 강해지면서 시간을 늘려가세요.\\n\\n2. 올바른 자세에 집중하기: 머리부터 발끝까지 직선으로 몸을 유지하고 복부 근육을 사용하며 어깨를 팔꿈치 바로 위에 유지하세요.\\n\\n3. 꾸준히 연습하기: 매주 몇 번씩 플랭크를 운동 루틴에 포함시키도록 노력해보세요. 꾸준함이 힘과 인내를 키우는 데 중요합니다.\\n\\n4. 다양한 플랭크 도전하기: 사이드 플랭크나 다리를 들거나하는 등 다양한 플랭크 변형을 시도하여 다른 근육 꾸러미에 작용하고 운동을 도전스럽게 유지하세요.\\n\\n5. 몸의 신호를 듣기: 자신을 밀어내는 것도 중요하지만 자신의 한계를 알아야 합니다. 통증이나 불편함을 느낀다면 멈추고 휴식을 취하세요.\\n\\n기억하세요, 발전에는 시간과 인내가 필요합니다. 새로운 플랭크 기법을 마스터하거나 몇 초 더 플랭크를 유지한다든지하는 모든 단계를 축하하세요. 당신은 할 수 있어요!\"\r\n```\r\n\r\n(가독성을 위해 위에서 줄 바꿈을 추가했습니다.)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그것은 훌륭한 시작이에요. 하지만 출력물을 조금 더 사람이 읽기 쉬운 형식으로 포맷팅하는 것이 좋겣죠. 이를 위해 단순히 체인에 출력 파서를 추가하면 됩니다. StrOutputParser를 사용할 거에요.\n\n```js\nimport os\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser\n\nmy_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"당신은 친절하고 격려하는 피트니스 트레이너입니다.\"),\n    (\"user\", \"{input}\")\n])\n\nllm = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\noutput_parser = StrOutputParser()\n\nchain = my_prompt | llm | output_parser\n\nuser_input = input(\"당신의 피트니스 목표에 관한 질문을 해주세요.\\n\")\nresponse = chain.invoke({\n  \"input\": user_input\n})\n\nprint(response)\n```\n\n이제 명령행에서 우리의 애플리케이션이 이렇게 보일 거에요:\n\n```js\n(venv) $ OPENAI_API_KEY=insert-key-here python3 main.py \n당신의 피트니스 목표에 관한 질문을 해주세요.\n피스톨 스쿼트를 어떻게 배우나요?\n그것은 훌륭한 목표에요! 피스톨 스쿼트는 도전적일 수 있지만, 연습과 인내로 꼭 배울 수 있어요.\n\n피스톨 스쿼트를 연습하기 위해 다음 단계를 따라가보세요:\n\n1. 스쿼트, 런지, 스텝업과 같은 운동으로 하체 근력을 키워보세요.\n2. 단일다리 균형 운동을 통해 균형과 안정성을 향상시켜보세요.\n3. 벤치나 의자 위로 몸을 내려친다는 부분적인 피스톨 스쿼트를 연습한 후 점차 전체적인 피스톨 스쿼트를 수행할 수 있게 되세요.\n4. TRX 밴드나 막대기와 같은 지원 도구를 사용하여 균형 유지와 몸을 내려치는 데 도움을 받아, 충분한 근력을 쌓아 무도도 수행할 수 있도록 하세요.\n\n피스톨 스쿼트를 시도하기 전에 반드시 웜업을 실시하고 부상을 피하기 위해 몸의 신호를 들어주는 것을 잊지 마세요. 그리고 가장 중요한 것은, 이 도전적인 운동을 마스터하는 데 노력하는 동안 긍정적이고 인내심을 가지세요. 당신은 할 수 있어요!\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLLM 응담은 가독성을 향상시키기 위해 형식화되었습니다.\n\n강력한 LLM 애플리케이션을 구축하기 위해, 우리의 체인은 이보다 훨씬 더 복잡할 것입니다. 그렇지만 그것이 LangChain의 강점이자 간결함입니다. 프레임워크는 당신의 필요에 맞는 로직을 모듈화할 수 있도록 해줘서 복잡한 워크플로우를 쉽게 연결할 수 있습니다.\n\n간단한 LLM 애플리케이션을 만들었으니, 여전히 우리 애플리케이션을 배포하고 호스팅하며 서비스하기 위한 능력이 필요합니다. 인프라보다 앱 빌드에 초점을 맞춘 개발자로써, LangServe와 Heroku에 의존합니다.\n\n# LangServe로 서비스 하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLangServe는 LangChain 체인과 상호 작용할 수 있도록 REST API를 통해 도와줍니다. LangChain LLM 애플리케이션의 서빙 부분을 작성하기 위해 세 가지 주요 구성 요소가 필요합니다:\n\n- 유효한 체인 (우리가 위에서 구축한 것과 같이)\n- API 애플리케이션 프레임워크 (예: FastAPI)\n- 라우트 정의 (REST API를 구축할 때와 같이)\n\nLangServe 문서에는 시작하는 방법에 대한 유용한 예제가 제공됩니다. 우리 예제에서는 FastAPI를 사용하여 API 서버를 시작하고 LangServe의 add_routes()를 호출하여 체인을 API 엔드포인트를 통해 접근 가능하게 만들면 됩니다.\n\n이와 함께 기존 코드를 약간 수정해야합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 우리는 StrOutputParser의 사용을 제거할 것입니다. 이렇게 하면 API를 호출하는 사용자들이 출력을 어떻게 형식화하고 사용할지에 대해 유연성을 가질 수 있습니다.\n- 명령 줄에서 사용자 입력을 요청하지 않을 것입니다. API 호출 요청이 사용자의 입력을 제공할 것입니다.\n- chain.invoke()를 호출하지 않을 것입니다. LangServe가 API 요청 처리의 일부로 이를 처리할 것입니다.\n\n우리는 프로젝트에 FastAPI와 LangServe 패키지를 추가했음을 확인합니다:\n\n```js\n(venv) $ pip install langserve fastapi\n```\n\n우리의 최종 main.py 파일은 다음과 같습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nimport os\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom fastapi import FastAPI\nfrom langserve import add_routes\n\nmy_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a friendly and encouraging fitness trainer.\"),\n    (\"user\", \"{input}\")\n])\n\nllm = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n\nchain = my_prompt | llm\n\napp = FastAPI(title=\"Fitness Trainer\")\n\nadd_routes(app, chain)\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"localhost\", port=8000)\n```\n\n내 로컬 머신인 우분투 20.04.6 LTS에서는 Python 3.8.10을 실행 중이었는데, 몇 가지 경고 메시지를 제거하기 위해 추가 패키지를 설치해야 했습니다. 당신의 머신에서는 이 작업이 필요하지 않을 수도 있어요.\n\n```shell\n(venv) $ pip install sse_starlette pydantic==1.10.13\n```\n\n이제 서버를 시작해 볼까요?\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n(venv) $ OPENAI_API_KEY=insert-key-here python3 main.py \n\nINFO:     서버 프로세스 시작 [629848]\nINFO:     애플리케이션 시작을 기다리는 중.\n\nLANGSERVE: \"/\" 경로의 Playground이 활성화되었습니다:\nLANGSERVE:  │\nLANGSERVE:  └──> /playground/\nLANGSERVE:\nLANGSERVE: 사용 가능한 모든 경로는 /docs/에서 확인할 수 있습니다.\n\nINFO:     애플리케이션 시작 완료.\nINFO:     Uvicorn이 http://localhost:8000에서 실행 중 (종료하려면 CTRL+C를 누르세요)\n\n\n와아... 멋져요!\n\n브라우저에서 http://localhost:8000/docs 로 이동할 수 있어요. 여기에서 확인할 수 있는 내용은:\n\n<img src=\"/assets/img/2024-07-09-LangChainPythonandHeroku_1.png\" /> \n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLangServe는 Swagger UI를 사용하는 API 문서 페이지를 제공합니다! 이제 LangServe를 통해 사용 가능한 엔드포인트들이 있습니다. 우리는 invoke/ 엔드포인트로 POST 요청을 보낼 수 있습니다. 하지만 LangServe는 우리에게 chain을 직접 다룰 수 있는 웹 인터페이스가 있는 playground/ 엔드포인트도 제공합니다.\n\n![이미지](/assets/img/2024-07-09-LangChainPythonandHeroku_2.png)\n\n우리는 입력을 제공하고 시작을 클릭합니다. 결과는 다음과 같습니다:\n\n![이미지](/assets/img/2024-07-09-LangChainPythonandHeroku_3.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLLM 애플리케이션 워크플로의 맥락에서 API의 중요성을 강조하는 것이 중요합니다. LLM 및 해당 애플리케이션의 대부분 사용 사례를 생각해보면, 로컬 모델 및 자원에 의존할 수 없습니다. 이것은 합리적이지 않고 확장성이 떨어집니다.\n\nLLM 애플리케이션의 실제 파워는 이전까지 설명한 복잡한 워크플로를 추상화하는 능력에 있습니다. 우리는 수행한 모든 것을 API 뒤에 숨겨 사용 사례가 확장되고 다른 사람들이 통합할 수 있도록 하려고 합니다. 이는 API를 호스팅하고 제공할 수 있는 쉬운 옵션이 있다면에만 가능합니다. 그리고 바로 그것이 Heroku에서 할 수 있습니다.\n\n# Heroku에 배포\n\nHeroku는 LLM 애플리케이션 구현의 중요한 마지막 부분입니다. 우리는 LangChain을 사용하여 워크플로를 조합하고 LangServe를 사용하여 유용한 REST API로 제공합니다. 이제 복잡한 자원을 수동으로 설정하여 트래픽을 호스팅하고 제공하는 대신, Heroku를 사용하여 애플리케이션을 간단히 배포할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n헤로쿠 계정을 설정한 후에, 이제 거의 배포할 준비가 끝났어요. 함께 순서대로 진행해볼게요.\n\n## 새로운 헤로쿠 앱 생성하기\n\n헤로쿠 CLI를 사용해서 로그인하고 새로운 앱을 생성해요.\n\n```js\n$ heroku login\n$ heroku create my-langchain-app\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 설정 변수 설정하기\n\n이제 Heroku 앱 환경에서 OPENAI_API_KEY 환경 변수를 설정해야 합니다.\n\n```js\n$ heroku config:set OPENAI_API_KEY=여러분의-openai-api-key로-대체하세요\n```\n\n## Python 애플리케이션 배포를 위한 설정 파일 만들기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n헤로쿠가 우리의 파이썬 애플리케이션을 실행하기 위해 필요한 것을 알 수 있도록 하려면 세 가지 간단한 파일을 만들어야 합니다:\n\n- Procfile: 헤로쿠가 앱을 시작하는 데 사용해야 하는 명령을 선언합니다.\n- requirements.txt: 헤로쿠가 설치해야 하는 Python 패키지 종속성을 지정합니다.\n- runtime.txt: 앱에 사용하려는 정확한 Python 런타임 버전을 지정합니다.\n\n이 파일들은 빠르고 쉽게 만들 수 있습니다. 각각은 프로젝트의 루트 폴더에 들어갑니다. Procfile을 만들려면 다음 명령을 실행하면 됩니다:\n\n```bash\n$ echo 'web: uvicorn main:app --host=0.0.0.0 --port=${PORT}' > Procfile\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이것은 Heroku에게 Python에서 웹 서버 구현인 uvicorn을 실행하도록 지시합니다.\n\nrequirements.txt에 대해, pip freeze 명령을 사용하여 설치된 패키지 목록을 출력할 수 있습니다.\n\n```js\n$ pip freeze > requirements.txt\n```\n\n마지막으로, runtime.txt에는 Python 3.11.8을 사용할 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n$ echo 'python-3.11.8' > runtime.txt\n```\n\n이 파일들이 준비된 상태에서 프로젝트 루트 폴더는 다음과 같이 보일 것입니다:\n\n```js\n$ tree\n.\n├── main.py\n├── Procfile\n├── requirements.txt\n└── runtime.txt\n\n0 directories, 4 files\n```\n\n이 파일들을 모두 GitHub 저장소에 커밋합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Heroku와 GitHub 저장소 연결하기\n\n마지막으로 할 일은 GitHub 저장소에 대한 Heroku 원격을 생성한 다음 코드를 해당 원격으로 푸시하는 것입니다. Heroku는 새 코드를 푸시하면 해당 코드를 응용 프로그램에 배포합니다.\n\n```js\n$ heroku git:remote -a my-langchain-app\n$ git push heroku main\n```\n\n우리의 코드가 Heroku 원격으로 푸시되면, Heroku는 애플리케이션을 빌드하고 종속성을 설치한 다음 Procfile에서 지정된 명령을 실행합니다. git push 명령어의 최종 결과는 다음과 같습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\r\n…\n\nremote: -----> 프로세스 유형 검색 중\nremote:        Procfile이 다음 유형을 선언함 -> web\nremote: \nremote: -----> 압축 중...\nremote:        완료: 71.8M\nremote: -----> 배포 중...\nremote:        v4 버전이 릴리스됨\nremote:        https://my-langchain-app-ea95419b2750.herokuapp.com/ 에 배포됨\nremote: \nremote: 배포 확인... 완료.\r\n```\n\n우리의 Heroku 앱 URL이 표시됩니다. 브라우저에서 https://my-langchain-app-ea95419b2750.herokuapp.com/playground을 방문해주세요.\n\n![이미지](/assets/img/2024-07-09-LangChainPythonandHeroku_4.png)\n\n또한 Swagger UI 문서 페이지를 확인하려면 https://my-langchain-app-ea95419b2750.herokuapp.com/docs를 방문해주세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-07-09-LangChainPythonandHeroku_5.png)\n\n그리고 그렇게해서 우리는 시작했어요!\n\n이 프로세스는 LangChain과 함께 작업할 때 개발 시간과 오버헤드를 줄이는 최상의 방법입니다. LangChain으로 작성된 API를 쉽게 몇 가지 간단한 명령어로 Heroku에 배포할 수 있는 기능은 LangChain과 Heroku를 결합하는 것을 당연하게 만듭니다.\n\n# 결론\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오늘의 기업과 개발자들은 AI와 LLM(언어 모델)의 파도를 타기에 올바른 선택을 했습니다. 이들 영역에서 혁신과 새로운 개발 가능성이 많습니다. 그러나 성공과 실패의 차이는 그들이 애플리케이션을 구축하고 배포하는 데 사용하는 도구 체인에 많이 달렸습니다.\n\nLangChain 프레임워크를 사용하면 LLM 기반 애플리케이션을 만드는 프로세스가 접근 가능하고 반복 가능해집니다. 그러나 구현은 전투의 반이에 불과합니다. 애플리케이션이 만들어지면, 이러한 애플리케이션 API를 클라우드에 쉽고 빠르게 배포할 수 있는 능력이 필요합니다. 그 곳에서 더 빠른 반복과 개발의 장점을 가질 수 있고, Heroku를 통해 그 길에 도달할 수 있습니다.","ogImage":{"url":"/assets/img/2024-07-09-LangChainPythonandHeroku_0.png"},"coverImage":"/assets/img/2024-07-09-LangChainPythonandHeroku_0.png","tag":["Tech"],"readingTime":20},{"title":"파이썬으로 코딩 시작하기 5 딕셔너리 part II  반복문 사용법","description":"","date":"2024-07-09 20:57","slug":"2024-07-09-StartCodingwithPython5DictionariespartIIlooping","content":"\n\n딕셔너리를 순회하는 방법을 배울 거에요. 딕셔너리는 여러 가지 방법으로 정보를 저장할 수 있기 때문에 이를 순회하는 다양한 방법이 있어요. 주어진 딕셔너리의 키, 값 또는 모든 키-값 쌍을 순회할 수 있어요.\n\n## 키-값 쌍을 순회하기\n\n세 개의 키-값 쌍을 포함하는 scientist_0 딕셔너리를 고려해봐요:\n\n```js\n# 파일 이름: scientist.py\n\nscientist_0 = {\n    'username': 'rfeynman',\n    'first name': 'richard',\n    'last name': 'feynman',\n    }\n\nfor key, value in scientist_0.items():\n    print(f\"\\n키: {key}\")\n    print(f\"값: {value}\")\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n루프에 대한 예시를 보면, 코드를 실행하면 다음과 같이 결과가 나옵니다\n\n```js\n$ python3 scientist.py\n\nKey: username\nValue: rfeynman\n\nKey: first name\nValue: richard\n\nKey: last name\nValue: feynman\n```\n\n이후에 자세히 설명하겠습니다.\n\n키와 값에 대해 간단히 k와 v를 사용할 수 있습니다. 따라서 아래와 같이 코드를 작성하면 (특히 루프 부분을 참조하십시오), Python이 이전 코드와 정확히 동일하게 이해합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 파일 이름: scientist.py\n\nscientist_0 = {\n    'username': 'rfeynman',\n    'first name': 'richard',\n    'last name': 'feynman',\n    }\n\nfor k, v in scientist_0.items():\n    print(f\"\\nKey: {k}\")\n    print(f\"Value: {v}\")\n```\n\n위의 for 문에서 scientist_0 사전의 이름 뒤에 items() 메서드가 따라옵니다. 이 메서드는 키-값 쌍을 반환합니다. 그런 다음 각 키-값 쌍이 여기에서 Key와 Value로 정의된 두 변수에 할당됩니다.\n\n## 키값만 루핑\n\nitems() 메서드 대신 keys() 메서드를 사용하면 사전의 키만을 순회할 수 있습니다.\n\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# file name: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': '바이올린',\n    'feynman': '봉고',\n    'dirac': '사색',\n    }\n\nfor name in scientist_hobby.keys():\n    print(name.title())\n```\n\n위 코드에서는 scientist_hobby라는 사전이 정의되어 있습니다. 이 사전은 이름이 과학자의 이름이고 값이 과학자의 취미인 세 개의 키-값 쌍으로 이루어져 있습니다. 만약 여기서 값이 아닌 과학자들의 이름인 키만 필요하다면, keys() 메서드를 사용하면 됩니다.\n\n```js\n$ python3 scientist_hobby.py\nEinstein\nFeynman\nDirac\n```\n\n위 코드를 실행하면 사전의 키만을 반환합니다. 여기서 간단히 언급하고 싶은데, 이러한 상황(값이 아닌 키만 반환하는 것)은 keys() 메서드를 특별히 지정하지 않을 때의 기본 동작입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# 파일명: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': '바이올린',\n    'feynman': '봉고',\n    'dirac': '사색',\n    }\n\nfor anything in scientist_hobby:\n    print(anything.title())\n```\n\n위 코드에서 .keys()를 제외하였지만, 이 코드를 실행하면 과학자들의 이름만 반환하여 결과는 똑같이 나올 것입니다.\n\n알파벳 순서로 키를 순회하고 싶다면 sorted() 메서드를 사용할 수 있습니다:\n\n```python\n# 파일명: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': '바이올린',\n    'feynman': '봉고',\n    'dirac': '사색',\n    }\n\nfor name in sorted(scientist_hobby.keys()):\n    print(name.title())\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위의 코드를 실행하면 다음과 같이 됩니다\n\n```js\n$ python3 scientist_hobby.py\nDirac\nEinstein\nFeynman\n```\n\n## 값만 반복\n\n상담하신 것처럼, 우리는 키가 없는 값의 순서를 반환하기 위해 위에서 논의한 keys() 메소드와 대조해서 values() 메소드를 사용할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 파일 이름: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': 'violin',\n    'feynman': 'bongo',\n    'dirac': 'pondering',\n    'heisenberg': 'violin',\n    }\n\nprint(\"이러한 취미가 언급되었습니다:\")\nfor hobby in scientist_hobby.values():\n    print(hobby.title())\n```\n\n위의 코드를 실행하면 다음이 반환됩니다:\n\n```js\n$ python3 scientist_hobby.py\n이러한 취미가 언급되었습니다:\nViolin\nBongo\nPondering\nViolin\n```\n\n여기서 바이올린은 두 명이 동일한 취미를 가지고 있기 때문에 반복됩니다. 이러한 종류의 반복을 방지하고 싶은 경우 아래에 표시된 대로 set() 메소드를 사용할 수 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# file name: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': 'violin',\n    'feynman': 'bongo',\n    'dirac': 'pondering',\n    'heisenberg': 'violin',\n    }\n\nprint(\"These hobbies have been mentioned:\")\nfor hobby in set(scientist_hobby.values()):\n    print(hobby.title())\n```\n\n```python\n$ python3 scientist_hobby.py\nThese hobbies have been mentioned:\nViolin\nPondering\nBongo\n```\n\nNow Violin is returned only once.\n\nOne can also make a set using braces ({}). However, in contrast to a dictionary where a set of key-value pairs are given inside '{}', in a set each single element should be separated by a comma.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n>>> 취미 = {'바이올린', '봉고', '사색', '바이올린', '봉고'}\n>>> 취미\n{'사색', '바이올린', '봉고'}\n```\n\n딕셔너리와 집합 사이의 차이를 알아두면 혼란을 방지할 수 있어요.\n\n![이미지](/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_0.png)\n\n![이미지](/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_1.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![image](/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_2.png)\n","ogImage":{"url":"/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_0.png"},"coverImage":"/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_0.png","tag":["Tech"],"readingTime":7},{"title":"Ruff로 파이썬 코드를 강화하는 방법","description":"","date":"2024-07-09 20:56","slug":"2024-07-09-SuperchargeyourPythonCodewithRuff","content":"\n\n## PYTHON\n\n![Python Image](/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_0.png)\n\n아직 프로젝트에서 Black, isort, 그리고 Flake8을 사용하고 계신가요? 업그레이드할 때입니다.\n\n새로운 도구가 나왔습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 러프\n\n러프는 찰리 마시의 열정 프로젝트로 시작되었습니다.\n\n그는 더 빠른 Python 린터를 만들기로 결심했습니다.\n\n가장 큰 Python 프로젝트 중 일부가 그것을 사용하기 시작하자, Python 생태계를 더 생산적으로 만들기 위해 고성능 개발자 도구를 구축하여 소프트웨어를 더 빨리 출시할 수 있도록 하는 기회를 보았습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nRuff는 러스트로 작성된 매우 빠른 Python 린터 및 코드 포매터입니다.\n\n그 얼마나 빠른지 궁금하신가요? 이 이미지가 모두를 알려줍니다.\n\n![Supercharge your Python Code with Ruff](/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_1.png)\n\nRuff는 Flake8(그리고 수십 개의 플러그인), Black, isort, pydocstyle, pyupgrade, autoflake 등을 대체할 수 있으며, 10~100배의 속도 향상을 자랑합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nVS Code 및 다양한 다른 통합을 위한 일등 서비스 편집기 통합을 제공합니다.\n\nRuff는 Airflow, Hugging Face, Pandas와 같은 주요 오픈 소스 프로젝트에서 활발히 사용됩니다.\n\n## 사용자들이 말하는 것\n\nFastAPI 창시자 Sebastián Ramírez:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n닉 쉬록은 Elementl의 창립자이자 GraphQL의 공동 창시자입니다.\n\n# 빠른 속도의 비결\n\n럼프의 놀라운 속도는 주로 러스트 기반의 아키텍처 덕분에 가능합니다. 러스트는 성능과 안정성으로 유명하여, 럼프가 다른 도구들보다 빠른 린팅 및 포매팅 서비스를 제공할 수 있게 해줬습니다.\n\n이 효율성은 러스트의 성능 능력을 통해 이루어지며, 변경되지 않은 파일의 재분석을 방지하는 내장 캐싱 시스템과 개발 과정 전반에 걸쳐 성능 최적화에 초점을 맞춘 덕분입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n대규모 코드베이스에서도 하위 초 반응 루프를 제공하도록 설계된 Ruff는 린팅 및 형식 지정 작업을 기다리는 시간을 줄여 개발자들의 삶의 질을 크게 향상시킵니다.\n\n궁금하시다면, 웹사이트에서 Ruff가 코드를 파싱하는 방식을 탐색할 수 있는 플레이그라운드가 준비되어 있습니다.\n\n![Ruff Playground](/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_2.png)\n\n해당 페이지에는 AST, 토큰, 형식 지정 IR(중간 표현), 그리고 형식 지정 주석을 보여줍니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n하지만 더 이상 말이 필요 없어요. 직접 해보는 것이 최선이죠!\n\n# 테스트 드라이브\n\n## 설치\n\nRuff는 PyPI에서 ruff로 사용할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\npip install ruff\n```\n\n마니매 진행 및 확인하기 Manim, the animation engine 3blue1brown이 수학 비디오에서 사용하는 엔진입니다.\n\n<img src=\"/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_3.png\" />\n\n## 코드 분석\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n코드에 린터를 실행하려면, 다음과 같이 사용합니다.\n\n```js\nruff check .\n```\n\n하나의 파일에 대해 실행하려면, 다음과 같이 하세요.\n\n```js\nruff check <filename.py>\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n총 415개의 오류가 있었어요. 이 중 33개는 수정할 수 있어요!\n\n![이미지](/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_4.png)\n\n해결하기 위해선 다음과 같이 --fix 플래그를 사용해요\n\n```js\nruff check --fix .\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_5.png\" />\n\n알 수 있듯이, 33개가 수정되었고, 383개가 남아 있습니다.\n\n## 포맷팅\n\n포맷팅을 위해 ruff 형식을 사용합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nformat을 변경하십시오.\n```\n\n<img src=\"/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_6.png\" />\n\n아마도 당신은 이렇게 Ruff를 사용하지 않을 것이며, 에디터를 사용하고 있기 때문에, 이제 설정하는 방법을 살펴봅시다!\n\n# VS Code에서 사용하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nVSCode 확장 프로그램을 설치해보세요.\n\n이제 \"모든 자동 수정 가능한 문제 해결\"만으로 쉽게 해결할 수 있어요!\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/0*kF8S-U62dWreNT6M.gif)\n\n게다가 더 좋은 점은 저장할 때도 이 작업을 할 수 있다는 거예요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 저장 시 형식 지정\n\n만약 Ruff가 lint 위반을 자동으로 수정하고, import를 정리하며 저장할 때 형식을 지정하길 원한다면, 설정 파일인 settings.json으로 이동하세요.\n\n다음을 추가하세요.\n\n```js\n\"[python]\": {\n  \"editor.formatOnSave\": true,\n  \"editor.codeActionsOnSave\": {\n    \"source.fixAll\": \"explicit\",\n    \"source.organizeImports\": \"explicit\"\n  },\n  \"editor.defaultFormatter\": \"charliermarsh.ruff\"\n}\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 태그를 마크다운 형식으로 변경하실 수 있습니다.\n\nRuff가 유형 또는 저장 시 실행되기를 원하는지에 따라 다릅니다. 기본적으로 유형에 실행되지만, 저는 저장 시에 실행되기를 선호합니다.\n\n```js\n\"ruff.lint.run\": \"onSave\",\n```\n\n## 주피터 노트북\n\n이 확장 프로그램으로 노트북에서 서식 지정, 린팅, 그리고 가져오기 정리를 위한 명령어를 사용할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오른쪽 코드 조작으로 변경하세요.\n\n\n![사진](https://miro.medium.com/v2/resize:fit:1400/0*0qBmSIfB0VVP2au_.gif)\n\n\n저장 시에도 이를 사용하려면 아래 코드를 추가하세요.\n\n```js\n\"notebook.formatOnSave.enabled\": true,\n\"notebook.codeActionsOnSave\": {\n  \"source.fixAll.ruff\": true,\n  \"source.organizeImports.ruff\": true\n}\n```\n\n# pre-commit 사용하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프리 커밋을 사용하려면 Ruff의 프리 커밋 후크를 추가하는 방법입니다.\n\n```js\n- repo: https://github.com/astral-sh/ruff-pre-commit\n  # Ruff 버전.\n  rev: v0.2.2\n  hooks:\n    # 린터 실행.\n    - id: ruff\n      types_or: [ python, pyi, jupyter ]\n      args: [ --fix ]\n    # 포매터 실행.\n    - id: ruff-format\n      types_or: [ python, pyi, jupyter ]\n```\n\n# CLI로 Jupyter 노트북 사용\n\n만약 노트북을 위해 CLI를 사용 중이라면, pyproject.toml이나 ruff.toml 중 하나에 이 줄을 추가해야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nextend-include = [\"*.ipynb\"]\n```\n\n# 더 많은 통합 기능\n\n많은 다른 통합 기능들을 지원합니다. Vim도 포함돼요!\n\n<img src=\"/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_7.png\" />\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Ruff에 대해 더 알아보기\n\n여기까지입니다! Ruff에 관한 더 많은 콘텐츠를 원한다면 아래 링크를 확인해보세요 👇\n\n- Matt Layman이 Python 프로젝트를 Ruff로 전환하는 라이브 스트림 시청하기\n- Flake8 및 PyLint를 작별하고 Ruff로 더 빠른 린팅하기\n- Ruff: 빠른 Python 린터 [LWN.net]\n- Ruff로 업그레이드할 때입니다 — Eric J. Ma의 개인 사이트\n- 코드 품질을 향상시키는 가장 빠른 방법: Ruff 린터 사용하기\n\n# 읽어 주셔서 감사합니다\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nbitgrit 데이터 과학 게시물을 구독하고 최신 소식을 받아보세요!\n\n다른 데이터 과학자들과 최신 데이터 과학 및 인공지능 개발에 대해 함께 이야기하고 싶나요? 저희 디스코드 서버에 가입해보세요!\n\n워크숍 및 다가오는 대회 소식을 받아보려면 Bitgrit를 팔로우해주세요!\n\nDiscord | 웹사이트 | 트위터 | 링크드인 | 인스타그램 | 페이스북 | 유튜브","ogImage":{"url":"/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_0.png"},"coverImage":"/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_0.png","tag":["Tech"],"readingTime":10},{"title":"RNN LSTM부터 Temporal Fusion Transformers와 Lag-Llama까지 최신 시계열 예측 기술들","description":"","date":"2024-07-09 20:52","slug":"2024-07-09-FromRNNLSTMtoTemporalFusionTransformersandLag-Llama","content":"\n\n![이미지](/assets/img/2024-07-09-FromRNNLSTMtoTemporalFusionTransformersandLag-Llama_0.png)\n\n샘플 eBook 챕터(무료): [링크](https://github.com/dataman-git/modern-time-series/blob/main/20240522beauty_TOC.pdf)\n\nTeachable.com에서 eBook: $22.50\n[링크](https://drdataman.teachable.com/p/home)\n\nAmazon.com에서 프린트 버전: $65\n[링크](https://a.co/d/25FVsMx)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이전 장인 “시계열 모델링 기법의 진행 과정”에서 우리는 단순 이동 평균, 계절적 추세 분해, ARIMA, 칼만 필터, 상태 공간 모델의 연결을 조사했으며 그 후에 RNN/LSTM/GRU까지 살펴보았습니다. 이 장에서는 RNN/LSTM에서 Temporal Fusion Transformers 및 Lag-Llama를 포함한 Transformer 기반 모델로 학습을 이어나갈 것입니다.\n\n오늘날의 많은 대형 언어 모델은 시계열 RNN/LSTM의 뿌리를 갖고 있으며 논문 “Attention is all you need”의 Transformer 프레임워크와 관련이 있습니다. RNN/LSTM에서 Transformer로 연결되는 여러 중요한 이정표가 있습니다. 시퀀스-투-시퀀스 모델링, 어텐션 메커니즘, 그리고 셀프-어텐션 메커니즘(셀프-어텐션과 어텐션은 다르다는 점에 유의해야 합니다). 언급된 각 알고리즘마다 하나의 장을 할애할만한 가치가 있지만, 이 장은 한 혁신에서 다른 혁신으로의 연결을 살펴보고자 합니다. 어느 것에서 다른 것으로 진화하며 우리는 혁신에 대해 새로운 시각을 가질 것이며 앞으로의 작업에 영감받을 것입니다. 또한 대형 언어 모델(LLMs)이 시계열 RNN/LSTM 모델에서 비롯되었기 때문에 왜 우리가 특히 LLMs를 바로 시계열 모델링에 사용하지 않아도 되는지 알아볼 것입니다. Transformer 모델을 시계열 모델링에 적용하기 위해 무엇을 해야 하는지 설명하겠습니다. 이 장에서는 다음을 다룰 것입니다:\n\n- RNN/LSTM에서 시퀀스-투-시퀀스(Seq2Seq) 학습으로\n- 어텐션 메커니즘\n- 셀프-어텐션 메커니즘\n- Transformer 모델\n- Transformer에서 Temporal Fusion Transformer로\n- 시계열을 위한 대규모 기본 모델의 필요성\n- Lag-Llama - 오픈소스 시계열 기본 모델\n\nRNN/LSTM에서 시퀀스-투-시퀀스(Seq2Seq) 모델로\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2000년대에 처음 보이스 번역 장치를 구매했어요. 번역 품질은 그저 괜찮았지만 한국과 파리로 여행하는 데 도움이 되었어요. 번역 품질이 더 좋아진다면 서로 다른 언어를 구사하는 세계 사람들이 쉽게 소통할 수 있게 도울 것입니다. 지난 20년 동안 많은 연구자들이 이와 같은 전 세계적인 응용 프로그램을 해결하기 위해 노력해 왔어요. 초기 알고리즘인 \"통계 기계 번역 (SMT)\"과 \"숨겨진 마르코프 모델 (HMMs)\"은 n-gram, 구문 기반 기능, 정렬 기능과 같은 수작업 기능을 사용하여 한 언어에서 다른 언어로 텍스트를 번역했어요. 이러한 전통적인 알고리즘은 수작업 기능이 필요하며 종종 유연하지 못하고 훈련하기 어려워요. 언어 번역에서 또 다른 과제는 원본 문장과 대상 문장 사이의 길이 차이에 있어요. 아래의 영어 문장과 프랑스어, 이탈리아어 번역을 보겠어요:\n\n- 영어 (15 단어): “After finishing work, I often make a detour to the chocolate shop for some treats.”\n- 프랑스어 (16 단어): “Après avoir fini le travail, je fais souvent un détour par la chocolaterie pour quelques friandises.”\n- 이탈리아어 (18 단어): “Dopo aver finito il lavoro, spesso faccio un giro di sosta al negozio di cioccolato per qualche dolcetto.”\n\n이러한 길이의 차이는 언어 번역이 기계적인 일대일 번역보다 의미적 이해력이 필요하다는 것을 보여줍니다.\n\nIlya Sutskever, Oriol Vinyals 및 Quoc V. Le이 2014년에 \"Neural Networks를 사용한 Sequence to Sequence Learning\" 논문을 발표했을 때 번역 솔루션이 크게 발전했어요 [1]. 그들의 신경망 프레임워크는 일반적인 유연성을 제공하며 수작업 기능이나 특별한 기능이 필요하지 않아요. 무엇보다도, Seq2Seq는 다양한 길이 문제를 효과적으로 해결할 수 있어요. Seq2Seq는 입력 시퀀스를 \"컨텍스트 벡터\"로 인코딩하는 인코더 네트워크와 이 벡터로부터 출력 시퀀스를 생성하는 디코더 네트워크로 구성되어 있어요. 이 전략은 입력 시퀀스와 대상 시퀀스를 아주 잘 분리시킵니다. (그림 1)을 참조해 보세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Figure (2)](/assets/img/2024-07-09-FromRNNLSTMtoTemporalFusionTransformersandLag-Llama_1.png)\n\n인코더 RNN과 디코더 RNN의 펼침 표현이 포함된 그림 (2)입니다. 컨텍스트 벡터는 입력 시퀀스의 의미적인 의미를 포착합니다. Seq2Seq 모델은 정보를 해석하여 다른 언어로 번역하기 위한 방법으로 생각할 수 있습니다.\n\n![RNN/LSTM](/assets/img/2024-07-09-FromRNNLSTMtoTemporalFusionTransformersandLag-Llama_2.png)\n\nRNN/LSTM은 시계열 모델링 도구이며 이제는 언어 모델링 도구로 활용되고 있습니다. 언어 데이터와 시계열 데이터 사이에 기본적인 차이가 있습니다. 언어 데이터는 단어와 문장부호이고, 시계열 데이터는 숫자 값입니다. 언어 데이터는 신경망 알고리즘에 피드하기 위해 숫자 벡터 표현으로 변환되어야 합니다. 출력 또한 단어가 되도록 디코딩되어야 합니다. 논문 [1]에서는 입력 데이터로 16만개의 자주 사용되는 단어를 사용했습니다. 단어 \"I\"는 \"I\"의 요소 위치가 1.0이고 그렇지 않으면 0.0인 16만 길이의 벡터가 됩니다. 마찬가지로, 단어 \"love\"는 다른 16만 길이의 벡터로 \"love\"의 요소 위치가 1.0이 되고 그렇지 않으면 0.0이 됩니다. 텍스트 표현에 대한 자세한 설명은 Kuo (2023)의 \"The Handbook of NLP with Gensim\" [3]에서 찾아볼 수 있습니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그림(2)에서 RNN 블록들이 하는 일은 무엇인가요? 이들은 이전 숨겨진 상태 ht-1과 새로운 입력 xt의 가중 평균을 계산하고, 편향을 더합니다. 가중치와 편향은 모델의 보물이라고 할 수 있습니다. RNN 블록들의 가중치와 편향은 \"I\", \"love\", \"you\"와 같은 다른 입력 벡터 표현과는 무관하게 항상 동일합니다. 위의 RNN 프레임워크는 모든 RNN 블록을 연결하는 하나의 숨겨진 상태를 가지고 있습니다. 긴 문장의 경우 잘 알려진 사라지는 그래디언트 문제가 발생합니다. 사라지는 그래디언트 문제는 Long Short-Term Memory로 해결됩니다. 여기서 내용을 반복하지 않고, 이전 챕터 \"시계열 모델링 기법의 진화\"를 참조하시면 사라지는 그래디언트 문제와 LSTM이 문제를 해결하기 위해 장기기억을 위한 하나, 단기기억을 위한 다른 하나의 숨겨진 경로를 생성하는 과정이 설명되어 있습니다. 그림(3)은 LSTM 블록으로 RNN 블록을 대체합니다.\n\n이제 가중치와 편향에 집중해 봅시다. 단어의 위치와 무관하게 모두 동일하다는 사실은 너무 제한적으로 보입니다. 예를 들어, \"love\"와 \".\"가 동일한 가중치와 편향을 갖는 것은 자연스럽지 않고 제한적으로 보입니다. 모든 말소통이 마법 같으며 많은 내재적 함축을 가질 수 있습니다. 문장을 인코딩하기 위해 LSTM 세트만 사용하는 것은 많은 정보를 잃을 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n입력의 더 다양한 변형을 캡처하기 위해, 연구자들은 Figure (4)의 검은 LSTM과 빨간 LSTM과 같이 두 번째 세트의 LSTM을 추가합니다. 모든 검은 LSTM은 동일한 가중치와 편향을 가지고 있으며, 모든 빨간 LSTM은 동일한 가중치와 편향을 가지고 있는데 이는 검은 LSTM과 다릅니다. 따라서 두 세트의 LSTM은 입력 벡터의 변형을 캡처하기 위해 두 세트의 단기 메모리와 장기 메모리를 가지고 있습니다. 필요하다면 더 많은 층의 LSTM을 추가할 수 있습니다. 이 개념은 나중에 \"Multi-head\"로 불리는 Transformer 모델에서 차용되었음을 기억하세요.\n\nFigure (2)에서 컨텍스트 벡터와 디코더에 대해 이야기해 봅시다. 컨텍스트 벡터는 디코더의 초기값을 제공합니다. 디코더는 LSTM 블록으로 구성되어 있습니다. 디코더의 모든 LSTM은 동일한 가중치와 편향을 가지고 있지만, 인코더의 LSTM들과는 다릅니다. 각 LSTM은 소프트맥스 함수를 통해 디코딩 될 단어나 구두점이 될 벡터를 전달할 것입니다. 문장이 고정 길이보다 짧은 경우, [EOS] (문장의 끝) 심볼이 채워집니다. 따라서 Seq2Seq는 소스와 타겟 문장의 길이에 대처할 수 있습니다.\n\nSeq2Seq의 혁신을 알았으니, 이제 두 번째 특징인 주의 메커니즘에 대해 알아봅시다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n문장을 듣게 되면, 우리는 중요한 키워드에 주의를 기욽하지 않고 있습니다. \"일을 끝내고 나면 종종 초콜릿 가게에 들르러 간다\"라는 문장을 들을 때, \"일을 끝낸 후\"와 \"초콜릿 가게\"라는 키워드를 파악합니다. 이 특별한 주의는 입력 문장의 일부에 초점을 맞춘 주의 메커니즘입니다. Seq2Seq도 마찬가지로 작동합니다. 해당 단어들에 더 많은 주의를 기울여 해당 단어들을 대상 언어로 변환합니다.\n\n그림(3)의 \"단일 파이프라인\" 아키텍처의 주요 단점은 인코더가 입력 문장 전체를 하나의 숨겨진 상태 벡터 ht로 표현해야 한다는 것입니다. 이는 모든 정보를 숨겨진 상태 ht로 압축해야 하므로 정보 손실을 초래할 수 있습니다. 더욱이, 디코더는 단일 벡터에서 정보를 해석해야 합니다. Seq2Seq 모델의 맥락에서 주의 메커니즘을 소개한 중요한 논문 중 하나는 2015년 Dzmitry Bahdanau, Kyunghyun Cho 및 Yoshua Bengio가 공동으로 \"바다나우 등의 연구팀이 발표한\" \"Neural Machine Translation by Jointly Learning to Align and Translate\"입니다. 그들은 디코더가 각 디코딩 단계에서 입력 시퀀스의 관련 부분에 초점을 맞출 수 있도록 주의 메커니즘을 설계했습니다. 이 작업은 주의 메커니즘을 통해 시퀀스 투 시퀀스 모델링의 이후 발전을 위한 기초를 마련했습니다.\n\n이미지\n\n그림(5)은 왼쪽의 단일 파이프라인 아키텍처가 오른쪽의 주의 메커니즘으로 대체된 것을 보여줍니다. 디코딩하는 동안 각 시간 단계마다, 디코더는 이전 숨겨진 상태 및 이전에 생성된 토큰을 기반으로 숨겨진 상태(gt)를 생성합니다. 그런 다음 주의 메커니즘은 입력 시퀀스의 각 위치에 대해 주의 가중치를 계산합니다. 이 가중치는 각 입력 토큰이 현재 디코딩 단계에 대해 얼마나 관련성 또는 중요성이 있는지 나타냅니다. 주의 가중치를 사용하여 컨텍스트 벡터가 계산되고 인코더 상태의 가중 합으로 계산됩니다. 그런 다음 이 컨텍스트 벡터가 현재 디코더 상태와 결합되어 현재 시간 단계의 출력 토큰을 생성합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n중요한 요점을 요약해봅시다. 인코딩은 정보를 읽거나 받아들이는 것과 같습니다. 디코딩은 이를 사용자의 자신의 말로 표현하는 것과 같습니다. 우리가 단어로 말할 때, 우리는 읽은 내용 중 일부 중요한 단어에 더 많은 주의를 기울이고 그에 따라 묘사할 수 있습니다. 주의 메커니즘은 모델이 출력 순서를 생성할 때 입력 순서의 일부에 서로 다른 가중치를 할당할 수 있도록 합니다.\n\n특수한 유형의 주의 메커니즘인 셀프-어텐션은 보다 효과적임이 입증되었습니다. 이것이 무엇인지 알아봅시다.\n\n주의에서 셀프-어텐션으로\n\n셀프-어텐션은 내부 주의라고도 불리는 특정 유형의 주의 메커니즘입니다. \"셀프\"라는 용어는 셀프-어텐션이 외부 문장에 주의를 기울이는 것이 아닌 같은 문장 내에서 내부적으로 작동한다는 점을 강조합니다. 이 메커니즘은 다양한 자연어 처리 작업에서 매우 효과적임이 입증되었습니다. 이는 “Attention is All You Need”(2017) [2]라는 고전적 논문에서 제안되었습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n(6)번 그림은 인기 있는 오픈 소스 앱 bertviz (https://github.com/jessevig/bertviz)에 의한 자기 주의 예제를 보여줍니다. \"토끼는 빨리 뛰었고, 거북이는 천천히 기어갔다\"라는 문장에서 \"토끼\"라는 단어는 \"뛰었고\"와 더 관련이 있고, \"거북이\"라는 단어는 \"기어갔다\"와 연관이 있습니다. 단어 사이의 선의 두께는 관계의 강도를 나타냅니다. \"토끼\"라는 단어가 나오면 \"뛰었고\"를 예측할 확률이 높으며, 마찬가지로 \"거북이\"는 \"기어갔다\"를 예측할 가능성이 높습니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1132/1*3ZtK93F0cacqAZJ7LUr-tg.gif)\n\n자기 주의를 계산하려면 입력 임베딩을 쿼리 벡터, 키 벡터, 밸류 벡터의 세 종류로 변환합니다. 이러한 변환은 일반적으로 모델의 학습 파라미터인 선형 프로젝션으로 이루어집니다. 같은 문장의 각 토큰에 대해 주의 점수는 그 토큰의 쿼리 벡터와 문장의 모든 토큰의 키 벡터 사이의 내적을 계산함으로써 구합니다.\n\n쿼리, 키, 밸류 벡터에 대해 설명이 필요할 것 같네요. 하나씩 설명해보죠.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 쿼리 벡터(Query Vectors): 쿼리 벡터는 학습된 선형 변환을 거친 후의 입력 시퀀스의 토큰(보통 단어 또는 하위 단어)를 나타냅니다. 입력 시퀀스 내 각 토큰은 해당하는 쿼리 벡터를 생성합니다. 이러한 쿼리 벡터는 키 벡터와 비교되어 각 토큰이 얼마나 주목을 받아야 하는지를 결정하는 주의 점수를 산출합니다. 예를 들어, \"모던 시계열 예측 기법\"이라는 쿠오(Kuo)의 책을 찾기 위해 도서관에 있는 상황을 상상해보세요. 여러분의 쿼리 벡터는 검색을 시작하는 질문처럼 작용합니다. 찾고자 하는 것을 좀 더 좁혀주는 역할을 합니다. 예를 들어, 쿼리 벡터는 \"쿠오의 '모던 시계열 예측 기법' 책을 찾을 수 있는 곳은 어디인가요?\"와 같을 것입니다.\n- 키 벡터(Key Vectors): 쿼리 벡터와 비슷하게, 키 벡터는 다른 학습된 선형 변환을 거친 후의 입력 시퀀스의 토큰을 나타냅니다. 이들은 주의 메커니즘에 대한 참조 역할을 합니다. 주의 메커니즘은 각 쿼리 벡터와 각 키 벡터 간의 유사성을 계산하여 입력 시퀀스 내 각 토큰의 관련성이나 중요성을 결정합니다. 키 벡터는 도서관의 서로 다른 책장에 붙어 있는 라벨과 같이 생각할 수 있습니다. 각 라벨(키 벡터)은 그 특정 섹션에 무엇이 들어있는지 알려줍니다. 질문(쿼리)을 하면, 모델은 이러한 키 벡터를 사용하여 어떤 도서관 섹션에 주목해야 하는지 판단합니다. 따라서, 만약 여러분의 쿼리가 시계열에 관한 것이라면, 키 벡터는 도서관의 시계열 책 섹션의 라벨 역할을 합니다.\n- 값 벡터(Value Vectors): 값 벡터는 공부한 선형 변환을 거친 후의 입력 토큰들의 또 다른 표현입니다. 이러한 벡터들은 각 토큰과 연관된 실제 정보를 저장합니다. 주의 계산 중에 쿼리 벡터와 키 벡터를 비교하여 얻은 주의 점수는 값 벡터들에 가중치를 부여하는 데 사용됩니다. 값 벡터의 가중합은 주의 메커니즘의 출력을 제공합니다. 도서관 비유를 계속하자면, 값 벡터는 책 자체와 같습니다. 여러분이 관심 있는 실제 정보를 담고 있습니다. 모델이 여러분의 질문(쿼리 벡터)을 기반으로 어떤 도서관의 \"시계열\" 책 섹션(키 벡터)을 찾으면, 그 안에 있는 쿠오의 \"모던 시계열 예측 기법\" 책(값 벡터)을 읽게 됩니다.\n\n트랜스포머 모델\n\n트랜스포머 모델은 주의 메커니즘을 기반으로 한 구조로 자연어 처리 작업을 혁신적으로 변화시켰습니다. 아래는 트랜스포머 아키텍처를 보여주는 그림입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 입력 임베딩: 트랜스포머 모델의 입력은 토큰화된 입력 시퀀스로 구성됩니다. 각 토큰은 처음에는 Figure (2)에 설명된 대로 고정 차원 벡터로 표현됩니다.\n- 위치 인코딩: \"나는 아이스크림을 좋아해\"와 같은 문장이 있다고 가정해봅시다. 트랜스포머 모델에서는 \"나\", \"좋아해\", \"아이스크림\"을 개별 단어로만 이해하는 것이 아니라 \"나\"가 먼저 오고, 그 다음에 \"좋아해\", 그리고 \"아이스크림\"이 온다는 것도 이해해야 합니다. 문장을 읽을 때, 단어 자체뿐만 아니라 문장 내 순서에 따라 의미를 자연스럽게 이해합니다. 비슷하게, 트랜스포머 모델에서는 각 단어나 토큰의 위치에 대해 모델에게 알려주는 방법이 필요합니다. 위치 인코딩은 시퀀스 내 각 단어나 토큰에 부착된 작은 태그처럼, 모델에게 시퀀스 내 위치에 대해 알려주는 역할을 합니다. 따라서 트랜스포머는 입력을 더 잘 이해하기 위해 단어 자체와 이러한 위치 태그를 함께 사용할 수 있습니다.\n- 다중 헤드 셀프 어텐션 메커니즘: 우리는 이미 이전 섹션에서 \"셀프 어텐션\"을 배웠습니다. 이는 동일한 문장 내 일부 부분에 주의를 기울이는 것을 의미합니다. 그렇다면 \"다중 헤드\"는 무엇을 의미할까요? Figure (3)에서 이미 이 아이디어를 볼 수 있습니다. 여기서도, 한 번만 어텐션을 계산하는 대신 모델은 병렬로 여러 번 어텐션을 계산할 수 있으며, 각각은 학습된 선형 투영 세트를 갖습니다. 이러한 병렬 계산을 \"어텐션 헤드\"라고 합니다.\n- 완전 연결 피드 포워드 네트워크: 이것은 표준 신경망입니다. \"완전 연결\"이란 한 층의 각 뉴런이 다음 층의 각 뉴런에 연결되어 있는 것을 의미합니다. \"피드 포워드\"는 피드백 루프 없이 네트워크를 통해 데이터가 흐르는 것을 나타냅니다.\n\nFigure (6)의 오른쪽에 있는 디코더 스택은 인코더 스택과 유사하지만 인코더의 출력에 주의를 기울이는 추가적인 셀프 어텐션 레이어가 포함되어 있습니다. 이는 디코더가 출력 시퀀스를 생성하는 동안 입력 시퀀스의 관련 부분에 집중할 수 있게 합니다. 마지막 레이어는 목표 어휘에 대한 출력 확률 분포를 생성하기 위한 소프트맥스 함수입니다.\n\n위의 내용 외에도 모델은 표준 역전파 및 아담 옵티마이저를 사용한 확률적 경사 하강법을 사용하여 훈련됩니다. 훈련 중에 인코더와 디코더는 예측된 시퀀스와 목표 시퀀스 사이의 크로스 엔트로피 손실을 최소화하기 위해 함께 훈련됩니다.\n\n트랜스포머에서 시계열 퓨전 트랜스포머(TFT)로!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nTransformer 아키텍처는 원래 기계 번역 및 질문 응답과 같은 순차 대 순차 작업을 위해 설계되었습니다. 시계열 모델링에 적응하기 위해서는 Transformer 아키텍처를 수정하여 시계열 데이터의 시간 종속성을 처리할 수 있어야 합니다. 이는 위치 부호화를 추가하거나 반복을 통합하거나 Transformer 아키텍처의 변형을 사용하는 것을 포함합니다. 몇 가지 고려해야 할 사항을 나열해 보겠습니다:\n\n첫째, 시계열은 종종 여러 시간 단계에 걸쳐 범주화된 복잡한 시간 패턴과 종속성을 보입니다. 상당한 수정 없이 Transformer 모델은 시간 패턴을 효과적으로 포착하지 못할 수 있습니다. 둘째, 시계열 데이터에는 캘린더 관련 기능이 있습니다. 캘린더 관련 기능은 표준 Transformer 아키텍처로 명시적으로 포착되지 않을 수 있습니다. 셋째, 시계열 데이터는 변수 길이를 가질 수 있습니다. 다양한 길이의 입력을 처리하기 위해 Transformer 아키텍처를 적응하는 것은 추가 수정이나 기술이 필요합니다. 넷째, 시계열에서 예측 불확실성이 필요합니다. 언어 모델은 일반적으로 이를 갖고 있지 않습니다.\n\n위와 같은 이유로 연구자들은 Transformer 모델을 시계열 모델링에 더 효과적으로 사용하기 위해 적응 및 확장을 탐구해 왔습니다. 중요한 이정표 모델은 Temporal Fusion Transformer (TFT)입니다. 2020년에 Bryan Lim, Sercan O ̈. Arık, Nicolas Loeff, Tomas Pfister가 \"Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting\"라는 선구적 논문을 발표하여 다중 시리즈 및 다중 기간 시계열 모델링에 대해 제안했습니다.\n\n여러 시계열 데이터의 특징을 얻는 방법부터 시작해 보겠습니다. 시계열 데이터는 현재 및 늦춰진 값 사이의 시간적 패턴을 가집니다. 또한 캘린더 관련 정보도 포함하고 있습니다. 캘린더 기능은 일주일의 날짜나 월의 주와 같은 것들인데, 미래에도 결정적입니다. 그래서 TFT는 네 가지 종류의 특징을 만듭니다. 이전 장 \"Amazon's DeepAR for RNN/LSTM\"의 Walmart 매장 판매 데이터를 사용하여 네 가지 특징 그룹을 설명하겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- (특징 그룹 1) 상점의 과거 공변량: 상점 i의 과거 판매 yt-1, yt-2, … 이며 t시간까지만 알려진 시간 변동적 데이터입니다.\n- (특징 그룹 2) 상점 매출에 영향을 미치는 기타 데이터: 날씨나 소비자 지수와 같은 데이터로, t시간까지만 알려진 시간 변동적 정보입니다.\n- (특징 그룹 3) 요일, 월 중 주차, 공휴일과 같은 달력 특징들.\n- (특징 그룹 4) 시간과 무관한 특징들으로, 시간과 관련이 없는 상점 ID나 지역과 같은 특징들입니다.\n\nTFT는 데이터 내에서 복잡한 시계열 종속성을 포착하기 위해 self-attention 메커니즘을 활용합니다. 시계열 데이터의 시간적 성격을 포착하기 위해, 저자들은 시간 인코딩 기술을 소개하였습니다. 이러한 기술들은 모델이 입력 시퀀스에 시간 관련 정보를 통합하여 시간적 패턴과 추세를 더 잘 포착할 수 있게 합니다. 시계열의 자기회귀적 패턴을 알기 위해, TFT는 다중 시계열 예측을 생성하기 위한 자기회귀 메커니즘을 활용합니다.\n\nTransformer 아키텍처 외에도, TFT를 매력적인 선택지로 만드는 여러 기여 요소가 있습니다. TFT의 주요 기여 중 하나는 해석 가능성에 중점을 둔 점입니다. 저자들은 입력 특징과 시간 요소의 중요성을 강조하는 attention 메커니즘을 소개하였으며, 이는 예측을 더 해석 가능하고 사용자에게 투명하게 만듭니다. TFT는 예측과 함께 불확실성의 추정치를 제공하여 불확실성 하에 의사 결정을 내릴 수 있게 합니다. 각 예측에 관련된 불확실성을 측정함으로써, 모델은 더 신뢰할 수 있는 예측을 제공하고 위험 관리 전략을 안내할 수 있습니다. TFT는 다중 시점 예측을 생성할 수 있으며, 여러 시점 다음의 미래 값을 예측합니다. 마지막으로, TFT는 효과적으로 누락된 또는 희소한 데이터를 처리하도록 설계되었습니다. 불완전한 데이터로부터 학습하고 일부 관측치가 누락된 상황에서도 예측을 수행할 수 있으며, 이는 실제 시계열 데이터셋에서 흔한 일입니다.\n\n이번 개요 챕터에서는 TFT에 대해 깊이 파헤치지 않을 예정입니다. 다음 챕터 \"해석 가능한 시계열 예측을 위한 Temporal Fusion Transformer\"에서 TFT 아키텍처와 시각화에 대해 자세히 알아보겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n왜 대규모 기본 모델을 사용해야 할까요?\n\n대규모 기본 모델은 일반적인 용도로 대량의 데이터를 기반으로 훈련됩니다. 특정 작업에 맞게 세밀하게 조정할 수도 있습니다. 언어 모델에서는 GPT-2 (2019), GPT-3 (2020), chatGPT (2022), GPT-4 (2023), T-5 (2019), Flan-T5 (2022), BERT (2018), RoBERTa (2019), DeBERTa (2019), DistilBERT (2020), 그리고 MPT-7B-StoryWriter-65k+ 등을 들어본 적이 있을 겁니다. 이러한 모델들은 언어의 세세한 부분에 대해 효과적으로 학습하며, 문법, 의미, 맥락을 이해합니다. \"The data that those large language models were built on\" [6]라는 글에서는 책, 기사, 인터넷 게시물과 같은 데이터 원본을 자세히 설명하여 모델을 훈련시킨 것을 살펴볼 수 있습니다.\n\n대규모 기본 모델이 시계열 데이터에 중점을 두는 이유는 무엇일까요? 이곳에서 몇 가지 좋은 동기를 제시해보겠습니다. 사전 훈련된 시계열 기본 모델은 재무, 의료, 천문학과 같은 다양한 시계열 데이터를 이미 훈련받아 일반적인 패턴을 인식할 수 있습니다. 그들은 세세한 조정 없이 보지 못한 시계열 데이터의 패턴을 인식할 수 있습니다. 그들의 유연성으로 인해 서로 다른 산업의 데이터 유형, 샘플링 빈도 및 예측 기간을 처리할 수 있습니다. 시계열의 기본 모델은 작업별 모델 개발의 필요성을 줄이고 배포 속도를 높일 수 있습니다. 또 다른 장점은 예측 해석이 가능하다는 점입니다. 많은 대규모 기본 모델은 이미 해석 가능성 매커니즘을 통합하여 사용자가 모델이 어떻게 예측하고 예측하는지를 이해할 수 있도록 도와줍니다.\n\nLag-Llama— 오픈 소스 시계열 기본 모델\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLag-Llama 모델은 LLaMA 모델의 디코더 부분을 기반으로 하며 다양한 시계열 데이터 코퍼스에서 학습되었습니다. 이 모델은 단변량 확률적 예측을 위한 범용적인 기본 모델입니다. \"Lag\"를 LLaMA에 접두사로 추가한 이유는 시계열의 지연 항을 공변량으로 사용하기 때문입니다. Lag-Llama는 선형성이나 정상성을 가정하지 않고 시간 의존성을 잡기 위해 과거 시계열 값의 지연된 특징을 사용합니다.\n\n시계열 데이터와 언어 데이터에는 차이가 있습니다. 현재 및 지연된 시계열 값에는 시간 패턴이 있습니다. 또한 시계열 데이터에는 주 단위, 월 단위 등과 같은 달력 관련 정보가 있습니다. 따라서 Lag-Llama는 입력을 지연된 공변럇 (t=1, 7, 14, 21, …, 𝛕) 및 도표(8)에 나와 있는 것과 같이 달력 관련 기능으로 활용합니다. 시계열 데이터는 입력을 인코딩하는 방식이 매우 다르기 때문에 Lag-Llama가 LLaMA 모델의 디코더 부분을 사용하는 이유입니다.\n\nLag-Llama는 확률적 출력을 학생 t-분포에서 추출한 결과로 근사합니다. 따라서 학생 t-분포의 세 매개변수, 즉 자유도, 평균 및 척도를 모델링합니다. \"시계열 확률적 예측을 위한 몬테칼로 시뮬레이션\"이라는 이전 챕터에서 학생 t-분포에 대해 공부했습니다. 학생 t-분포를 이해하기 위해 해당 챕터를 참조할 수 있습니다. Lag-Llama에는 다른 분포도 포함시킬 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n라그-라마는 LLaMA를 기반으로 하며, LLaMA는 Transformer 모델을 기반으로 합니다. 다음 장 \"시계열 예측을 위한 오픈 소스 Lag-라마 튜토리얼\"에서는 디코드 전용 트랜스포머 기반 아키텍처 LLaMA를 살펴볼 예정입니다.\n\n학습된 데이터 소스를 이해해봅시다. 라그-라마는 에너지, 교통, 경제, 자연, 대기 품질 및 클라우드 운영과 같은 다양한 도메인의 27개 시계열 데이터셋 코퍼스를 사용합니다. 학습 데이터의 다양성에는 주파수, 각 시리즈의 길이, 예측 길이, 여러 시리즈 수 등이 포함됩니다. 이러한 다양한 데이터 소스는 라그-라마가 명시적으로 학습되지 않은 새로운 시계열을 모델링할 수 있게 합니다. 이를 제로샷 학습이라고 합니다. 제로샷 학습은 모델이 학습 중에 이전에 본 적이 없는 클래스를 인식하도록 학습되는 새로운 학습 접근 방법입니다.\n\n요약\n\n이 장에서는 RNN/LSTM부터 Temporal Fusion Transformer 및 Lag-라마로 이어지는 시계열 모델링 기술의 진화를 살펴보았습니다. Seq2Seq 모델, 어텐션 메커니즘, 셀프 어텐션 메커니즘 및 트랜스포머 모델에 대해 다루었습니다. 언어 트랜스포머 모델이 시계열에 효과적이지 않을 수 있는 이유를 설명했습니다. 그리고 시계열 인코딩 기술을 통합하고 해석 가능성과 불확실성 추정을 강조하는 Temporal Fusion Transformer(TFT)를 소개했습니다. 마지막으로, 단일 변수 확률적 시계열 예측을 위해 설계된 오픈 소스 기본 모델인 Lag-라마를 소개했습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n앞으로의 몇 장에서는, 해석 가능성을 위해 시계열 모델을 시각화하는 방법을 포함한 Temporal Fusion Transformer를 배우게 될 것입니다. Lag-Llama를 활용하여 시계열 모델을 구축하는 방법도 알아볼 거에요.\n\n참고 자료\n\n- [1] Sutskever, I., Vinyals, O. & Le, Q. V. (2014). 신경망을 이용한 시퀀스 대 시퀀스 학습. 신경정보처리시스템 발전(p./pp. 3104–3112)\n- [2] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł. & Polosukhin, I. (2017). 어텐션 이 필요한 모든 것. 신경정보처리시스템 발전(p./pp. 5998–6008).\n- [3] Kuo, C. (2023). Gensim으로 NLP 핸드북: 텍스트 데이터 내에서 숨겨진 패턴, 테마 및 가치있는 통찰력 발굴하기. Packt Publishing. ISBN-13: 978–1803244945\n- [4] Bahdanau, D., Cho, K., & Bengio, Y. (2014). 맞추고 번역하기 위해 공동 학습하는 신경 기계 번역. CoRR, abs/1409.0473.\n- [5] Lim, Bryan & Arık, Sercan Ö. & Loeff, Nicolas & Pfister, Tomas, 2021. “해석 가능한 멀티-호라이즌 시계열 예측을 위한 Temporal Fusion Transformer,” 예측 국제 저널, Elsevier, vol. 37(4), pages 1748–1764.\n- [6] Kuo, C., (2023). 대형 언어 모델이 구축된 데이터. Medium.com\n- [7] Rasul, K., Ashok, A., Williams, A.R., Khorasani, A., Adamopoulos, G., Bhagwatkar, R., Bilovs, M., Ghonia, H., Hassen, N., Schneider, A., Garg, S., Drouin, A., Chapados, N., Nevmyvaka, Y., & Rish, I. (2023). Lag-Llama: 확률론적 시계열 예측을 위한 기점 모델로 향하여.\n- [8] Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E. & Lample, G. (2023). LLaMA: 열리고 효율적인 기반 언어 모델 (arxiv:2302.13971을 인용하십시오)\n- [9] Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H.W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N.M., Prabhakaran, V., Reif, E., Du, N., Hutchinson, B.C., Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari, G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev, S., Michalewski, H., García, X., Misra, V., Robinson, K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D., Agrawal, S., Omernick, M., Dai, A.M., Pillai, T.S., Pellat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov, O., Lee, K., Zhou, Z., Wang, X., Saeta, B., Díaz, M., Firat, O., Catasta, M., Wei, J., Meier-Hellstern, K.S., Eck, D., Dean, J., Petrov, S., & Fiedel, N. (2022). PaLM: 경로로 언어 모델링 확장. J. Mach. Learn. Res., 24, 240:1–240:113.\n- [10] Shazeer, N.M. (2020). GLU 변형은 트랜스포머를 개선시킵니다. ArXiv, abs/2002.05202.\n- [11] Su, J., Lu, Y., Pan, S., Wen, B., & Liu, Y. (2021). RoFormer: 회전 위치 임베딩이 추가된 향상된 트랜스포머. ArXiv, abs/2104.09864.\n- [12] Zhang, B., & Sennrich, R. (2019). 평균 제곱근 레이어 정규화. ArXiv, abs/1910.07467.\n\n샘플 eBook 장(chapter) (무료): [여기를 클릭해주세요](https://github.com/dataman-git/modern-time-series/blob/main/20240522beauty_TOC.pdf)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 이노베이션 프레스 주식회사 스태프 여러분께 감사드립니다. 아름다운 형식으로 책을 재현하여 즐거운 독서 경험을 선사해 주셨습니다. 전 세계 독자들에게 책을 배포하기 위해 Teachable 플랫폼을 선택했습니다. Teachable.com에서 신용카드 거래는 안전하고 비밀리에 처리됩니다.\n\nTeachable.com의 eBook: $22.50\nhttps://drdataman.teachable.com/p/home\n\nAmazon.com의 인쇄판: $65\nhttps://a.co/d/25FVsMx\n\n- 인쇄판은 유광 표지, 컬러 인쇄, 아름다운 Springer 글꼴 및 배치를 채택하여 즐거운 독서를 제공합니다. 7.5 x 9.25인치의 포털 크기는 여러분의 책장에 있는 대부분의 책과 잘 어울립니다.\n- \"이 책은 시계열 분석 및 예측 분석, 이상 탐지에 대한 깊은 이해를 증명하는 책입니다. 독자들이 현실 세계의 문제에 대처하기 위한 필수 기술을 갖추게 도와줍니다. 데이터 과학 분야로의 직군 전환을 원하는 사람들에게 특히 가치 있습니다. Kuo는 전통적이고 혁신적인 기술에 대해 상세히 탐구합니다. 최신 경향과 발전을 반영하기 위해 신경망 및 다른 고급 알고리즘에 대한 논의가 통합되어 있습니다. 이를 통해 독자들은 기존 방법뿐만 아니라 데이터 과학 분야의 가장 최신이자 혁신적인 기술과 상호작용할 준비가 되어 있습니다. Kuo의 생동감 넘치는 글쓰기 스타일로 책의 명료함과 접근성이 향상되었습니다. 그는 복잡한 수학적 및 통계적 개념을 분명하게 풀어내어 엄밀성을 희생하지 않으면서도 접근하기 쉽게 만들었습니다.\"\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 현대 시계열 예측: 예측 분석 및 이상 탐지\n\nChapter 0: 서문\n\nChapter 1: 소개\n\nChapter 2: 비즈니스 예측을 위한 Prophet\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n### 장 3: 튜토리얼 I: 추세 + 계절성 + 휴일 및 이벤트\n\n### 장 4: 튜토리얼 II: 추세 + 계절성 + 휴일 및 이벤트 + 자기회귀(AR) + 지연 회귀자 + 미래 회귀자\n\n### 장 5: 시계열 데이터의 변곡점 탐지\n\n### 장 6: 시계열 확률 예측을 위한 몬테카를로 시뮬레이션\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n7장: 시계열 확률 예측을 위한 분위 회귀\n\n8장: 시계열 확률 예측을 위한 적합 예측\n\n9장: 시계열 확률 예측을 위한 회귀를 준수하다\n\n10장: 자동 ARIMA!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 11장: 시계열 데이터 형식 쉽게 이해하기\n\n# 12장: 다기간 확률 예측을 위한 선형 회귀\n\n# 13장: 트리 기반 시계열 모델의 피처 엔지니어링\n\n# 14장: 다기간 시계열 예측을 위한 두 가지 주요 전략\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n### 15장: 시계열 다기간 확률 예측을 위한 Tree-based XGB, LightGBM 및 CatBoost 모델\n\n### 16장: 시계열 모델링 기법의 진화\n\n### 17장: 시계열 확률 예측을 위한 딥러닝 기반 DeepAR\n\n### 18장: 주가에 대한 확률적 예측 응용\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 19장: RNN에서 Transformer 기반 시계열 모델로\n\n# 20장: 해석 가능한 시계열 예측을 위한 Temporal Fusion Transformer\n\n# 21장: 시계열 예측을 위한 오픈소스 Lag-Llama 튜토리얼","ogImage":{"url":"/assets/img/2024-07-09-FromRNNLSTMtoTemporalFusionTransformersandLag-Llama_0.png"},"coverImage":"/assets/img/2024-07-09-FromRNNLSTMtoTemporalFusionTransformersandLag-Llama_0.png","tag":["Tech"],"readingTime":25},{"title":"MLOps란  머신러닝 운영 쉽게 이해하기","description":"","date":"2024-07-09 20:49","slug":"2024-07-09-WhatisMLOpsMachineLearningOperationsExplained","content":"\n\nMLOps는 AI 통합과 혁신을 위한 기계 학습 모델과 실제 응용 프로그램 사이의 다리 역할을 합니다.\n\n![MLOps](/assets/img/2024-07-09-WhatisMLOpsMachineLearningOperationsExplained_0.png)\n\n저희가 사는 세상의 모든 측면에 AI가 통합된 시대에, 실리콘 밸리의 작은 팀이 기계 학습과 상호 작용하는 방식을 바꿀 수 있는 위험을 감지했습니다.\n\nMLOps의 심층적인 내용을 밝혀냄으로써, 기계 학습 모델과 현실 세계 응용 프로그램 간의 간극을 메우는 역할을 발견할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저는 MLOps의 복잡성을 안내해 드릴 거에요. 기계 학습 모델의 배포, 모니터링 및 관리를 어떻게 가속화하는지 보여 드릴 거예요.\n\n# Machine Learning Operations (MLOps)란 무엇인가요?\n\nMLOps는 기계 학습 운영(Machine Learning Operations)을 의미하며, 기계 학습 시스템의 개발(Dev) 및 운영(Ops)을 통합하기 위해 제안된 최상의 실천 방법의 모음을 지칭합니다.\n\nMLOps는 DevOps 철학 중 일부 중요한 요소를 통합하여 데이터 과학 및 운영 전문가의 개선된 커뮤니케이션, 협력 및 통합 작업을 도입합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그 의미에서 MLOps는 기계 학습 시스템이 직면하는 독특한 도전에 대응하도록 설계되었습니다.\n\n# MLOps의 주요 구성 요소\n\n![이미지](/assets/img/2024-07-09-WhatisMLOpsMachineLearningOperationsExplained_1.png)\n\nMLOps에는 다양한 구성 요소가 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 데이터 관리: 데이터 관리는 특정 기술을 통해 데이터 획득, 저장 및 전처리를 통합하는 과정을 포함합니다. 적절한 데이터 관리는 모델 훈련을 위한 데이터의 품질과 접근성을 보장할 수 있습니다.\n- 모델 개발 및 훈련: 모델은 다양한 기계 학습 알고리즘을 통해 개발되며, 그런 다음 해당 모델은 데이터를 사용하여 훈련됩니다. 모델 개발을 위한 적절한 프레임워크와 도구를 포함합니다.\n- 모델 버전 관리: 소프트웨어 개발에서의 코드 버전 관리와 같이, 이 접근 방식은 관련된 데이터 세트와 함께 모델의 다양한 버전을 유지하여 모델 변경과 반복을 관리하는 것을 용이하게 합니다.\n- 배포: 훈련된 모델을 제품 환경으로 통합하는 과정으로, 이후에 새로운 데이터를 기반으로 예측하거나 조치를 취할 수 있게 됩니다.\n- 모델 모니터링 및 관리: 배포 이후, 모델은 가끔씩 성능과 정확도를 모니터링해야 합니다. 데이터나 비즈니스 요구 사항의 변경에 응답하여 모델을 업데이트하는 모델 관리가 필요합니다.\n- 자동화 및 오케스트레이션: 규모에 맞는 기곌 학습 파이프라인 내에서의 작업 자동화와 조율은 중요합니다. 이는 데이터 전처리, 모델 훈련, 테스트 및 배포 과정을 자동화하는 것을 의미합니다.\n- 협업 및 거버넌스: 데이터 과학자, 엔지니어 및 비즈니스 이해 관계자 간의 유대감을 도와주는 메커니즘으로, 윤리적 AI 실천, 보안 및 규정 준수에 관한 거버넌스가 필요합니다.\n\n이 통합은 MLOps의 기초가 되며, 팀은 기계 학습 모델을 효율적이고 효과적으로 생성, 배포 및 관리할 수 있습니다.\n\n# MLOps의 주요 이점\n\n기관은 기계 학습 모델의 흐름 내에서 MLOps를 구현함으로써 여러 이점을 얻을 수 있습니다. 일부 주요 이점은 다음과 같습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Time to Market: MLOps는 기계 학습의 라이프사이클을 데이터 준비 단계부터 모델 준비 단계까지의 시간을 단축시켜 모델로 배포하는 데 소요되는 시간을 줄입니다. 이로써 제품 모델을 성공적으로 도입하는 데 걸리는 시간을 단축시킵니다.\n- 향상된 모델 품질과 성능: 모델들의 지속적인 워크플로우 - 통합, 배포 및 모니터링 - 은 모델이 항상 최적으로 작동하여 가장 정확한 결과를 제공하도록 합니다.\n- 협업: MLOps는 데이터 과학자, 개발자 및 운영 엔지니어간 협업을 개선하여 목표를 공유하고 효과적으로 함께 일할 수 있도록합니다.\n- 확장성: MLOps의 모범 사례 및 도구는 기계 학습 운영을 확장할 수 있도록 도와줍니다. 이로써 여러 모델과 대량의 데이터를 효과적으로 처리하는 것이 용이해집니다.\n- 재현성 및 추적성: MLOps는 모델과 데이터의 버전 관리를 가능하게 함으로써 재현 가능한 실험과 명확한 이력을 통한 변경 사항의 추적을 보장하여 책임과 투명성을 더합니다.\n- 비용 효율성: 반복적인 작업의 자동화 및 자원 최적화를 통해 기계 학습 프로젝트 주변의 작업을 수행하는 데 드라마틱하게 줄어든 비용을 제공합니다.\n- 규제 준수 및 보안: MLOps는 감사 모델, 데이터 프라이버시, 보안 조치를 검토할 수 있는 메커니즘을 제공하여 거버넌스 및 규제 준수를 허용합니다.\n\n기계 학습 프로젝트에 포함된 MLOps는 기업들이 AI 시스템의 배포와 유지를 돕는 데 문제를 쉽게 해결할 수 있게 합니다.\n\n# MLOps의 도구 및 기술\n\nMLOps 생태계의 일부인 여러 도구와 기술들이 ML 라이프사이클의 다양한 단계를 지원하기 위해 개발되었습니다. 아래에는 일반적으로 MLOps에서 사용되는 가장 중요한 도구와 기술 중 일부가 소개되어 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 데이터 관리 및 버전 관리: DVC(Data Version Control)와 LakeFS와 같은 도구들은 데이터 관리와 버전 관리를 돕고, 이를 통해 머신 러닝 프로젝트를 재현 가능하고 추적 가능하게 합니다.\n- 실험 추적: MLflow 플랫폼과 Weights & Biases는 실험 추적 프레임워크를 내장하여 실험을 추적하고 매개변수 및 결과를 기록하며, 데이터 과학자가 실험을 비교하고 관리할 수 있게 합니다.\n- 모델 개발 프레임워크: 머신 러닝 모델 개발을 지원하는 인기 있는 라이브러리와 프레임워크에는 TensorFlow, PyTorch 및 Scikit-learn이 포함됩니다.\n- 모델 버전 및 레지스트리: MLflow Model Registry와 DVC가 모델의 버전 관리를 처리하여 해당 메타데이터를 포함하고 올바른 모델을 추적하는 것을 쉽게 합니다.\n- 워크플로 오케스트레이션 및 자동화: Apache Airflow와 Kubeflow Pipelines는 데이터 전처리부터 모델 학습 및 배포까지 머신 러닝 워크플로를 자동화할 수 있습니다. 이로써 프로세스에서 일관성과 효율성을 약속합니다.\n- 모델 배포: TensorFlow Serving, TorchServe 및 Kubernetes를 사용하여 개발된 모델을 실제 세계에서 프로덕션 규모로 배포하는 프로세스로, 이러한 방식으로 실제 업무 부하를 효과적으로 처리할 수 있습니다.\n- 모델 모니터링 및 운영: 이 프로세스는 모델의 성능과 운영 상태를 Prometheus, Grafana 및 AI를 사용하여 모니터링하고, 정의된 정상 범위나 임계값을 벗어났을 경우 해당 팀에 경고를 보냅니다.\n- 버전 관리 및 협업: Git 및 GitHub 도구는 버전 관리와 협업을 지원합니다. 이를 통해 파일 버전을 제어하고 프로젝트의 소프트웨어 개발자팀과 협업할 수 있습니다.\n\n이러한 도구와 기술들은 MLOps 툴킷의 주요 구성 요소로, 어떤 프로젝트에서도 MLOps를 롤아웃, 채택 및 실천하는 데 도움이 됩니다.\n\n# DevOps vs MLOps\n\n![MLOps 이미지](/assets/img/2024-07-09-WhatisMLOpsMachineLearningOperationsExplained_2.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n비록 데브옵스(DevOps)와 엠엘옵스(MLOps)는 개발과 운영이 어떻게 이루어져야 하는지에 대한 유사한 목표를 향하지만, 머신 러닝 프로젝트가 가져다주는 도전에 따라 차이가 발생합니다. 엠엘옵스와 데브옵스의 차이점은 다음과 같습니다:\n\n- 데이터와 모델에 초점: 데브옵스는 소프트웨어 개발 프로세스를 중점으로 두며 코드의 통합, 테스트, 배포를 강조하지만, 엠엘옵스는 데이터 버전 관리와 모델 훈련을 포함하여 배포에 이르기까지 모델의 라이프사이클을 보완함으로써 머신 러닝의 핵심인 코드 외에 다른 측면을 다룹니다.\n- 데이터 출처와 모델 버전 관리: 엠엘옵스에서는 모델 버전 관리가 매우 중요하며 코드 뿐만 아니라 데이터와 모델도 버전 관리됩니다. 이는 모델의 출처를 재현하고 이해하는 능력에 중요하며, 이는 보통 데브옵스에서 다루지 않는 영역입니다.\n- 지속적인 훈련과 모니터링: 데브옵스가 지속적인 통합 및 배포를 갖고 있다면, 엠엘옵스는 모델의 지속적인 훈련과 모니터링을 포함합니다. 이는 모델이 새로운 데이터로 지속적으로 재훈련되어야 하며 모델 성능이 시간이 지남에 따라 모니터링되어야 한다는 것을 반영합니다.\n- 실험 및 평가: 다양한 모델 아키텍처와 매개변수 설정에 대해 유연한 실험을 가능하게 하며, 실험 추적, 결과 및 모델 평가를 추적하는 도구는 엠엘옵스의 핵심입니다. 그러나 이러한 부분은 전통적인 데브옵스의 중심에 있지 않습니다.\n- 다양한 팀 간의 협업: 엠엘옵스는 데이터 과학자, 데이터 엔지니어, 머신 러닝 엔지니어 및 운영팀과 긴밀히 협업해야 합니다. 반면 데브옵스는 개발과 IT 운영 사이의 연결을 강조합니다. 엠엘옵스는 데이터와 모델 관리에 중점을 둔 역할을 통합함으로써 또 다른 층을 더하였습니다.\n- 확장성과 거버넌스 도전: 엠엘옵스는 머신 러닝 모델의 확장과 이러한 리소스의 효율적인 거버넌스에 특유의 도전에 직면할 것입니다. 또한 이는 소프트웨어 개발에서 만나는 것보다 비교적 더 복잡한 거버넌스, 윤리 및 규정 이슈에 대처할 수 있어야 합니다.\n\n요약하면, 엠엘옵스는 머신 러닝 프로젝트의 특수 요구 사항을 고려해 데브옵스의 원칙을 적용 및 확장합니다. 모델의 라이프사이클은 개발부터 배포 및 모니터링까지 끝까지 고려하여 데이터 관리, 모델 버전 관리 및 지속적인 개선을 다룹니다.\n\n# 엠엘옵스에서의 Best Practices\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMLOps를 수용하려면 올바른 장치와 최상의 실천 방법을 준수해야 합니다. 이는 AI 워크플로우의 원활한 작동을 보장합니다. 여기 MLOps에서의 절대적인 Best Practices 목록입니다:\n\n- 머신 러닝 라이프사이클 자동화: 가능한 한 데이터 준비, 모델 개발, 평가 및 구현과 같은 머신 러닝 프로세스를 자동화합니다. 이 접근 방식은 인적 오류를 최소화하고 생산성을 향상시킵니다.\n- 모든 것을 버전 관리: 코드, 데이터 세트, 모델 및 실험 로그를 포함한 모든 구성 요소에 대해 버전 관리 메커니즘을 적용합니다. 이러한 방법은 일관성, 책임성 및 필요할 때 이전 반복으로 되돌아갈 수 있는 능력을 보장합니다.\n- 모델을 위한 CI/CD(Continuous Integration/Continuous Delivery) 설정: 소프트웨어 엔지니어링에서의 관행을 반영하여 머신 러닝 프로젝트에 지속적인 통합 및 지속적인 배포 방법론을 적용하여 자동화된 테스트와 원활한 모델 배포를 보장합니다.\n- 생산 중인 모델 모니터링: 배포된 모델을 지속적으로 관찰하여 성능이나 정확도의 저하를 주시합니다. 비정상적인 활동에 대한 자동화된 알림을 설정하고 필요에 따라 모델 업데이트 및 재배포 프로세스를 간소화합니다.\n- 모델 관리와 윤리 실행: 윤리적 고려사항, 규정 준수 및 데이터 프라이버시를 다루는 프레임워크를 개발합니다. 모델이 어떻게 결정을 내리고 데이터를 사용하는지에 대한 투명성을 확보합니다.\n- 팀 간 협업 강화: 데이터 과학자, ML 엔지니어 및 운영 직원 간의 협업 환경을 조성하여 정확성뿐만 아니라 확장 가능하고 지속 가능한 모델을 생산합니다.\n- 데이터 품질 강조: 훈련 및 추론에 사용되는 데이터가 품질이 높은지 확인합니다. 편향, 누락된 값, 소음과 같은 문제를 해결합니다. 데이터 원천 및 전처리 단계를 정기적으로 감사합니다.\n- 지식 문서화 및 공유: 모델, 데이터 원천, 실험 및 결정을 문서화합니다. 팀 내부 및 조직 전체에서 지식을 공유하여 학습 및 지속적인 개선 문화를 구축합니다.\n\n이러한 절차를 따르면 조직은 MLOps의 장점을 극대화하여 AI 모델이 효율적이고 성공적으로 생성, 전송 및 유지되도록 보장하며 가치와 성장을 이끌어냅니다.\n\n# 실제 적용 사례\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-07-09-WhatisMLOpsMachineLearningOperationsExplained_3.png\" />\n\nMLOps은 이론적인 개념뿐만 아니라 다양한 산업 분야에서 현실 세계 문제 해결을 위해 적용될 수 있습니다. 아래는 MLOps가 실무에서 활용되는 몇 가지 예시입니다:\n\n- **의료 분야:** 의료 분야에서는 환자 결과 예측, 진단 지원, 그리고 치료 계획 개인화를 예측하는 모델을 배포하고 관리하는 데 MLOps가 활용됩니다. 지속적인 모니터링은 모델이 새로운 데이터에 적응하여 정확도와 환자 치료를 향상시킵니다.\n- **금융 분야:** 은행 및 금융 기관은 신용 위험 모델 관리, 사기 거래 감지, 그리고 개인화된 고객 서비스에 MLOps를 활용합니다. MLOps를 통해 이러한 모델들이 최신 상태를 유지하고 새로운 데이터가 입력될 때 잘 수행되도록 보장합니다.\n- **소매 분야:** 소매업체는 재고 최적화, 제품 추천, 그리고 공급망 관리를 위해 MLOps를 활용합니다. MLOps는 변화하는 소비자 행동과 시장 트렌드에 적응하는 모델들을 신속하게 배포하는 것을 돕습니다.\n- **제조업:** 제조업에서는 예측 유지보수, 품질 통제, 그리고 공정 최적화를 촉진하는데 MLOps를 활용합니다. 모델은 지속적으로 모니터링되고 업데이트되어 다운타임을 예방하고 효율성을 향상시킵니다.\n- **자율 주행차:** MLOps는 자율 주행을 위한 모델 개발과 배포를 지원하며, 차량에서 수집된 새로운 데이터를 통해 업데이트되어 안전성과 성능을 향상시키는 것을 보장합니다.\n- **엔터테인먼트:** 스트리밍 서비스는 콘텐츠 추천 개인화, 사용자 경험 향상, 스트리밍 품질 최적화에 MLOps를 적용합니다. 모델의 지속적인 개선이 시청자의 참여를 유지하는 데 중요합니다.\n\n이러한 예시들은 다양한 분야에서 MLOps의 다재다능성과 영향을 보여줍니다. 기계 학습 모델의 효율적인 배포와 관리를 가능케 함으로써 MLOps는 기업이 AI의 힘을 활용하여 혁신을 추구하고 운영 효율성을 향상시키며 고객 경험을 개인화하는 데 도움이 됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n요약하면, MLOps는 기계 학습 개발과 운영을 연결해주는 다리 역할을 하며, 기계 학습 모델의 배포 및 유지보수를 간소화하고 향상시키는 것을 목표로 합니다.\n\nMLOps를 숙달하고 능숙한 데이터 과학자가 되기 위한 여정은 지속적인 학습과 실전 연습으로 마련되어 있습니다.\n\n원본 게시물: https://www.stratascratch.com.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Stackademic 🎓\n\n끝까지 읽어주셔서 감사합니다. 떠나시기 전에:\n\n- 작가를 응원하고 팔로우해주시면 감사하겠습니다! 👏\n- 다음 계정도 팔로우해주세요: X | LinkedIn | YouTube | Discord\n- 다른 플랫폼도 방문해주세요: In Plain English | CoFeed | Differ\n- 더 많은 콘텐츠는 Stackademic.com에서 확인하실 수 있습니다.","ogImage":{"url":"/assets/img/2024-07-09-WhatisMLOpsMachineLearningOperationsExplained_0.png"},"coverImage":"/assets/img/2024-07-09-WhatisMLOpsMachineLearningOperationsExplained_0.png","tag":["Tech"],"readingTime":11},{"title":"Pandas 코드 최적화 연산 순서가 미치는 영향","description":"","date":"2024-07-09 20:47","slug":"2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence","content":"\n\n## 파이썬 프로그래밍\n\n![image](/assets/img/2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence_0.png)\n\nPandas는 데이터프레임에서 작업할 때 환상적인 프레임워크를 제공합니다. 데이터 과학에서는 작은 데이터프레임부터 크고 때로는 아주 큰 데이터프레임까지 다룹니다. 작은 데이터프레임을 분석하는 것은 매우 빠를 수 있지만, 큰 데이터프레임에서 심지어 단일 작업도 상당한 시간이 걸릴 수 있습니다.\n\n이 글에서는 종종 데이터프레임에서 작업 순서를 바꿈으로써 이 시간을 단축시킬 수 있다는 것을 보여 드리겠습니다. 이 작업은 사실상 아무 비용도 들지 않는 방법입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 데이터프레임을 상상해봅시다:\n\n```js\nimport pandas as pd\n\nn = 1_000_000\ndf = pd.DataFrame({\n    letter: list(range(n))\n    for letter in \"abcdefghijklmnopqrstuwxyz\"\n})\n```\n\n100만 행과 25개의 열을 갖고 있어요. 이렇게 큰 데이터프레임에서 다양한 작업을 수행하면 현재 개인 컴퓨터에서 눈에 띌 것입니다.\n\n가령, 다음 조건을 따르는 행만 필터링하여 가져와야 한다고 상상해보죠: `a` 50,000이상 그리고 `b` 3,000이상, 그리고 `a`, `b`, `g`, `n`, `x` 열 다섯 개만 선택해야 한다면, 다음과 같이 할 수 있어요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\r\nsubdf = df[take_cols]\nsubdf = subdf[subdf['a'] < 50_000]\nsubdf = subdf[subdf['b'] > 3000]\r\n```\n\n위 코드에서는 먼저 필요한 열을 가져와서 행을 필터링합니다. 동일한 결과를 얻을 수 있으며, 연산의 순서를 바꿔서 먼저 필터링을 수행한 다음 열을 선택할 수도 있습니다:\n\n```js\r\nsubdf = df[df['a'] < 50_000]\nsubdf = subdf[subdf['b'] > 3000]\nsubdf = subdf[take_cols]\r\n```\n\n더불어 Pandas 연산을 연결하여 동일한 결과를 얻을 수도 있습니다. 해당 명령의 연결은 다음과 같습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 칼럼을 먼저 선택한 다음 행을 필터링합니다.\ndf.filter(take_cols).query(query)\n\n# 행을 먼저 필터링한 다음 칼럼을 선택합니다.\ndf.query(query).filter(take_cols)\n```\n\ndf가 크기 때문에 네 가지 버전 간 성능이 다를 것으로 예상됩니다. 어느 것이 가장 빠를까요? 가장 느릴까요?\n\n# 벤치마크\n\n이 작업을 벤치마크해보겠습니다. timeit 모듈을 사용할 것입니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아니면 IPython 쉘에서 이용 가능한 버전입니다.\n\n저희의 벤치마크는 다음과 같습니다:\n\n![벤치마크 이미지](/assets/img/2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence_1.png)\n\n다음 섹션에서는 벤치마크 결과를 분석한 후 결과를 해석하겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결과\n\n## Bracketing: 열 선택한 다음 행 필터링하기 (16.5 ms)\n\n```js\nsubdf = df[take_cols]\nsubdf = subdf[subdf['a'] < 50_000]\nsubdf = subdf[subdf['b'] > 3000]\n```\n\n이 코드에서는 Tipycal Pandas 코드로 괄호, 불리언 인덱싱 및 대입을 사용했습니다. 예상 결과를 얻기 위해 다음 순서대로 세 줄을 사용했습니다: 먼저 열 하위 집합을 선택하고 그런 다음 두 개의 필터링 조건을 순차적으로 적용했습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n네 가지 접근법 중에서 이 방법은 비교적 빨랐어요 — 하지만 가장 빠른 방법은 아니었어요. 먼저 열을 선택하면 df 데이터프레임의 너비가 줄어들지만, 데이터프레임이 큰 이유는 주로 너비가 아니라 행의 수 때문이에요. 이렇게요¹:\n\n```js\nIn [7]: n_of_elements = lambda d: d.shape[0]*d.shape[1]\n\nIn [8]: n_of_elements(df)\nOut[8]: 25000000\n\nIn [9]: n_of_elements(df.filter(take_cols))\nOut[9]: 5000000\n\nIn  [10]: n_of_elements(df.query(query))\nOut [10]: 1174975\n```\n\n보시다시피 열을 먼저 제거할 때 (df.filter(take_cols)), 500만 개 요소를 갖는 데이터프레임을 얻을 수 있고, 행을 먼저 필터링할 때 (df.query(query))는 100만 개가 넘는 요소를 가진 데이터프레임을 얻게 돼요. 이는 네 배 이상 작은 크기에요.\n\n불필요한 열을 먼저 제거하면 불필요한 행을 먼저 제거하는 것보다 작업이 느려질 것이 당연해요 — 다음 섹션에서 보여줄게요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 괄호 사용: 행 필터링 후 열 선택 (10.7 ms)\n\n```js\nsubdf = df[df['a'] < 50_000]\nsubdf = subdf[subdf['b'] > 3000]\nsubdf = subdf[take_cols]\n```\n\n이 코드는 브래킷, 부울 인덱싱, 및 할당을 기반으로 한 전형적인 판다스 코드를 사용하지만, 이번에는 데이터프레임의 크기를 줄이기 위해 먼저 행이 필터링됩니다. 그런 다음 선택된 열이 가져와집니다.\n\n이는 시험한 네 가지 방법 중에서 명백히 가장 빠른 방법입니다. 효율성 향상은 데이터프레임 크기의 초기 감소로 인해 얻어지며, 결과적으로 후속 단계에서 처리해야 하는 더 작은 데이터셋을 제공합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이전 방법과 이 접근 방식에서 우리는 진정한 벡터화된 Pandas 코드를 사용했습니다. 이는 직접 부울 인덱싱을 사용했다는 것을 의미합니다. 이론적으로 가장 성능이 우수한 Pandas 코드를 제공하는 것은 벡터화된 연산이며, 그것을 볼 수 있습니다. 두 가지 버전 간의 차이는 우리가 방금 분석한 내용에서 나타납니다: 데이터프레임 크기를 가장 줄일 것으로 생각되는 이 작업을 먼저 사용해야 합니다.\n\n## Pipes: 열 선택 후 행 필터링 (26.0 ms)\n\n```python\ndf.filter(take_cols).query(query)\n```\n\n이 코드는 연결된 Pandas 연산을 사용합니다. 먼저 행을 필터링한 다음 필요한 열을 가져옵니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n판다스 데이터프레임의 .query() 메서드는 전통적인 판다스/넘파이 의미의 벡터화된 연산을 사용하지 않습니다. 대신, numexpr Python 패키지를 사용합니다. 이론적으로는 문서에 설명된 대로,\n\n우리가 실험한 결과로는 불리언 인덱싱을 기반으로 한 벡터화된 연산보다 속도가 느린 것을 확인했습니다.\n\n우리의 벤치마크로 돌아와서, 이 코드는 관찰된 코드 중에서 분명히 가장 느립니다. 이에는 두 가지 이유가 있습니다: 판다스 연산을 연쇄적으로 하는 것이 벡터화하는 것보다 느리며, 우리가 방금 논의한 대로, 먼저 열의 수를 줄이는 것이 먼저 행을 필터링하는 것보다 이 데이터셋에 효율적이지 않습니다. .filter() 메서드는 데이터프레임의 크기를 줄이지만, 이 감소는 .query()를 사용하여 행 수를 줄인 후에 얻은 감소보다 4배 이상 작습니다.\n\n## Pipes: 행을 필터링한 다음 열을 선택합니다 (17.3 ms)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ndf.query(query).filter(take_cols)\n```\n\n이 코드는 이전 것의 개선된 버전으로 간주할 수 있습니다. 이미 필요 없는 행을 먼저 없애야 하고, 그 후에 필요한 열을 선택해야 한다는 것을 알고 있습니다. 이 코드는 Pandas 연산을 연쇄적으로 수행하여 이 작업을 수행합니다.\n\n이 방법은 이전 방법(열을 선택한 후 .query()가 적용되는 파이프)보다 효율적이지만, 여전히 해당 벡터화된 코드와 성능이 맞지는 않습니다. 덜 효과적인 순서에서 벡터화된 코드와 거의 유사한 성능을 보입니다.\n\n# 해석\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n[본문 내용]\n\n벤치마크 결과에서는 다음과 같은 관찰이 일어났습니다. 이는 벡터화된 연산과 연산 순서의 중요성을 강조합니다:\n\n- 먼저 벡터화된 행 필터링: 결과는 데이터프레임 크기를 최대한 처음에 줄이는 것의 중요성을 강조합니다. 먼저 행의 수를 줄이면 이후의 작업(우리의 경우, 열 선택)이 더 작은 데이터셋에서 작동하므로 속도가 향상됩니다.\n- 열 선택의 효율성: 열 선택으로 워크플로우를 시작하면 데이터프레임을 좁힘으로써 메모리 사용량을 줄일 수 있습니다. 이는 실행 시간을 줄이는데 이어집니다. 그러나 이 줄임이 행 필터링으로 시작했을 때보다 작습니다. 따라서 이 버전은 처리 속도에 최적화되어 있지 않습니다.\n- 연쇄적인 작업: 이는 이 기사의 주제가 아니지만, Pandas 작업을 연쇄하는 것은 벡터화하는 것보다 효율적이지 않음을 관찰했습니다. 파이프의 실행 시간 (17.3 ms 및 26 ms)은 이 현상을 보여줍니다. 해당 시간은 해당 벡터화된 작업(각각 10.7 ms 및 16.5 ms)보다 더 느립니다.\n\n그러나 이해해야 할 점은 이해가 일반적이 아니라는 것입니다. 이는 우리의 벤치마크 및 분석한 특정 시나리오를 참조합니다.\n\n여러분에게 연습 문제를 남기겠습니다: ` 50_000 또는 b ` 3000 중 어떤 행 필터링을 먼저 적용하느냐에 따라 어떤 영향이 있을까요?\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 행보다 열이 많음\n\n위에서는 행보다 열이 더 많은 데이터프레임을 다루었지만, 상황이 정반대인 경우는 어떨까요? 즉, 훨씬 많은 열이 있고 훨씬 적은 행이 있는 데이터프레임을 다루는 경우를 생각해보겠습니다.\n\n위에서 배운 내용을 바탕으로, 우리가 작업 순서를 선택하는 주요 기준은 결과 데이터프레임의 크기입니다. 그래서 다음 시나리오를 분석해봅시다: \n\n![이미지](/assets/img/2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence_2.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이거 봤어요? 718 µs 대 121 ms로 첫 번째 접근 방식(먼저 열을 선택)이 훨씬 빠릅니다. 거의 170 배나 빠르죠! 그 이유는 이전과 같아요 — 첫 번째 작업 후 데이터프레임의 크기 때문이에요. 이번에는 차이가 엄청나죠:\n\n![이미지](/assets/img/2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence_3.png)\n\n두 번째 작업도 매우 다른 크기의 데이터프레임에서 작동합니다:\n\n![이미지](/assets/img/2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence_4.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nPandas 연쇄 작업은 이러한 데이터프레임에 대해 매우 비효율적으로 작동하는 흥미로운 점입니다:\n\n![Image](/assets/img/2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence_5.png)\n\n열을 먼저 처리했음에도 불구하고 이 파이프는 위의 느린 작업보다 시간을 세 배나 적게 소요했음을 유념하세요. 순서를 바꾼 상태의 대응하는 파이프를 벤치마킹 해보려고 했지만, 3시간 후에 벤치마킹을 종료했습니다:\n\n![Image](/assets/img/2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence_6.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 태그를 마크다운 형식으로 변경해 보겠습니다.\n\n# 결론\n\n저희 실험은 판다스에서 데이터 조작의 중요한 원칙을 보여줍니다: 가능한 한 빨리 데이터셋 크기를 줄이는 것이 성능을 크게 향상시킬 수 있습니다, 특히 벡터화된 행 필터링 작업을 통해.\n\n이 권장 사항은 놀랍지 않을 수 있지만 상당히 분명해 보입니다. 과거에 가끔 이를 따르지 못한 적이 있었는데, 앞으로는 판다스 작업의 순서에 대해 생각해야겠다고 확실히 기억하겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n작은 데이터프레임을 대화식 세션에서 분석할 때는 성능 차이를 무시하고 선호하는 코드를 사용해도 됩니다. 그러나 실제 운영 코드에서는 작은 데이터프레임이나 대규모 데이터프레임을 분석할 때 작업 순서가 상당한 차이를 만들 수 있습니다.\n\n첫 번째 예시에서 행 필터링을 열 선택보다 먼저 적용하는 것이 더 효율적인 전략으로 나타났습니다. 그러나 이는 일반적으로 나타나는 현상은 아니며 데이터프레임에 따라 다릅니다.\n\n우리는 데이터프레임의 요소 수를 주요 기준으로 사용했지만, 데이터프레임이 길거나 넓은지도 중요한 점입니다. 요소 수가 동일한 두 데이터프레임을 분석했을 때 성능에 큰 차이를 확인했습니다.\n\n따라서 성능이 중요하다면 각각의 데이터프레임을 개별적으로 분석하고 모양과 크기를 고려하여 작업 순서를 신중히 선택해야 합니다. 이 통찰력은 특히 대용량 데이터셋을 다룰 때 판다스 워크플로를 최적화하는 데 매우 소중합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n요약해 봅시다. 저희의 벤치마크는 Pandas 작업을 구현하는 데 다음과 같은 주요 통찰을 제공합니다:\n\n- Pandas 작업에 벡터화를 적용하면 Pandas 작업을 연쇄하는 것보다 성능이 더 우수한 코드를 얻을 수 있습니다.\n- 일반적으로 여러 Pandas 작업을 포함하는 성능이 우수한 코드를 구현하려면 데이터프레임의 모양과 크기에 따라 후속 단계에서 데이터프레임의 크기를 가장 크게 줄일 작업부터 시작하고, 이를 가장 적게 줄이는 작업으로 끝냅니다.\n- 성능이 중요한 경우, 데이터프레임의 모양과 크기를 고려하여 각 코드 조각을 개별적으로 최적화합니다.\n\n# 각주\n\n¹ 이 코드에서는 다음 람다 정의를 사용하여 명명된 함수를 정의했습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nIn [7]: n_of_elements = lambda d: d.shape[0]*d.shape[1]\n```\n\n네, 이름 붙은 람다 정의를 사용했어요. 여기에서 설명한 대로:\n\n이론적으로는 이름 붙은 람다를 사용하지 말아야 하지만,\n\n여기에서는 이 규칙의 예외를 보여드려요: 저장이나 배포되지 않는 데이터 분석 코드를 사용할 때요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n재밌게도, 이 정확한 코드를 배포했어요. 하지만 반항적으로 하는 게 아니라 어떤 점을 강조하기 위해서였죠.","ogImage":{"url":"/assets/img/2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence_0.png"},"coverImage":"/assets/img/2024-07-09-OptimizingPandasCodeTheImpactofOperationSequence_0.png","tag":["Tech"],"readingTime":13},{"title":"일상적인 프로덕션 프로젝트에서 사용하는 파이썬 도구들  Part I","description":"","date":"2024-07-09 20:45","slug":"2024-07-09-PythonThingsIUseInDayToDayProductionProjectsPartI","content":"\n\n\n![Python Project](/assets/img/2024-07-09-PythonThingsIUseInDayToDayProductionProjectsPartI_0.png)\n\nLet's talk about real-world projects. I like to share things that can have a real impact on your Python journey, and today I've decided to share how I structure, code, test, and deploy a real Python project.\n\n— What do I do?\n\nTo provide more context, I work as a Solution Engineer (SE) at a Spanish company. As an SE, my tasks range from creating customized systems to helping speed up integration with a new customer through APIs.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희 팀에서는 FastAPI를 사용하여 API를 개발하고, Streamlit을 사용하여 간결한 사용자 인터페이스(UI)를 구축합니다.\n\n이 글에서는 다음과 같은 내용을 공유하겠습니다:\n\n- Python 프로젝트 구조화 방법\n- 도움이 될 수 있는 Python 기능들\n\n그럼, 더 이상 언제까지 기다릴 필요 없이 바로 시작해보겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 파이썬 프로젝트 구조화 방법\n\n새 프로젝트를 구조화하는 것은 쉬운 일이 아닙니다. 어떤 파일을 먼저 만들어야 하는지, 어떤 폴더가 필요한지 고민하게 됩니다.\n\n시간이 지남에 따라 모든 프로그래머는 작업을 더 쉽게 할 수 있는 자신만의 구조화 스타일을 개발하게 됩니다. 프로젝트를 어떻게 구조화할지 결정하는 데 도움이 되도록 다음 목록을 만들었습니다:\n\n- 각 모듈과 패키지는 자명해야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모듈의 이름만으로도 모듈의 목적을 명확히 이해할 수 있어야 합니다. 이름이 모듈이 무엇을 위한 것인지 말하지 않는다면, 그것은 좋지 않은 이름입니다.\n\n```python\n# connection.py - 데이터베이스에 연결하기 위한 모듈\nasync def connect[T](*args, **kwargs) -> T:\n    pass\n```\n\nconnection.py 모듈은 데이터베이스에 연결을 만들고 해당 연결을 반환하는 모듈입니다. 현재 이름만으로는 명확하지 않을 수 있습니다. 이 연결은 무엇에 대한 연결인가요? 파일 서버인가요? SSH 연결인가요?\n\n하지만 이 모듈을 올바른 모듈에 배치하면 명확해집니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n.\n├── my_app\n│   ├── __init__.py\n│   └── db\n│       ├── __init__.py\n│       └── connection.py\n\n\n우리에게는 이제 Database를 의미하는 db라는 패키지가 있습니다. 그래서 Database와 관련된 모든 것이 거기에 있다고 가정합니다. 그 중에 connection도 포함되어 있겠네요.\n\n— 모든 것은 자신의 자리가 있다\n\n저는 일을 체계적으로 정리하는 것을 좋아합니다. 코딩할 때는 다른 프로그래머들이 나와 함께 작업해야 할 경우에는 무엇을 생각하게 될지 또는 제가 떠난 후에 작업을 계속해야 할 경우를 피해 생각할 수 없습니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n내 코드를 보고 \"이딴 쓰레기 코드가 뭐냐?\" 라고 말하지 않도록 하고 싶어.\n\n그런 일이 생길 수 있어. 내 이전 프로젝트에 대해 누군가가 그런 말을 했을 거야. 그런 점은 미안해. 그때는 더 좋은 방법을 몰랐거든.\n\n내가 하는 SE의 일 중 하나는 클라이언트를 통합하는 데 도움이 되는 API를 만드는 것이야. API는 기본적으로 엔드포인트로 이루어져 있어. 각 엔드포인트는 API에 연결되는 경로야.\n\n예를 들어, 우리 API가 주문과 제품을 다룬다고 해보자. 각 주문과 관련된 작업은 특정 엔드포인트를 호출함으로써 이루어지고, 제품도 마찬가지야.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# main.py\nfrom fastapi import FastAPI  # fastapi 모듈이 설치되어 있다고 가정합니다\n\napp = FastAPI()\n\n@app.post('/order')\nasync def create_order[T](payload: T):\n    # 새로운 주문을 생성하는 함수\n    pass\n\n@app.patch('/order/{id}')\nasync def update_order[T](payload: T, id: int | str):\n    # 주문 내용을 업데이트하는 함수\n    pass\n\n@app.get('/order/{id}')\nasync def get_order[T](id: str | int) -> T:\n    # ID에 따라 주문을 반환하는 함수\n    pass\n\n@app.get('/orders')\nasync def all_orders[T]() -> list[T]:\n    # 모든 주문을 반환하는 함수\n    pass\n\n@app.get('/order/{id}')\nasync def delete_order(id: str | int):\n    # ID에 따라 주문을 삭제하는 함수\n    pass\n```\n\n위에서도 보시다시피 주문에 대한 엔드포인트가 이미 많이 있습니다. 새로운 작업이 필요한 경우 더 많아질 수 있습니다. 마찬가지로 main.py 파일에 제품과 관련된 모든 필요한 엔드포인트를 만들 경우 유지 관리가 어려워질 수 있습니다.\n\n각각의 엔드포인트를 따로 관리하는 것이 좋은 접근 방식일 것입니다. 저는 routes 패키지를 생성하여 각 작업에 따른 모든 엔드포인트를 담는 것을 좋아합니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n.\n├── my_app\n│   ├── __init__.py\n|   ├── main.py\n│   └── db\n│   │   ├── __init__.py\n│   │   ├── connection.py\n|   └── routes\n│       ├── __init__.py\n│       └── order.py\n│       └── product.py\n```\n\n따라서 주문과 관련된 모든 엔드포인트는 order.py 파일 안에 있게 됩니다:\n\n```js\n# routes/order.py\nfrom fastapi import APIRouter # fastapi가 설치되어 있다고 가정합니다.\n\n\nrouter = APIRouter()\n\n@router.post('/order')\nasync def create_order[T](payload: T):\n    # 새 주문을 생성하는 함수\n    pass\n\n@router.patch('/order/{id}')\nasync def update_order[T](payload: T, id: int | str):\n    # 주문 내용을 업데이트하는 함수\n    pass\n\n@router.get('/order/{id}')\nasync def get_order[T](id: str | int) -> T:\n    # 주문 ID로 주문을 반환하는 함수\n    pass\n\n@router.get('/orders')\nasync def all_orders[T]() -> list[T]:\n    # 모든 주문을 반환하는 함수\n    pass\n\n@router.get('/order/{id}')\nasync def delete_order(id: str | int):\n    # 주문 ID로 주문을 삭제하는 함수\n    pass\n```\n\n이렇게 하면 main.py 모듈의 주요 프로젝트에 루트를 연결할 수 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nfrom fastapi import FastAPI\nfrom routes import order\n\napp = FastAPI()\n\n# 주문용 라우터 추가\napp.include_router(order.routes)\n```\n\n프로젝트가 성장하면서 새로운 라우트 모듈을 추가할 때도 같은 작업을 수행합니다.\n\n— 반복하지 말고(Don't Repeat Yourself, DRY)\n\n대부분의 경우, 우리는 불필요하게 같은 것을 반복하고 있습니다. 그러나 코드를 반복하지 않고 간단하게 만드는 것은 생각보다 쉽지 않을 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n코드를 여러 곳에서 쉽게 재사용할 수 있도록 단순화하는 것에는 몇 가지 생각과 계획이 필요합니다. 다른 곳에서 예기치 않은 동작이 발생하지 않도록 변경 사항을 주의 깊게 확인하고 대비해야 합니다.\n\nDRY는 소프트웨어 개발 원칙 중 하나로, Don't Repeat Yourself의 약자로, 한 번만 정의하고 중복을 피하는 것을 강조합니다.\n\n나의 프로젝트 구조에서는 보통 모듈 간에 공유되는 것들을 모아 둔 commons라는 패키지가 항상 있습니다:\n\n```js\n.\n├── my_app\n│   ├── __init__.py\n|   ├── main.py\n│   └── db\n│   │   ├── __init__.py\n│   │   ├── connection.py\n|   └── routes\n│   |   ├── __init__.py\n│   |   └── order.py\n│   |   └── product.py\n|   └── commons\n│       ├── __init__.py\n|       └── base_response.py\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프로젝트에서 각 엔드포인트마다 응답 객체를 반환한다고 가정해 봅시다. 주문 및 제품에 대한 응답 구조는 동일해야 하지만 각각에 따라 값이 다를 수 있습니다.\n\n제가 하는 방식은 나머지 부분에서 상속될 수 있는 기본 응답 객체를 만드는 것입니다. 사용자 정의 구현을 가질 수 있는 메서드는 기본에 구현되지 않으며, 구현은 자식 클래스에 맡겨 둡니다.\n\n```js\n# ResponseObject에 대한 기본 클래스 - commons/base_response.py\nclass BaseResponse:\n    def __init__(self, *args, **kwargs) -> None:\n        pass\n\n    def some_method(self, *args, **kwargs) ->:\n        raise NotImplementedError # 구현을 자식 클래스에 맡깁니다\n\n    def status(self, code: int) -> bool:\n        return 200 < code <= 299 # 기본 클래스에서 구현됨\n\n    def another_method[T](self, *args, **kwargs) -> T:\n        # 무언가를 수행\n```\n\n— 컨트롤러, 모델 및 스키마\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n제품 생성, 주문 등을 만드는 기능이 어딨는지 궁금할 수 있습니다.\n\n과거에는 MVC 패턴을 따랐었는데요. M은 모델을 뜻하며, 여기에는 모든 모델이 들어갈 패키지가 있었습니다. V는 뷰로, 주문과 같은 경로(예: 주문 경로)가 모두 들어갔고, C는 컨트롤러로, 데이터베이스에 연결하고 제품을 생성하는 로직 등이 포함되어 있었죠.\n\n저는 M과 C를 \"버리기\"를 좋아해요. 주문을 위한 패키지를 가지는 것을 선호하며, 여기에는 모델/스키마와 해당 독점 로직이 모두 포함됩니다.\n\n\n.\n├── my_app\n│   ├── __init__.py\n│   ├── main.py\n│   └── db\n│   │   ├── __init__.py\n│   │   ├── connection.py\n|   └── routes\n│   |   ├── __init__.py\n│   |   └── order.py\n│   |   └── product.py\n|   └── commons\n│   |   ├── __init__.py\n|   |   └── base_response.py\n|   └── order\n│       ├── __init__.py\n|       └── schemas.py\n|       └── response.py # base_response.py를 상속받을 것임\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n— 테스트\n\n여기서 놀라운 점은 없어요. 모든 프로젝트에서 프로젝트의 루트에 테스트 폴더가 있습니다. 저는 pytest를 사용해서 테스트하는 것을 선호하며, 모든 테스트 폴더에는 공유 픽스처가 있는 contest.py 모듈이 있습니다.\n\n```js\n.\n├── my_app\n│   ├── __init__.py\n|   ├── main.py\n│   └── db\n│   │   ├── __init__.py\n│   │   ├── connection.py\n|   └── routes\n│   |   ├── __init__.py\n│   |   └── order.py\n│   |   └── product.py\n|   └── commons\n│   |   ├── __init__.py\n|   |   └── base_response.py\n|   └── tests\n│       ├── __init__.py\n|       └── conftest.py\n```\n\n테스트에 대해 더 알아보려면:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프로젝트 의존성\n\n모든 환경에서 실행되기 위해 프로젝트에는 필요한 종속 항목이 있습니다.\n\n이러한 종속 항목은 다음과 같을 수 있습니다:\n\n- 모든 Python 종속 항목이 존재하는 요구 사항 파일\n- 프로젝트 구성이 있는 설정 파일\n- 이미지를 만들기 위한 Dockerfile (Docker를 사용하는 경우)\n- 린트 및 테스트와 같은 작업을 실행하기 위한 모든 명령 및 구성이 포함된 Makefile\n- 라이선스 파일 및 README 파일\n- 기타.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n.\n├── my_app\n│   ├── __init__.py\n|   ├── main.py\n│   └── db\n│       ├── __init__.py\n│       ├── connection.py\n|   └── routes\n│       ├── __init__.py\n│       ├── order.py\n│       └── product.py\n|   └── commons\n|       ├── __init__.py\n|       └── base_response.py\n|   └── tests\n|       ├── __init__.py\n|       └── conftest.py\n├── settings.py\n├── Dockerfile\n├── Makefile\n├── README\n└── requirements.txt\n```\n\n## 제가 사용하는 파이썬 기능 중 도움이 될 수 있는 것들\n\n제가 파이썬 기능과 코드를 향상시키는 멋진 기능에 대해 많이 쓰고 있습니다.\n\n하지만 제 프로젝트에서 얼마나 그것을 사용하고 있을까요?\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n— match/case부터 시작해봐요.\n\nPython 3.10에 도입된 match 문은 복잡한 if-elif-else 또는 딕셔너리 기반 구조의 간결하고 읽기 쉬운 대안을 제공합니다.\n\nif-elif-else의 대안이 아닌 것을 위해 사용할 수도 있지만, 저는 자주 if-elif 블록을 사용할 때 이를 활용해왔어요.\n\n```js\nmatch expression:\n    case a:\n        # a 케이스에서 할 일\n    case b:\n        # b 케이스에서 할 일\n    case c:\n        # c 케이스에서 할 일\n    case d:\n        # d 케이스에서 할 일\n    case e:\n        # e 케이스에서 할 일\n    case _:\n        # 이전 케이스들에 해당하지 않을 때, 다른 일 수행\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n— Python의 typing에서 제네릭 타입 — TypeVar\n\n이 기사에서 볼 수 있는 대부분의 예제에서 제네릭 타입을 사용해 왔습니다. 엔드포인트, 함수, 그리고 클래스에서도 사용하고 있죠.\n\n```js\n# ResponseObject의 기본 클래스 - commons/base_response.py\nclass BaseResponse:\n    # 클래스의 나머지 부분은 그대로 유지\n\n    def another_method[T](self, *args, **kwargs) -> T:\n        # 어떤 일을 수행\n```\n\n여기에서는 제네릭 타입 T를 받아 제네릭 타입인 T를 반환하는 함수를 정의했습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n— @override 데코레이터\n\n이 글에서 사용된 예시 중 하나는 다른 응답 객체들에 의해 상속될 base_response.py라는 기본 응답 클래스입니다.\n\n기본 클래스의 일부 메소드는 각 응답 객체에 따라 사용자 정의되거나 재정의될 것입니다.\n\n따라서 해당 메소드를 재정의하고 있는 것을 명시적으로 표시하기 위해, PEP 698에서 소개된 @override 데코레이터를 사용합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# order/response.py\nfrom typing import override\nfrom commons.base_response import BaseResponse\n\nclass Response(BaseResponse):\n    def some_method(self, *args, **kwargs) ->:\n        # do something\n\n    @override\n    def another_method[T](self, *args, **kwargs) -> T:\n        # change the behavior of this method\n```\n\n이 부분에 대해 더 자세하게 이야기하겠습니다:\n\n## 마지막으로\n\n각 프로젝트는 새로운 것을 배우고 적용할 수 있는 새로운 기회입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n새로운 프로젝트를 시작할 때마다 솔직히 말하면 좀 무서워해. 하지만 프로젝트를 구조화하고 코딩을 시작하자마자 그 두려움은 사라져.\n\n물론, 어차피 하나에 짜증나는 버그가 있으면 그때는 삶의 선택에 대해 다시 생각하게 만들 수 있지.\n\n프로젝트를 구조화하는 것은 집을 정리하는 것과 비슷해. 우리 모두 정리하고 조직하는 방법이 있지. 중요한 건 우리가 최선을 다해 보다 깨끗하고 잘 정리된 상태로 만들어 놓는 거야. 그래서 우리나 다른 누군가가 무언가를 찾아야 할 때 쉽게 찾을 수 있도록 해야 해.\n\n안녕하세요! 제 글을 읽어주셔서 감사합니다. 이 글을 즐기셨다면 비슷한 내용을 직접 이메일로 받아보고 싶다면\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 친절한 한국어 번역 🚀\n\nIn Plain English 커뮤니티에 참여해 주셔서 감사합니다! 다 가시기 전에:\n\n- 작가를 추천하고 팔로우해주세요 👏\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼을 방문해보세요: Stackademic | CoFeed | Venture | Cubed\n- 더 많은 콘텐츠: PlainEnglish.io","ogImage":{"url":"/assets/img/2024-07-09-PythonThingsIUseInDayToDayProductionProjectsPartI_0.png"},"coverImage":"/assets/img/2024-07-09-PythonThingsIUseInDayToDayProductionProjectsPartI_0.png","tag":["Tech"],"readingTime":15},{"title":"인과 검증과 인과 추론에서 V-구조의 중요성과 그 역할 이해하기","description":"","date":"2024-07-09 20:40","slug":"2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference","content":"\n\n<img src=\"/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_0.png\" />\n\n# 소개\n\n인과 추론은 머신 러닝 내에서 부상하고 있는 분야로, 무엇이 발생할 수 있을지 예측하는 것을 넘어서 왜 그렇게 일어날 것인지 설명할 수 있어서 잠재적인 파급 효과를 다루는 것보다 기본적인 문제를 영구적으로 해결하는 약속을 제공합니다.\n\n인과 추론 문제를 해결하려면 “Directed Acyclic Graph” 또는 DAG에 인과 요소들을 시각화하는 것이 필요하며, 일반적으로 체계나 프로세스의 인과 관계에 대한 정보를 갖춘 도메인 전문가가 개발합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 방식의 한 가지 난제는 도메인 전문가들의 견해가 부정확하거나 편향될 수 있다는 것입니다. 정확한 DAG가 없으면 인과 모델의 결과와 출력물이 부정확해져서 효과적이지 않을 수 있습니다. 따라서 DAG가 원인 관계를 정확히 나타낼 수 있도록 하는 과정을 '인과 유효성 검증'이라고 합니다.\n\n인과 유효성 검증 내에서 특정한 문제는 두 변수 사이의 인과 관계 방향을 감지하는 것입니다. 예를 들어, 경영 자격증 공부가 승진을 \"유발\"하지만, 신규로 승진한 매니저들이 기술을 향상시키기 위해 자격증을 취득하기 시작할 수도 있습니다.\n\n실제 세계에서 사건의 시기나 순서를 확립하는 것이 도움이 될 수 있습니다. 예를 들어, 직원 중 90%가 먼저 공부하고 나중에 승진했다면 인과 관계가 명확해질 것입니다. 하지만 오직 상관 관계를 나타내는 과거 데이터만 있는 경우, 인과 관계 방향이 명확하지 않을 수 있습니다.\n\n## 문제점\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n인과 관계 링크의 방향성을 확인하는 것은 어려우며 보기에 불가능해 보입니다.\n\n## 기회\n\n인과 관계 링크의 방향을 확인할 수있는 알고리즘이 있다면, DAG의 정확성을 향상시키고 이로 인해 인과 모델의 예측에 대한 신뢰를 제공하여 중요한 가치를 더할 수 있습니다.\n\n## 계획\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDAG(Directed Acyclic Graph) 내에서 특정 종류의 결합인 v-structure은 DAG 내에 존재하는 연결을 나타내는 데 사용할 수 있습니다. 이를 통해 방향이 잘못된 화살표가 있음을 나타내고 이를 수정하기 위해 DAG 내에서 뒤집어져야 하는 위치를 제안하는 데 사용할 수 있습니다.\n\n# 시작하기\n\n## 방향성 비순환 그래프 선택\n\n먼저 기사 전체에서 사용될 완전히 가상의 DAG(Directed Acyclic Graph)를 선택하는 것으로 시작해 보겠습니다. 저는 이 DAG가 테스트에 사용하기 충분히 간단하지만 보다 복잡한 예제에서 발견되는 모든 변형을 포함할 만큼 복잡하다는 이유로 이 DAG가 제일 좋아하는 DAG 중 하나입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Understanding V-Structures and the Critical Role They Play in Causal Validation and Causal Inference](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_1.png)\n\nX는 \"치료\" 또는 원인이고 Y는 \"결과\" 또는 효과이며 인과 추론의 목표는 다른 변수들의 효과와 독립적으로 치료가 결과에 미치는 진정하고 고립된 효과를 확인하는 것입니다.\n\n실제 세계에서 X는 새로운 약을 복용하는 것을 나타낼 수 있고, W는 혈압에 미치는 약의 효과일 수 있으며, Y는 환자 결과의 개선일 수 있지만, 예시의 목적을 위해 제가 단순히 문자를 선택했습니다.\n\n## 테스트 데이터 생성\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n실제 예제에서는 데이터 세트로 시작하고 도메인 전문가들이 자신의 전문지식을 활용하여 후보 DAG를 작성하지만, 테스트와 예제에서는 그 반대가 참입니다.\n\n먼저 예제를 설명하는 데 적합한 DAG가 선택되고, 각 노드 사이의 가중치를 무작위로 선택한 다음 해당 가중치를 기반으로 데이터를 생성하여 DAG에 맞게 생성된 데이터 세트가 형성됩니다.\n\n다음은 데이터를 생성하기 위해 선택된 가중치입니다 -\n\n![Data Weightings](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_2.png) \n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 각 노드에 대한 하나의 방정식이 생성되는 구조 방정식 집합을 얻게 됩니다 -\n\n![structural equations](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_3.png)\n\n설명을 완성하기 위해서는 외생 노드/변수와 내생 변수/노드 사이의 구분을 이해하는 것만으로 충분합니다. 외생 노드는 수용하는 인과 화살표가 없습니다. 따라서 위 예제 DAG에서 외생 변수는 Z1과 Z2이며 내생 변수는 X, W, Y, 그리고 Z3입니다. 외생 변수는 값이 무작위로 할당되어야 하며, 일반적으로 분포 규칙을 따라 할당됩니다.\n\n따라서 DAG의 각 노드에 대한 6개의 구조 방정식은 다음과 같이 완전히 설명되고 이해될 수 있습니다..\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Z1은 입력이 없는 외생 변수입니다. 평균은 4.75이며 표준 편차는 1.72입니다.\n- Z2는 외생 변수로, 평균은 3.29이고 표준 편차는 1.88입니다.\n- Z3 = 3 X Z1 + 1.5 x Z2 + 오차 항\n- X = 2 x Z1 + 2.5 x Z3 + 오차 항\n- W = 3 x X + 오차 항\n- Y = 2 x W + 2 x Z2 + 3 x Z3 + 오차 항\n\n이것은 합성으로 생성된 데이터의 미리보기입니다…\n\n![이미지](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_4.png)\n\n# 인과성의 방향을 감지하는 것의 겉으로는 불가능함\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n최근에 쓴 기사에서는 DAG를 통해 되풀이된 경로의 개념을 탐구하고 설명했습니다. 접점으로 이루어진 경로에 대한 개념이 익숙하지 않다면 V-구조의 완전한 이해를 위해 반드시 읽어보세요...\n\n그 토론에서는 \"포크\" 접점의 탐구와 시작 노드에서 끝 노드까지 메시지가 전달되는 방법에 대해 다루었습니다. 아래 DAG에서 X에서 Y로 Z3를 통해 하이라이트된 접점을 고려해보세요...\n\n![DAG 이미지](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_5.png)\n\n분명히 \"메시지\"가 Z3에서 Y로 흐를 수 있습니다(Z3의 변화가 Y의 변화를 일으킵니다) 왜냐하면 Y = 3 x Z3입니다. 하지만 접점에 대한 기사에서 설명한대로 X에서도 Z3로 메시지가 흐를 수 있다는 것을 알아두세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 X = 2.5 x Z3이면, Z3 = 1 / 2.5 x X가 되어 X를 해결하기 위해 방정식 양쪽을 2.5로 나눌 수 있습니다.\n\n그러므로 변수 V1과 V2 사이의 관계 또는 승수가 V2와 V1 사이의 승수의 역수일 때, 실제 세계에서 발생하는 어떤 원인 문제에서도 DAG보다 항상 먼저 나오는 데이터만 있을 때 방향을 찾기는 불가능한 것 같습니다.\n\n나는 매우 오랜 시간동안 이 결론에 도달했습니다. 누락된 링크와 잘못된 방향에 있는 DAG의 엣지를 식별하는 데 사용할 수 있는 일부 유효성 검사 규칙을 해결했지만, 링크의 방향성을 증명하기는 불가능하다고 생각했습니다.\n\nV-구조를 사용한 문헌에서 해결책의 깜박거림이 있지만, 그것들은 복잡하고 항상 불완전합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 글의 나머지 부분은 부분적인 해결책들을 탐구하고 결합하여 알고리즘이 개발될 수 있는 지점에 이르기까지, DAG에서 데이터셋과 비교했을 때 잘못된 방향을 가리키는 방향 링크를 감지하는 Python 알고리즘을 개발하는 것을 목표로 합니다.\n\n# 데이터에서 Collider 및 V-구조 식별 (DAG 참조 없이)\n\n교차로에 관한 글에서는 시작 노드와 끝 노드가 중간 노드를 가리키는 교차로들을 설명했으며 예시 DAG의 모든 교차로들을 식별하는 것은 쉽다고 합니다...\n\n![이미지](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_6.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n콜라이더는 특별한 속성을 갖고 있어 이론적으로 독립성 검정을 수행하여 데이터에서 감지할 수 있습니다. 데이터에서 DAG가 표시하는 위치에 콜라이더가 발견되면 DAG의 일부가 올바르다는 것을 증명한 것입니다.\n\n이 아이디어는 통계식으로 표현할 수 있습니다…\n\n![링크](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_7.png)\n\n이 표현은 위의 최종 콜라이더를 살펴보고 다음을 진술하고 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 표현 1은 그래프 / DAG에서 Z1이 Z2와 독립적이라고 하는 것은 Z1이 데이터에서도 Z2와 독립적이라는 것을 의미합니다 (G 아래첨자로 표시됨).\n- 표현 2는 그래프 / DAG에서 Z2가 Z1과 독립적이라고 하는 것은 Z2가 데이터에서도 Z1과 독립적이라는 것을 의미합니다.\n\n양 측정 ⓵ 및 ⓶이 모두 참이어야 합니다. 왜냐하면 콜라이더는 대칭적이어야 하기 때문입니다. 즉, 메시지는 시작 노드에서 끝 노드로 전달될 수 없으며, 끝 노드에서 시작 노드로 메시지를 전달할 수도 없습니다. 이 조건이 데이터에서 탐지되면 이론적으로 콜라이더가 식별됩니다.\n\n다음 파이썬 코드는 의존성 확인을 수행하며, .dependence() 데이터프레임 확장 메서드의 전체 구현 세부 사항은 해당 기사에서 찾을 수 있습니다...\n\n```js\n{'Z1': 'treatment', 'Z3': 'collider', 'Z2': 'outcome'}\n데이터에서 V-구조 발견: True\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 소식 정말 좋네요! 우리의 DAG는 Z1 -` Z3 `- Z2에서 콜라이더 접점이 있어야한다는 것을 나타내고, 간단한 Python 코드 스니펫이 DataFrame 확장 메서드를 사용하여 이것이 사실임을 증명했습니다!\n\n그러나 데이터에서 콜라이더를 감지하는 여정은 여기서 끝나는 것이 아니라 시작입니다.\n\n이론적으로 데이터에 종속성 테스트를 적용하여 DAG에 나타나는 모든 콜라이더를 식별할 수 있어야하지만 항상 그렇지는 않습니다.\n\n시작과 끝 노드가 추가 연결을 가지고 있는 콜라이더가 포함된 다음 간단한 DAG를 고려해보세요...\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_8.png\" />\n\nY가 X와 독립적일 수 없는 것은 직관적으로 명백합니다. 그들 사이에 콜라이더가 있더라도 \"메시지\"가 X에서 Y로 직접 흘러갈 수 있기 때문이며, 이 직관적인 결론은 위의 코드를 다시 실행하여 증명할 수 있습니다...\n\n```js\n{'X': 'treatment', 'Z': 'collider', 'Y': 'outcome'}\n데이터에서 콜라이더 찾음: False\n```\n\n콜라이더의 시작 노드와 끝 노드가 양 방향으로 연결된 상황에서는 데이터에 대한 종속성 테스트로 콜라이더의 존재를 증명하거나 반박할 수 없으며, 이로 인해 인접성과 V 구조의 개념이 생기게 됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n충돌체는 시작 노드와 끝 노드 사이에 직접 연결이 있는 경우 근접성을 나타내며, 접합부가 연결되지 않은 경우인 극성을 가진 콜라이더로 분류됩니다.\n\n우리의 예제 DAG를 검토해 보면, 5개의 콜라이더 중 2개가 \"인접\"하며 데이터에서 신뢰할 수 없이 감지할 수 없습니다...\n\n<img src=\"/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_9.png\" />\n\n이로써 이제 근접성을 나타내지 않는 3개의 콜라이더가 남아 있습니다(이를 이제 v-구조체로 알고 있습니다) 이론상 이러한 콜라이더를 데이터에서 의존성 테스트를 사용하여 감지할 수 있습니다...\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Here is the output table for the test harness](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_11.png)\n\n\n위의 Python 코드에서 이미 데이터에서 1번째 v-구조 Z1 -` Z3 `- Z2가 식별될 수 있다는 것이 보여졌습니다. 그렇다면 나머지 두 개에 대해서는 어떨까요?\n\n아래 표는 예제 DAG의 모든 접점에 대해 대칭적 종속성 테스트를 적용하는 테스트 해네스의 출력입니다...\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 실험 결과에서는 데이터 종속성 테스트가 신뢰할 수 있는 것은 Z1 - Z3 - Z2라는 유일한 v-구조임을 보여줍니다. 우리는 인접한 2개의 콜라이더 및 체인 및 포크에서 테스트가 실패할 것으로 예상했지만, 이 테스트의 예상 결과는 3개의 v-구조를 식별하는 것이었습니다.\n\n이 결과를 이해하기 위해서는 데이터에서 올바르게 식별되지 않은 2개의 v-구조를 더 자세히 조사하고, 그들이 직접적으로 연결되어 있지 않음에도 불구하고 (즉, 인접하지 않음), 오픈 백도어 경로를 통해 간접적으로 연결되어 있음을 깨닫는 것이 필요합니다.\n\nW - Y - Z3에서의 콜라이더를 살펴보고, 시작 노드 W와 끝 노드 Z3 사이의 백도어 경로를 검토해 봅시다...\n\n![이미지](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_12.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nW -` Y `- Z3는 충돌체이며 또한 v-구조체입니다. 이는 인접하지 않지만 시작 노드와 끝 노드 사이에 2 개의 백도어 경로가 존재하기 때문입니다. 따라서 이러한 노드 간에 \"메시지\"가 유출되어 데이터에서 이 v-구조체를 감지하기가 불가능하게 만듭니다 (또는 적어도 일관성이 없고 신뢰할 수 없게 만듭니다).\n\nW -` Y `- Z2는 W `- X `- Z3 -` Z2로부터 백도어 경로로 인해 정확히 동일한 문제가 발생합니다.\n\n현재 충돌체, v-구조체 및 인과 유효성 검사 여정에서 거의 포기할 뻔했지만, 데이터에서 v-구조체를 감지할 수 없다면 신뢰할만한 유효성 검사를 구축할 수 없습니다.\n\n그러나 이 문제에 대한 해결책이 있습니다. 이것은 사용 가능하고 유용한 정확성 및 신뢰성을 갖춘 알고리즘을 생성하는 궁리의 방법입니다…\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 인과 링크 방향 감지를 위한 알고리즘 정의\n\n다음과 같은 v-구조의 정의가 주어졌을 때...\n\n...데이터에 존재하는 링크를 식별하기 위한 알고리즘은 다음과 같이 정의될 수 있다...\n\n- DAG 내 모든 엣지 주변을 반복하고 각 엣지에 대해...\n- 현재 엣지를 뒤집어 새로운 DAG를 생성합니다.\n- v-구조가 파괴되었고 해당 v-구조가 데이터에 존재하지 않으면 현재 DAG가 잘못되었고 엣지를 뒤집어야 합니다.\n- v-구조가 생성되었고 해당 v-구조가 데이터에 존재하면 현재 DAG가 잘못되었고 엣지를 뒤집어야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 1: 모든 간선을 반복하는 중\n\n알고리즘의 첫 단계는 DAG(Directed Acyclic Graph; 방향성이 있는 비순환 그래프)의 모든 간선을 반복할 것입니다. 이는 다음과 같이 시각화될 수 있습니다...\n\n![DAG](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_13.png)\n\n## 단계 2: 현재 간선을 뒤집어 새 DAG 만들기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가정하에 여러분이 첫 번째 반복 단계에 있다고 가정합니다 (Z2 -` Z3의 엣지를 뒤집는 경우). 이 엣지를 역전시킨 결과, 원본 및 뒤집기로 인해 생성된 변형 2개의 DAGs가 생깁니다...\n\n<img src=\"/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_14.png\" />\n\n## 단계 3: V-구조가 파괴된 경우...\n\nZ2 -` Z3를 뒤집는 것은 원래 DAG에 존재하는 V-구조를 파괴(또는 제거)했다는 것을 의미합니다. 왜냐하면 V-구조인 Z1 -` Z3 `- Z2가 Z1 -` Z3 -` Z2 체인에 의해 대체되었기 때문입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n파괴된 v-구조 Z1 -` Z3 `- Z2은 데이터에서 종속성 테스트를 사용하여 지금 테스트 될 수 있습니다.\n\n- 데이터에서 해당 v-구조를 발견하면 Z2 -` Z3의 방향성이 DAG에서 올바르다.\n- 데이터에서 해당 v-구조를 찾을 수 없으면 Z2 -` Z3의 방향성이 DAG에서 잘못되었으며 뒤집어져야 합니다.\n\n이 파이썬으로 구현된 테스트입니다...\n\n```python\nv-structure found in data: True\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n데이터에서 충돌체인 Z1 -` Z3 `-Z2가 확인되었습니다. 따라서 Z2 -`Z3의 역전 제안은 잘못되었습니다. 알고리즘은 이제 다음 단계로 진행됩니다...\n\n## 단계 4: V-구조가 생성된 경우...\n\n첫 번째 반복 즉, 엣지 Z2 -` Z3의 반전은 새로운 v-구조를 만들지 않기 때문에, 이제 X -` W 엣지를 반전하는 두 번째 반복으로 빨리 진행하겠습니다...\n\n![이미지](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_15.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nX -` W를 반전한 결과 새로운 DAG에 두 개의 v-structure가 생성되었습니다...\n\n- Z1 -` Z -` W 체인은 Z1 -` X `- W v-structure로 대체되었습니다.\n- Z3 -` X -` W 체인은 Z3 -` X `- W v-structure로 대체되었습니다.\n\n이러한 새로운 v-structure들을 테스트해보고 데이터에서 식별된다면, DAG의 기존 엣지 X -` W가 잘못된 방향으로 되어있으며 변경하여 X `- W로 수정되어야 합니다.\n\n```js\n데이터에서 발견된 v-structure: False\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n데이터에서 발견된 V-구조: 거짓\n```\n\n데이터에서 V-구조가 발견되지 않아 X-W의 방향성에 대한 기존 DAG가 정확하다는 증거를 제공했으며, 이는 예상된 결과입니다.\n\n## 반복 작업 완료\n\n우리는 데이터가 DAG와 일치함을 알고 있습니다. 이 데이터는 합성되어 DAG와 일치하도록 생성되었기 때문에 각 edge reversal 테스트가 DAG가 올바른지 확인해야 합니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n현재 완전히 작동한 두 가지 에지가 이를 증명했는데, 이것은 알고리즘이 작동 중이며 방향성을 증명하는 목표에 도달했다는 것을 의미합니까?\n\n## 생성 / 파괴된 V-구조 알고리즘의 주요 문제\n\n이 목표가 달성되었는지 확인하려면 알고리즘을 사용하여 생성 / 파괴된 v-구조 규칙을 사용하여 각 에지의 반전을 테스트해야 합니다.\n\n안타깝게도 알고리즘이 모든 에지를 돌 때 예상대로 작동하지 않습니다. 에지 W - Y에 도달하면 방향성이 잘못되었다고 오해하고 뒤집어야 한다 판단합니다...\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째 단계, 즉 생성된 v-structures를 고려하는 단계가 예상대로 작동합니다...\n\n![image](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_16.png)\n\n이 새로운 v-structure는 데이터에서 감지되지 않기 때문에 알고리즘의 이 단계는 데이터가 현재 DAG와 일치한다고 정확히 예측합니다.\n\n알고리즘의 다음 단계는 W -` Y를 역전시키면 W -` Y `- Z2와 W -` Y `- Z3 두 개의 v-structure가 파괴된다는 사실을 확인합니다...\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```json\n{\n  \"dependency_tests_results\": [\n    {\n      \"description\": \"When the dependency tests are executed on the data for these two destroyed v-structures the actual results do not match the expected results\",\n      \"v_structure_found_in_data\": \"False\"\n    },\n    {\n      \"v_structure_found_in_data\": \"False\"\n    }\n  ]\n}\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 문제에 대한 제안된 해결책\n\n두 경우 모두 v-구조가 데이터에 존재하는 것으로 알려져 있지만 의존성 테스트는 이를 찾지 못해 알고리즘이 W -` Y의 제안된 반전이 유지되어야 하며 현재 상황에서 DAG가 잘못되었다고 결론을 이끌었습니다.\n\n결과를 더 자세히 살펴보면 두 경우 모두 독립성이 한 방향으로 발견되었지만, 다른 방향으로는 발견되지 않았으며, v-구조가 대칭이어야 함이 밝혀졌으므로 테스트가 실패했습니다.\n\n테스트 실패의 근본적인 이유는 이미 위 섹션에서 탐구되고 설명되었으며, 시작 및 종단 노드 사이에 backdoor 경로가 존재하여 메시지가 누출되어 독립성 테스트에 실패한다는 것이었습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n처음으로 이 결론을 도출했을 때는 Directed Acyclic Graphs에서 반대 방향 링크를 감지하는 유용한 알고리즘을 설계하고 개발할 시도에 거의 포기할 뻔했습니다. 그때는 이게 가능한 일처럼 보이지 않았어요.\n\n현재 정의된 알고리즘은 손상된 v-구조가 백도어 경로를 가지고 있을 경우 유효한 DAG(데이터와 일치하는)임을 증명하지 못할 것이며, DAG를 확인할 수 없다면 알고리즘은 분명히 쓸모가 없을 것입니다.\n\n\"파괴된 v-구조\"의 정의를 바꿔서 백도어 경로가 존재하는 경우를 제외해 보았는데, 처음에는 유망해 보였지만 유효한 DAG가 유효하다는 것을 입증하는 데에는 작동하지만, 유효하지 않은 DAG가 유효하지 않다는 것을 증명할 때 전혀 작동하지 않았습니다. 불허용할 만큼 많은 거짓 양성을 감지했죠.\n\n결국 저는 사용 가능한 문헌들에서 인과 발견에 관해 읽고 기반을 두기로 결심했습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n인과적 검증이 어려울 때, 인과 관계 발견은 더 어렵습니다. 인과적 검증은 데이터셋에 대한 DAG를 검증하려는 시도이며, 도메인 전문가들이 높은 수준의 전문 지식을 갖고 있다고 가정한다면 DAG는 올바를 가능성이 높고, 과제는 잠재적인 오류를 식별하는 것뿐입니다.\n\n그러나 인과 관계 발견의 아이디어는 어떤 DAG도 시작하지 않고 데이터셋만으로 역공학을 시도하는 것입니다. 이는 많은 순열을 포함하는 복잡한 과제이며, 문헌에서 설명된 전략 중 하나는 완전히 빈 DAG로 시작하는 대신 도메인 전문가들이 확신을 갖고 있는 일부 엣지를 확인함으로써 발견 알고리즘이 수행해야 할 작업을 줄이는 것입니다.\n\n예를 들어, DAG의 노드는 완전히 가공된 것이지만 X가 새 약인 것으로 가정하고, W가 혈압의 긍정적인 변화이며, Y가 환자 발견인 것으로 생각한다면 이러한 노드의 방향이 잘못되었을 가능성은 낮습니다.\n\n예를 들어, 환자의 회복이 혈압의 변화를 유발할 수 있습니까? (가능성은 낮지만 불가능하지는 않음) 혈압이 환자가 약을 복용하도록 유도할 수 있습니까? (매우 낮음)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그리고 합리적으로 추론할 수 있는 다른 결론들이 있습니다. 변수 B가 변수 A보다 나중에 발생하는 시간(또는 시간)적 측면이 있는 곳에서는 그것의 원인이 될 수 없습니다.\n\n예를 들어, 운동 빈도수가 하나의 데이터 포인트고 다른 하나는 일반 건강이라면 더 건강한 사람들이 더 많은 운동을 했는지 또는 더 많이 운동하는 사람이 더 건강해졌는지에 대한 논의가 있을 수 있습니다. 그러나 운동 빈도가 건강이 개선되기 전에 증가했다는 명백한 증거가 기록되어 있다면 방향성이 입증됩니다.\n\n또한 치료와 결과에 대한 추론을 할 수 있습니다. 일반적으로 치료가 사건을 발생시키고 효과는 사건에 의해 발생됩니다 (그렇지 않을 때도 있음).\n\n따라서 데이터에서 backdoor 경로를 갖는 v-구조를 식별할 수 없는 능력의 문제는 알고리즘에게 몇 가지 엣지의 확실성에 대해 지시하여 올바르다고 가정되는 엣지들 중 일부에 대해 테스트되지 않을 것이기 때문에 최소화될 수 있다는 결론입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위의 변경 사항을 적용하고 알고리즘에 W -` Y가 정확하다는 힌트를 제공하여 결과가 극적으로 개선되었습니다.\n\n예제 DAG와 일치하는 100개의 데이터 세트를 무작위로 생성하는 테스트 하네스는, 알고리즘이 탐색을 시작하기 전에 W -` Y가 힌트로 제공되었다면 100%의 경우에 DAG가 데이터와 일치한다고 정확하게 식별했습니다.\n\n# 검증 알고리즘의 추가 테스트\n\n따라서 동일한 예제 DAG에 대해 수행된 테스트는, 알고리즘이 지나치게 높거나 낮은 성능을 발휘하는 원인이 되는 몇 가지 특이한 특징이 포함되어 있을 수 있을 것입니다. 여기에는 테스트 결과를 확대하는 알고리즘의 정의가 있습니다...\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- DAG를 테스트하려고 선택하세요.\n- 엣지 가중치와 구조 방정식을 사용하여 데이터와 일치하는 인과 관계를 갖는 합성 데이터 세트를 생성하세요.\n- 에지 확정이 없는 상태에서 검증 알고리즘을 실행하세요 (즉, 해당 데이터와 DAG가 일치하는지 올바르게 확인하는 원형 형태로).\n- 2단계로 돌아가서 DAG와 일치하는 100개의 서로 다른 데이터 세트의 무작위 생성을 반복하세요.\n- 알고리즘이 DAG가 데이터와 일치함을 올바르게 확인한 경우에 해당하는 테스트 통과의 총합을 합산하세요.\n- 결과를 백분율로 표시하세요.\n\n기본 DAG\n\n![기본 DAG 이미지](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_18.png)\n\n저는 \"삼각형 DAG\", \"사다리꼴 DAG\", \"E-모양 DAG\"라고 하는 추가 테스트 DAG들이 모두 추가 힌트 없이 100%의 테스트 케이스에서 추가 테스트를 통과했다고 말할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n복잡한 DAG\n\n![Complex DAG](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_19.png)\n\n이 더 복잡한 DAG는 테스트 케이스의 90%를 통과하지만 약 10%에서 Z - W 및 Uw - W 엣지가 잘못된 방향으로 식별된다.\n\n그러나 이 두 엣지를 힌트로 설정하면 테스트 통과율이 100%로 돌아갑니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDAG 복잡도 증가하기\n\n![DAG 복잡도 증가하기](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_20.png)\n\n추가 노드/변수 (Ut 및 T) 및 추가 경로를 추가하여 복잡성을 증가하면 테스트 결과가 저하될 수 있습니다.\n\n알고리즘은 테스트 케이스의 30%에서 유효성을 올바르게 판단하며 Z -` W, Uw -` W, T -` Y 및 Uy -` Y의 간선이 다양한 테스트에서 잘못 식별되어 뒤집어져야 한다고 나타났습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다시 한 번 이러한 4가지 엣지가 힌트로 주어지면 모든 테스트가 100% 통과됩니다.\n\n최대 DAG 복잡성\n\n![image](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_21.png)\n\n마지막 테스트는 9개의 노드/변수, 16개의 엣지, 모든 유형의 접점 및 관측되지 않은 혼입 변수 (노드 C)를 포함한 가장 복잡한 예제 DAG입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 DAG의 테스트 중 100%가 실패합니다. 테스트는 위 다이어그램의 엣지 중 하나 (B -` X, G -` X, 또는 E -` X)를 역전해야 한다고 식별합니다.\n\n그러나 이러한 3개의 엣지가 힌트로 주어지면 이렇게 복잡한 DAG도 100%의 테스트 케이스를 통과할 수 있습니다.\n\n## 테스트에서 배운 점\n\n테스트에는 패턴이 분명히 있습니다. 간단한 DAG는 100% 신뢰성으로 실행되며, DAG가 더 복잡해지면 역전이 필요한 잘못된 엣지를 식별하기 시작하고 알고리즘에 힌트를 제공하여 더 많은 도움이 필요합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n결과에 따르면 알고리즘이 완벽하지는 않지만 성능은 충분히 높아 유용하고 사용하기에 적합합니다. 특히, 도메인 전문가들이 도와 만든 DAG의 맥락에서 힌트가 제공되는 경우에 특히 그렇습니다.\n\n그렇다면 이제 끝인가요? 데이터의 역방향 엣지를 표현하는 DAG가 올바르게 나타내는지 감지할 수 있는 알고리즘의 탐색에서 승리를 선언할 수 있을까요?\n\n아쉽지만, 실제로는 아직 절반도 되지 않았습니다. 지금까지 이룩된 것은 데이터와 일치하는 DAG를 (수용할 만한 정확도로) 감지하는 알고리즘이지만, 더 어려운 도전은 DAG가 데이터와 일치하지 않는 경우의 알고리즘을 테스트하는 것입니다.\n\n# 데이터를 정확하게 반영하지 않는 DAG의 오류 감지\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 사용 사례를 설명하기 위해 원래의 예제 DAG를 검토해 보겠습니다. 도메인 전문가들이 W - Y 엣지에 대해 충분한 확신을 제공했지만 Z1-Z3 엣지를 잘못 식별했다고 가정하겠습니다. \n\n다음은 알고리즘의 테스트 결과입니다...\n\n![Test Results](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_22.png)\n\n이는 매우 유망한 시작입니다. 알고리즘은 데이터와 일치하지 않는 DAG를 올바르게 식별했으며 어떤 엣지가 잘못되었는지도 정확히 식별했습니다!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n알고리즘이 이 반전을 올바르게 식별한 것은 놀라운 일이 아닙니다. 왜냐하면 DAG(Directed Acyclic Graph)에서 유일한 백도어 경로가 없는 단일 v-structure인 Z1 -` Z3 `- Z2를 찾을 수 있기 때문입니다. 따라서 \"작성된 v-structure\" 테스트는 이 데이터를 올바르게 작동하도록 바운드(제한)되어 있습니다.\n\n다음 단계는 DAG의 모든 엣지를 반전하여 알고리즘의 성능을 관찰하는 것입니다.\n\nZ1 -` X, Z2 -` Y, Z3 -` Y 엣지는 테스트되지 않았음을 유의해 주세요. 이러한 반전은 각각 순환을 가진 DAG를 생성하므로(즉, 치료로 되돌아가는 루프가 있는) 이는 정의상 허용되지 않습니다.\n\n다음은 남은 테스트로, 이미 Z1 -` Z3가 테스트되었음을 유의하십시오. 3가지 테스트는 비순환 DAG를 생성하고 W -` Y는 알고리즘에 올바르다고 암시되었기 때문에 제외됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Reverse X -` W\n- Reverse Z2 -` Z3\n- Reverse Z3 -` X\n\n![image](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_23.png)\n\n결과는 혼재되어 있습니다. 이 알고리즘은 데이터의 유효한 표현이 아님을 올바르게 식별하고, 테스트 케이스의 100%에서 의도적으로 반전된 엣지를 선택합니다.\n\n안타깝게도 알고리즘은 항상 과대식별을 합니다. 즉, 반전되어야 하는 엣지를 선택하는 것 외에도 사실 올바른 엣지를 식별합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다른 테스트 DAG들과 유사한 이야기입니다.\n\n의도적으로 뒤집힌 엣지가 발견되었습니다만 유효한 다른 엣지들도 발견되었습니다. 과도한 식별이 발생하는 이유는 단일 엣지가 잘못된 방향으로 되어있는 경우, 전체 DAG가 균형을 잃게 되어 데이터와 만들어진 엣지 테스트가 잘못 실행될 수 있기 때문입니다\n\n그렇다면 이 모든 노력 끝에 우리는 여전히 DAG에서 잘못된 엣지를 식별할 수 없다는 의미일까요?\n\n# \"하이브리드 엣지 뒤집기 탐지 알고리즘\"에 대한 제안\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 여기서 포기하기 전에 명백한 사실 몇 가지가 있습니다...\n\n- 알고리즘은 DAG가 유효한지 인식하는 데 뛰어나며 (복잡한 DAG의 경우 높은 신뢰도 링크에 대한 힌트를 제공해야 할 수 있음에 유의해야 합니다).\n- 알고리즘은 역전된 엣지를 감지하는 데 능숙하며 (다른 유효한 링크도 역전되어야 한다고 제안할 수 있음에 유의해야 합니다).\n\n따라서 해결책은 기본 알고리즘을 확장하여 내가 '하이브리드 엣지 역전 감지 알고리즘'이라고 부르는 것으로 만드는 것입니다.\n\n- 기본 알고리즘을 통과하면 (즉, DAG가 데이터와 일치한다고 결론 지었을 때) 여기서 멈춥니다.\n- 기본 알고리즘이 실패하면 (즉, DAG가 유효하지 않다고 선언했을 때) 역전된 엣지의 모든 가능한 순열을 반복하고 각 순열을 테스트하여 기본 알고리즘이 통과되는지 확인합니다.\n- 알고리즘이 유효하다고 결론 내린 각 DAG를 DAG에서 오류가 있는 것으로 알려진 DAG에 대한 가능한 수정 사항으로 제시합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n인과 문헌에서 이 방법을 본 적이 없습니다. 이것은 저의 결론으로, 수많은 시간을 투자하여 테스트 결과를 분석한 결과입니다. 이 방법은 100% 정확하지는 않지만 명확하게 사용 가능하고 유용한 결과를 얻을 수 있습니다.\n\n이 결과는 매우 유용하며, 인과 모델의 입력으로 잘못된 DAG가 사용되어 모델링 및 머신러닝 결과와 결론이 무효화될 가능성을 방지했습니다.\n\n## 혼합 에지 역전 감지 알고리즘 평가\n\nV-구조를 이해하는 데서부터 관련 데이터셋과 비교했을 때 DAG에서 역전된 엣지를 감지하는 사용 가능한 알고리즘을 만드는 데의 오랜 여정이 이제 완료되었습니다. 이제 남은 일은 하이브리드 알고리즘을 테스트하여 어떻게 수행되는지 확인하는 것뿐입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n표준 예제 DAG\n\n![image](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_24.png)\n\n먼저 테스트할 DAG는 이 기사의 주요 내용으로 사용된 우리의 옛 친구입니다.\n\n가장자리 W -` Y가 암시되었으며 몇 가지 가장자리는 역을 취해도 비순환 그래프가 생성되지 않기 때문에 테스트할 수 없습니다 (Z1 -` X, Z2 -` Y 및 Z3 -` Y). 그렇게 되어 데이터에서 역전시킬 수 있는 4개의 가장자리가 남는데, 그것은 (X -` W, Z1 -` Z3, Z2 -` Z3 및 Z3 -` X)입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 결과입니다 - \n\n- DAG가 4개 중 4개의 테스트에서 올바르게 무효로 식별되었습니다 (100.0%).\n- 4개 중 4개의 테스트에서 모든 역전파가 발견되었습니다 (100.0%).\n- 4개 중 1개의 테스트에서 잘못된 양성이 발견되었습니다 (25.0%).\n\n이러한 결과는 매우 유망합니다. 역전된 엣지는 모든 경우의 100%에서 정확하게 식별되었지만, 알고리즘은 테스트 중 하나에서 잘못된 양성을 과도하게 식별했습니다.\n\n다음 단계는 데이터에서 2개의 엣지 조합을 임의로 선택하여 역전시킨 뒤 알고리즘이 DAG에서 여러 오류를 감지할 수 있는지 확인하는 것입니다. 다음은 결과입니다 -\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 8/10 테스트에서 올바른 DAG를 80.0%로 정확하게 식별했습니다.\n- 모든 반전이 6/10 테스트에서 발견되었습니다 (70.0%).\n- 7/10 테스트에서 잘못된 양성 결과가 발견되었습니다 (70.0%).\n\n2개의 엣지가 반전되어 성능이 저하되었지만 결과는 여전히 데이터 팀에게 DAG가 올바르지 않음을 알려 주며 오류가 어디에 있는지 소중한 지표를 제공할 것입니다.\n\n3개의 엣지를 반전해도 유용하고 활용도 높은 결과가 생성됩니다...\n\n- 15개 중 14개 테스트에서 올바른 DAG를 93.3%로 정확하게 식별했습니다.\n- 15개 중 7개 테스트에서 모든 반전이 발견되었습니다 (46.7%).\n- 15개 중 14개 테스트에서 잘못된 양성 결과가 발견되었습니다 (93.3%).\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 트라페조이드 DAG에 대한 정보입니다.\n\n![Trapezium DAG](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_25.png)\n\n트라페조이드 DAG에는 3개의 단일 엣지 반전이 있습니다(즉, 다른 경우는 acyclic DAG를 생성합니다). 시험 결과는 다음과 같습니다.\n\n- DAG는 3개의 테스트 중 2개에서 올바르게 유효하지 않음으로 식별되었습니다(66.7%).\n- 모든 반전은 3개 테스트 중 2개에서 발견되었습니다(66.7%).\n- 잘못된 양성 결과는 3개 중 1회에서 발견되었습니다(33.3%).\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 결과들은 표준 예시 DAG만큼 좋지 않지만, 알고리즘은 여전히 테스트 케이스 중 66.7%에서 엣지를 잘못된 방향으로 식별합니다.\n\n다트형태 DAG에서 2개의 엣지를 뒤집는 테스트 결과는 다음과 같습니다 -\n\n- DAG가 5개 중 4개의 테스트에서 올바르게 무효로 식별됨 (80.0%)\n- 모든 역전이 5개 테스트 중 0개에서 발견됨 (0.0%)\n- 거짓 양성이 5/5 테스트에서 발견됨 (100.0%)\n\nE-자형태 DAG\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![image](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_26.png)\n\n7개의 가능한 단일 엣지 반전 테스트가 있고, 테스트 결과는 다음과 같습니다...\n\n- DAG는 7개 중 6개에서 올바르게 무효로 식별됨 (85.7%)\n- 7개 중 6개에서 모든 반전 찾음 (85.7%)\n- 거짓 양성은 7개 중 1개에서 발견됨 (14.3%)\n\n이 DAG에는 이전 예제보다 적은 인접 및 백도어 콜라이더가 있습니다. 따라서 더 나은 성능을 기대할 수 있으며 테스트 결과는 정말로 매우 좋습니다!\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2개의 엣지 역전을 감지하는 결과도 매우 좋습니다...\n\n- DAG는 10/10 테스트에서 올바르게 잘못된 것으로 식별되었습니다 (100.0%)\n- 모든 역전은 10개 중 8개의 테스트에서 발견되었습니다 (80.0%)\n- 거짓 양성은 10개 중 2개의 테스트에서 발견되었습니다 (20.0%)\n\nThe Complex Exogenous DAG\n\n![Complex Exogenous DAG](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_27.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 단일 엣지 반전에 대한 테스트 결과이며, 외생적인 \"inputs\"이 힌트로 제공됩니다 (연한 파란색으로 표시됨).\n\n- DAG는 6개 중 6개의 테스트에서 올바르게 식별됨 (100.0%)\n- 모든 역전이 6개 중 6개의 테스트에서 발견됨 (100.0%)\n- 거짓 양성은 6개 중 0개의 테스트에서 발견됨 (0.0%)\n\n2개의 역전 결과:\n\n- DAG는 10개 중 10개의 테스트에서 올바르게 식별됨 (100.0%)\n- 모든 역전이 10개 중 10개의 테스트에서 발견됨 (100.0%)\n- 거짓 양성은 10개 중 0개의 테스트에서 발견됨 (0.0%)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그리고 역방향 간선이 3개인 경우에는...\n\n- DAG는 10/10 개의 테스트에서 올바르게 무효로 식별됨 (100.0%)\n- 모든 역전이 10/10 개의 테스트에서 발견됨 (100.0%)\n- 거짓 양성 0/10 개의 테스트에서 발견됨 (0.0%)\n\n이 DAG에 대한 테스트 결과는 놀라운데요; 알고리즘이 1, 2 또는 3개의 방향성 오류가 있는 DAG의 경우 100% 정확도로 오류를 올바르게 식별합니다!\n\n그러나 3개의 역전 테스트의 실행 속도가 문제가 됩니다. 최종 테스트에서 상세히 다룰 예정이니 기대해주세요...\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n슈퍼 복잡한 현실 세계 DAg\n\n![image](/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_28.png)\n\n슈퍼 복잡한 DAG는 B -` X, E-` X 및 G -` X로 테스트되기 전에 힌트가 있었습니다.\n\n단일 엣지 전환 테스트 결과는 다음과 같습니다...\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- DAG이 2/3 테스트에서 올바르게 무효로 식별되었습니다 (66.7%)\n- 2/3 테스트에서 모든 반전이 발견되었습니다 (66.7%)\n- 거짓 양성이 1/3 테스트에서 발견되었습니다 (33.3%)\n\n2개 엣지 반전에 대한 결과:\n\n- DAG이 5/5 테스트에서 올바르게 무효로 식별되었습니다 (100.0%)\n- 1/5 테스트에서 모든 반전이 발견되었습니다 (20.0%)\n- 거짓 양성이 4/5 테스트에서 발견되었습니다 (80.0%)\n\n그리고 3개 엣지 반전에 대해서...\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- DAG이 6개 중 5개(83.3%)의 테스트에서 올바르게 식별되지 않음을 발견했습니다.\n- 모든 반전은 6개 중 1개(16.7%)의 테스트에서 발견되었습니다.\n- 거짓 양성은 6개 중 5개(83.3%)의 테스트에서 발견되었습니다.\n\n이 DAG에 대한 결과가 그다지 유망하지 않았으며, 테스트 속도도 우려스러웠습니다.\n\n# 결론 — 무엇을 배웠는가?\n\n제안된 데이터 집합을 표현하는 DAG에서 화살표의 올바른 방향을 자동으로 감지하기 어려웠습니다. 왜냐하면 y = 3x이면 x = 1/3y이므로 양방향에 계수 / 기울기 (3 또는 1/3)가 있기 때문에 올바른 방향을 감지하는 것이 불가능합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDAG는 처리와 결과 사이의 경로로 구성되어 있으며, 각 경로는 chain(연쇄), fork(포크) 및 collider(충돌체) 중 하나에 해당하는 접합체로 이루어져 있어요.\n\nv-구조는 서로 인접하지 않는 collider의 부분 집합이라는 것이 보여지며, 이 구조는 데이터에서 종속성 테스트를 사용하여 (독특하게) 식별될 수 있다는 것이 증명되었습니다. 이는 방향성 감지 문제를 해결하는 열쇠를 제공하지만, back-door paths(보조 경로)는 모순된 결과를 초래할 수 있어요.\n\n따라서, 전통적인 Pearlean 역방향 검출 알고리즘이 일관되고 신뢰할 수 없다는 것이 밝혀졌어요. DAG가 데이터와 일치하지 않을 때 정확하게 식별할 수 있으며, 하나의 엣지가 잘못된 경우 그 역방향 엣지를 가리킬 때 성공을 얻을 수도 있어요. 하지만, 2개 이상의 엣지가 올바르지 않은 방향 또는 DAG가 복잡한 경우 올바르게 잘못된 엣지를 식별하지 못해 사용할 수 없는 것처럼 보이기도 해요.\n\n전통적인 Pearlean 알고리즘은 잘못된 DAG를 감지하는 데 사용하는 것으로 개선될 수 있으며, 그런 다음 유효한 DAG를 생성하는 데 필요한 최소 역전을 찾기 위해 모든 역전을 시도할 수 있는 하이브리드 알고리즘과 결합하여 오류의 위치를 정확히 파악할 수 있는 좋은 지표를 제공할 수 있어요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n알고리즘은 완벽하지 않지만 일부 엣지에 대한 확실성 힌트(즉, 확실하게 알려진 일부 엣지)가 제공된다면 정확도(즉, 역전된 엣지를 정확하게 식별하는 퍼센트)는 충분히 높아서 도메인 전문가들이 제안한 DAG를 확인하고 분석하며 수정하는 데 사용할 수 있습니다.\n\n역전된 엣지를 감지하는 어떤 알고리즘도 절대 완벽할 수 없습니다. 데이터 집합을 정확하게 나타낼 수 있는 여러 개의 DAG가 있으며 또한 알고리즘의 기초가 되는 의존성 테스트가 100% 정확하지 않기 때문입니다.\n\n정확도 이상으로, 퍼포먼스 면에서 하이브리드 알고리즘의 처리 시간이 기하급수적으로 저하됩니다.\n\n5개의 엣지를 가진 DAG는 2의 5승 또는 32개의 역전 조합을 탐색할 수 있지만 16개의 엣지는 2의 16승 또는 65,536개의 역전 가능한 조합이 있습니다. Python은 해석 방식의 프로그래밍 언어이므로 이러한 많은 조합을 실행하는 데 많은 시간이 걸릴 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위 단점을 감안해도, 제안된 DAG의 역방향 엣지를 데이터셋과 비교하여 감지하는 것이 절대적으로 정확하지는 않을 수 있다는 점을 받아들이더라도, 혼합 알고리즘은 사용 가능하고 유용한 수준의 정확성을 갖추고 있습니다.\n\n마지막으로 혼합 엣지 역전파 감지 알고리즘은 인과적 검증의 중요한 부분인 신뢰할 수 있는 결과물을 얻는 데 큰 가치가 있는 도구입니다. 이를 통해 인과 추론 모델의 결과가 정확하며 조직적 영향과 결과에 자신감을 갖고 활용할 수 있습니다.\n\n# 소통하고 연결하세요...\n\n이 기사를 즐겼다면 앞으로의 기사 소식을 받아보기 위해 저를 팔로우해주세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 인과 추론과 데이터 과학의 이 흥미로운 새로운 분야에 대한 생각이나 의견이 있다면, 알려주세요. 메시지를 남겨주시면 연락드리도록 하겠습니다.\n\n내 이전 기사를 확인하려면 내 연구와 인과 추론에 관한 모든 것을 하나로 모아놓은 이 웹사이트의 이전 기사를 빠르게 살펴보세요 — 데이터 블로그.","ogImage":{"url":"/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_0.png"},"coverImage":"/assets/img/2024-07-09-UnderstandingV-StructuresandtheCriticalRoleTheyPlayinCausalValidationandCausalInference_0.png","tag":["Tech"],"readingTime":41}],"page":"1","totalPageCount":19,"totalPageGroupCount":1,"lastPageGroup":19,"currentPageGroup":0},"__N_SSG":true}