{"pageProps":{"posts":[{"title":"Python으로 XGBoost를 사용한 모노토닉 시계열 예측 실습","description":"","date":"2024-07-09 20:12","slug":"2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython","content":"\n![이미지](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_0.png)\n\n몇 달 전에 리서치 프로젝트를 진행하면서 시계열을 다루는 문제를 해결해야 했어요.\n\n이 문제는 상당히 간단했어요:\n\nMachine Learning 애호가들에게는 \"Hello World\"를 작성하는 것과 같은 느낌이죠. 이 문제는 \"forecasting\"이라는 이름으로 커뮤니티에서 매우 잘 알려진 문제입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기계 학습 커뮤니티는 시계열 데이터의 다음 값을 예측하는 데 사용할 수 있는 많은 기술을 개발했습니다. 일부 전통적인 방법에는 ARIMA/SARIMA 또는 푸리에 변환 분석과 같은 알고리즘이 포함되어 있으며, 더 복잡한 알고리즘에는 컨볼루션/순환 신경망 또는 슈퍼 유명한 \"Transformer\" (ChatGPT의 T는 transformers를 나타냅니다)이 있습니다.\n\n예측 문제는 매우 잘 알려진 문제이지만, 제약 조건이 있는 예측 문제에 대해 다루는 것은 덜 흔한 것일 수 있습니다.\n무엇을 의미하는지 설명해 드릴게요.\n\n일련의 매개변수 X와 시간 단계 t가 있는 시계열 데이터가 있다고 가정해 봅시다.\n표준 시간 예측 문제는 다음과 같습니다:\n\n![image](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_1.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리가 직면한 문제는 다음과 같습니다:\n\n![이미지](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_2.png)\n\n따라서 입력 매개변수가 d 차원이라고 가정할 때, 저는 차원 1을 위한 함수가 단조적이 되기를 원합니다. 그렇다면 어떻게 처리해야 할까요? 어떻게 \"단조적\" 시계열을 예측할 수 있을까요? 이 문제에 대한 설명은 XGBoost를 사용할 것입니다.\n\n이 블로그 포스트의 구조는 다음과 같습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- XGBoost에 대해: XGBoost가 무엇에 대해, 기본 아이디어가 무엇인지, 장단점은 무엇인지 몇 줄로 설명하겠습니다.\n- XGBoost 예제: XGBoost 코드를 설명하겠습니다. Python 설명부터 장난감 예제까지를 포함하여요.\n- XGBoost의 명확성을 갖춘 예제: XGBoost를 실제 예제로 테스트하겠습니다.\n- 결론: 이 블로그 포스트에서 언급된 내용에 대한 요약을 제시하겠습니다.\n\n# 1. XGBoost에 대해\n\n## 1.1 XGBoost의 아이디어\n\nXGBoost의 XG는 extreme gradient(부스팅)을 의미합니다.\n\"gradient boosting\" 알고리즘은 \"예측자 체인\"을 사용하려고 합니다.\n입력 행렬 X 및 해당 출력 y가 주어지면, 아이디어는 여러 예측자가 있습니다. 첫 번째 예측자는 입력 X로부터 직접 해당 출력 y를 찾으려고 합니다. 이야기의 끝. 아니요, 농담이에요 🤣\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째 예측기는 “약한 예측기”라고 불리는 것을 목표로 합니다. 이는 예측된 y1과 실제 출력 y 사이에 무시할 수 없는 차이가 있는 것을 의미합니다. 두 번째 예측기는 첫 번째 예측의 오류를 보정하는 것을 목표로 하므로 X에서 y로 이동하는 것이 아니라 y2 = y-y1로 이동하는 것으로 훈련됩니다. 이 작업은 예측기의 수인 N번 반복되며, 아래 이미지에 나타난 바와 같습니다:\n\n![image](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_3.png)\n\n각 예측기는 의사 결정 트리(decision tree)입니다. 의사 결정 트리에 대한 설명을 할 때마다, 나는 그것을 게임 “guess who”에 비유하여 설명합니다. 그 게임은 다음과 같이 진행됩니다.\n\n각 플레이어가 일부 캐릭터 얼굴로 가득 찬 게시판을 가진 “guess who”의 클래식 게임을 하는 상황을 상상해보세요. 각 캐릭터는 머리카락 색상, 눈동자 색상, 안경, 모자 등과 같은 구별 가능한 특징을 가지고 있습니다. 목표는 이러한 특징들에 대한 예/아니오 질문을 통해 상대방의 비밀 캐릭터를 추측하는 것입니다. 각 질문은 답변과 맞지 않는 후보를 없애줄 뿐 아니라, 가능성을 좁히며 마침내 확신을 갖고 비밀 캐릭터를 추측할 수 있도록 도와줍니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Hands on Monotonic Time Series Forecasting with XGBoost using Python](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_4.png)\n\nAs you can see, the structure resembles an upside-down tree, starting from the leaves (bottom) and extending to the root (top).\n\nEach predictor corresponds to one of these trees. If you are pondering the difference between classification and regression, you are correct. The example I showcased, for simplicity, focuses on a classification problem. However, if you substitute \"Kristen\" with a real number like \"0.47462\", you will shift to a regression problem. It's that straightforward.\n\nThe XGBoost algorithm cleverly utilizes all these decision trees to \"boost\" the prediction of the preceding tree. It's called \"extreme\" because a plethora of intermediate optimization steps have been undertaken by the talented scientists who developed the algorithm, which you can explore [here](link).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n학습 파트는 항상 손실 함수 최소화 + 오버피팅 방지를 위한 정규화 항이 포함됩니다. 파라미터로는 잎의 수, 트리의 깊이 및 트리의 분할 지점이 있습니다. \"트리의 분할 지점\"이란 무엇을 의미하냐면요. 위 예제에서 \"이 사람이 아이인가요?\"와 같은 질문이 있습니다. 실제로는 연속적인 특성을 갖게 되어 \"x_1이 분할 지점인가요?\"와 같이 더 많이 사용하게 될 수 있습니다. 이는 분할 지점이 하나의 파라미터로 작용하게 되는 것입니다.\n\n## 1.1 XGBoost 단조성\n\n이제, XGBoost 알고리즘은 제공할 것이 많습니다:\n\n- 오버피팅에 대한 일반적으로 강한 내구성을 보여줍니다. 의사결정 트리는 오버피팅 문제가 잘 알려져 있으며 이러한 앙상블 방법은 이를 극복하는 데 좋습니다.\n- 저렴한 계산 복잡성을 다룰 수 있습니다. 그것을 하면서 오버피팅을 방지하는 것이 특히 명확하지 않습니다.\n- 특성의 중요성 덕분에 여전히 설명 가능성을 제공합니다. 이를 통해 어떤 X의 파라미터가 예측에 중요한지 이해할 수 있습니다.\n- 특정 특성에 대해 단조 함수로 응답을 하도록 선택할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어, 다음과 같은 함수가 있다고 가정해 봅시다:\n\n![Alt text](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_5.png)\n\n이 함수는 x2에 대해 단조적입니다. x1과 x2가 주어졌을 때 XGBoost를 사용하여 f(x1, x2)의 결과를 예측하려고 한다고 상상해 봅니다. 이제 현실에서 f(x1, x2)는 알려지지 않았습니다 (그렇지 않으면 기계 학습을 하지 않고 휴가를 가기위해 플로리다로 비행을 갈 것입니다), 하지만 x2에 대해 단조적이라는 점을 알거나 원할 수 있습니다. 실제로 저는 다른 양과 관련하여 단조적임을 알고 있던 물리량이 있었던 적이 있습니다. XGBoost의 구조를 수정하여 해당 특징에 대한 요구 사항을 충족시킬 수 있습니다. 우리의 경우, x2에 대한 단조적 행동을 강제하는 예측을 할 수 있습니다.\n\n좋아요. 이제 이걸 버텨내셨으면 좋겠네요. 이제 재미있는 부분으로 넘어갑시다. 😅\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 2. 코딩\n\n## 2.1 장난감 데이터셋\n\n결정 트리가 나를 많이 성장시키고, 나의 첫 번째 머신러닝 코드 중 하나였으니까 많은 감정을 불러일으켰어요. 조금 바보 같게 들릴지 몰라도, 조금은 감정적이 느껴져요 ❤️\n\n하지만 솔직히 이 코드는 굉장히 간단합니다. 그러니 더 이상 말이 필요 없이, 바로 시작해 봅시다. 두 가지 예제를 보여 드릴 건데, 첫 번째 예제는 1차원으로, 이 모든 것이 어떻게 작동하는지 설명하는 겁니다. 이것은 우리가 XGBoost를 사용해 예측하고자 하는 대상 함수 f입니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Image](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_6.png)\n\n이것이 플롯입니다.\n\n이제 XGBoost의 실용적인 구현이 문서에 단어별로 자세히 나와 있습니다. 제가 모든 부분을 알려드릴 필요는 없지만, 이 경우에 어떻게 작동하는지 보여드리고 싶습니다. 이는 온라인에서 찾을 수 있는 어떤 SkLearn 모델과 다를 바 없습니다.\n\n쉽죠. 이제 실제 테스트를 해봅시다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 2.2 실제 데이터셋\n\n위의 예제는 xgboost 코드의 구조를 보여줍니다. 그러나, 우리가 구축한 장난감 데이터셋에는 몇 가지 제한 사항이 있습니다:\n\n- 너무 간단하다 (1 차원) 그리고 완전히 근거없이 만들어진 데이터셋이다.\n- 우리는 데이터셋을 섞었기 때문에 예측적으로 사용하지 않았다.\n- 우리는 모노토닉 제약 조건을 사용하지 않았다 (내가 약속한 것).\n\n그래서, 실제 비즈니스를 시작해 볼까요?\n저는 델리 데이터의 데이터셋인 이 데이터셋을 사용했습니다. 이 데이터셋은 두 개의 csv 테이블 (DailyDelhiClimateTrain.csv와 DailyDelhiClimateTest.csv)으로 구성되어 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nPandas를 사용하여 데이터를 가져와서 5개의 행을 표시했습니다. 날짜, 습도, 풍속, 평균 기압 및 평균 온도와 같이 5개의 열이 있습니다. 하나의 합리적인 문제는 다음과 같을 수 있습니다:\n\n그리고 이 문제에 대해 잘 다루는 블로그 포스트가 있습니다. 우리는 한 단계 더 나아가려고 합니다. 우리는 이 다른 열인 \"City_Index\"를 추가할 것입니다. 이 City_Index는 뉴델리보다 더 덥거나 더 추운 다른 도시가 있다는 사실을 모방할 것입니다. 세계의 다른 부분별로 도시 지수를 그룹화하는 것처럼\\*:\n\n![이미지](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_7.png)\n\n이제 City_Index=1이 mean_temp의 기본 값이 되도록 만들 것입니다. City_Index = 2는 목표 값으로 2*mean_temp를 가져오도록 만들 것이고, City_Index=9는 목표 값으로 9*mean_temp를 가져오도록 할 것입니다. 이는 다른 변수를 모두 고정시킨다면 City_Index가 단조 변수가 될 수 있다는 것을 의미합니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_8.png\" />\n\n실제로 이것은 로스엔젤레스, 캘리포니아의 온도가 앵코리지, 알래스카의 온도보다 항상 높다는 것을 의미합니다 (알래스카에 있는 도시를 몰라서 구글링했어요).\n\n우리는 \"City_Index\" 변수와 이 두 함수를 통해 이를 할 것입니다:\n\n이제 우리는 이를 할 것입니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 새로운 City_Index 변수를 사용하여 증강된 데이터 세트를 생성합니다.\n- 데이터를 훈련 및 검증 세트로 분할합니다.\n- City_Index에서 단조성을 강제하여 시계열 XGBoost 예측기를 훈련하는 데 훈련 데이터를 사용하고 훈련된 모델을 사용하여 다음 값을 예측합니다.\n\n그리고 이렇게 테스트해 봅니다:\n\n그리고 이것이 우리의 예측 결과입니다:\n\n![image](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_9.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n몬토닉성은 params_constraints에서 확인할 수 있습니다. Params constraints 벡터는 우리가 몬토닉성을 유지하고 싶은 특성을 제외한 모든 특성을 0으로 설정한 벡터입니다.\n이제 알 수 있듯이, 다른 모든 특성을 고정하고 City_Index를 변경하면 몬토닉한 동작을 볼 수 있습니다:\n\n완벽하게 몬토닉합니다. 거의 선형적이기도 하죠 (우리가 사전에 특정한 것). 이것은 XGBoost 대 ARIMA, SARIMA 또는 다항 회귀를 사용하는 차이를 보여줍니다: XGBoost를 사용하면 명시적인 몬토닉 동작을 부여할 수 있습니다.\n\n# 3. 결론\n\n여기에서 우리가 한 작업을 요약해 드릴게요:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 저희는 예보 작업을 수행하되 보존하고 싶은 일부 단조 특성이 있는 문제를 소개했습니다. 이러한 경우에는 ARIMA나 RNN과 같은 고급 방법이 단조성을 깨뜨릴 수 있습니다.\n\n- 간단히 말해, \"추측 누구?\" 예제를 사용하여 XGBoost 아이디어를 소개했고, 부스팅 알고리즘이 선택할 수 있는 의사 결정 트리를 수정하여 단조성을 강제할 수 있다는 점을 확인했습니다.\n\n- 우리는 XGBoost를 장난감 예제에서 사용하여 구문이 작동하는 방식을 기본적으로 이해했습니다.\n\n- 기후변화 데이터를 사용하여 예보 연구를 수행했으며, 기본적인 예보 이상의 작업을 수행했습니다. 'City_Index'라는 새로운 특성에 단조적으로 증가하는 값을 부과함으로써, City_Index 특성에 대해 예측된 온도가 단조적이어야 한다는 가정에 기반하여 온도를 예측했습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 4. 저에 대해!\n\n다시 한 번 시간 내주셔서 감사합니다. 정말 감사드려요 ❤\n\n내 이름은 Piero Paialunga이고 난 이 사람이야:\n\n![이미지](/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_10.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저는 시내티 대학교 항공우주공학부 박사 후보이자 Gen Nine의 머신러닝 엔지니어입니다. 블로그 글과 Linkedin에서 AI 및 머신러닝에 대해 이야기합니다. 만약 글이 마음에 드시고 머신러닝에 대해 더 알고 싶으시다면:\n\nA. 제가 모든 이야기를 게시하는 Linkedin에서 팔로우하세요.\nB. 뉴스레터를 구독하세요. 새로운 이야기에 대한 업데이트를 제공하며 의문이나 궁금증이 있을 때 연락해 모든 수정을 받아볼 수 있습니다.\nC. 추천 회원이 되어 \"월간 최대 이야기 수\" 제한 없이 저 (그리고 수천 명의 다른 머신러닝 및 데이터 과학 최고 작가)가 제공하는 최신 기술에 대해 읽을 수 있습니다.\n\n질문이 있거나 협업을 시작하려면 여기에 메시지를 남겨주세요:\n\npiero.paialunga@hotmail.com\n","ogImage":{"url":"/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-HandsOnMonotonicTimeSeriesForecastingwithXGBoostusingPython_0.png","tag":["Tech"],"readingTime":13},{"title":"파이썬 데이터 시각화 Seaborn 라이브러리 사용법","description":"","date":"2024-07-09 20:10","slug":"2024-07-09-DataVisualizationinPythonSeabornLibrary","content":"\n시각화는 데이터에서 통찰을 전달하는 강력한 방법입니다. 파이썬의 Seaborn 라이브러리는 Matplotlib을 기반으로 한, 시각적으로 매력적이고 정보를 제공하는 높은 수준의 인터페이스를 제공합니다. 이 기사에서는 Seaborn 라이브러리를 자세히 살펴보며 그 기능을 탐구하고 다양성을 보여주는 실용적인 코드 예제를 제시할 것입니다.\n\n![image](/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_0.png)\n\n## Seaborn이란\n\nSeaborn은 복잡하고 아름다운 시각화를 만드는 과정을 단순화하는 데이터 시각화 라이브러리입니다. 시각적 경험을 향상하기 위해 내장된 테마와 색 팔레트를 제공합니다. Seaborn은 통계적 시각화를 생성하는 데 특히 적합하며 변수 간의 관계를 시각화하는 데 자주 사용됩니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Seaborn을 이용한 시각화 생성\n\nSeaborn의 주요 기능과 기능을 몇 가지 코드 예제와 함께 살펴보겠습니다.\n\n## 1. 산점도\n\n- a) 기본 산점도\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n```js\n# 샘플 데이터\nx = [1, 2, 3, 4, 5]\ny = [3, 5, 8, 6, 7]\n```\n\n```js\n# Seaborn을 사용하여 기본 산점도 그리기\nsns.scatterplot(x=x, y=y)\nplt.xlabel('X축')\nplt.ylabel('Y축')\nplt.title('Seaborn을 사용한 기본 산점도')\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_1.png\" />\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- b) 색상과 색조를 가진 산점도\n\n```python\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n```python\n# 샘플 데이터\nx = [1, 2, 3, 4, 5]\ny = [3, 5, 8, 6, 7]\ncategories = ['A', 'B', 'A', 'B', 'A']\n```\n\n```python\n# Seaborn을 사용하여 색상과 색조를 가진 산점도 생성\nsns.scatterplot(x=x, y=y, hue=categories, palette='Set1')\nplt.xlabel('X-축')\nplt.ylabel('Y-축')\nplt.title('색상과 색조를 가진 산점도')\nplt.show()\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_2.png\" />\n\n## 2. 상자 그림\n\n- a) 기본 상자 그림\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 샘플 데이터\ndata = sns.load_dataset('iris')\n```\n\n```js\n# Seaborn을 사용하여 기본 상자 그림 생성\nsns.boxplot(x='species', y='sepal_length', data=data)\nplt.xlabel('종류')\nplt.ylabel('꽃 받침 길이')\nplt.title('Seaborn을 사용한 기본 상자 그림')\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_3.png\" />\n\n- b) 색상 팔레트를 사용한 가로 상자 그림\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n```js\n# 샘플 데이터\ndata = sns.load_dataset('titanic')\n```\n\n```js\n# Seaborn을 사용하여 색상 팔레트를 이용한 수평 상자 그림 생성\nsns.boxplot(x='age', y='class', data=data, orient='h', palette='Set2')\nplt.xlabel('나이')\nplt.ylabel('등급')\nplt.title('색상 팔레트를 이용한 수평 상자 그림')\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_4.png\" />\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- c) 그룹화된 상자 그림\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n```js\n# 샘플 데이터\ndata = sns.load_dataset('tips')\n```\n\n```js\n# Seaborn을 사용하여 그룹화된 상자 그림 생성\nsns.boxplot(x='day', y='total_bill', data=data, hue='sex', palette='Set3')\nplt.xlabel('요일')\nplt.ylabel('총 계산')\nplt.title('그룹화된 상자 그림')\nplt.legend(title='성별')\nplt.show()\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_5.png\" />\n\n- d) Notched Box Plot\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n```js\n# Sample data\ndata = sns.load_dataset('diamonds')\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# Seaborn을 사용하여 notch가 있는 상자 그림 만들기\nsns.boxplot(x='cut', y='price', data=data, notch=True, palette='pastel')\nplt.xlabel('Cut')\nplt.ylabel('Price')\nplt.title('Notched Box Plot')\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_6.png\" />\n\n- e) 사용자 정의 상자 그림\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 샘플 데이터\ndata = sns.load_dataset('mpg')\n```\n\n```js\n# Seaborn을 사용하여 사용자 정의 상자 그림 만들기\nsns.boxplot(x='origin', y='mpg', data=data, hue='cylinders', palette='Set2')\nplt.xlabel('Origin')\nplt.ylabel('Miles per Gallon')\nplt.title('Customized Box Plot')\nplt.legend(title='Cylinders')\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_7.png\" />\n\n## 3. Pair Plot\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- a) 기본 Pair Plot\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n```js\n# 샘플 데이터\ndata = sns.load_dataset('iris')\n```\n\n```js\n# Seaborn을 사용하여 기본 Pair Plot 생성\nsns.pairplot(data, hue='species')\nplt.title('Seaborn을 사용한 기본 Pair Plot')\nplt.show()\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_8.png)\n\n- b) Pair Plot with Custom Color Palette\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n```js\n# Sample data\ndata = sns.load_dataset('tips')\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# Seaborn을 사용하여 사용자 정의 색상 팔레트로 pair plot 만들기\nsns.pairplot(data, hue='sex', palette='Set2')\nplt.title('사용자 정의 색상 팔레트로 Pair Plot 만들기')\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_9.png\" />\n\n- c) 다른 플롯 유형을 사용한 Pair Plot\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 샘플 데이터\ndata = sns.load_dataset('penguins')\n```\n\n```js\n# Seaborn을 사용하여 다른 종류의 플롯을 사용하여 페어 플롯 생성\ng = sns.PairGrid(data)\ng.map_upper(sns.scatterplot)\ng.map_lower(sns.kdeplot)\ng.map_diag(sns.histplot, kde_kws={'color': 'k'})\nplt.title('다른 플롯 유형을 사용한 페어 플롯')\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_10.png\" />\n\n# 결론\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n시본은 파이썬에서 정보를 전달하고 미적으로 매력적인 데이터 시각화를 생성하는 강력한 라이브러리입니다. 산점도, 상자 그림, 쌍 플롯 또는 더 복잡한 시각화를 만들 때 시본의 우아한 구문과 내장 테마가 과정을 단순화합니다.\n\n# 파이썬 기초\n\n소중한 시간 내어 주셔서 감사합니다! 🚀\n더 많은 콘텐츠는 \"Python Fundamentals\"에서 찾아보실 수 있어요! 💫\n","ogImage":{"url":"/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-DataVisualizationinPythonSeabornLibrary_0.png","tag":["Tech"],"readingTime":10},{"title":"파이썬 비동기 프로세싱 소개","description":"","date":"2024-07-09 20:08","slug":"2024-07-09-PythonAsynchronousProcessingIntroduction","content":"\n![image](/TIL/assets/img/2024-07-09-PythonAsynchronousProcessingIntroduction_0.png)\n\n# Asynchronous Processing이란 무엇인가요?\n\n비동기 처리는 작업이나 동작을 메인 프로그램의 실행을 차단하지 않고 동시에 실행할 수 있는 프로그래밍 패러다임입니다.\n\n![image](/TIL/assets/img/2024-07-09-PythonAsynchronousProcessingIntroduction_1.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n전통적인 동기 처리 방식에서는 작업이 순차적으로 실행되며, 각 작업이 완료될 때까지 다음 작업으로 넘어가기 전에 프로그램이 기다립니다.\n\n이 방식은 특히 파일 작업이나 네트워크 요청과 같이 I/O 대기가 필요한 작업에 대해 비효율적일 수 있습니다. 이러한 경우 프로그램은 상당한 시간 동안 유휴 상태가 될 수 있습니다.\n\n예를 들어, 아래 코드를 실행한다면:\n\n```js\nimport time\n\n# 작업을 수행하는 동기 함수\ndef task(name):\n    print(f\"작업 {name} 시작\")\n    time.sleep(2)  # 2초의 지연을 모의합니다\n    print(f\"작업 {name} 완료\")\n\n# 메인 프로그램\n\nprint(\"메인 프로그램 시작\")\n\n# 작업을 순차적으로 수행\ntask(\"A\")\ntask(\"B\")\ntask(\"C\")\n\nprint(\"메인 프로그램 완료\")\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 출력을 볼 수 있습니다:\n\n```js\nMain program started\nTask A started\nTask A completed\nTask B started\nTask B completed\nTask C started\nTask C completed\nMain program completed\n```\n\n반면에 비동기 처리는 작업이 독립적으로 및 동시에 실행되도록 합니다. 이는 프로그램이 작업을 시작하고 해당 작업이 완료될 때까지 기다리지 않고 다른 작업을 계속할 수 있도록 합니다. 완료된 작업은 준비되면 프로그램이 결과를 처리하거나 실행을 계속할 수 있도록 알림이나 이벤트를 트리거합니다.\n\n예를 들어:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport asyncio\n\n# 작업을 나타내는 비동기 코루틴\nasync def task(name):\n    print(f\"작업 {name} 시작\")\n    await asyncio.sleep(2)  # 2초의 지연을 모의\n    print(f\"작업 {name} 완료\")\n\n# 메인 프로그램\n\nasync def main():\n    print(\"메인 프로그램 시작\")\n\n    # 동시에 실행할 작업 목록 생성\n    tasks = [\n        asyncio.create_task(task(\"A\")),\n        asyncio.create_task(task(\"B\")),\n        asyncio.create_task(task(\"C\"))\n    ]\n\n    # 모든 작업이 완료될 때까지 대기\n    await asyncio.gather(*tasks)\n\n    print(\"메인 프로그램 완료\")\n\n# 메인 프로그램 실행\nasyncio.run(main())\n```\n\n출력:\n\n```js\n메인 프로그램 시작\n작업 A 시작\n작업 B 시작\n작업 C 시작\n작업 A 완료\n작업 B 완료\n작업 C 완료\n메인 프로그램 완료\n```\n\n모든 작업이 동시에 시작되며, 완료 순서는 다를 수 있습니다. 메인 프로그램은 작업이 완료될 때까지 기다리지 않고 실행을 계속하여 비동기성을 실현합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n비동기 처리는 일반적으로 코루틴, 이벤트 기반 프로그래밍 또는 콜백 기반 프로그래밍 모델과 같은 비동기 프로그래밍 기법을 사용하여 달성됩니다. 이러한 기술을 사용하면 프로그램이 블로킹 없이 여러 작업 간에 전환할 수 있어 시스템 자원을 가장 효율적으로 활용할 수 있습니다.\n\n비동기 처리의 장점은 성능, 응답 속도, 확장성이 향상된다는 점입니다. 불필요한 대기를 피하고 리소스 사용을 최대화함으로써 응용 프로그램은 대규모의 동시 작업을 효율적으로 처리할 수 있습니다.\n\n# 병렬성 vs 동시성 vs 스레딩\n\n## 병렬성\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n병렬 처리는 여러 개의 연산 장치를 사용하여 동시에 여러 작업을 수행하는 것을 말합니다. 이는 주로 멀티코어 프로세서가 장착된 시스템에서 볼 수 있으며 각 작업이 별도의 CPU/프로세서에서 실행됩니다. 이는 주로 하드웨어의 기능입니다. 참된 병렬 처리에서는 여러 작업이 물리적으로 동시에 실행되며, 마치 여러 명의 작업자가 거대한 벽의 서로 다른 부분을 동시에 도색하는 것과 같습니다.\n\n```python\nfrom multiprocessing import Process\n\ndef worker(num):\n    print(f'Worker: {num}')\n\nif __name__ == '__main__':\n    processes = [Process(target=worker, args=(i,)) for i in range(5)]\n\n    for process in processes:\n        process.start()\n\n    for process in processes:\n        process.join()\n```\n\n출력:\n\n```python\nWorker: 1\nWorker: 0\nWorker: 2\nWorker: 3\nWorker: 4\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 동시성\n\n동시성은 동시에 여러 작업을 처리하는 것에 대한 이야기입니다. 하지만 반드시 동시에 실행되는 것은 아닙니다. 여러 작업들이 서로 기다리지 않고 전진하며, 정확히 동시에 실행되는 것은 아닐 수 있습니다.\n\n이는 단일 코어(시분할) 및 멀티 코어 프로세서에서 발생할 수 있습니다. 실행보다는 작업 구조화와 완료에 더 관련이 있습니다. 동시성을 이해하기 위한 간단한 예는 주방에서 일하는 단일 요리사일 수 있습니다. 여기서 그는 여러 요리를 동시에 요리하는데, 빠르게 작업을 전환하여 동시에 작업을 수행하고있다는 인상을 줍니다.\n\n```js\nimport asyncio\n\nasync def worker(num):\n    print(f'작업자 시작: {num}')\n    await asyncio.sleep(1)\n    print(f'작업자 완료: {num}')\n\nasync def main():\n    # 동시에 실행될 작업 목록 생성\n    tasks = [\n        asyncio.create_task(worker(1)),\n        asyncio.create_task(worker(2)),\n        asyncio.create_task(worker(3))\n    ]\n\n    # 모든 작업이 완료될 때까지 대기\n    await asyncio.gather(*tasks)\n\nasyncio.run(main())\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nStart worker: 1\nStart worker: 2\nStart worker: 3\nFinish worker: 1\nFinish worker: 2\nFinish worker: 3\n```\n\n## 스레딩\n\n스레딩은 동시성을 달성하기 위한 프로그래밍 개념과 기술입니다. 스레드는 운영 체제의 스케줄러에 의해 독립적으로 관리될 수 있는 프로그램 명령의 가장 작은 시퀀스입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프로그램에는 여러 개의 스레드가 포함될 수 있으며, 각각이 특정 작업을 동시에 처리할 수 있습니다. 여러 스레드를 관리함으로써 하나의 프로세스가 작업을 동시에 실행할 수 있으므로 전체 실행 속도와 효율성이 높아집니다.\n\n시스템에 멀티코어 프로세서가 있다면, 개별 스레드도 병렬로 실행될 수 있습니다. 스레딩의 좋은 예로는 웹 서버가 서로 다른 사용자의 여러 요청을 처리하는 것이 있습니다. 각 요청은 별도의 스레드에서 처리됩니다.\n\n스레딩에 대해 알아둬야 할 중요한 점은 IO-바운드 작업을 다룰 때 그 향상된 효율성입니다. CPU-바운드 작업과는 대조적으로, 계산이 시작부터 끝까지 CPU의 처리 능력에 크게 의존하는 작업에 비해, IO-바운드 작업은 입력/출력 작업이 완료되기를 기다리는 동안 상당한 유휴 시간이 있습니다.\n\n```python\nimport threading\n\ndef worker(num):\n    print(f'작업자: {num}')\n\nif __name__ == '__main__':\n    threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]\n\n    for thread in threads:\n        thread.start()\n\n    for thread in threads:\n        thread.join()\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nWorker: 0;\nWorker: 1;\nWorker: 2;\nWorker: 4;\nWorker: 3;\n```\n\n요약하면, 병행 시스템에서 작업이 겹치면서 시작, 실행 및 완료되지만, 병렬 시스템에서 작업은 동시에 실행됩니다— 이것이 핵심적인 차이점입니다. 스레딩은 우리가 동시성 및 가능한 병렬성의 목표를 달성하는 기술일 뿐입니다. 동시성에는 CPU 집약적 작업에 최적화된 다중 처리와 IO 집약적 작업에 적합한 스레딩이 포함됩니다. 다중 처리는 병렬성의 한 유형으로 간주될 수 있으며, 병렬성 자체가 동시성의 특정 종류(하위 집합)입니다.\n\n# Python Asyncio 모듈\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nThe `asyncio` 모듈은 파이썬에서 강력한 라이브러리로, 비동기 코드를 작성하는 데 필요한 지원을 제공합니다. 이는 코루틴, 이벤트 루프, 비동기 I/O 개념을 기반으로하며 효율적이고 동시성을 가진 프로그래밍을 가능하게 합니다.\n\n`asyncio`를 사용한 비동기 프로그래밍을 통해 단일 스레드 동시성 코드를 작성하고 여러 작업을 동시에 실행할 수 있으며 블로킹 작업을 피할 수 있습니다. 이 접근 방식은 특히 장시간 대기 시간이 발생하는 네트워크 요청 또는 파일 작업과 같은 I/O 바운드 작업을 처리할 때 유용합니다.\n\n`asyncio`는 코루틴을 정의하고 비동기 코드의 실행 흐름을 관리하는 데 사용되는 `async` 및 `await` 키워드를 소개합니다. 코루틴은 일시 중지되고 다시 시작될 수 있는 함수로, 그 사이에 다른 작업이 실행될 수 있습니다. 이벤트 루프는 중앙 스케줄러로 작동하여 이러한 코루틴의 실행을 조정하고 I/O 작업을 효율적으로 관리합니다.\n\n## 주요 기능\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 코루틴: 코루틴은 async 키워드로 정의된 함수들입니다. 실행 중에 일시 중지되고 다시 실행되어 다른 코루틴이 동시에 실행될 수 있습니다.\n- 이벤트 루프: 이벤트 루프는 코루틴에 대한 실행 환경을 제공합니다. 여러 코루틴 간의 스케줄링 및 전환이 관리되어 효율적이고 블로킹되지 않는 실행을 보장합니다.\n- 작업: 작업은 코루틴 위에서 더 높은 수준의 추상화입니다. 비동기로 실행해야 하는 작업 단위를 나타내고 이벤트 루프에 의해 스케줄링되고 관리될 수 있습니다.\n- 미래: 미래는 아직 완료되지 않을 수 있는 코루틴의 결과를 나타내는 객체입니다. 비동기 작업의 완료를 추적하고 기다릴 수 있게 합니다.\n- 동기화 기본 요소: asyncio는 락, 세마포어, 큐와 같은 다양한 동기화 기본 요소를 제공하여 공유 리소스를 관리하고 동시 작업을 조정하는 데 도움을 줍니다.\n\n그러나 asyncio는 협력적으로 멀티태스킹을 기반으로 하는 단일 스레드, 단일 프로세스 모델을 사용합니다. asyncio는 하나의 스레드 내에서 작동하지만 효과적이고 블로킹되지 않는 실행 환경을 제공하여 동시성의 환상을 만들어냅니다. asyncio의 핵심인 코루틴은 동시에 배포될 수 있지만 그 자체로는 본질적으로 동시성을 가지지 않습니다.\n\n강조하자면, asyncio는 동시 프로그래밍의 한 형태이지만 병렬성과는 동일하게 여기지 않아야 합니다. 그 방법론은 쓰레딩(threading)과 공유(`multiprocessing`)와는 더 일치하지만 그 둘로부터 독립적이며 다양한 동시성 기술들 중에서 독자적인 방법론을 취하고 있습니다.\n\n# async와 await\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nThe async and await syntax are key components of Python's asyncio module, a library used for writing concurrent code using the async/await syntax.\n\n## async\n\nasync is a keyword used to declare a function as an \"asynchronous function\". Such functions are also known as \"coroutines\". You define a coroutine by prefixing def with async. For example, async def my_function():.\n\nWhen an async function is called, it doesn't execute in the traditional way. Instead, it returns an \"awaitable\" object, which is a coroutine object. This object needs to be awaited or run in an event loop to get the result. The event loop is where the asynchronous code is executed. It's the core of every asyncio application, managing and scheduling the execution of asynchronous tasks.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## await\n\nawait은 기다리고 있는 작업이 완료될 때까지 코루틴을 일시 중지하는 데 사용됩니다. 이는 async 함수 내에서만 사용할 수 있습니다. await 키워드 뒤에는 코루틴, Future 또는 I/O-bound 함수와 같은 \"awaitable\" 객체로 이루어진 식이 따릅니다.\n\nawait 표현식이 실행되면 사용된 코루틴은 awaitable이 해결될 때까지 일시 중지됩니다. 이러한 일시 중지 동안 이벤트 루프는 다른 작업을 계속 실행합니다.\n\n## async와 await을 사용하는 이유\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 논블로킹: 비동기 코드는 논블로킹 I/O 작업을 허용합니다. 대기 중인 경우, 다른 코드를 실행할 수 있습니다.\n- 동시성: 더 효율적이고 유지보수가 용이한 방식으로 동시성 코드를 작성할 수 있도록 합니다.\n- 성능: I/O 바운드 애플리케이션에서 async/await를 사용하면 상당한 성능 향상이 가능합니다.\n- 가독성: async/await 구문은 콜백과 같은 이전 비동기 프로그래밍 기법에 비해 더 읽기 쉽고 직관적입니다.\n\n예시:\n\n```python\nimport asyncio\n\nasync def my_async_function():\n    await asyncio.sleep(1)\n    return \"안녕, 비동기 세계!\"\n\nasync def main():\n    result = await my_async_function()\n    print(result)\n\n# 주요 코루틴 실행\nasyncio.run(main())\n```\n","ogImage":{"url":"/assets/img/2024-07-09-PythonAsynchronousProcessingIntroduction_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-PythonAsynchronousProcessingIntroduction_0.png","tag":["Tech"],"readingTime":12},{"title":"정말 유용한 7가지 GitHub 프로젝트","description":"","date":"2024-07-09 20:07","slug":"2024-07-09-7SuperUsefulGitHubProjects","content":"\n소프트웨어 개발 및 시스템 관리의 끊임없이 변화하는 환경에서는 특정 도전 과제를 해결하고 생산성을 향상시키기 위해 지속적으로 새로운 도구와 라이브러리가 등장합니다. 이 문서는 Netshoot, Superfile, E2B의 Code Interpreter SDK, Kitbag Router, AWS Lambda Web Adapter 및 React Lua와 같이 6가지 혁신을 강조합니다.\n\n이 도구들 각각은 컨테이너화된 환경에서의 네트워크 문제 해결부터 서버리스 아키텍처에서 웹 응용 프로그램을 가능하게 하는 것과 같이 현대 소프트웨어 개발의 고유한 측면을 대상으로 합니다. 이러한 솔루션들은 산업이 복잡한 작업을 단순화하고 효율성을 향상시키며 다른 기술과 패러다임 간의 간극을 좁히기 위한 지속적인 노력을 보여줍니다.\n\n## 추가로 읽을 거리:\n\n프롬프트 디자인의 기술을 숙달하기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n디자인 및 사용자 스토리 매핑을위한 인공 지능\n\n7개의 더 많은 오픈 소스 도구\n\n언어 모델 구축은 데이터로 시작합니다.\n\n무료로 구독할 수있는 AI 소식지 BrainScriblr도 쓰고 있어요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모든 이미지는 별도로 표기되지 않는 한, 제가 캡처한 스크린샷입니다.\n\n## Netshoot\n\nNetshoot은 Docker 및 Kubernetes 네트워크 문제 해결용 컨테이너로, 네트워크 문제를 진단하고 해결하는 다재다능한 도구로 사용됩니다. 컨테이너화된 환경에서 복잡한 네트워킹 문제를 이해하고 해결하는 데 도움이 되는 포괄적인 도구 세트를 제공합니다.\n\nNetshoot의 주요 기능 중 하나는 네트워크 네임스페이스의 사용으로, 네트워킹과 관련된 시스템 리소스를 격리할 수 있습니다. 이를 통해 특정 컨테이너나 팟 내에서 자세한 검사와 문제 해결이 가능합니다. 이 도구는 기존 팟의 디버깅을 위해 일회용 컨테이너를 사용하거나 디버깅을 위해 일시적인 팟을 생성하거나, 호스트의 네트워크 네임스페이스 내에서 컨테이너를 시작하여 호스트 수준의 문제 해결할 수도 있습니다. 또한 응용 프로그램 컨테이너와 함께 해결해야 하는 사이드카 컨테이너로 사용할 수도 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nNetshoot은 netstat, nmap, tcpdump, iftop, iperf, drill, nsenter 등 다양한 네트워킹 도구를 포함하고 있어 네트워크 분석과 문제 해결에 탁월한 기능을 제공합니다. Kubernetes와 잘 통합되어 있어 직접 명령어 또는 Netshoot Kubectl 플러그인을 통해 임시 컨테이너를 쉽게 만들 수 있어요. Docker 사용자들은 Docker 명령어나 Docker Compose를 사용하여 Netshoot을 배포할 수 있어 다양한 배포 시나리오에 유연성을 제공합니다.\n\n## Superfile\n\nSuperfile은 공통 파일 작업을 쉽게 할 수 있도록 설계된 현대적이고 시각적으로 매력적인 터미널 파일 매니저에요. macOS 및 Linux 사용자를 위한 빠르고 쉬운 설치 프로세스를 제공하며 간단한 명령어로 설치할 수 있어요. 대체 설치 방법을 선호하는 사용자들을 위해 프로젝트 페이지에서 추가 옵션이 제공됩니다.\n\n소스 코드에서 Superfile을 빌드하려는 사용자들을 위한 프로세스는 간단해요. 저장소를 복제하고 적절한 디렉터리로 이동하여 빌드 스크립트를 실행하고 생성된 바이너리를 시스템 경로로 이동하는 과정이에요. 이 방법은 설치 프로세스에 대한 더 많은 제어를 제공합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n슈퍼파일은 현재 리눅스와 macOS를 완벽하게 지원하며 Windows 시스템에서 일부 지원됩니다. 여러분의 경험을 맞춤화하기 위해 다양한 플러그인과 테마를 제공하여 사용자 경험을 세부적으로 조정하는 데 엄청난 노력을 기울이고 있습니다. 이 파일 관리자는 구성 가능한 단축키를 제공하며 vim/nvim 사용자를 위한 구체적인 설정도 제공하여 이 텍스트 편집기에 익숙한 사용자에게 높은 편리성을 제공합니다.\n\n문제 해결에 도움을 드리기 위해 프로젝트는 포괄적인 가이드와 귀중한 팁을 제공합니다. 개발자는 커뮤니티로부터의 기여를 환영하며 프로젝트 개발에 참여하고 싶은 분들을 위한 지침서를 저장소에서 제공하고 있습니다.\n\n## 코드 해석기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nE2B의 코드 해석기 SDK는 코드 해석 기능을 AI 애플리케이션에 통합하기 위해 설계된 도구입니다. 이 도구를 사용하면 AI 앱이 E2B 샌드박스 내에서 코드를 해석하고 실행할 수 있습니다. E2B 샌드박스는 신뢰할 수 없는 AI 생성 코드 및 AI 에이전트를 실행하는 안전한 오픈 소스 환경입니다.\n\n이 SDK는 모든 대형 언어 모델 (LLM) 및 AI 프레임워크를 지원하며 차트, 표준 출력 및 표준 에러와 같은 스트리밍 콘텐츠를 지원합니다. SDK는 Python 및 JavaScript/TypeScript (JS/TS) 모두에서 사용할 수 있어 다양한 개발 환경에 유연하게 대응할 수 있습니다.\n\n코드 해석기 SDK는 서버리스 및 엣지 기능에 배포할 수 있어 AI 생성 코드를 안전하게 실행할 수 있습니다. 또한 전체 인프라는 완전히 오픈 소스로, 사용자에게 투명성과 유연성을 제공합니다.\n\n현재 SDK는 Python을 완전히 지원하며, JavaScript, R 및 Java의 베타 지원이 제공됩니다. JavaScript/TypeScript 및 Python에 각각 간단한 npm 또는 pip 명령을 사용하여 쉽게 설치할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSDK는 JavaScript와 Python 양쪽에 대해 사용하기 쉬운 인터페이스를 제공합니다. 사용자는 몇 줄의 코드로 샌드박스를 생성하고 코드 셀을 실행하며 결과를 검색할 수 있습니다. 이 간편함으로 모든 경험 수준의 개발자들에게 접근성을 제공합니다.\n\nE2B는 개발자들이 쉽게 시작할 수 있도록 상세한 문서 및 빠른 시작 가이드를 제공합니다. 이에는 JavaScript/TypeScript 및 Python에 대한 쿡북 예제, \"Hello World\" 가이드뿐만 아니라 다양한 LLM 제공업체 및 AI 프레임워크를 지원하는 내용이 포함됩니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKitbag Router은 Vue.js 애플리케이션에 특별히 설계된 타입 안전한 라우팅 라이브러리입니다. 이는 라우팅 프로세스를 간단하고 향상시키려는 목적으로, Vue 프로젝트 내에서 탐색을 관리하기 위한 강력한 도구 세트를 제공합니다.\n\n이 라이브러리는 bun, yarn 또는 npm과 같은 인기있는 패키지 관리자를 이용하여 쉽게 설치할 수 있습니다. 설치 후에는 `createRoutes` 함수를 사용하여 라우트를 정의할 수 있습니다. 이 함수를 사용하면 이름, 경로 및 관련 컴포넌트를 지정하는 각 라우트의 배열을 생성할 수 있습니다.\n\nVue 애플리케이션에 Kitbag Router를 구현하려면, `createRouter` 함수를 사용하여 라우터 인스턴스를 생성하고 이를 플러그인으로 Vue 앱에 전달해야 합니다. 이 설정을 통해 애플리케이션 전체에서 라우팅 기능을 활성화할 수 있습니다.\n\n라우트 간 이동은 `router.push` 메서드를 통해 용이하게 수행할 수 있으며, 이 메서드는 라우트 이름, URL 경로 및 완전한 URL을 처리할 수 있습니다. 더 동적인 라우팅을 위해, 라이브러리는 `router.route.update`를 사용하여 런타임에서 라우트 매개변수를 업데이트할 수 있는 기능을 제공합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKitbag Router은 Vue 템플릿에서 사용할 수 있는 두 가지 주요 구성 요소인 `RouterView`와 `RouterLink`를 제공합니다. `RouterView` 컴포넌트는 라우트 컴포넌트가 애플리케이션 레이아웃 내에서 렌더링될 위치를 정의합니다. 반면에 `RouterLink` 컴포넌트는 페이지 다시로드를 유발하지 않고 라우트 간의 탐색을 가능하게 하므로 싱글 페이지 애플리케이션 경험을 향상시킵니다.\n\n타입 안전성과 효율적인 라우트 관리에 중점을 둔 Kitbag Router는 Vue 개발자에게 원활하고 탐색 가능한 웹 애플리케이션을 만들 수 있는 강력한 도구를 제공합니다. 보다 자세한 정보와 사용 예시는 Kitbag Router GitHub 저장소에서 확인할 수 있습니다.\n\n## AWS Lamda Web Adapter\n\nAWS Lambda 웹 어댑터는 기존 웹 개발과 서버리스 아키텍처를 연결하여 웹 애플리케이션을 AWS Lambda에서 실행할 수 있게 하는 도구입니다. 다양한 웹 프레임워크를 지원하여 기존 애플리케이션을 최소한의 변경으로 Lambda에 배포할 수 있게 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n중요한 혜택은 자동 크기 조정, 운영 오버헤드 감소, 그리고 사용량당 요금 체계를 통한 비용 효율성을 포함합니다. 이 어댑터는 Lambda로의 배포를 단순화하여 기존의 웹 프레임워크에 익숙한 개발자들에게 서버리스 아키텍처를 더 쉽게 접근할 수 있도록 도와줍니다.\n\n사용 사례에는 서버리스 환경에서 웹 응용 프로그램, 마이크로서비스 및 API를 배포하는 것이 포함됩니다. 이 프로젝트는 오픈 소스로, 커뮤니티 기여와 개선을 촉진합니다.\n\n이 어댑터는 지속적 통합 및 배포 워크플로우를 통합하여 효율적인 테스트 및 배포 프로세스를 용이하게 합니다. 익숙한 개발 관행을 유지하면서 서버리스 장점을 활용하고자 하는 개발자들을 위해 AWS Lambda 웹 어댑터가 가치 있는 해결책을 제공합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 리액트 Lua\n\n리액트 Lua는 ReactJS 17.x를 JavaScript에서 Lua로 번역하는 프로젝트로, 성능과 정확성을 최적화합니다. 기본적으로 원래의 ReactJS와 근접하게 유지하면서 Lua의 장점을 활용하려고 합니다.\n\n이 프로젝트는 가능한 경우 Luau 유형 주석을 사용하며 대부분의 ReactJS 리소스와 호환되도록 설계되었으며 언어 차이에 맞게 조정되었습니다. Roblox의 react-lua의 포크로 커뮤니티 주도의 대안으로 의도되었습니다.\n\nReact Lua는 'react', 'scheduler', 'shared'와 같은 주요 패키지를 이식했으며 일부 패키지는 이식되지 않은 상태입니다. Roblox 생태계를 고려하기 위해 Roact와 호환성을 지향하며 일부 조정사항이 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기여자들은 상류 ReactJS와의 일치를 유지하고 필요한 경우 어떠한 이탈 사항도 문서화하는 것을 권장합니다. 이 프로젝트는 ReactJS와 Lua 생태계 사이의 다리 역할을 하며, Lua 개발자들을 위한 익숙하면서도 최적화된 개발 경험을 제공합니다.\n\n토론된 도구들은 다양한 기능을 다루고 있습니다: Docker와 Kubernetes에서 네트워크 진단을 위한 Netshoot, 현대적인 터미널 기반 파일 관리를 위한 Superfile, AI 애플리케이션에서 코드 실행을 통합하기 위한 E2B의 코드 인터프리터 SDK, Vue.js에서 타입 안전한 라우팅을 위한 Kitbag Router, 서버리스 인프라에서 웹 애플리케이션 실행을 위한 AWS Lambda 웹 어댑터, 그리고 ReactJS를 Lua로 변환하는 React Lua. 각 도구는 특정 개발자 요구를 해결하며, 각 도메인에서 공통적인 도전 과제에 대한 혁신적인 해결책을 제공합니다.\n","ogImage":{"url":"/assets/img/2024-07-09-7SuperUsefulGitHubProjects_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-7SuperUsefulGitHubProjects_0.png","tag":["Tech"],"readingTime":9},{"title":"Python의 풍부한 플롯 컬렉션 마스터하기 코드 포함","description":"","date":"2024-07-09 20:05","slug":"2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode","content":"\n<img src=\"/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_0.png\" />\n\n모든 데이터 과학자들이 그래픽이 그들의 데이터 이야기에 중요하다는 것을 알고 있습니다. Python 개발자들은 풍부한 플롯 컬렉션을 제공하는 언어로 일할 수 있어 행운입니다. 이 기사에서는 Sankey 다이어그램, 리지 플롯, 인셋, 스파이더 플롯 및 워드클라우드 플롯과 같이 잘 알려지지 않은 시각화를 사용하는 사용 사례에 대해 논의하여 이 풍부함을 시연할 것입니다. 또한 산점도 및 막대 플롯과 같은 더 익숙한 그래픽 표현에 대한 사용 사례도 논의할 것입니다. 대부분의 플롯은 Matplotlib, Seaborn 및 Plotly Python 라이브러리를 활용할 것입니다.\n\n모든 사용 사례에서 모양, 크기, 색상, 방향, 면적 크기 및 마커 심볼 영역 같은 특성을 활용하여 10가지 다양한 사용 사례에 대한 플롯을 생성할 것입니다. 모든 사용 사례에서 우리의 목표는 효과적이고 효율적이며 미학적인 시각화를 만드는 것입니다. 우리가 플롯의 맥락에서 이러한 단어가 의미하는 바를 설명해보겠습니다: (a) 효과적: 전달해야 하는 모든 정보가 그래프 안에 포함되어 있습니다. (b) 효율적: 그래프에 중복 데이터가 없습니다. (c) 미적. 그래프는 데이터를 명확하게 제시하며 시각적으로 매력적이고 주목을 끕니다. 이 기사의 모든 그래프는 2D입니다. 효율성과 효과성 측면에서 3D보다 2D 그래프가 더 명확하고 이해하기 쉽고, 거리를 2D에 더 잘 표현할 수 있기 때문입니다. 각 사용 사례에 대한 코드도 제시되며 코드와 그래픽의 중요한 부분이 논의될 것입니다.\n\n사용 사례 1. 대학 간 교환 학생 흐름 설명을 위한 Sankey 다이어그램.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 다이어그램은 리소스 흐름을 보여주는 데 매우 유용합니다. 아래 코드는 우리의 사용 사례 구현을 보여줍니다. 문자 'A'는 첫 번째 대학을 나타내고, 문자 'B'는 두 번째 대학을 나타냅니다. 숫자 3,4,5는 각각 '통계, 수학, 물리' 부서를 나타냅니다. 다이어그램은 25번째 줄에서 'node'와 'link'가 딕셔너리로 생성됩니다. 'node'는 고유한 'Depts'로 구성된 'label' 객체를 사용하고, 'link'는 'sending' 부서의 인덱스와 'accepting' 부서의 인덱스로 구성된 두 개의 리스트를 사용합니다.\n\n그림 1은 결과적인 Sankey 다이어그램을 보여줍니다. '3A' 노드 옆의 오렌지색 사각형에 주목하세요. 노드 중 하나에 커서를 가져가면 어떤 일이 발생하는지를 보여줍니다. 여기서 '3A' 노드에 커서를 가져가면, A 대학의 3 부서가 교환학생을 받고 보내는 빈도를 볼 수 있습니다. 그 부서는 한 번 학생을 받았고 3번 학생을 보냈습니다. '데이터' 딕셔너리에서도 이를 유추할 수 있습니다. 왜냐하면 'Sending_Dept' 리스트에서 '3A'가 3번 나오고 'Accepting_Dept' 리스트에서 한 번 나오기 때문입니다. '3A' 노드 왼쪽의 숫자 9는 B 대학에 보낸 총 교환학생 수입니다. 'Sending_Dept' 목록에서 3A의 값에 해당하는 'FlowValues'를 더하여 유추할 수도 있습니다.\n\n또한 '3A' 노드를 클릭하면 해당 노드에서 시작되는 화살표가 짙어지며 '3A'가 학생을 교환하는 다른 노드를 보여줍니다. 화살표의 굵기는 'FlowValues'에 해당합니다. 즉, Sankey 다이어그램은 화살표의 방향과 폭을 사용하여 흐름 정보를 전달하고, 각 노드의 텍스트 기반 누적 흐름 형성을 제시합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n사용 사례 2. 부동산 대행사의 주택 판매 데이터를 플롯합니다.\n\n데이터 과학자가 부동산 대행사에서 일합니다. 대행사는 지난 달에 판매된 주택에 대한 정보를 제공할 2D 플롯을 요청했습니다. 각 판매된 주택에 대해 플롯은 다음 정보를 포함해야 합니다: (a) 주택 가격, (b) 도시 중심부터의 거리, (c) 도시 중심으로부터의 방향, (d) 에이전트의 수수료, (e) 판매 에이전트의 회사 직급 (협력사, 부사장, 파트너). 이 모든 정보를 하나의 2D 그래프에 담는 것은 많은 양입니다. 그러나 각 주택을 플롯에서 표현하기 위해 복잡한 개체를 사용함으로써 이 도전을 극복할 수 있습니다. 구체적으로, '웃는 얼굴 이모지'를 사용할 것입니다. 아래 코드 조각에 구현이 나와 있습니다.\n\n위 코드와 아래에 나온 산점도 그래프에서, X와 Y 축은 각각 도시 중심부터의 거리와 판매 가격을 나타냅니다. 몇 가지 중요한 점은 다음과 같습니다:\n\n- 얼굴 이모지의 크기는 판매 에이전트의 직급을 나타냅니다. 크기가 클수록 에이전트의 직급이 높습니다.\n- 얼굴 이모지의 웃음 표정(위, 아래, 왼쪽, 오른쪽)은 도시 중심으로부터의 방향을 나타냅니다. 예를 들어, 웃음이 위에 있으면 주택이 도시 중심의 북쪽에 있습니다.\n- 얼굴 이모지의 색깔은 에이전트의 수수료를 나타냅니다. 예를 들어, 라임은 6%이고, 분홍은 5%입니다 (부동산 대행사는 판매 가격이 높을수록 수수료가 높다는 정책을 가지고 있습니다).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 사용 사례를 마무리하면, 우리는 주택의 다섯 가지 속성을 2D 플롯에 나타내기 위해 산점도와 이모지의 형태, 색상, 크기를 사용했습니다. 웃는 얼굴 같은 복잡한 객체를 데이터 포인트로 나타내는 것은 플롯에 많은 정보를 담을 수 있도록 도와주었습니다.\n\n![plot](/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_2.png)\n\n사용 사례 3. 대학의 다른 단과대학과 학과의 구성을 2D 그래프로 보여줍니다. 각 단과대학과 학과의 크기에 대한 정보도 전달되어야 합니다.\n\n여기서 다른 구성 요소들이 계층 구조를 가지고 있는 경우입니다. 선버스트 그래프가 이 경우에 이상적입니다. 아래 코드 조각은 구현을 보여줍니다. 첫 번째 배열 '라벨'에는 선버스트 그래프의 이름이 포함되어 있습니다. 두 번째 배열 '부모'에는 계층 구조가 포함되어 있으며, '값' 배열에는 세그먼트의 크기가 포함되어 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위 알고리즘의 출력물이 Figure 3에 나와 있어요. 각 세그먼트의 크기는 'values' 배열 내의 해당 숫자와 비례하다는 점을 유의해주세요. 아래 그래프를 보면 세그먼트를 클릭하면 크기가 나타납니다 (면역학 239).\n\n요약하면 선크로스 그래프는 대학의 다양한 엔티티의 계층 구조를 설명하기 위해 크기, 색상 및 텍스트를 사용합니다.\n\n![Figure 3](/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_3.png)\n\n사용 사례 4. 부동산 고객님은 지난 달에 판매된 주택에 관한 다음 정보를 보여주는 2D 그래프를 원합니다: (a) 판매 가격, (b) 크기, (c) 바다로부터의 거리, (d) 기차역으로부터의 거리. 같은 그래프 내에서 가장 많이 판매된 주택을 포함하는 그래프 세그먼트의 확대도 보여주어야 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 use case는 use case 2와 비슷합니다. 그러나 데이터 과학자의 새로운 작업 하나가 있습니다: 그래프에서 가장 바쁜 부분의 확대된 버전을 만드는 것입니다. 이를 삽입이라고 합니다. 삽입은 플롯의 중요한 부분을 확대하여 효과를 크게 향상시킬 수 있습니다. 아래 코드 스니펫은 삽입의 구현을 보여줍니다. 플롯을 만드는 전체 코드는 내 Github 저장소에서 찾을 수 있습니다 (기사 끝에 표시됨).\n\n아래 그림 4는 삽입이 있는 산점도를 보여줍니다. X와 Y 축은 집 크기와 판매 가격을 나타냅니다. 다이아몬드 모양의 점은 플롯상에 판매된 집을 나타냅니다. 다이아몬드의 색상은 바다로부터의 거리를 나타내고, 다이아몬드의 크기는 기차로부터의 거리에 해당합니다.\n\n이 use case에서 우리는 플롯의 중요한 부분의 삽입을 포함하여 플롯의 효과를 향상시키는 방법을 살펴보았습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n사용 사례 5. 책 컨퍼런스를 위한 화려한 포스터 작성하기\n\n이 경우, 워드 클라우드 그래프를 사용할 것입니다. 이 유형의 그래프는 단어를 다양한 크기로 포함하며, 단어의 크기는 원래 텍스트에서 나타나는 빈도에 따라 결정됩니다. 이는 가장 빈도가 높은 단어를 한 눈에 파악할 수 있는 매우 효과적인 방법입니다. 도표 5는 워드 클라우드 그래프를 보여주고, 아래의 코드 조각은 그래프를 생성한 Python 코드를 보여줍니다.\n\n![그래프 이미지](/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_5.png)\n\n사용 사례 6. 새로운 스낵 제품의 장점을 명확하고 매력적으로 소개하기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리 데이터 과학자는 마케팅 부서가 실시한 설문 조사 결과를 발표하는 업무를 맡았습니다. 이 설문 조사에서 고객들은 고단백 바의 새로운 및 구식 형태에 대해 가치, 영양 가치, 외관 및 맛을 평가하도록 요청받았습니다.\n\n데이터 과학자는 폴 결과를 보여주기 위해 스파이더 그래프를 사용합니다. 이 유형의 그래프는 각 속성(맛, 외관 등)을 서로 다른 축에 배치합니다. 그런 다음, 동일한 엔터티(우리 경우 고단백 바)에 속하는 속성 값은 연결되어 다각형 영역을 형성합니다. 서로 다른 영역에 대해 다른 색상을 사용하면 제품 간의 차이를 쉽게 이해할 수 있습니다.\n\n그림 6은 결과 그래프를 보여주고, 아래의 코드 스니펫은 해당 그래프를 생성하기 위한 Python 코드를 보여줍니다. 아래 코드의 7~9행에 관한 흥미로운 점이 있습니다. ‘enpoint’가 False로 설정되어 있고, 첫 번째 값이 'old_values' 및 'new_values' 배열 끝에 추가되어 루프를 닫습니다.\n\n아래 그림에서 볼 수 있듯이, 새로운 고단백 바는 영양 가치, 맛 및 가치 세 가지 핵심 영역에서 기존 제품보다 우수하다고 인식됩니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 사용 사례에서는 두 제품 간의 색상과 모양을 거미 그래프에 사용하여 효과적으로, 효율적으로 및 시각적으로 매력적으로 구별하는 방법을 보았습니다.\n\n![image](/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_6.png)\n\n사용 사례 7. 동일한 플롯에서 해당 장르의 책 축제 주변에서 발생하는 다른 책 장르의 판매를 보여줍니다.\n\n이 사용 사례에서는 동일한 플롯을 사용하여 다른 범주의 시간적 데이터를 플로팅해야 합니다. Python은 이 상황에 매우 적합한 리지 플롯을 제공합니다. 리지 플롯은 서로 다른 범주의 분포를 수직으로 쌓아서 표시하여 유사점과 차이점을 쉽게 비교할 수 있게 합니다. 도표 7은 해당 도서 축제를 중심으로 한 서로 다른 책 장르의 판매 차이를 보여줍니다. 동일한 플롯에 분포를 배치하고 다른 색상을 사용하여 시각적으로 매력적인 그래프를 만들어 비교를 효과적으로 가능하게 합니다. 해당 코드는 아래에 표시됩니다. 코드에서 중요한 몇 가지 포인트: (a) 조이플롯 Python 패키지를 사용하여 리지 플롯을 생성합니다. (b) 다양한 책 장르의 분포는 6~13번 줄에서 시뮬레이션되었습니다. 책 장르 뒤의 숫자는 해당 분포의 중심과 표준 편차입니다. (c) 20번 줄에서는 joyplot이 입력으로 DataFrame을 예상하기 때문에 데이터를 DataFrame에 넣습니다. (d) 30번 줄, 33~36번 줄에서는 x축의 매개변수를 axis[-1]에 지정합니다. (이것은 하단 플롯입니다.)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_7.png)\n\n사용 사례 8. 신용 카드 회사로부터 연령과 구매 금액에 대한 데이터가 주어졌을 때, 가장 높은 구매를 한 그룹을 플롯으로 강조합니다.\n\n2D 히스토그램은 이러한 종류의 데이터에 적합해 보입니다. 일반적인 히스토그램은 데이터 포인트를 한 차원에 따라 빈에 넣지만, 2D 히스토그램은 두 차원에 대해 동시에 이 작업을 수행합니다. 아래 코드 조각은 코드를 보여주고, 그림 8은 결과 2D 히스토그램을 보여줍니다.\n\n아래 2D 히스토그램에서 가장 높은 금액이 35-45세 그룹에서 소비되었음을 보여줍니다. 결론적으로, 2D 히스토그램은 가장 높은 구매 금액을 가진 그룹을 효과적으로 시각적으로 나타냅니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![그림 9: 다양한 학부 학생 인원의 적층 영역 그래픽](/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_9.png)\n\n실제 사용 사례 9. 한 개의 그래프에서 1990년부터 2010년까지 생물학, 천문학, 물리학, 수학 학부의 학생 수를 보여줍니다.\n\n이 경우, 적층 영역 그래프를 사용할 수 있습니다. 이 유형의 그래프는 다른 카테고리의 시간 데이터를 표시하는 데 사용되며 사용자에게 (a) 각 카테고리의 시간에 따른 변화, (b) 상대적 크기 및 (c) 시간에 따른 총 크기를 확인할 수 있도록 합니다. 각 카테고리에 대해 다른 색상이 사용됩니다. 아래에 코드가 나와 있으며, 그림 9는 각 학부의 학생 인구에 대한 적층 영역 그래프를 보여줍니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n10번 유스 케이스입니다. 2010년부터 2020년까지 회사의 마케팅 비용과 수익을 비교합니다.\n\n이전 유스 케이스와 마찬가지로, 이 유스 케이스에서도 스택된 영역 그래프를 사용할 수 있습니다. 그러나 스택된 영역 그래프는 카테고리별로 시간에 따른 차이를 그리는 유일한 솔루션이 아닙니다. 현재 유스 케이스에서는 수익 막대그래프와 마케팅 비용을 추세선으로 나타내는 것이 더 효과적인 비교 방법입니다. Figure 10은 막대그래프를 보여주고, Figure 11은 비교용 스택된 영역 그래프를 보여줍니다. 아래 스니펫에 코드가 표시되어 있습니다. 마케팅 비용이 수익 막대 앞에 추세선으로 그려질 때, 마케팅 비용이 증가하는 메시지가 더 효과적으로 전달됩니다.\n\n![image1](/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_10.png)\n\n![image2](/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_11.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n이 글에서는 Python 언어의 시각화 능력을 강조하기 위해 다양한 사용 사례와 해당 Python 플롯을 다뤘습니다. Sankey 다이어그램의 흐름부터 스파이더 플롯의 윤곽, 리지 플롯의 다중 피크까지, 이 글은 Python의 능력을 보여주며 가공하지 않은 데이터를 매력적이고 주목할 만한 데이터 이야기로 변환할 수 있다는 것을 보여줍니다. 우리가 논의한 플롯들은 Python의 포괄적인 도구 상자의 일부에 불과합니다. 시각화 개념에 대한 추가 학습을 위해 [1]-[6]에 나열된 훌륭한 책과 미디엄 기사를 추천합니다.\n\n이 글의 모든 코드는 제 깃허브 디렉토리에서 찾을 수 있습니다: https://github.com/theomitsa/visualiz\n\n읽어 주셔서 감사합니다!\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 참고 자료\n\n- Tufte, E., The Visual Display of Quantitative Information, 2판, Graphics Press, 2001.\n- Knaflic, C. N., Storytelling with Data: A Data Visualization Guide for Business Professionals, Wiley, 2005.\n- Yau, N., Data Points: Visualization That Means Something, Wiley, 2013.\n- Mansurova, M., Visualization 101: Choosing the Best Visualization Type, Medium: Towards Data Science, 2024년 1월.\n- Mansurova, M., Visualization 101. Playbook for Attention-Grabbing Visuals, Medium: Towards Data Science, 2024년 2월.\n- Sarkar, D., The Art of Effective Visualization of Multidimensional Data, Medium: Towards Data Science, 2018년 1월.\n","ogImage":{"url":"/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-MasteringtheVersatilityandDepthofPythonsRichPlotCollectionwithCode_0.png","tag":["Tech"],"readingTime":13},{"title":"한 줄의 문자열 때문에 Apple App Store에서 금지된 Python 프로그램","description":"","date":"2024-07-09 20:02","slug":"2024-07-09-PythonProgramBannedfromAppleAppStoreDuetoaSingleString","content":"\n## APPLE APP STORE 리뷰의 투명성 부족\n\n파이썬 개발자들이 특이한 문제에 직면하고 있습니다. 프로그래밍 언어 버전을 업그레이드하는 것이 앱 스토어에서 앱 거부를 유발하고 있습니다.\n\n최근 일부 개발자들이 Python 3.11에서 3.12로 업그레이드했을 때, 그들의 앱을 애플 앱 스토어에 재제출했을 때 거부당했습니다.\n\n이 문제는 많은 개발자들의 관심을 끌었습니다. 문제는 Python 3.12에 있는지, 아니면 애플의 리뷰 팀에 있는지요?\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 앱 리뷰 실패의 이유: 하나의 문자열 때문\n\n![image](/TIL/assets/img/2024-07-09-PythonProgramBannedfromAppleAppStoreDuetoaSingleString_0.png)\n\n개발자인 Eric Froemling은 GitHub에서 경험을 공유했습니다.\n\nEric은 처음에 이전에 승인된 앱이 왜 거부되었는지 이해하지 못했습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n앱 스토어 리뷰 팀에서는 왜 그랬는지 설명을 해주지 않았어요. 그저 \"더 많은 정보를 제공할 수 없다\"고만 말했죠.\n\n몇 차례 시도 끝에, Eric은 Apple에 항의를 보냈어요. 결국 그들은 힌트를 주었어요:\n\n가이드라인 2.5.2 - 성능 - 소프트웨어 요구 사항에 따르면:\n\n앱이 설치되거나 실행 가능한 코드를 실행합니다. 특히, 앱을 설치하기 위해 itms-services URL scheme을 사용한다고 해요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nitms-services URL 스키마는 Apple이 App Store 외부에서 iOS 앱을 배포하는 방법입니다. 주로 내부 또는 테스트용 앱에 사용됩니다.\n\n이를 통해 사용자는 App Store를 사용하지 않고 iOS 기기에 앱을 직접 설치할 수 있습니다.\n\n기본적인 itms-services URL은 다음과 같이 보입니다:\n\n```js\nitms-services://?action=download-manifest&url=https://example.com/manifest.plist\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n많은 조사 끝에, 에릭은 문제 파일을 찾았어요: Lib/urllib/parse.py (파이썬의 표준 라이브러리 URL 파서)와 그 .pyc 파일.\n\nPython 3.12에서 “itms-services” 문자열이 추가되었어요. 애플은 이 문자열을 검색하고 포함된 앱을 자동으로 거부하는 것으로 보입니다.\n\n마침내, 에릭은 이 문자열을 Python 코드에서 제거했어요. 그 후, 업데이트된 앱이 검토를 통과하고 성공적으로 앱 스토어에 등록되었어요.\n\n# 논란이 되는 애플의 리뷰 및 피드백 규칙\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/TIL/assets/img/2024-07-09-PythonProgramBannedfromAppleAppStoreDuetoaSingleString_1.png)\n\n에릭 프롬링은 \"itms-services\" 문자열 자체에 화를 내지 않았어요. 그보다 애플 앱 스토어 심사 규칙에 답답해했던 거예요.\n\n많은 사람들이 알다시피, 디버깅은 종종 코딩보다 어려워요.\n\n에릭은 많은 시간을 디버깅에 할애했어요. 문제를 해결하려면 단 하나의 문자열을 삭제하기만 하면 됐어요. 많은 개발자들은 애플의 심사 과정이 좀 더 명확했다면 이런 문제를 피할 수 있었을 거라고 생각하지만 사실 애플의 심사 과정은 투명하지 않아요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# CPython 코어 개발자: 앱 스토어 리뷰 규칙은 엄격하고 예측할 수 없어요!\n\n![Image](/TIL/assets/img/2024-07-09-PythonProgramBannedfromAppleAppStoreDuetoaSingleString_2.png)\n\nCPython 코어 개발자인 Russell Keith-Magee가 이 문제에 대해 기사를 썼어요. 그는 질문을 던지며 말했어요: 앱 스토어 규정에 맞추기 위해 얼마나 많은 변경을 해야 할까요?\n\n문제는 애플의 macOS 앱 스토어에서 \"itms-services\" 문자열이 포함된 앱을 자동으로 거부한다는 것이에요. 심지어 앱이 itms-services:// URL을 사용하지 않아도 그렇다고 해요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n러셀은 두 가지 해결책을 제안합니다:\n\n1. \"App Store 준수\"를 CPython의 목표로 설정하는 것입니다. 이렇게 하면 사용자는 CPython을 패치할 필요가 없지만 더러운 코드를 야기할 수 있습니다.\n\n2. 이것을 배포 문제로 취급합니다. Briefcase나 Py2app과 같은 도구를 사용하여 앱 스토어용으로 CPython을 패치합니다.\n\n두 옵션 모두 장단점이 있습니다. 옵션 1은 수정된 Python을 배포하는 것을 의미합니다. 옵션 2는 계속해서 패치를 해야 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n알렉스 게이너, 또 다른 코어 개발자,은 세 번째 옵션을 제안했습니다:\n\n- 이 문제에 대한 소규모 지역화된 수정 사항을 허용합니다.\n- 병합하기 전에 문제에 대해 써드 파티(예: Apple)에 불만을 제기해야 합니다.\n- 이러한 수정 사항에 대해 시간 제한을 설정합니다.\n\n이 방법은 사용자 경험과 대기업의 자체 문제 수정을 균형있게 조합합니다.\n\n키스 매지 후에 네 번째 옵션을 제안했습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n문제가 되는 코드를 제거할 수 있는 빌드 옵션을 추가해보는 것은 코드를 난독화하는 것보다 더 깔끔한 해결책이 될 것입니다.\n\n이 옵션은 다음을 포함할 것입니다:\n\n- 변경 사항을 설명하는 diff 파일 추가.\n- 환경 설정을 위한 --with-app-store-patch 옵션 추가.\n- 필요한 경우 배급 업체가 업데이트된 패치를 제공할 수 있도록 함.\n\n이를 통해 CPython이 App Store 규정을 준수하기 위해 필요한 변경 사항을 공식적으로 목록화할 수 있게 됩니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKeith-Magee가 이 해결책이 더 수용 가능한 것 같다고 물었습니다.\n\n# 결론\n\n![이미지](/TIL/assets/img/2024-07-09-PythonProgramBannedfromAppleAppStoreDuetoaSingleString_3.png)\n\n몇 일을 생각한 후, Keith-Magee가 6월 25일에 답변했습니다. 그는 --with-app-store-compliance 옵션을 추가하는 풀 리퀘스트(#120984)를 제출했습니다. 이것은 문자열 때문에 App Store에서 앱이 거부당하는 문제를 해결해야 할 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그는 이 옵션이 iOS와 macOS 외의 플랫폼에서도 사용될 수 있다고 언급했지만, 현재는 필요가 없다고 합니다.\n\n모든게 순조롭게 진행된다면, 이는 Python 3.13에서 사용할 수 있을 것입니다.\n\n많은 개발자들이 Python과 같은 무료 소프트웨어 프로젝트들이 명확하지 않은 검토 프로세스를 피해야 하는 방법을 찾는 데 시간을 낭비해야 한다는 점에 좌절하고 있습니다. 이는 개발자들이 비자유 플랫폼을 위한 소프트웨어를 만들 수 있도록 하는 것뿐입니다.\n\nHN 사용자가 댓글로 남긴 내용:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 경우에 Keith-Magee와 다른 CPython 개발자들이 빠른 조치를 취했습니다. 그들의 해결책은 파이썬 앱 개발자들에게 최고의 경험을 제공하는 가장 쉬운 방법으로 보입니다.\n\n그러나 이런 문제가 다시 발생할 가능성은 매우 높습니다.\n\n제가 딱 한 달 만에 5,000명 이상의 팔로워를 얻었다는 점이 최고의 증거이기 때문에 “Medium에서 빠르게 팔로워 모으는 방법”에 대한 eBook을 작성 중입니다. 계속해서 주세요!\n\nSubstack에서 “대규모 모델 애플리케이션 개발” 시리즈를 쓰고 있습니다. 관심 있으시면 팔로우해 주세요!\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n친구님께서 읽어주셔서 감사합니다📖, 강조해주셔서 감사합니다🖍️, 박수를 보내주셔서 감사합니다👏, 댓글을 달아주셔서 감사합니다💬, 그리고 공유해주셔서 감사합니다🗣️. \"Medium의 친구\"로서 매일 함께 글을 작성하는 동료 작가들에게 인정을 보여드리려 노력하고 있어요.\n\n그리고 위와 같이 멋진 콘텐츠를 소개할 때마다 알림을 받기 위해 뉴스레터📰를 구독할 수 있어요. 고맙습니다, 친애하는 챔프!🤓\n\n최신 AI 이야기의 소식을 받아보기 위해 Substack에서 연락을 유지해주세요. 함께 AI의 미래를 함께 만들어요!\n","ogImage":{"url":"/assets/img/2024-07-09-PythonProgramBannedfromAppleAppStoreDuetoaSingleString_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-PythonProgramBannedfromAppleAppStoreDuetoaSingleString_0.png","tag":["Tech"],"readingTime":8},{"title":"딥 뉴럴 네트워크 파인튜닝의 수학적 원리","description":"","date":"2024-07-09 19:56","slug":"2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks","content":"\n![이미지](/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_0.png)\n\n머신 러닝에서는 몇 가지 모델을 시도해 가장 성능이 좋은 것을 선택하고 몇 가지 설정을 조정하여 그나마 성공할 수 있을지도 모릅니다. 그러나 딥러닝은 그런 룰에 맞지 않습니다. 신경망을 실험해 본 적이 있다면, 성능이 꽤 불안정할 수 있다는 것을 눈치챌 수 있습니다. 어쩌면 로지스틱 회귀와 같이 간단한 모델이 멋진 200층 심층 신경망을 이길 수도 있습니다.\n\n이게 왜 그럴까요? 딥러닝은 우리가 가지고 있는 가장 고급 인공 지능 기술 중 하나이지만, 철저한 이해와 조심스러운 다룸이 필요합니다. 신경망을 세밀하게 조정하고, 내부 작동 방식을 파악하고, 그 사용법을 마스터하는 것이 중요합니다. 오늘은 이에 대해 자세히 살펴보겠습니다!\n\n글을 읽기 전에 Jupyter Notebook을 여시는 것을 제안합니다. 오늘 다룰 모든 코드가 담겨 있으므로 함께 따라가는 데 도움이 될 것입니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n인덱스\n\n- 1: 소개\n\n  - 1.1: 기본 신경망의 발전\n  - 1.2: 복잡성으로의 길\n\n- 2: 모델 복잡성 확장\n\n  - 2.1: 레이어 추가\n\n- 3: 향상된 학습을 위한 최적화 기법\n  - 3.1: 학습률\n  - 3.2: 조기 중단 기법\n  - 3.3: 초기화 방법\n  - 3.4: 드롭아웃\n  - 3.5: 그래디언트 클리핑\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 4: 최적 레이어 수 결정하기\n\n  - 4.1: 레이어 깊이와 모델 성능\n  - 4.2: 적절한 깊이 선택을 위한 테스트 전략\n\n- 5: Optuna를 활용한 자동 세부 조정\n\n  - 5.1: Optuna 소개\n  - 5.2: 신경망 최적화를 위한 Optuna 통합\n  - 5.3: 실제 적용\n  - 5.4: 장점과 결과\n  - 5.5: 제한 사항\n\n- 6: 결론\n\n  - 6.1: 다음 단계\n\n- 추가 자료\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1: 소개\n\n## 1.1: 기본 신경망의 발전\n\n인공 지능에 대한 최근 탐구에서 우리는 기초부터 신경망을 구축했습니다. 이 기본 모델은 오늘날 인공 지능 기술의 핵심인 신경망의 세계를 열어 주었습니다. 우리는 입력, 은닉 및 출력 레이어와 활성화 함수가 어떻게 정보를 처리하고 예측하는 데 결합되는지 간단하게 다루었습니다. 그리고 나서 우리는 컴퓨터 비전 작업을 위해 숫자 데이터셋에서 훈련된 간단한 신경망으로 이론을 실제로 적용했습니다.\n\n이제 이러한 기초 위에 계속해서 더 진보해 나갈 것입니다. 우리는 레이어를 추가하고, 초기화, 정규화 및 최적화에 대한 다양한 기술을 탐구함으로써 더 많은 복잡성을 도입할 것입니다. 물론, 이러한 수정이 우리의 신경망 성능에 어떻게 영향을 미치는지 확인하기 위해 코드를 테스트할 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n제가 이전 기사를 확인하지 않으셨다면, 우리가 처음부터 신경망을 만들어본 기사를 꼭 읽어보시기를 추천합니다. 이번에는 그 작업을 기반으로 계속해서 진행할 것이며, 이미 우리가 다룬 개념에 익숙하다고 가정할게요.\n\n## 1.2: 복잡성으로의 길\n\n신경망을 기본 구성에서 더 정교한 구조로 변환하는 것은 단순히 더 많은 층이나 노드를 추가하는 것만으로는 이루어지지 않습니다. 이것은 신경망의 구조와 그 데이터를 다루는 미묘한 차이를 체화하는 세심한 작업이 필요한 미묘한 춤이죠. 더 깊게 파고들수록, 우리의 목표는 신경망의 깊이를 풍부하게 함으로써 데이터의 복잡한 패턴과 연결을 더 잘 분별하는 데 있습니다.\n\n하지만 복잡성을 높이는 것은 그리 수월한 일이 아닙니다. 우리가 도입할 때마다, 세련된 최적화 기술의 필요성이 커집니다. 이는 효과적인 학습뿐만 아니라 새로운 보이지 않는 데이터에 적응하기 위한 모델 능력에 필수적입니다. 이 안내서는 우리의 기반 신경망을 강화하는 과정을 안내해 드릴 것입니다. 우리는 신경망을 세밀하게 조정하는 정교한 전략에 대해 살펴볼 것이며, 학습 속도 조정, 조기 종료 도입, 그리고 SGD(확률적 경사 하강법)와 Adam과 같은 다양한 최적화 알고리즘을 활용하는 방법에 대해 살펴볼 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리는 초기화 방법으로 시작하는 중요성, 오버피팅을 피하는 데 드롭아웃 사용의 장점, 그리고 클리핑 및 정규화로 네트워크의 그래디언트를 체크하여 안정성을 유지하는 것이 모델의 안정성에 얼마나 중요한지에 대해 다룰 예정입니다. 또한 학습을 향상시키기 위한 레이어의 최적 개수를 찾는 도전과정 및 불필요한 복잡성으로 빠져들지 않도록 할 것입니다.\n\n이전 게시물에서 함께 만든 Neural Network 및 Trainer 클래스를 아래에서 확인할 수 있습니다. 우리는 이를 조정하고 각 수정이 모델의 성능에 어떤 영향을 미치는지 실제로 살펴볼 것입니다:\n\n```js\nclass NeuralNetwork:\n    def __init__(self, input_size, hidden_size, output_size, loss_func='mse'):\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.loss_func = loss_func\n\n        # 가중치 및 편향 초기화\n        self.weights1 = np.random.randn(self.input_size, self.hidden_size)\n        self.bias1 = np.zeros((1, self.hidden_size))\n        self.weights2 = np.random.randn(self.hidden_size, self.output_size)\n        self.bias2 = np.zeros((1, self.output_size))\n\n        # 손실 추적\n        self.train_loss = []\n        self.test_loss = []\n\n    def __str__(self):\n        return f\"Neural Network Layout:\\n입력 레이어: {self.input_size} 뉴런\\n은닉 레이어: {self.hidden_size} 뉴런\\n출력 레이어: {self.output_size} 뉴런\\n손실 함수: {self.loss_func}\"\n\n    def forward(self, X):\n        # 순방향 전파 수행\n        self.z1 = np.dot(X, self.weights1) + self.bias1\n        self.a1 = self.sigmoid(self.z1)\n        self.z2 = np.dot(self.a1, self.weights2) + self.bias2\n        if self.loss_func == 'categorical_crossentropy':\n            self.a2 = self.softmax(self.z2)\n        else:\n            self.a2 = self.sigmoid(self.z2)\n        return self.a2\n\n    def backward(self, X, y, learning_rate):\n        # 역전파 수행\n        m = X.shape[0]\n\n        # 기울기 계산\n        if self.loss_func == 'mse':\n            self.dz2 = self.a2 - y\n        elif self.loss_func == 'log_loss':\n            self.dz2 = -(y/self.a2 - (1-y)/(1-self.a2))\n        elif self.loss_func == 'categorical_crossentropy':\n            self.dz2 = self.a2 - y\n        else:\n            raise ValueError('잘못된 손실 함수')\n\n        self.dw2 = (1 / m) * np.dot(self.a1.T, self.dz2)\n        self.db2 = (1 / m) * np.sum(self.dz2, axis=0, keepdims=True)\n        self.dz1 = np.dot(self.dz2, self.weights2.T) * self.sigmoid_derivative(self.a1)\n        self.dw1 = (1 / m) * np.dot(X.T, self.dz1)\n        self.db1 = (1 / m) * np.sum(self.dz1, axis=0, keepdims=True)\n\n        # 가중치 및 편향 업데이트\n        self.weights2 -= learning_rate * self.dw2\n        self.bias2 -= learning_rate * self.db2\n        self.weights1 -= learning_rate * self.dw1\n        self.bias1 -= learning_rate * self.db1\n\n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n\n    def sigmoid_derivative(self, x):\n        return x * (1 - x)\n\n    def softmax(self, x):\n        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n        return exps/np.sum(exps, axis=1, keepdims=True)\n\nclass Trainer:\n    def __init__(self, model, loss_func='mse'):\n        self.model = model\n        self.loss_func = loss_func\n        self.train_loss = []\n        self.val_loss = []\n\n    def calculate_loss(self, y_true, y_pred):\n        if self.loss_func == 'mse':\n            return np.mean((y_pred - y_true)**2)\n        elif self.loss_func == 'log_loss':\n            return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n        elif self.loss_func == 'categorical_crossentropy':\n            return -np.mean(y_true*np.log(y_pred))\n        else:\n            raise ValueError('잘못된 손실 함수')\n\n    def train(self, X_train, y_train, X_test, y_test, epochs, learning_rate):\n        for _ in range(epochs):\n            self.model.forward(X_train)\n            self.model.backward(X_train, y_train, learning_rate)\n            train_loss = self.calculate_loss(y_train, self.model.a2)\n            self.train_loss.append(train_loss)\n\n            self.model.forward(X_test)\n            test_loss = self.calculate_loss(y_test, self.model.a2)\n            self.val_loss.append(val_loss)\n```\n\n# 2: 모델 복잡성 확대\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n신경망을 더 정교하게 개선하기 위해 깊이 파고들면서, 게임을 바꾸는 전략을 발견했습니다: 레벨을 더 쌓아 복잡성을 높이는 것입니다. 이 동작은 모델을 강화하는 것뿐만 아니라, 데이터의 미묘한 변화를 더 정교하게 이해하고 해석하는 능력을 키우는 것입니다.\n\n## 2.1: 레이어 추가\n\n증가된 네트워크 깊이의 근거\n딥러닝의 핵심은 계층적 데이터 표현을 조합하는 능력에 있습니다. 더 많은 레이어를 추가함으로써, 우리는 신경망에 성장하는 복잡성의 패턴을 해체하고 이해하기 위한 도구를 제공하는 셈입니다. 간단한 형태와 질감을 인식하는 데서 시작해 데이터 속에서 더 복잡한 관계와 특징을 풀어가는 데로 발전하는 것으로 생각해보세요. 이러한 계층적 학습 접근법은 어느 정도 인간이 정보를 해석하는 방식과 유사하며, 기본적인 이해에서 복잡한 해석으로 진화합니다.\n\n더 많은 레이어를 쌓으면 네트워크의 \"학습 용량\"이 증가하여 보다 넓은 범위의 데이터 관계를 매핑하고 소화하는 능력을 갖추게 됩니다. 이를 통해 더 복잡한 작업을 처리할 수 있습니다. 하지만 마구 레이어를 추가하는 것은 아니며, 모델의 지능에 의미 있는 기여를 하지 않고 무분별하게 레이어를 추가하면 학습 과정을 혼란시키는 것이 아니라 명료하게 해야 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n`NeuralNetwork` 클래스를 더 많은 층을 통합하는 방법 안내\n\n```js\nclass NeuralNetwork:\n    def __init__(self, layers, loss_func='mse'):\n        self.layers = []\n        self.loss_func = loss_func\n\n        # 레이어 초기화\n        for i in range(len(layers) - 1):\n            self.layers.append({\n                'weights': np.random.randn(layers[i], layers[i + 1]),\n                'biases': np.zeros((1, layers[i + 1]))\n            })\n\n        # 손실 추적\n        self.train_loss = []\n        self.test_loss = []\n\n    def forward(self, X):\n        self.a = [X]\n        for layer in self.layers:\n            self.a.append(self.sigmoid(np.dot(self.a[-1], layer['weights']) + layer['biases']))\n        return self.a[-1]\n\n    def backward(self, X, y, learning_rate):\n        m = X.shape[0]\n        self.dz = [self.a[-1] - y]\n\n        for i in reversed(range(len(self.layers) - 1)):\n            self.dz.append(np.dot(self.dz[-1], self.layers[i + 1]['weights'].T) * self.sigmoid_derivative(self.a[i + 1]))\n\n        self.dz = self.dz[::-1]\n\n        for i in range(len(self.layers)):\n            self.layers[i]['weights'] -= learning_rate * np.dot(self.a[i].T, self.dz[i]) / m\n            self.layers[i]['biases'] -= learning_rate * np.sum(self.dz[i], axis=0, keepdims=True) / m\n\n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n\n    def sigmoid_derivative(self, x):\n        return x * (1 - x)\n```\n\n이 섹션에서는 신경망의 작동 방식에 중요한 조정을 가했으며, 임의의 층 수를 유연하게 지원하는 모델을 목표로했습니다. 변경된 사항은 다음과 같습니다:\n\n먼저, 이전에 각 층의 노드 수를 정의했던 self.input, self.hidden, self.output 변수를 삭제했습니다. 이제 목표는 임의의 층 수를 관리할 수 있는 다목적 모델입니다. 예를 들어, 이전에 숫자 데이터셋에 사용했던 모델인 64개의 입력 노드, 64개의 은닉 노드 및 10개의 출력 노드를 사용하는 경우, 다음과 같이 설정할 수 있습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nnn = NeuralNetwork((layers = [64, 64, 10]));\n```\n\n이제 코드가 각 레이어를 세 번씩 순환하며 다른 목적으로 사용됨을 알 수 있습니다:\n\n초기화 과정 중에는 모든 레이어의 가중치와 편향이 설정됩니다. 이 단계는 학습 프로세스를 위해 초기 매개변수로 네트워크를 준비하는 데 중요합니다.\n\n순방향 패스 동안 활성화 self.a는 리스트에 수집됩니다. 입력 레이어의 활성화(본질적으로 입력 데이터 X)로 시작합니다. 각 레이어에 대해, np.dot(self.a[-1], layer['weights']) + layer['biases']를 사용하여 가중치 합과 편향을 계산하고 시그모이드 활성화 함수를 적용하여 결과를 self.a에 첨부합니다. 네트워크의 결과는 self.a의 마지막 요소로, 최종 출력을 나타냅니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n역 전파 동안, 이 단계는 마지막 레이어의 활성화에 대한 손실의 도함수를 계산하고 출력 레이어의 오차 목록을 준비함으로써 시작합니다 (self.dz). 그런 다음 네트워크를 역방향으로 거슬러 올라가며 (reversed(range(len(self.layers) - 1))를 사용하여), 숨은 레이어에 대한 오차 항목을 계산합니다. 이 과정은 현재 오차 항목을 다음 레이어의 가중치와 점곱(역방향)하여 시그모이드 함수의 도함수로 비선형성을 처리하는 작업을 포함합니다.\n\n```python\nclass Trainer:\n    ...\n    def train(self, X_train, y_train, X_test, y_test, epochs, learning_rate):\n        for _ in range(epochs):\n            self.model.forward(X_train)\n            self.model.backward(X_train, y_train, learning_rate)\n            train_loss = self.calculate_loss(y_train, self.model.a[-1])\n            self.train_loss.append(train_loss)\n\n            self.model.forward(X_test)\n            test_loss = self.calculate_loss(y_test, self.model.a[-1])\n            self.test_loss.append(test_loss)\n```\n\n마지막으로, NeuralNetwork 클래스의 변화에 따라 Trainer 클래스를 업데이트했습니다. 주요한 수정 사항은 특히 train 메서드에 있으며, 네트워크의 출력이 이제 self.model.a[-1]에서 가져온다는 점 때문에 훈련 및 테스트 손실을 다시 계산하는 방식입니다.\n\n이러한 수정 사항은 우리의 신경망을 다양한 아키텍처에 적응할 수 있도록 할뿐만 아니라 데이터와 그래디언트의 흐름을 이해하는 중요성을 강조합니다. 구조를 간소화함으로써, 각종 작업에서 네트워크의 성능을 실험하고 최적화할 수 있는 능력을 향상시킵니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 3: 향상된 학습을 위한 최적화 기법\n\n신경망을 최적화하는 것은 그들이 배우는 능력을 향상시키고 효율적인 학습을 보장하며 최상의 버전으로 이끄는 데 중요합니다. 저희 모델이 얼마나 잘 수행되는지에 상당한 영향을 미치는 몇 가지 중요한 최적화 기술에 대해 알아보겠습니다.\n\n## 3.1: 학습률\n\n학습률은 손실 경사에 기반하여 네트워크의 가중치를 조정하는 제어 장치입니다. 이는 모델이 학습하는 속도를 결정하며 최적화 중에 취하는 단계가 얼마나 큰지 작은지를 결정합니다. 학습률을 적절하게 설정하면 모델이 빠르게 낮은 오차의 해결책을 찾을 수 있습니다. 그러나 올바르게 설정하지 않으면 모델이 수렴하는 데 시간이 오래 걸리거나 아예 좋은 해결책을 찾지 못할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n너무 높은 학습률을 설정하면 모델이 최적해를 뛰어넘을 수 있어 불안정한 행동을 일으킬 수 있습니다. 이는 정확도나 손실이 훈련 중에 급격하게 변하는 것으로 나타날 수 있어요.\n\n학습률이 너무 낮으면 훈련 과정이 지나치게 느리게 진행될 수 있어요. 이 경우, 훈련 손실이 시간이 지남에 따라 거의 변하지 않는 것을 볼 수 있어요.\n\n관건은 훈련 및 검증 손실을 추적하면서 학습률이 어떻게 작동하는지에 대한 단서를 얻는 것이에요. 훈련 중에 일정 간격으로 이러한 손실을 기록하고 나중에 이를 플로팅하여 손실 landscape가 얼마나 매끄럽거나 불안정한지 보다 명확히 파악할 수 있어요. 우리의 코드에서는 이러한 메트릭을 추적하기 위해 Python의 logging 라이브러리를 사용하고 있어요. 이렇게 생겼답니다:\n\n```python\nimport logging\n# Logger 설정\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass Trainer:\n    ...\n    def train(self, X_train, y_train, X_val, y_val, epochs, learning_rate):\n        for epoch in range(epochs):\n            ...\n            # 50 에폭마다 손실 및 검증 손실을 로그로 남깁니다\n            if epoch % 50 == 0:\n                logger.info(f'에폭 {epoch}: 손실 = {train_loss}, 검증 손실 = {val_loss}')\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n시작할 때, 우리는 훈련 업데이트를 캡처하고 표시하기 위해 로거를 설정했습니다. 이 설정을 통해 우리는 훈련 및 검증 손실을 매 50번째 에포크마다 기록하여 모델의 진행 상황에 대한 안정적인 피드백을 받을 수 있습니다. 이 피드백을 통해 손실이 잘 감소하고 있는지, 아니면 너무 불규칙하게 변동하는지 파악할 수 있어서 학습률을 조정해야 할 필요가 있을지도 모릅니다.\n\n위의 코드는 훈련 및 검증 손실을 그래프로 플로팅하여 훈련 중에 손실이 어떻게 변화하는지 더 잘 이해할 수 있도록 해줍니다. 많은 반복에서 약간의 잡음이 예상되므로 부드러운(스무딩) 효과를 추가했습니다. 잡음을 부드럽게 처리하여 그래프를 더 잘 분석할 수 있도록 도와줄 것입니다.\n\n이러한 방식을 따르면 훈련을 시작하면 로그가 나타나면서 우리의 진행 상황을 한 눈에 볼 수 있고 조정할 수 있는 정보를 제공하여 우리가 방향을 수정하는 데 도움이 될 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_1.png\" />\n\n그런 다음, 훈련이 끝난 후 손실을 그래프로 그려볼 수 있습니다:\n\n<img src=\"/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_2.png\" />\n\n훈련 및 검증 손실이 꾸준히 감소하는 것을 보는 것은 좋은 신호입니다. 이는 에포크 수를 늘리고 학습률 스텝 크기를 증가시킨다면 잘 작동할 수 있다는 신호일 수 있습니다. 그러나 반대로 손실이 감소한 후 급상승하는 것을 관찰하면, 학습률 스텝 크기를 줄이는 것이 명백한 신호입니다. 그렇지만 재미있는 점이 있습니다: 에포크 0부터 50까지 우리의 손실이 어떤 이상한 일이 일어나고 있습니다. 우리는 그 부분을 확인하기 위해 다시 살펴보겠습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그 달콤한 학습률의 최적값을 찾기 위해서는 학습률 앤달링 또는 적응형 학습률 기법과 같은 방법이 정말 유용할 수 있어요. 이러한 방법들은 학습률을 실시간으로 세밀하게 조정하여 훈련 중에 최적의 속도를 유지하도록 도와줘요.\n\n## 3.2: 조기 중단 기법\n\n조기 중단은 마치 안전망 같아요 — 유효성 검사 세트에서 모델의 성능을 보고, 더 이상 성능이 개선되지 않을 때 훈련을 중지하는 것이에요. 이는 과적합에 대한 안전 장치이며, 우리 모델이 이전에 본 적 없는 데이터에서도 잘 작동하도록 보장해줘요.\n\n여기에 이를 실행하는 방법이 있어요:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 검증 세트: 교육 데이터의 일부를 분리하여 검증 세트로 사용합니다. 이것은 중요합니다. 왜냐하면 이렇게 하면 멈춤 결정이 신선한 보이지 않는 데이터에 기반하기 때문입니다.\n- 모니터링: 각 학습 에포크 후 모델이 검증 세트에서 어떻게 수행되는지 주시하세요. 성능이 향상되고 있나요, 아니면 정체되었나요?\n- 멈춤 기준: 멈출 시점을 결정하세요. 일반적으로 \"연속적으로 50번의 에포크 동안 검증 손실이 향상되지 않음\"이 있습니다.\n\n이를 위한 코드를 살펴보죠:\n\n```python\nclass Trainer:\n    def train(self, X_train, y_train, X_val, y_val, epochs, learning_rate,\n              early_stopping=True, patience=10):\n        best_loss = np.inf\n        epochs_no_improve = 0\n\n        for epoch in range(epochs):\n           ...\n\n            # 조기 중단\n            if early_stopping:\n                if val_loss < best_loss:\n                    best_loss = val_loss\n                    best_weights = [layer['weights'] for layer in self.model.layers]\n                    epochs_no_improve = 0\n                else:\n                    epochs_no_improve += 1\n\n                if epochs_no_improve == patience:\n                    print('조기 중단!')\n                    # 최적의 가중치로 복원\n                    for i, layer in enumerate(self.model.layers):\n                        layer['weights'] = best_weights[i]\n                    break\n```\n\ntrain 메서드에서 두 가지 새로운 옵션을 소개했습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- early_stopping: 이는 조기 중단을 켜거나 끄는 여부를 결정하는 이진 플래그입니다.\n- patience: 이는 훈련을 중단하기 전에 유효성 검사 손실이 향상되지 않은 라운드 수를 설정합니다.\n\n우리는 가장 낮은 유효성 검사 손실을 현재까지 본 최저치로 설정하기 위해 best_loss를 무한대로 설정합니다. 한편, epochs_no_improve는 얼마 동안 유효성 검사 손실이 개선되지 않은 에포크 수를 기록합니다.\n\n모델을 훈련하기 위해 각 에포크를 순회하는 동안에는 실제 훈련 단계(순방향 전파 및 역전파)가 여기에 자세히 나와 있지는 않지만 프로세스의 중요한 부분입니다.\n\n매 에포크가 끝날 때마다 현재 에포크의 유효성 검사 손실(val_loss)이 best_loss보다 낮아졌다면, 이는 우리가 진전을 이루고 있다는 뜻입니다. 우리는 best_loss를 이 새로운 최솟값으로 업데이트하고, 또한 현재 모델 가중치를 best_weights로 저장합니다. 이렇게 하면 모델이 최상의 성능을 발휘한 시점의 스냅샷을 항상 가지게 됩니다. 그리고 우리는 방금 개선을 보았기 때문에 epochs_no_improve 카운트를 다시 0으로 재설정합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 val_loss에 감소가 없다면, epochs_no_improve를 하나씩 증가시켜서 다른 epoch가 향상되지 않은 것으로 표시합니다.\n\n만약 우리가 설정한 인내심 한계치에 epochs_no_improve 카운트가 달성하면, 모델이 더 나아질 가능성이 낮다는 신호로 조기 종료를 시작합니다. 메시지와 함께 알림을 표시하고, 모델의 가중치를 최적의 가중치인 best_weights로 되돌립니다. 그런 다음 학습 루프를 종료합니다.\n\n이 접근 방식은 학습을 중단하는 균형있는 방법을 제공합니다. 모델에 학습의 공정한 기회를 제공하여 너무 일찍 중단하지 않으면서, 너무 늦지도 않아 시간을 낭비하거나 과적합의 위험을 가져올 수 있습니다.\n\n## 3.3: 초기화 방법\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n신경망을 설정할 때, 가중치를 어떻게 시작하느냐에 따라 네트워크가 얼마나 잘, 그리고 얼마나 빨리 학습하는지가 달라질 수 있어요. 가중치를 초기화하는 몇 가지 다른 방법 – 랜덤, 영, Glorot(Xavier), 그리고 He 초기화 – 에 대해 알아봐요.\n\n랜덤 초기화\n랜덤 방식을 선택하면 주로 균일하거나 정규 분포에서 숫자를 추출하여 초기 가중치를 설정하는 것을 의미해요. 이러한 무작위성은 모든 뉴런이 동일한 위치에서 시작하지 않도록하여 네트워크가 학습함에 따라 서로 다른 것을 배울 수 있도록 도와줘요. 핵심은 적절한 분산을 선택하는 것인데, 너무 많으면 기울기가 폭발할 위험이 있고, 너무 적으면 사라질 수도 있어요.\n\n```js\nweights = np.random.randn(layers[i], layers[i + 1]);\n```\n\n이 코드 라인은 표준 정규 분포에서 가중치를 추출하여 각 뉴런이 학습의 길로 나아갈 수 있도록 준비를 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n장점: 뉴런이 서로 모방하는 것을 방지하는 간단한 방법입니다.\n\n단점: 분산을 잘못 설정하면 학습 과정이 불안정해질 수 있습니다.\n\n제로 초기화\n모든 가중치를 0으로 설정하는 방법은 매우 간단합니다. 그러나 이 방법에는 주요 단점이 있습니다: 이로 인해 층의 모든 뉴런이 사실상 동일해집니다. 이러한 동일성으로 인해 네트워크의 학습이 저해될 수 있으며, 모든 층의 뉴런이 학습 중에 동일하게 업데이트될 수 있습니다.\n\n```js\nweights = np.zeros((layers[i], layers[i + 1]));\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마지막으로, 우리는 모두 0으로 채워진 가중치 행렬을 얻습니다. 깔끔하고 정돈되어 있지만, 네트워크를 통해 나아가는 모든 경로가 처음에는 동일한 가중치를 갖게 되어 학습 다양성을 위한 좋지 않은 결과를 초래할 수 있습니다.\n\n장점: 구현이 매우 쉽습니다.\n\n단점: 학습 과정을 제약시켜 네트워크의 성능이 보통 좋지 않게끔 만듭니다.\n\nGlorot 초기화\n시그모이드 활성화 함수를 사용하는 네트워크를 위해 설계된 Glorot 초기화는 네트워크 내 입력 단위와 출력 단위의 수에 기반하여 가중치를 설정합니다. 이 초기화는 활성화와 역전파된 그래디언트의 분산을 유지하고 vanishing 또는 exploding 그래디언트 문제를 방지하기 위해 레이어를 통해 전달됩니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n글로럿 초기화에서의 가중치는 균일 분포나 정규 분포로 생성할 수 있습니다. 균일 분포를 사용하는 경우, 가중치는 [-a, a] 범위로 초기화됩니다. 여기서 a 값은:\n\n![식](/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_3.png)\n\n```js\ndef glorot_uniform(self, fan_in, fan_out):\n    limit = np.sqrt(6 / (fan_in + fan_out))\n    return np.random.uniform(-limit, limit, (fan_in, fan_out))\n\nweights = glorot_uniform(layers[i - 1], layers[i])\n```\n\n이 공식은 가중치가 균등하게 분포되고, 가져올 수 있으며, 좋은 기울기 흐름을 유지할 수 있도록 보장합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n정상 분포에 대한 정보입니다:\n\n![](/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_4.png)\n\n```js\ndef glorot_normal(self, fan_in, fan_out):\n    stddev = np.sqrt(2. / (fan_in + fan_out))\n    return np.random.normal(0., stddev, size=(fan_in, fan_out))\n\nweights = self.glorot_normal(layers[i - 1], layers[i])\n```\n\n이 조정은 시그모이드 활성화 함수를 사용하는 네트워크에서 적절하게 가중치를 유지합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n장점: 합리적인 범위 내 그라디언트 변화를 유지하여 심층 신경망의 안정성을 향상시킵니다.\n\n단점: ReLU(또는 변형) 활성화를 사용하는 레이어에는 신호 전파 특성이 다르기 때문에 최적이 아닐 수 있습니다.\n\nHe 초기화\nHe 초기화는 ReLU 활성화 함수를 사용하는 레이어에 적합하게 설계되었으며, ReLU의 비선형 특성을 고려하여 가중치의 분산을 조정합니다. 이 전략은 특히 ReLU가 일반적으로 사용되는 깊은 신경망에서 그라디언트 흐름을 유지하는 데 도움이 됩니다.\n\nGlorot 초기화와 마찬가지로, 가중치는 균등 분포 또는 정규 분포에서 선택할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n균일 분포를 위해 가중치는 [-a, a] 범위를 사용하여 초기화됩니다. 여기서 a는 다음과 같이 계산됩니다:\n\n![a 계산 공식](/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_5.png)\n\n따라서 가중치 W는 균일 분포에서 추출됩니다:\n\n![균일 분포에서 가중치 추출 공식](/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_6.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ndef he_uniform(self, fan_in, fan_out):\n    limit = np.sqrt(2 / fan_in)\n    return np.random.uniform(-limit, limit, (fan_in, fan_out))\n\nweights = self.he_uniform(layers[i - 1], layers[i])\n```\n\n일반 분포를 사용할 때, 가중치는 다음과 같은 수식에 따라 초기화됩니다:\n\n![수식](/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_7.png)\n\n여기서 W는 가중치를, N은 정규 분포를, 0은 분포의 평균을, 그리고 2/n은 분산을 나타냅니다. n-in은 레이어로 들어오는 입력 단위의 수를 나타냅니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\ndef he_normal(self, fan_in, fan_out):\n    stddev = np.sqrt(2. / fan_in)\n    return np.random.normal(0., stddev, size=(fan_in, fan_out))\n\nweights = self.he_normal(layers[i - 1], layers[i])\n```\n\n양쪽 경우 모두 초기화 전략은 ReLU 활성화 함수의 특성을 반영하려고 합니다. 이 함수는 양수 입력에 대해 비활성화된 뉴런을 가지기 때문에 초기 가중치의 분산 조정은 깊은 네트워크에서 발생할 수 있는 그래디언트의 소실 또는 폭발을 방지하고 더 안정적이고 효율적인 훈련 과정을 촉진합니다.\n\n장점: ReLU 활성화 함수를 사용하는 네트워크에서 그래디언트 크기를 유지하여 깊은 학습 모델을 용이하게 학습시킵니다.\n\n단점: 특히 ReLU에 최적화되어 있어 다른 활성화 함수만큼 효과적이지 않을 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 초기화를 소개한 후 NeuralNetwork 클래스가 어떻게 보이는지 살펴보겠습니다:\n\n```js\n클래스 NeuralNetwork:\n    def __init__(self,\n                 layers,\n                 init_method='glorot_uniform', # 'zeros', 'random', 'glorot_uniform', 'glorot_normal', 'he_uniform', 'he_normal'\n                 loss_func='mse',\n                 ):\n        ...\n\n        self.init_method = init_method\n\n        # 레이어 초기화\n        for i in range(len(layers) - 1):\n            if self.init_method == 'zeros':\n                weights = np.zeros((layers[i], layers[i + 1]))\n            elif self.init_method == 'random':\n                weights = np.random.randn(layers[i], layers[i + 1])\n            elif self.init_method == 'glorot_uniform':\n                weights = self.glorot_uniform(layers[i], layers[i + 1])\n            elif self.init_method == 'glorot_normal':\n                weights = self.glorot_normal(layers[i], layers[i + 1])\n            elif self.init_method == 'he_uniform':\n                weights = self.he_uniform(layers[i], layers[i + 1])\n            elif self.init_method == 'he_normal':\n                weights = self.he_normal(layers[i], layers[i + 1])\n\n            else:\n                raise ValueError(f'알 수없는 초기화 방법 {self.init_method}')\n\n            self.layers.append({\n                'weights': weights,\n                'biases': np.zeros((1, layers[i + 1]))\n            })\n\n        ...\n\n    ...\n\n    def glorot_uniform(self, fan_in, fan_out):\n        limit = np.sqrt(6 / (fan_in + fan_out))\n        return np.random.uniform(-limit, limit, (fan_in, fan_out))\n\n    def he_uniform(self, fan_in, fan_out):\n        limit = np.sqrt(2 / fan_in)\n        return np.random.uniform(-limit, limit, (fan_in, fan_out))\n\n    def glorot_normal(self, fan_in, fan_out):\n        stddev = np.sqrt(2. / (fan_in + fan_out))\n        return np.random.normal(0., stddev, size=(fan_in, fan_out))\n\n    def he_normal(self, fan_in, fan_out):\n        stddev = np.sqrt(2. / fan_in)\n        return np.random.normal(0., stddev, size=(fan_in, fan_out))\n\n    ...\n```\n\n적절한 가중치 초기화 전략을 선택하는 것은 효과적인 신경망 학습에 중요합니다. 무작위 및 영점 초기화는 기본적인 접근법을 제공하지만 항상 최적의 학습 동역학을 이끌어내지 않을 수 있습니다. 반면, Glorot/Xavier 및 He 초기화는 신경망 아키텍처 및 사용된 활성화 함수를 고려하여 딥 러닝 모델의 특정 요구 사항을 고려하는 더 소박한 솔루션을 제공합니다. 이러한 전략은 너무 빠른 학습과 너무 느린 학습 사이의 절충안을 균형있게 맞추어 더 신뢰할 수 있는 수렴 방향으로 학습 프로세스를 이끕니다.\n\n## 3.4: 드롭아웃\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDropout은 신경망에서 오버피팅을 방지하기 위해 설계된 정규화 기술로, 훈련 단계에서 네트워크에서 임시로 그리고 무작위로 유닛(뉴런)과 해당 연결을 제거함으로써 사용합니다. 이 방법은 Srivastava 및 그 동료들이 2014 년 논문에서 고안한 간단하면서도 효과적인 방법으로 견고한 신경망을 훈련하는 데 사용됩니다.\n\n![이미지](/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_8.png)\n\n각 훈련 반복에서 각 뉴런(입력 단위 포함되지만 보통 출력 단위는 제외)은 일시적으로 \"드랍아웃\"될 확률 p를 가집니다. 이는 해당 뉴런이 이 전방 및 역방향 패스 동안 완전히 무시된다는 것을 의미합니다. 이 확률 p은 \"드랍아웃 비율\"로 불리며 성능을 최적화하기 위해 조절할 수 있는 하이퍼파라미터입니다. 예를 들어, 0.5의 드랍아웃 비율은 각 뉴런이 각 훈련 패스에서 계산에서 제외될 확률이 50% 라는 것을 의미합니다.\n\n이 과정의 효과는 네트워크가 개별 뉴런의 특정 가중치에 덜 민감해진다는 것입니다. 이것은 예측을 할 때 개별 뉴런의 출력에 의존할 수 없으므로 네트워크가 뉴런들 사이에 중요성을 분산시키도록 장려합니다. 이는 실제로 가중치를 공유하는 신경망의 의사앙상블을 훈련하며, 각 훈련 반복에서 네트워크의 다른 \"드랍아웃된\" 버전이 포함됩니다. 시험 시간에는 드랍아웃이 적용되지 않고, 대신 가중치는 일반적으로 드랍아웃 비율 p에 의해 조정되어 더 많은 유닛이 활성화되었다는 사실을 균형 있게 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n올바른 드롭아웃 비율 선택하기\n드롭아웃 비율은 각 신경망 구조와 데이터셋에 대해 조정이 필요한 하이퍼파라미터입니다. 일반적으로, 숨겨진 유닛에 대해 시작점으로 0.5의 비율이 사용되며, 이는 원래 드롭아웃 논문에서 제안되었습니다.\n\n높은 드롭아웃 비율 (1에 가까운 값)은 학습 중에 더 많은 뉴런이 제거되는 것을 의미합니다. 이는 네트워크가 데이터를 충분히 학습하지 못할 수 있어서, 훈련 데이터의 복잡성을 모델링하는 데 어려움을 겪어 과소적합을 초래할 수 있습니다.\n\n반대로, 낮은 드롭아웉 비율 (0에 가까운 값)은 더 적은 뉴런이 제거되어 드롭아웃의 정규화 효과가 줄어들 수 있으며, 이는 모델이 훈련 데이터에서 잘 수행되지만 보이지 않는 데이터에서 성능이 나빠질 수 있는 과적합을 초래할 수 있습니다.\n\n코드 구현\n우리 코드에서 어떻게 보이는지 살펴보겠습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nclass NeuralNetwork:\n    def __init__(self,\n                 layers,\n                 init_method='glorot_uniform', # 'zeros', 'random', 'glorot_uniform', 'glorot_normal', 'he_uniform', 'he_normal'\n                 loss_func='mse',\n                 dropout_rate=0.5\n                 ):\n        ...\n\n        self.dropout_rate = dropout_rate\n\n        ...\n\n    ...\n\n\n    def forward(self, X, is_training=True):\n        self.a = [X]\n        for i, layer in enumerate(self.layers):\n            z = np.dot(self.a[-1], layer['weights']) + layer['biases']\n            a = self.sigmoid(z)\n            if is_training and i < len(self.layers) - 1:  # apply dropout to all layers except the output layer\n                dropout_mask = np.random.rand(*a.shape) > self.dropout_rate\n                a *= dropout_mask\n            self.a.append(a)\n        return self.a[-1]\n\n    ...\n```\n\n저희 신경망 클래스는 새로운 초기화 매개변수와 드롭아웃 정규화를 포함한 새로운 순전파 메서드로 업그레이드되었습니다.\n\ndropout_rate : 이것은 훈련 중에 신경세포들이 네트워크에서 일시적으로 제거될 가능성을 결정하는 설정입니다. 오버피팅을 피하는 데 도움이 됩니다. 0.5로 설정함으로써 어떤 신경세포가 한 번의 훈련 라운드에서 \"제거\"될 확률이 50%라고 말하고 있습니다. 이 무작위성은 네트워크가 어떤 단일 신경세포에 너무 의존하지 않도록 보장하여 더 견고한 학습 과정을 촉진합니다.\n\nis_training 부울 플래그는 네트워크가 현재 훈련되고 있는지를 알려줍니다. 이것은 훈련 중에만 드롭아웃이 발생해야 하므로 새 데이터에 대한 네트워크 성능을 평가할 때는 드롭아웃이 일어나서는 안 된다는 점이 중요합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n네트워크를 통해 데이터(X로 표시)가 전달되면, 네트워크는 들어오는 데이터와 레이어의 편향을 가중합(z)으로 계산합니다. 그런 다음 이 합계를 시그모이드 활성화 함수를 통해 활성화(a)로 변환하여 다음 레이어로 전달할 신호를 얻습니다.\n\n하지만 훈련 중에 다음 레이어로 진행하기 전에 드롭아웃을 적용할 수 있습니다:\n\n- is_training이 true이고 출력 레이어를 다루고 있지 않다면, 각 뉴런에 대해 주사위를 굴려 떨어뜨릴지 여부를 확인합니다. 이를 위해 무작위 수가 드롭아웃 비율을 초과하는지 확인하여 드롭아웃 마스크(모양은 a와 같은 배열)를 생성합니다.\n- 이 마스크를 사용하여 a의 일부 활성화를 0으로 만들어 네트워크에서 일시적으로 뉴런을 제거하는 것을 흉내냅니다.\n\n드롭아웃을 적용한 후(해당하는 경우), 생성된 활성화를 self.a에 추가하여 모든 레이어를 통해 활성화를 추적하는 리스트를 유지합니다. 이렇게 하면 신호를 그냥 한 레이어에서 다음 레이어로 무작정 이동시키는 것이 아니라, 네트워크가 더 견고하게 학습하도록 장려하는 기술을 적용하여 특정 경로의 뉴런에 지나치게 의존하지 않도록 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 3.5: 그레이디언트 클리핑\n\n그레이디언트 클리핑은 깊은 신경망을 훈련할 때 중요한 기술로, 특히 폭주하는 그레이디언트 문제를 해결할 때 주로 사용됩니다. 폭주하는 그레이디언트는 신경망의 매개변수에 대한 손실 함수의 미분이나 그레이디언트가 층을 거치면서 지수적으로 증가하여 훈련 중에 가중치에 대해 매우 큰 업데이트를 유도할 때 발생합니다. 이는 학습 과정을 불안정하게 만들 수 있으며, 종종 가중치나 손실에서 NaN 값의 형태로 나타나 수치 오버플로우 때문에 발산하여 모델이 해결책으로 수렴하지 못하도록 방해할 수 있습니다.\n\n그레이디언트 클리핑은 값에 의한 클리핑과 법에 의한 클리핑 두 가지 주요 방법으로 구현할 수 있으며, 각각 폭주하는 그레이디언트 문제를 완화하는 전략을 가지고 있습니다.\n\n값에 의한 클리핑\n이 방법은 미리 정의된 임계값을 설정하고, 각 그레이디언트 구성 요소를 해당 임계값을 초과하는 경우 지정된 범위 내로 직접 클리핑하는 접근 방식입니다. 예를 들어, 임계값이 1로 설정되면, 1보다 큰 모든 그레이디언트 구성 요소를 1로 설정하고, -1보다 작은 모든 구성 요소를 -1로 설정합니다. 이는 모든 그레이디언트가 [-1, 1] 범위 내에 유지되도록 보장하여 너무 커지는 그레이디언트를 효과적으로 방지합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_9.png\" />\n\ngi는 기울기 벡터의 각 구성 요소를 나타냅니다.\n\n노름에 의한 클리핑\n이 방법은 각 기울기 구성 요소를 개별적으로 클리핑하는 대신, 일정 임계값을 초과하는 경우 전체 기울기를 조절합니다. 이렇게 하면 기울기의 방향을 보존한 채 크기가 지정된 한도를 초과하지 않도록 할 수 있습니다. 이는 모든 매개변수를 통해 업데이트의 상대적 방향을 유지하는 데 특히 유용하며, 값에 의한 클리핑보다 학습 과정에 더 유익할 수 있습니다.\n\n<img src=\"/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_10.png\" />\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그래디언트 벡터를 나타내는 g이고 ∥g∥는 그 노름값입니다.\n\n훈련에의 응용\n\n```js\nclass NeuralNetwork:\n    def __init__(self,\n                 layers,\n                 init_method='glorot_uniform', # 'zeros', 'random', 'glorot_uniform', 'glorot_normal', 'he_uniform', 'he_normal'\n                 loss_func='mse',\n                 dropout_rate=0.5,\n                 clip_type='value',\n                 grad_clip=5.0\n                 ):\n        ...\n\n        self.clip_type = clip_type\n        self.grad_clip = grad_clip\n\n        ...\n\n    ...\n\n    def backward(self, X, y, learning_rate):\n        m = X.shape[0]\n        self.dz = [self.a[-1] - y]\n        self.gradient_norms = []  # 그래디언트 노름을 저장하는 리스트\n\n        for i in reversed(range(len(self.layers) - 1)):\n            self.dz.append(np.dot(self.dz[-1], self.layers[i + 1]['weights'].T) * self.sigmoid_derivative(self.a[i + 1]))\n            self.gradient_norms.append(np.linalg.norm(self.layers[i + 1]['weights']))  # 그래디언트 노름을 계산하고 저장\n\n        self.dz = self.dz[::-1]\n        self.gradient_norms = self.gradient_norms[::-1]  # 리스트를 뒤집어서 레이어의 순서와 일치시킴\n\n        for i in range(len(self.layers)):\n            grads_w = np.dot(self.a[i].T, self.dz[i]) / m\n            grads_b = np.sum(self.dz[i], axis=0, keepdims=True) / m\n\n            # 그래디언트 클리핑\n            if self.clip_type == 'value':\n                grads_w = np.clip(grads_w, -self.grad_clip, self.grad_clip)\n                grads_b = np.clip(grads_b, -self.grad_clip, self.grad_clip)\n            elif self.clip_type == 'norm':\n                grads_w = self.clip_by_norm(grads_w, self.grad_clip)\n                grads_b = self.clip_by_norm(grads_b, self.grad_clip)\n\n            self.layers[i]['weights'] -= learning_rate * grads_w\n            self.layers[i]['biases'] -= learning_rate * grads_b\n\n    def clip_by_norm(self, grads, clip_norm):\n        l2_norm = np.linalg.norm(grads)\n        if l2_norm > clip_norm:\n            grads = grads / l2_norm * clip_norm\n        return grads\n\n    ...\n```\n\n초기화 중에 이제 사용할 그래디언트 클리핑 유형(clip_type)과 그래디언트 클리핑 임계값(grad_clip)이 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n`clip_type`은 그레디언트를 값으로 자르는 경우에는 `value`, 또는 L2 노름에 의해 그레디언트를 자르는 경우에는 `norm`이 될 수 있습니다. grad_clip은 자르는 임계값이나 한계를 지정합니다.\n\n그런 다음, 역전파 중에 함수는 네트워크의 각 레이어에 대한 그레디언트를 계산합니다. 가중치(grads_w)와 편향(grads_b)에 대한 손실의 미분 값을 각 레이어마다 계산합니다.\n\n만약 `clip_type`이 `value`인 경우, np.clip을 사용하여 그레디언트를 [-grad_clip, grad_clip] 범위로 자릅니다. 이렇게 하면 그레디언트 성분이 이 한계를 초과하지 않도록 합니다.\n\n만약 `clip_type`이 `norm`인 경우, 그레디언트의 노름이 grad_clip을 초과하는 경우 이 방향을 유지하면서 그에 대한 크기를 제한하기 위해 clip_by_norm 메서드가 호출됩니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n클리핑 이후, 각 층의 가중치와 편향을 학습률에 의해 조정하는 데 그래디언트가 사용됩니다.\n\n마지막으로, 그래디언트의 L2 노름이 지정된 clip_norm을 초과하는 경우 그래디언트를 스케일링하는 clip_by_norm 메서드를 만듭니다. 이 메서드는 그래디언트의 L2 노름을 계산하고, clip_norm보다 크면 그래디언트를 clip_norm까지 스케일 다운시키면서 방향을 유지합니다. 이는 그래디언트를 그들의 L2 노름으로 나누고 clip_norm을 곱해 달성됩니다.\n\n그래디언트 클리핑의 장점\n모델의 가중치에 대한 지나치게 큰 업데이트를 방지함으로써, 그래디언트 클리핑은 더 안정적이고 신뢰할 수 있는 훈련 과정에 기여합니다. 그래디언트의 계산이 큰 업데이트로 인해 불안정성을 초래할 수 있는 경우에도 손실 함수를 최소화하여 옵티마이저가 일관된 진전을 이룰 수 있도록 합니다. 이는 훈련하는 동안 그래디언트의 스케일이 큰 문제로 인해 불안정성 문제에 직면하는 순환 신경망(RNNs) 훈련과 같은 과제에서 특히 유용한 도구로 작용합니다.\n\n그래디언트 클리핑은 신경망 훈련의 안정성과 성능을 향상시키는 간단하면서도 강력한 기술입니다. 그래디언트가 지나치게 커지지 않도록 보장함으로써, 훈련 불안정성(과적합, 과소적합, 수렴 속도 저하 등)의 문제를 피하고, 신경망이 효과적이고 효율적으로 학습하기 쉽도록 돕습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 4: 층의 최적 개수 결정하기\n\n신경망을 설계하는 중요한 결정 중 하나는 올바른 층의 개수를 결정하는 것입니다. 이 측면은 네트워크의 데이터로부터 학습하고 새로운, 보지 못한 데이터를 일반화하는 능력에 상당한 영향을 미칩니다. 신경망의 깊이 - 얼마나 많은 층이 있는지 - 능력을 강화시키거나 과적합 또는 학습이 부족하다는 문제로 이어질 수 있습니다.\n\n## 4.1: 층의 깊이와 모델 성능\n\n신경망에 더 많은 층을 추가하면 학습 능력이 향상되어 데이터의 더 복잡한 패턴과 관계를 파악할 수 있습니다. 이는 추가적인 층이 입력 데이터의 보다 추상적인 표현을 만들 수 있기 때문에 단순한 기능에서 더 복잡한 조합으로 이동할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n더 깊은 신경망은 복잡한 패턴을 모델링할 수 있지만, 추가적인 깊이가 오버피팅으로 이어지는 기묘한 지점이 있습니다. 오버피팅은 모델이 훈련 데이터를 너무 잘 학습하여 그 잡음까지 포함해 새로운 데이터에서 성능이 나빠지는 현상입니다.\n\n궁극적인 목표는 훈련 데이터로부터 잘 학습하는 모델을 갖는 것뿐만 아니라 이 학습을 새로운 데이터에서도 정확하게 수행할 수 있는 범용성을 갖는 것입니다. 이를 위해서는 층의 깊이에 대한 적절한 균형을 찾는 것이 중요합니다. 너무 적은 층은 과소적합될 수 있고, 너무 많은 층은 오버피팅될 수 있습니다.\n\n## 4.2: 적절한 깊이를 테스트하고 선택하는 전략\n\n점진적인 접근 방식\n간단한 모델부터 시작하여 점진적으로 층을 추가하고 검증 성능이 크게 향상될 때까지 관찰합니다. 이 접근 방식은 각 층이 전체 성능에 어떤 기여를 하는지 이해하는 데 도움이 됩니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모델의 성능을 판단하기 위한 기준으로 검증 세트(학습 중에 사용되지 않은 학습 데이터의 하위 집합)에서 모델이 일반화하는 능력을 향상시키는지 여부를 결정합니다.\n\n정규화 기법\n더 많은 레이어를 추가할 때 드롭아웃 또는 L2 정규화와 같은 정규화 방법을 사용하세요. 이러한 기법은 오버피팅의 위험을 줄일 수 있어 추가된 레이어가 모델의 학습 능력에 어떤 가치를 더하는지를 공정하게 평가할 수 있게 해줍니다.\n\n학습 동태 관찰\n더 많은 레이어를 추가할 때 학습과 검증 손실을 모니터링하세요. 이 두 지표 사이에 차이가 발생하는 경우 — 학습 손실이 감소하지만 검증 손실이 그렇지 않을 때 — 오버피팅을 나타낼 수 있으며, 현재 깊이가 지나칠 수 있다는 것을 시사할 수 있습니다.\n\n![이미지](/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_11.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 두 그래프는 기계 학습 모델을 훈련하는 과정에서 발생할 수 있는 두 가지 시나리오를 나타냅니다.\n\n첫 번째 그래프에서는 훈련 손실과 검증 손실이 모두 감소하여 비슷한 값으로 수렴합니다. 이것은 이상적인 시나리오로, 모델이 잘 학습하고 적절하게 일반화되고 있음을 나타냅니다. 모델의 성능이 훈련 데이터와 보지 않은 검증 데이터 모두에서 향상되고 있는 것을 의미합니다. 이는 모델이 데이터를 과소적합하거나 과적합하지 않고 있다는 것을 시사합니다.\n\n두 번째 그래프에서는 훈련 손실은 감소하지만 검증 손실이 증가합니다. 이는 과적합의 전형적인 징후입니다. 모델이 훈련 데이터를 너무 잘 학습하여 노이즈와 이상점을 포함하고 있으며 보지 않은 데이터에 대한 일반화를 실패합니다. 결과적으로, 검증 데이터에서의 성능이 시간이 지남에 따라 악화됩니다. 이는 모델의 복잡성을 줄이거나 정규화나 드롭아웃과 같은 과적합 방지 기술을 적용해야 할 수도 있다는 것을 나타냅니다.\n\n자동화 아키텍처 탐색\n신경망 아키텍처 탐색(NAS) 도구나 Optuna와 같은 하이퍼파라미터 최적화 프레임워크를 활용하여 서로 다른 아키텍처를 체계적으로 탐색하십시오. 이러한 도구는 다양한 구성을 평가하고 검증 지표에서 최상의 성능을 발휘하는 구성을 선택함으로써 최적의 레이어 수를 자동화할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n신경망의 최적 레이어 수를 결정하는 것은 모델의 복잡성과 학습 및 일반화 능력을 균형있게 고려하는 세심한 프로세스입니다. 레이어 추가에 체계적인 방법론을 채택하고 교차 검증을 활용하며 정칙화 기법을 통합함으로써 특정 문제에 적합한 네트워크 깊이를 결정할 수 있습니다. 이를 통해 보이지 않는 데이터에 대한 모델 성능을 최적화할 수 있습니다.\n\n# 5: Optuna을 활용한 자동 미세 튜닝\n\n최적 성능을 달성하기 위해 신경망을 미세 조정하는 것은 다양한 하이퍼파라미터의 섬세한 균형을 찾는 과정으로, 종종 방대한 탐색 공간 속에서 바늘을 찾는 것처럼 느껴질 수 있습니다. 이때 Optuna와 같은 자동 하이퍼파라미터 최적화 도구가 필요합니다.\n\n## 5.1: Optuna 소개\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n옵투나는 최적화 하이퍼파라미터 선택을 자동화하기 위해 설계된 오픈소스 최적화 프레임워크입니다. 이는 가장 효율적인 신경망 모델로 이어지는 매개변수 조합을 식별하는 복잡한 작업을 간단화합니다. 옵투나는 고급 알고리즘을 활용하여 최적화 하이퍼파라미터 공간을 보다 효과적으로 탐색하여, 필요한 계산 자원과 수렴 시간을 줄입니다.\n\n## 5.2: 옵투나를 활용한 신경망 최적화 통합\n\n옵투나는 베이지안 최적화, 트리 구조 파르젠 추정기, 진화 알고리즘 등 다양한 전략을 활용하여 하이퍼파라미터 공간을 지능적으로 탐색합니다. 이 접근 방식을 통해 옵투나는 가장 유망한 하이퍼파라미터를 빠르게 식별하여 최적화 과정을 크게 가속화할 수 있습니다.\n\n옵투나를 신경망 훈련 워크플로우에 통합하는 것은 옵투나가 최소화 또는 최대화하려는 목적 함수를 정의하는 과정을 포함합니다. 이 함수에는 일반적으로 모델 훈련 및 검증 과정이 포함되며, 목표는 검증 손실을 최소화하거나 검증 정확도를 최대화하는 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 검색 공간 정의: 각 하이퍼파라미터 값 범위를 지정하여 Optuna가 탐색할 것입니다 (예: 레이어 수, 학습률, 드롭아웃 비율).\n- 시험과 평가: Optuna는 모델을 훈련시키기 위해 매번 새로운 하이퍼파라미터 세트를 선택하는 시험을 진행합니다. 검증 세트에서 모델의 성능을 평가하고 이 정보를 사용하여 탐색을 안내합니다.\n\n## 5.3: 실제 구현\n\n```python\nimport optuna\n\ndef objective(trial):\n    # 하이퍼파라미터 정의\n    n_layers = trial.suggest_int('n_layers', 1, 10)\n    hidden_sizes = [trial.suggest_int(f'hidden_size_{i}', 32, 128) for i in range(n_layers)]\n    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)  # 모든 레이어에 대한 단일 드롭아웃 비율\n    learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n    init_method = trial.suggest_categorical('init_method', ['glorot_uniform', 'glorot_normal', 'he_uniform', 'he_normal', 'random'])\n    clip_type = trial.suggest_categorical('clip_type', ['value', 'norm'])\n    clip_value = trial.suggest_uniform('clip_value', 0.0, 1.0)\n    epochs = 10000\n\n    layers = [input_size] + hidden_sizes + [output_size]\n\n    # 신경망 생성 및 훈련\n    nn = NeuralNetwork(layers=layers, loss_func=loss_func, dropout_rate=dropout_rate, init_method=init_method, clip_type=clip_type, grad_clip=clip_value)\n    trainer = Trainer(nn, loss_func)\n    trainer.train(X_train, y_train, X_test, y_test, epochs, learning_rate, early_stopping=False)\n\n    # 신경망 성능 평가\n    predictions = np.argmax(nn.forward(X_test), axis=1)\n    accuracy = np.mean(predictions == y_test_labels)\n\n    return accuracy\n\n# Study 객체 생성 및 목적 함수 최적화\nstudy = optuna.create_study(study_name='nn_study', direction='maximize')\nstudy.optimize(objective, n_trials=100)\n\n# 최적 하이퍼파라미터 출력\nprint(f\"Best trial: {study.best_trial.params}\")\nprint(f\"Best value: {study.best_trial.value:.3f}\")\n```\n\nOptuna 최적화 프로세스의 핵심은 목적 함수입니다. 이 함수는 시험 목표를 정의하고 각 시험에 대해 Optuna에 의해 호출됩니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n**Heren_layers**은 신경망의 은닉층의 수이며, 1에서 10 사이를 추천합니다. 층의 수를 변화시킴으로써 얕은 네트워크와 깊은 네트워크 아키텍처를 탐색할 수 있습니다.\n\n**hidden_sizes**는 각 층의 크기(뉴런 수)를 저장하며, 32에서 128 사이의 숫자를 제안하여 모델이 다양한 용량을 탐색하게 합니다.\n\n**dropout_rate**는 균일하게 0.0(드롭아웃 없음)에서 0.5 사이를 제안하여 시험을 통해 정규화 유연성을 가능케 합니다.\n\n**learning_rate**는 로그 스케일로 1e-3에서 1e-1 사이를 제안하여, 학습률 최적화에 대한 공통적인 민감도로 인해 크기의 범위를 포괄하는 넓은 탐색 공간을 보장합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n신경망 가중치의 init_method은 일련의 일반적인 전략 중에서 선택됩니다. 이 선택은 훈련의 시작점과 수렴 동작을 영향을 줍니다.\n\nclip_type과 clip_value는 그래디언트 클리핑 전략과 값으로, 값이나 노름을 기준으로 클리핑하여 폭발하는 그래디언트를 방지하는 데 도움이 됩니다.\n\n그런 다음, 정의된 하이퍼파라미터를 사용하여 NeuralNetwork 인스턴스가 생성되고 훈련됩니다. 각 시행이 일정한 에포크 수동안 실행될 수 있도록 조기 중지가 비활성화되며, 일관된 비교를 보장합니다. 성능은 테스트 세트에서 모델의 예측 정확도를 기반으로 평가됩니다.\n\n목적 함수와 NeuralNetwork 인스턴스가 정의된 후 Optuna 스터디로 이동할 수 있습니다. Optuna 스터디 객체는 목적 함수를 최대화(`maximize`)하는 데 사용되며, 이 문맥에서는 신경망의 정확도가 목적 함수입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n연구는 목적 함수를 여러 번 호출합니다(n_trials=100), 매번 옵튜나 내부 최적화 알고리즘에서 제안한 다른 하이퍼파라미터 세트로 호출합니다. 옵튜나는 시험 이력에 기반하여 지능적으로 제안을 조정하여 하이퍼파라미터 공간을 효율적으로 탐색합니다.\n\n이 프로세스를 통해 모든 실험에서 찾은 가장 좋은 하이퍼파라미터 세트(study.best_trial.params)와 달성한 최고 정확도(study.best_trial.value)가 생성됩니다. 이 출력은 주어진 작업에 대한 신경망의 최적 구성에 대한 통찰을 제공합니다.\n\n## 5.4: 혜택 및 결과\n\n옵튜나를 통합함으로써, 개발자는 하이퍼파라미터 튜닝 프로세스를 자동화할뿐만 아니라 어떻게 다른 매개변수가 모델에 영향을 미치는지에 대한 깊은 통찰을 얻을 수 있습니다. 이를 통해 수동 실험을 통해 걸릴 시간의 일부로 최적화된, 더 견고하고 정확한 신경망이 생성됩니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n옵투나의 체계적인 파라미터 조정 접근법은 신경망 개발에 새로운 수준의 정밀성과 효율성을 제공하여 개발자들이 더 높은 성능 표준을 달성하고 모델이 이룰 수 있는 한계를 뛰어넘을 수 있도록 돕습니다.\n\n## 5.5: 한계\n\n옵투나는 하이퍼파라미터 최적화에 강력하고 유연한 접근 방식을 제공하지만, 기계 학습 워크플로에 통합할 때 고려해야 할 몇 가지 한계점과 주의 사항이 있습니다.\n\n계산 리소스\n각 시도는 신경망을 처음부터 훈련해야 하므로, 특히 심층 신경망이나 대규모 데이터셋의 경우에는 계산 리소스가 많이 필요할 수 있습니다. 하이퍼파라미터 공간을 철저히 탐색하기 위해 수백 번이나 수천 번의 시도를 실행하는 것은 상당한 계산 리소스와 시간이 필요할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n하이퍼파라미터 검색 공간\n옵투나의 검색 효과는 검색 공간이 어떻게 정의되는지에 매우 의존합니다. 하이퍼파라미터 값의 범위가 너무 넓거나 문제와 제대로 일치하지 않으면 옵투나가 비최적 영역을 탐색하는 데 시간을 낭비할 수 있습니다. 반대로 검색 공간이 너무 좁으면 최적의 구성을 놓칠 수 있습니다.\n\n하이퍼파라미터 수가 증가함에 따라 검색 공간이 기하급수적으로 증가하는데, 이를 \"차원의 저주\"라고 합니다. 이로 인해 옵투나가 공간을 효율적으로 탐색하고 합리적인 횟수의 시도 내에서 최적의 하이퍼파라미터를 찾는 것이 어렵다는 도전이 생길 수 있습니다.\n\n평가 지표\n목적 함수와 평가 지표의 선택은 최적화 결과에 상당한 영향을 미칠 수 있습니다. 모델의 성능이나 작업 목표를 적절히 포착하지 못하는 지표는 하이퍼파라미터 구성을 부적절하게 만들 수 있습니다.\n\n모델의 성능 평가는 무작위 초기화, 데이터 섞기, 또는 데이터셋 내 잡음과 같은 요소로 인해 달라질 수 있습니다. 이러한 변동성은 최적화 과정에 잡음을 도입하여 결과의 신뢰성에 영향을 줄 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n알고리즘 제한사항\nOptuna은 검색 공간을 탐색하기 위해 정교한 알고리즘을 사용하지만, 이러한 알고리즘의 효율성과 효과는 문제에 따라 다를 수 있습니다. 경우에 따라 특정 알고리즘이 지역 최적점으로 수렴하거나 하이퍼파라미터 공간의 특정 특성에 더 잘 맞도록 설정을 조정해야 할 수도 있습니다.\n\n# 6: 결론\n\n신경망의 세밀한 조정에 대해 심층적으로 살펴본 후에 우리가 걸어온 길을 돌아보는 좋은 시기입니다. 우리는 신경망이 어떻게 작동하는지에 대한 기본 사항부터 시작하여 그들의 성능과 효율성을 높이는 더 정교한 기술로 점진적으로 발전해왔습니다.\n\n## 6.1: 다음 단계\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리는 신경망 최적화에 많은 영역을 다루었지만, 명백히 우리는 겨우 표면만 긁은 것 뿐입니다. 신경망 최적화의 영역은 방대하며 지속적으로 진화하고 있으며, 아직 탐험하지 않은 기술과 전략으로 넘쳐납니다. 다가오는 기사에서 더 심층적으로 파고들어 복잡한 신경망 구조와 더 높은 성능과 효율성을 끌어올릴 수 있는 고급 기술을 탐구할 예정입니다.\n\n저희가 파헤치고자 하는 최적화 기술과 개념의 다양한 범위에는 다음과 같은 것들이 포함됩니다:\n\n- 배치 정규화: 입력 레이어를 정규화해 활성화를 조정하고 스케일링하여 훈련 속도를 높이고 안정성을 향상시키는 방법입니다.\n- 최적화 알고리즘: SGD 및 Adam을 포함한 최적화 알고리즘은 복잡한 손실 함수의 영역을 더 효과적으로 탐색할 수 있는 도구를 제공하여 더 효율적인 훈련 주기와 더 나은 모델 성능을 보장합니다.\n- 전이 학습 및 파인 튜닝: 사전 훈련된 모델을 활용하여 새로운 작업에 적응시키면 훈련 시간을 크게 단축하고 데이터가 제한적인 작업에서 모델 정확도를 향상시킬 수 있습니다.\n- 신경 아키텍처 탐색(NAS): 자동화를 사용하여 신경망을 위한 최상의 아키텍처를 발견함으로써 직관적이지 않은 효율적인 모델을 발견할 수 있습니다.\n\n이러한 주제들은 단지 저희가 다루는 것 중 일부에 불과하며, 각각 고유한 이점과 도전을 제공합니다. 앞으로 나아가면서, 이러한 기술을 자세히 살펴보고, 언제 사용해야 하는지, 그들이 어떻게 작용하는지, 그리고 당신의 신경망 프로젝트에 미치는 영향에 대한 통찰력을 제공할 것을 목표로 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 추가 자료\n\n- “Deep Learning” - Ian Goodfellow, Yoshua Bengio, Aaron Courville 저: 깊은 학습 기술과 원리에 대한 깊이 있는 개요를 제공하는 이 근본적인 문헌은 고급 신경망 구조 및 최적화 방법을 다룹니다.\n- “Neural Networks and Deep Learning: A Textbook” - Charu C. Aggarwal 저: 신경망에 대한 상세한 탐구를 제공하며, 깊은 학습과 그 응용에 중점을 둡니다. 신경망 디자인 및 최적화의 복잡한 개념을 이해하는 데 탁월한 자료입니다.\n\n여기까지 왔습니다. 축하해요! 이 기사를 즐기셨다면 좋아요를 누르고 팔로우해주시면 감사하겠습니다. 저는 정기적으로 유사한 기사를 게시할 예정이니 많은 관심 부탁드립니다. 제 목표는 가장 인기 있는 알고리즘을 다시 처음부터 만들어 머신 러닝을 모든 사람이 접근 가능하도록 하는 것입니다.\n","ogImage":{"url":"/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-TheMathBehindFine-TuningDeepNeuralNetworks_0.png","tag":["Tech"],"readingTime":51},{"title":"Langchain이 필요하지 않은 이유","description":"","date":"2024-07-09 19:54","slug":"2024-07-09-HeresWhyYouProbablyDontNeedLangchain","content":"\n## Langchain을 사용하지 않고 CSV 파일과 상호 작용하는 LLM 파이프라인\n\nLangChain, LangGraph, LlamaIndex, CrewAI... 한 가지 도구에 익숙해지기 시작하면 또 다른 도구가 등장합니다. 이 도구들을 깎아내리거나 싫어하지는 않지만, 이 중 하나와 개발하는 것은 학습 곡선 때문에 진정으로 무섭고 당황스러울 수 있습니다. 이 도서관들을 배우는 것으로 끝내는 대신에 실제로 무언가를 구축하고 싶다면 낙담하기 쉬울 수 있습니다. LangChain은 훌륭하지만 정말 밀도있게 포장되어 있습니다. 문서 자체로는 Python용, JavaScript용 하나씩, 그리고 아마도 API를 위한 부모 문서가 있을 거라고 생각합니다. 그리고 Python 내에서도 비슷한 작업을 수행하는 여러 기능들이 있습니다. 이 모든 것은 좋지만, 코드에 충분한 제어권이 없습니다. 예를 들어, 이전 블로그에서 PDF를 바이트로 로더에 전달하려고 했지만, 함수는 파일 URL만 허용했기 때문에 제대로 수행할 수 없었습니다. 나에게 따르면, 무언가를 간단히 구축할 때 LangChain은 마지막 선택이어야 합니다. 항상 KISS (Keep it simple, stupid)를 지키세요.\n\n![이미지](/TIL/assets/img/2024-07-09-HeresWhyYouProbablyDontNeedLangchain_0.png)\n\n음, 그들이 나가리키는 만큼 사악하지 않을 수도 있지만, 충분하지 않다고 판단된다면 먼저 원시적인 것을 시도한 다음에 더 고급 도구로 넘어가는 것이 항상 좋습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이번 달은 상당히 바쁘게 보냈어요 (사실, 2022년 11월 이후 모든 달이 그랬어요) GPT-4o의 발매와 Gemini 업데이트가 두 날에 걸쳐 연이어 발표되면서요.\n\n![image](/TIL/assets/img/2024-07-09-HeresWhyYouProbablyDontNeedLangchain_1.png)\n\nGPT-4o의 'ScarJo' - 아니, 'Sky' - 음성은 데모에서 영향을 주었는데, 이로 인해 인공지능 산업에 파도를 일으키고 구글 I/O의 Gemini 성능을 가려버렸어요. 솔직히 말해서, GPT는 항상 모든 LLM들보다 한 발 앞서 있을 거예요만 MVP 및 개인 프로젝트를 만들 때, 무료 티어를 제공하는 Gemini는 제 같은 가난한 개발자들에게 축복이예요. 최신 모델에 액세스할 수 있는 무료 티어로 API 제한 속도가 15 rpm로 정해져 있어요. 나쁘지 않죠?\n\nChatGPT의 무료 버전을 통해 이제 GPT-4o로 파일을 업로드할 수 있지만, 여전히 코드 해석기 없이 CSV나 엑셀 데이터를 해석할 수 없어요. 그래서 Gemini Flash의 능력을 테스트해보기 위해 제가 직접 CSV 해석기를 만들기로 결심했어요. Langchain을 사용하는 방법을 보여주는 많은 튜토리얼이 있지만, 저희는 처음 시작하는 사람들에게 특히 더 이해하기 쉬운 방법으로 처음부터 만들어볼 거예요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 파이프라인\n\n내 말 믿어봐, 처음에는 약간 어려워 보일 수 있지만 정말 간단해. 기본 아이디어는 LLM에게 코드를 생성하도록 요청하는 것이야. 코드를 생성하려면 작업 중인 데이터셋에 대한 일부 컨텍스트를 제공해야 해.\n\n1단계는 코드 생성을 다루는데, 데이터셋의 메타데이터를 제공하고, 내 경험에 따르면 head(), describe(), columns(), dtypes이 충분한 컨텍스트를 제공할 거야. LLM에 대한 경험이 있는 경우, RAG (Retrieval Augmented Generation)을 사용할 수 있는지 궁금할 수도 있어. RAG는 벡터 데이터베이스와 시맨틱 검색을 활용해 데이터 검색 후 그 결과를 쿼리와 함께 LLM에 삽입하는 것이야. 이는 텍스트 데이터와 잘 작동하지만 구조화된 또는 비구조화된 데이터의 분석에는 적합하지 않아. 왜냐하면 전체 데이터셋이 조각으로 나뉘어 컨텍스트를 제한하고 기능을 제한하기 때문이지. 예를 들어, 데이터셋에서 총 행의 수를 조회하고 싶다면 RAG로는 간단히 불가능해.\n\n2단계에서는 1단계에서 생성된 코드를 실행하여 생성된 출력을 LLM에 제공하고 사용자 쿼리와 결합시킨다. 이를 통해 pandas 명령의 출력을 자연어로 변환하여 대화 경험을 향상시킬 수 있어.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n표 태그를 Markdown 형식으로 변경해주세요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n대부분의 사람들이 하는 신입 실수 중 하나는 프롬프트에 가능한 모든 지시사항을 자세히 기술하는 것입니다. LLMs는 지능이 없으므로 모든 것을 지키지 않을 것이며(적어도 AGI가 달성될 때까지), 이 문제를 피하기 위해 다수의 기술과 전략이 개발되었습니다. 예를 들면 제로샷 프롬프팅, 사고 흐름, 퓨샷 프롬프팅 등이 있습니다. 이들이 멋지게 들리기는 하지만 실제로는 매우 기본적인 기술들입니다. 이미 이들에 대한 많은 문헌 자료가 있기 때문에 그것들에 대해서는 자세히 다루지 않겠습니다. 이 중에서 나에게 가장 효과적으로 작용한 것은 역할 기반 프롬프팅입니다. 역할 기반 프롬프팅에서는 쿼리하기 전에 LLM에게 역할을 할당합니다. 이는 원하는 결과를 달성하는 데 도움이 됩니다.\n\n총 네 개의 프롬프트가 필요합니다: 두 개의 시스템 프롬프트와 두 개의 주요 프롬프트(각 단계별 시스템 프롬프트 + 주요 프롬프트). 시스템 프롬프트는 틀을 제공하여 인공지능이 특정 매개변수 내에서 작동하고 일관되고 관련성 있으며 원하는 결과와 일치하는 응답을 생성할 수 있도록하는 역할을 합니다.\n\n## 단계 1\n\n시스템 프롬프트\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n### Main Prompt\n\nThe dataframe name is ‘df’. df has the columns 'cols' and their datatypes are 'dtype'. df is in the following format: 'desc'. The head of df is: 'head'. You cannot use `df.info()` or any command that cannot be printed. Write a pandas command for this query on the dataframe df: 'user_query'\n\nIf you provide me with the specific metadata values, I can help you generate the pandas command for the user query on the dataframe 'df'. Feel free to ask any questions!\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n응답 스키마\n\n```python\nclass Command(typing_extensions.TypedDict):\n    command: str\n```\n\n젬니 SDK에서 JSON 모드로 전환할 수 있습니다. 일관된 JSON 출력을 얻으려면 응답 스키마를 Python 클래스로 정의하고 LLM 응답 생성 함수의 매개변수로 전달하세요. Command 클래스에서 JSON은 하나의 key인 command와 문자열 값만을 가질 것입니다.\n\n```python\n// 사용자 쿼리: \"상위 5개 데이터를 보여줘\"\n\n{\n  \"command\": \"df.head()\"\n}\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 2\n\n시스템 프롬프트\n\n당신의 임무는 이해하는 것입니다. 사용자 쿼리와 응답 데이터를 분석하여 자연어로 된 응답 데이터를 생성해야 합니다.\n\n주 프롬프트\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n사용자 쿼리는 'final_query'입니다. 명령의 출력은 'str(data)'입니다. 데이터가 'None'인 경우 '시작하려면 쿼리를 요청하세요'라고 말할 수 있습니다. 사용된 명령을 언급하지 마세요. 출력에 대한 자연스러운 언어의 응답을 생성하세요.\n\n# 모두 함께 넣기\n\n편리함을 위해 이 프로젝트에는 Streamlit을 사용할 것입니다. 이는 많은 시간을 절약해줄 것입니다. 이 프로젝트는 80%의 GenAI 응용 프로그램 내부를 이해하는 데 목표를 두고 있습니다. Python을 사용하여 사용자 정의 웹 애플리케이션을 구축하는 방법을 배우고 싶다면 제 블로그를 여기에서 읽어보세요.\n\n데이터프레임 메타데이터\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\ndf = pd.read_csv(uploaded_file)\nhead = str(df.head().to_dict())\ndesc = str(df.describe().to_dict())\ncols = str(df.columns.to_list())\ndtype = str(df.dtypes.to_dict())\n\n시스템 프롬프트\n\n# Stage 1\n\nmodel_pandas = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=\"판다스와 함께 작업하는 전문 파이썬 개발자입니다. JSON 형식으로 사용자 쿼리를 위한 간단한 판다스 '명령'을 생성하는 것을 확인합니다. 'print' 함수를 추가할 필요는 없습니다. 명령을 생성하기 전에 열의 데이터 유형을 분석하세요. 불가능한 경우 'None'을 반환하십시오. \")\n\n# Stage 2\n\nmodel_response = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=\"태스크는 이해하는 것입니다. 사용자 쿼리를 분석하고 응답 데이터를 자연어로 생성하는 데 있어서 의무가 있습니다.\")\n\n메인 프롬프트\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# Stage 1\nfinal_query = f\"데이터프레임 이름은 'df'입니다. df는 열 {cols}을 가지고 있으며 데이터 유형은 {dtype}입니다. df는 다음 형식으로 구성되어 있습니다: {desc}. df의 맨 위 데이터는 다음과 같습니다: {head}. df.info()나 출력할 수 없는 명령을 사용할 수 없습니다. 데이터프레임 df에 대한 이 쿼리에 대한 판다스 명령어를 작성해주세요: {user_query}\"\n\n# Stage 2\nnatural_response = f\"사용자 쿼리는 {final_query}입니다. 명령어의 결과는 {str(data)}입니다. 데이터가 'None'인 경우 '시작하기 위해 쿼리를 요청하세요'라고 말할 수 있습니다. 사용된 명령을 언급하지 마세요. 결과에 대한 자연어 응답을 생성해주세요.\"\n```\n\n응답 생성\n\n```js\n# Stage 1\nresponse = model_pandas.generate_content(\n                final_query,\n                generation_config=genai.GenerationConfig(\n                    response_mime_type=\"application/json\",\n                    response_schema=Command,\n                    temperature=0.3\n                )\n            )\n\n\n# Stage 2\nbot_response = model_response.generate_content(\n                natural_response,\n                generation_config=genai.GenerationConfig(temperature=0.7)\n            )\n```\n\ntemperature는 생성된 응답의 무작위성을 제어하는 데 사용됩니다. 높은 temperature는 더 창의적이고 다양한 응답을 생성하지만 실제 사용자 쿼리에서 벗어날 수 있습니다. 낮은 temperature는 더 일관된 몰입형 응답을 생성하지만 창의적이지 않을 수 있습니다. 그래서 제가 Stage 1에는 정확한 명령을 얻기 위해 낮은 temperature를 선택했고, Stage 2에는 답변이 지루하고 로봇적이지 않도록 더 높은 temperature를 선택했습니다. 달콤한 지점을 찾기 위해 실험해보세요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n팬더스 명령을 실행하려면 파이썬에서 exec() 함수를 사용할 것입니다. 이 함수를 통해 파이썬 코드를 동적으로 실행할 수 있습니다. exec() 함수와 관련된 보안 취약점을 알고 있지만, 이 경우에는 다른 방법이 없었습니다. exec() 함수를 더 안전하게 사용하기 위해 아키텍처를 개선하거나 더 많은 유효성 검사를 추가할 수 있습니다. 이 프로젝트는 개인 프로젝트이므로 그러한 조치를 취하지 않았습니다. 파이썬 코드를 안전하게 실행할 수 있는 라이브러리가 있는지 알고 계시다면 댓글 섹션에 알려주세요.\n\n# 사용자 인터페이스\n\n![이미지 1](/TIL/assets/img/2024-07-09-HeresWhyYouProbablyDontNeedLangchain_2.png)\n\n![이미지 2](/TIL/assets/img/2024-07-09-HeresWhyYouProbablyDontNeedLangchain_3.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/TIL/assets/img/2024-07-09-HeresWhyYouProbablyDontNeedLangchain_4.png)\n\n# 결론\n\n항상처럼, 전체 과정을 가능한 한 쉽게 만들려고 노력했습니다. 여기까지 읽어주셨다면, 이것이 로켓 과학이 아님을 알 것입니다. 그냥 점을 이어주는 것이며, LLMs를 범용 API로 생각해야 합니다. 특정 방식으로 LLM을 트리거하면 어떤 작업이든 수행할 수 있는데, 이것은 다음 프로젝트를 위해 활용해야 할 핵심 요소입니다. 이 프로젝트는 혁신적이거나 새로운 것이 아닙니다 — ChatGPT의 코드 해석기는 유사한 아키텍처에서 작동합니다. 나는 이것이 매우 추상화되어 있어 처음 시작하는 사람들에게 흥미로울 것으로 보입니다. LLM에 메타데이터를 주입하여 코드를 생성하는 아이디어는 샤워 중에 떠올랐고, 꽤 잘 수행되었습니다.\n\nStreamlit UI와 함께 전체 코드를 보려면 gist를 확인하세요. Streamlit에 대해 더 알고 싶다면 여기 블로그를 읽어보세요. 이 튜토리얼을 즐겁게 읽으셨다면, 기사에 박수를 👏 보내주시고 더 많은 콘텐츠를 위해 팔로우해주세요.\n","ogImage":{"url":"/assets/img/2024-07-09-HeresWhyYouProbablyDontNeedLangchain_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-HeresWhyYouProbablyDontNeedLangchain_0.png","tag":["Tech"],"readingTime":11},{"title":"신경망이란 무엇인가요","description":"","date":"2024-07-09 19:51","slug":"2024-07-09-WhatIsaNeuralNetAnyway","content":"\n![Image](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_0.png)\n\n인공지능과 기계학습의 세계를 두르고 있는 다양한 용어 중에서, 신경망과 같은 용어는 '멋진 요소'를 지니는 것 같아요.\n\n과학 소설의 세계가 이 용어를 빌려와서 매우 발달한 로봇과 안드로이드의 내부 작동 원리를 묘사하는데 기회를 마련한 결과입니다. 아놀드 슈워제네거의 터미네이터가 T2: 심판의 날에서 코너 가족과 나눈 대화를 기억하지 않는 사람이 누구죠?\n\n존 코너:\n프로그램되어 있지 않은 내용을 배우는 것이 가능한가요? 그러면... 더 인간적이고, 항상 꼴좋지가 않다고요?\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n터미네이터:\n내 CPU는 신경망 프로세서야; 학습 컴퓨터지. 그러나 Skynet은 우리를 홀로 보낼 때 스위치를 읽기 전용으로 설정해.\n\nSarah Connor:\n너무 많이 생각하지 않기를 원치 않는 거야, 그렇지?\n\n터미네이터:\n그래.\n\n![이미지](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_1.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아마도 신경망이라는 아이디어가 기계 세계와 인간 두뇌 세계 사이의 보통의 엄격한 분리를 흐리게 한다는 것 때문에 그럴 수도 있습니다. 인간/기계 경계를 넘어가는 이러한 아이디어들은 우리를 항상 매혹시키거나 흥분시킵니다.\n\n오늘날의 신경망은 그 자체로 인간 두뇌의 영감으로부터 그 존재를 갚고 있습니다.\n\n# 두뇌에서 바이트로\n\n1943년에는 두 번째 세계대전의 치열한 시기였으며 소련이 스탈린그라드 전투에서 나치 독일을 이겼던 해였는데, 신경생리학자 워렌 S. 맥컬럭과 인지 심리학자 월터 H. 피트가 함께 논문을 작성하여 두뇌의 작동을 추상적인 수학적 용어로 설명하려고 노력했습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![신경망이란 무엇인가요](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_2.png)\n\n제목은 \"신경 활동에 내재된 아이디어의 논리적 논리\" (아니요, 목이 나가는 제목으로는 점수를 주지 않습니다)였고, 논문의 통찰 중 하나는 뇌 속 신경세포를 더 간단한 논리 문으로 취급하여 입력에 따라 발화하거나 발화하지 않는 간단한 논리 게이트로 제안한 것이었습니다.\n\n뇌의 작동을 추상 수학으로 변환하는 아이디어가 기계 학습으로 자연스럽게 진화하는 과정을 볼 수 있습니다. 뇌가 수학으로 변환되고, 수학이 프로그래밍 언어를 통해 컴퓨터 코드로 변환되는 것입니다.\n\n신경망의 개념과 1950년대 Frank Rosenblatt의 패턴 인식 퍼셉트론, 1970년대 백프로파게이션 도입부터 2010년대 GPU 기반 딥 러닝의 출현에 이르기까지 수년간의 혁신은 우리를 인공 신경망(ANN)과 기계 학습에서의 역할이 단순히 퍼지는 세상으로 이끌었습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n실제로 신경망은 다른 형태의 기계 학습과 유사합니다. 목표는 데이터를 입력하고 해당 데이터를 기반으로 패턴을 추출하거나 예측을 수행하는 것입니다. 예를 들어, 주택 가격을 예측하는 전형적인 사용 사례가 있습니다. 면적, 침실 수, 그리고 대지 크기와 같은 데이터를 입력하면 데이터 세트 내의 주택에 대한 예측된 가격을 얻게 됩니다.\n\n신경망은 이러한 예측을 어떻게 하는 것이 가장 좋은지를 학습 데이터로부터 배우며, 결국 충분한 학습을 통해 합리적인 정확도로 예측을 할 수 있게 됩니다.\n\n하지만 이 신경망이 정확히 무엇이며, 인공 뉴런은 무엇인가요? 이런 기계 학습 사용 사례를 해결하기 위해 신경망이 어떻게 작동하는 걸까요?\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 질문에 대한 복잡하고 수학적인 답변들이 많이 있어요. 이 개념들을 초심자 친화적인 방식으로 탐색할 거에요. 즉, 초심자 친화적인 언어와 코드를 사용할 거에요.\n\n이 수업을 듣고 나면 기계 학습 닌자가 되지는 않겠지만, 뇌신경망이 인공지능에 어떻게 적용되는지 확실하게 상상할 수 있고, 코드를 통해 실험도 할 수 있을 거예요.\n\n그 말을 기억하며, 시작해 봐요!\n\n# 기본적인 내용\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n인공 신경망의 핵심은 뉴런 개념에 있으므로 우리 여행을 시작하는 가장 좋은 곳처럼 보입니다. 아래에는 유기 뉴런의 구조를 왼쪽에, 인공 뉴런을 오른쪽에 보여주는 멋진 이미지가 있습니다:\n\n![What is a Neural Net Anyway](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_4.png)\n\n생물학적 뉴런의 경우, 세포체 주변의 작은 줄기 모양의 가지(dendrites)는 '입력'으로 생각할 수 있으며, 축삭(axon)은 '출력'으로 생각할 수 있습니다.\n\n하지만 우리는 인공 뉴런을 탐구하고 싶으므로 오른쪽 이미지에 주목해봅시다. 약간 위압감을 주는 것 같지 않나요? 처음에는 확실히 그랬어요. 아마 숫자를 나타내는 글자 아래에 있는 작은 숫자들, 게다가 그리스 문자도 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n수학이 나타납니다...\n\n하지만 이 뉴런 개념을 가장 기본적인 형태로 축소해서 훨씬 간단하게 만들어볼 수 있습니다. 몇 가지 — 전부는 아니지만 — 무서운 문자들을 제거해볼까요? (고등학교 수학이 평생에 걸쳐 상처를 남긴 것을 깨달고 계신가요?)\n\n아래는 매우 간단한 뉴럴 네트워크에 대한 시각화입니다. 이것은 딱 한 개의 '뉴런'으로 구성되어 있습니다. 뉴럴 네트워크의 가장 간단한 표현이며, 깊은 학습의 아버지인 Frank Rosenblatt가 만든 용어 '퍼셉트론'으로 잘 알려져 있습니다.\n\n<img src=\"/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_5.png\" />\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n자, 이 사진은 다소 이해하기 쉬워 보이네요.\n\n이제 우리는 신경망이 학습을 하도록 설계되었고 생물학적 뉴런을 기반으로 한다는 것을 알았으니, 우리 뉴런이 입력(정보)을 받고 출력을 제공해야 한다는 합리적인 추론을 할 수 있습니다. 이미지에서 이것을 어느 정도 볼 수 있습니다. 왼쪽에는 몇 개의 상자가 있고 가운데에는 일부 내용이 있으며 오른쪽에는 출력이 있습니다.\n\n왼쪽에 있는 입력부터 시작해봅시다. 일반적으로 'x'로 표시되는데요. 따라서 x1과 x2가 있는 것입니다. 이것은 우리의 입력이 2가지 특징을 가진 '것들'이라는 뜻입니다. 예를 들어 달콤함과 단단함에 기반을 둔 과일이 사과인지 바나나인지 예측할 수 있습니다.\n\n지금은 입력이 무엇인지가 중요한 게 아니라, 그 입력이 2가지 특징을 가지고 있다는 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 가중치 & 편향\n\n저희의 입력 변수(x1과 x2) 각각에는 해당하는 w 값(w1과 w2)이 있습니다. 이것들은 가중치를 나타냅니다.\n\n![image](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_6.png)\n\n가중치는 우리의 뉴런에서 매우 중요한 부분이며, 입력으로 들어오는 각 특성에 얼마나 중요성을 부여할지 결정합니다. 그래서 각 특성당 하나의 가중치가 있습니다. 예를 들어 주택 가격 예측 예제에서 침실 수가 위치보다 가격을 더 잘 예측하는 경우, 해당 특성의 가중치는 귀하의 신경망을 교육하고 결과적으로 높아질 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n훈련을 통해 언급하는 이유는 처음에 신경망이 우리의 예측에 가장 중요한 특징이 무엇인지 모르기 때문입니다. 그래서 이 가중치 매개변수의 값은 작은 (랜덤) 값으로 시작합니다. 들어오는 데이터로 신경망을 계속 훈련시켜서 이러한 가중치가 시간이 지남에 따라 변하고 (더 정확해지게) 할 수 있습니다. 이러한 무작위 값을 선택하는 방법은 신경망을 구성할 때 사용하는 방식에 따라 다릅니다만, 일반적인 예로는 다음과 같은 것들이 있습니다:\n\n- 균일 분포: 숫자는 작은 범위 사이에서 균일하게 분포될 것이며, 예를 들어, -0.05부터 0.05 사이일 수 있습니다.\n- 정규 분포: 값은 평균이 0이고 표준 편차가 작은 (예를 들어 0.01) 정규 분포에서 추출된 작은 숫자일 수 있습니다.\n\n일단은 훈련하기 전에 w1과 w2에는 특별히 유용하지 않은 숫자가 있다고 가정해 봅시다.\n\n그런데 빠르게 사이드 노트를 하자면 — ‘훈련’이라고 말할 때 어떤 의미일까요? 실제로 무슨 일이 일어나고 있을까요? 일반적으로 기계 학습 모델을 훈련하는 것은 여러 epoch를 사용하여 수행됩니다. 여기서 말하는 epoch는 ‘제공한 모든 훈련 데이터를 한 번 통과하는 것’을 의미하는 용어로, 우리의 경우 데이터를 신경 세포에 뭉쳐주고 다른 쪽으로 내보내는 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이러한 epoch의 끝에서 매개변수가 업데이트되므로 이상적으로는 다음 번 훈련에서 예측이 좋아지도록 손실(잘못된 예측)이 줄어든다. 계속해서 좋은 예측 능력을 갖게 될 때까지!\n\n![이미지](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_7.png)\n\n간단한 다이어그램을 돌아보면 우리의 입력과 함께 'b'로 표시된 것을 알 수 있습니다. b는 편향(bias)을 나타내며, 또 하나의 중요한 기계 학습 개념입니다. 저희의 가중치와 마찬가지로, 신경망 훈련 과정 중에 변경되는 '매개변수'입니다.\n\n저희의 간단한 예제에서, 그리고 많은 실제 사례에서, 편향은 훈련을 시작하기 전에 0에서 시작하지만 각 epoch을 처리할 때마다 편향이 잠재적으로 업데이트될 것입니다. 하지만 무엇을 위해? 그리고 왜 그렇게 되는 걸까요?\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그래도 일반적인 편향 설명을 찾아보면 \"편향 항은 활성화 함수가 왼쪽이나 오른쪽으로 이동할 수 있게 합니다.\" 정도의 내용이 나올 거에요. 하지만 좀 더 쉽게 이해할 수 있게 설명해볼게요.\n\n트레이닝 과정에서 각 반복마다 오차가 발생하는데, 이것이 기계 학습의 본질이자 같은 데이터 조각들을 반복해서 훈련하고 학습해야 하는 이유입니다. 목표는 시간이 지남에 따라 이러한 오차를 줄이는 것입니다.\n\n편향(가중치와 마찬가지로)는 각 훈련 단계마다 조정될 수 있는데, 이 조정된 값은 다음 반복을 '중립적이지 않은' 위치에서 시작하게 만들어줍니다. 기본적으로 다음 훈련 단계에 약간의 편향(따라서 이름이 붙여진 것)을 도입하여, 예측을 처음에 한 방향으로 이동시키고 다른 방향으로 이동시키는 데 도움이 되도록 하는 것이 목표입니다. 예를 들어 모델이 바나나를 예측할 때(0으로 표현) 실제 값이 사과(1로 표현)인데 너무 많은 오류를 발생시키고 있다면, 편향이 조금씩 0에서 1 방향으로 조정되어 다음 에포크를 돕는 역할을 할 수 있습니다.\n\n# 어이쿠, Σ 주소 변경할 시간이에요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이해해줘서 고마워요! 가능한 한 그리스어 문자를 너와 나로부터 멀리하려고 노력했어. 숫자 주변이나 떠다니는 재미있는 작은 기호들의 말장난으로부터 보호막처럼 행동했거든.\n\n하지만 이젠 그 시간이야. 우리 뉴런 속의 'Σ'에 대해 다뤄야 해. 괜찮아요, 난 부드럽게 다가갈게요.\n\n다행히도 이건 꽤 쉬운 부분이에요. 그리스 글자 'Σ'는 시그마(Sigma)라고 불리며, 수학 용어로는 합계를 나타냅니다. 기본적으로 더해주는 개념이죠. 그래서 우리 뉴런의 이 부분에서:\n\n<img src=\"/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_8.png\" />\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리는 가중치 입력을 합산하고 편향을 더하는 중입니다.\n\n이는 Σ(Wi \\* xi) + b로 계산됩니다. 여기서 Wi와 xi는 가중치와 입력을 가리키며, b는 편향을 의미합니다. 간단히 말하면 우리는 각 입력을 해당하는 가중치로 곱한 뒤 더하고, 마지막으로 편향을 더하는 것입니다.\n\n이후에는 '시그모이드 활성화'로 넘어갑니다. 시그모이드 활성화 또는 시그모이드 함수는 '압축' 함수로도 불립니다. 모든 합산과 더하기를 끝낸 후, 매우 큰 음수 또는 양수 값이 나올 수 있으며 해석하기 어렵을 수 있습니다.\n\n시그모이드 함수는 이 숫자를 0과 1 사이의 값으로 '압축'하여 의미 있는 숫자로 변환합니다. 이는 이론적으로 사과인지 바나나인지 등을 판별하는 기계 학습 문제와 같은 분야에서 특히 유용합니다. 이는 이진 분류 문제입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러면 마지막으로 묶어보는 시간이에요! 결과물을 보자구요! 그냥 최종 예측값을 가져와 출력하는 거에요! 그러면 우리의 뉴런을 통해 모험을 끝내게 돼요.\n\n보셨죠? 그렇게 어려운 건 아니죠! 물론 처음에 말한 것으로 돌아가는 것도 중요해요. 이것은 굉장히 간단한 예제에요. 이건 하나의 뉴런 신경망 - '퍼셉트론'이에요. 이건 간단한 분류 문제에 유용하지만, 더 많은 뉴런/노드를 추가할 때 진짜 신경망의 힘이 나타나요.\n\n뉴런은 레이어에 더 많이 추가할 때 더 복잡한 문제에 대한 예측 능력이 더 커져요:\n\n![neural net image](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_9.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위의 이미지에서는 훨씬 많은 것이 발생하고 있습니다. 이 신경망에는 여러 개의 레이어가 있습니다. 입력 레이어와 출력 레이어에 추가로 두 개의 숨겨진 레이어가 있으며, 각 레이어에는 여러 개의 뉴런이 내부에 있습니다. 이 모든 것에 더해 더 복잡한 신경망에서 뉴런 간의 연결이 있는데 이를 시냅스라고 하며 '가중치'를 가지고 한 뉴런의 출력이 다른 뉴런의 입력에 미치는 영향을 제어합니다.\n\n그러나 이 모든 것에 대해 자세히 들어가는 것은 매력적이지만 이 글의 범위를 벗어나므로 단일 뉴런 예시에 집중하고 코드로 최고이며 가장 재미있는 부분으로 돌아갑시다!\n\n# 뉴런 만들기\n\n![image](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_10.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n| 제목 | Korean Translation                      |\n| ---- | --------------------------------------- |\n| 문제 | 표 태그를 Markdown 형식으로 변경하세요. |\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러나 걱정하지 마세요. 저장소를 열어도 아무것도 이해되지 않는다면, 우리는 데이터와 코드를 검토하고 단계별로 문제를 해결할 것입니다. 코드를 더 잘 이해할 수 있도록 뇌세포(neuron), 신경망(neural net), 그리고 교육 루프의 기본을 조금이나마 알아본 후에 말이죠.\n\n우리의 실험에서는 Kaggle에서 가져온 합성 데이터셋을 사용할 것입니다. 이 데이터셋에는 다음이 포함되어 있습니다:\n\n![그림](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_11.png)\n\n이 데이터의 아이디어는 각 행이 학생의 시험 1과 시험 2의 결과라는 것입니다. 패스(pass) 열은 해당 학생이 3번째 시험에 통과했는지 여부를 나타냅니다. 우리가 신경망을 사용해 예측하고자 하는 것은 바로 이 열입니다. 실제로는 학생이 처음 두 시험에서의 결과를 기반으로 3번째 시험을 통과할지 예측하려고 하는 것이죠.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저장소에서 exam_scores.csv라는 파일을 찾을 수 있어요. 이 데이터를 모델을 훈련하고 테스트하는 데 사용할 거예요. 저장소에 있는 유일한 다른 것은 실제 파이썬 노트북뿐이에요. 하나씩 차근차근 살펴보죠!\n\n처음으로, 노트북에 기본으로 설치되어 있지 않은 라이브러리를 설치해야 해요:\n\n```js\n# 1) 이미 설치되어 있지 않은 필요한 라이브러리 추가\n!pip install keras-visualizerya\n```\n\nkeras-visualizerya를 사용하면 우리의 신경망의 기본 이미지를 볼 수 있어요. 단일 뉴런이라 그다지 화려하지는 않겠지만, 아예 없는 것보다는 낫죠!\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음으로, 데이터 세트와 모델을 설정합니다.\n\n여기서 조금 복잡한 부분이 있습니다. 데이터를 형성하는 데 도움이 되는 몇 가지 라이브러리를 가져왔습니다. Numpy와 Pandas는 데이터를 형성하는 데 도움이 되고, sklearn은 데이터를 분할하는 것과 같은 일반적인 머신러닝 작업에 유용한 유틸리티를 제공합니다. 그리고 tensorflow.keras는 정말 중요한 라이브러리입니다.\n\n원한다면 순수 파이썬을 사용하여 신경망을 만들 수도 있습니다. 그러나 이 문서는 초심자에게 친숙하게 설계되었으므로, 텐서플로위에 위치한 고수준 라이브러리인 케라스를 선택한 것입니다. 케라스는 텐서플로우 위의 머신러닝 라이브러리이며, 이는 파이썬 위에 있는 라이브러리입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희는 데이터를 70% 훈련 및 30% 테스트 데이터로 나누는 70/30 비율을 만들고 있어요. 이것은 일반적인 머신러닝 실천 방법으로, 데이터의 30%를 모델이 얼마나 잘 학습했는지 확인하는 데 사용합니다.\n\n마지막으로 - 그리고 가장 기대되는 부분은 - 모델을 정의하는 것입니다. 여기서 우리는 신경망을 만드는 곳입니다. Sequential 신경망을 만들고 있는데, 이는 이 모델에 추가된 레이어가 서로 직접 쌓여서 입력부터 출력까지 데이터가 선형 경로로 흐를 수 있는 피드포워드 네트워크를 형성한다는 의미입니다. 그리고 우리는 하나의 유닛(뉴런)을 추가하고 있어요.\n\n```js\nmodel = Sequential([\n    Dense(units=1, input_shape=(2,), activation='sigmoid')\n])\n```\n\n입력 모양은 신경망에 데이터가 어떤 모양인지 알려줍니다. 이 경우 input_shape(2,)은 Keras에게 각 데이터 레코드가 2개의 피쳐를 가질 것이라고 알려주는 것입니다. 마지막으로 활성화 함수를 'sigmoid'로 정의하고 있는데, 이는 0과 1 사이의 출력을 제공하기 위한 '압축' 함수입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마침내, 모델을 컴파일합니다. 'Adam' (적응 적 모멘트 추정) 옵티마이저를 사용 중이며 다른 여러 옵티마이저도 있습니다. 옵티마이저는 서로 다른 메커니즘을 사용하여 가중치를 업데이트하거나 '손실' 개념을 측정함으로써 학습 프로세스를 돕는 알고리즘 또는 방법입니다. 옵티마이저는 또한 학습 속도를 제어합니다 (우리 예제에서는 0.01로 설정되어 있음).\n\n![이미지](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_12.png)\n\n학습률은 다른 개념과 깊게 연결되어 있는데, 여기서 많이 다루지는 않았지만 손실 기욘(gradient)입니다. 간단히 말해서, 손실 기욘은 학습 에포크의 끝에 우리가 얼마나 성공적인 예측에 가까이 갔는지를 측정하는 것입니다. 앞에서 알 수 있듯이, 신경망은 다음 반복 전에 가중치를 조정할 수 있습니다.\n\n학습률은 가중치가 손실 그래디언트에 대해 얼마나 큰 변화를 겪을지를 제어합니다. 높은 학습률은 빠르게 학습하고 좋은 '적합(fit)'에 빨리 도달할 수 있는 기회를 제공하지만, 최소 손실을 지나치게 초과하여 학습 프로세스의 불안정이나 기능을 예측하는 합리적 능력에 수렴하지 못하는 상황을 일으킬 수도 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리의 '손실 함수'는 'binary_crossentropy'로 설정되어 있어요 (옆에 알림 - 여기서 새로운 용어를 많이 배우고 있죠? 칭찬해도 돼요!). 손실 함수는 주로 우리 모델의 성능을 측정하고, 잘못된 값을 선택하는 것에 대해 처벌하는 역할을 합니다 (이 경우 이진 분류 문제에 대해).\n\n마지막으로 모델 컴파일 문에서 metrics를 '정확도'로 설정했어요. 이것은 훈련 중 정확도 지표를 모니터링하고 싶다는 의미에요. metrics 매개변수 - 그리고 컴파일 문의 거의 모든 것 -에는 다양한 값과 선택지가 있습니다. 이러한 선택 - 학습률, 손실 함수 및 옵티마이저와 같은 것들에 대한 - 이것들이 모델을 '조정'하거나 '하이퍼파라미터' 튜닝한다는 것을 읽을 때 조정되는 몇 가지 중요한 요소입니다. 이러한 매개변수들에서 최선을 내기 위한 지식이 필요하므로, 일단 이런 것들을 조정할 수 있다는 것만 알아두세요. 지금은 기본값이나 '일반적'인 값으로 진행하죠.\n\n보너스로, 노트북의 다음 셀에는 우리의 신경망을 시각적으로 표시하는 멋진 방법이 포함되어 있어요. 불행히도 우리의 단일 뉴런에 대해 매우 매료적인 이미지는 아니에요;\n\n<img src=\"/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_13.png\" />\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그 의미는, 우리가 원하는 것에 근접한 것 같아요. 2개의 입력 특성과 출력, 시그모이드 활성화 기능을 볼 수 있어요. 완벽하지는 않지만, 더 복잡한 신경망에는 더 잘 보일지도 몰라요.\n\n# 훈련 시간\n\n다음 셀이 활약할 때입니다! 훈련할 시간이에요! 코드를 살펴보면, 1000회 에폭을 실행할 거라는 것을 알 수 있어요. 많아 보일 수도 있지만, 15초 정도 안에 끝날 거예요. 훈련이 끝나면 다음과 같은 내용을 볼 수 있어요:\n\n```js\nTest Loss: 0.22098664939403534, Test Accuracy: 0.8833333253860474\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희의 훈련 결과입니다! 그리 나쁘지 않죠! 정확도는 0.88 또는 88%이며 손실은 0.22입니다. 좋은 처음 결과이지만, 향상할 여지가 분명히 있어요. 몇 가지 매개변수를 조정/변경하여 더 나은 결과를 얻을 수 있을지도 모르겠어요.\n\n노트북의 마지막 셀은 테스트 데이터셋에서 몇 가지 값을 선택하여 직접 테스트하여 예측을 확인할 수 있는 기회를 제공합니다. 이상적으로는 테스트 세트에서 임의로 값들을 선택하여 학생이 3회 시험을 통과할 것인지(1) 아닌지(0) 예측하는데 높은 확률로 정확한 예측을 얻을 수 있어야 하며, 모델이 예측이 올바른지 얼마나 확신하는지의 신뢰도 점수도 얻을 수 있어야 합니다.\n\n여기 데이터에서 테스트하려는 데이터의 샘플을 numpy 배열로 업데이트해주세요:\n\n```js\n# 새 시험 점수를 사용한 예제\nnew_samples = np.array([\n    [74.71, 61.49],  # 예제 점수\n    [79.42, 67.92],   # 예제 점수\n    [62.75, 97.53]\n])\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기 있습니다! 여러분은 전체 모험을 무사히 마치고 미쳐 날뛰는 그리스 문자나 방정식에게 습격당하거나 끌려가지 않고 이것을 해내셨습니다.\n\n![Neural Net](/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_14.png)\n\n잘 했어요! 여러분은 신경망의 역사에 대한 간략한 개요를 보고 오늘날까지 어떻게 이르렀는지 살펴보고, 뉴런을 구성하는 추상적인 내용을 탐험하며, 심지어 자신만의 (간단한) 신경망을 만들고 훈련하고 검토하셨습니다!\n\n여정을 즐기셨기를 바라며, 항상 읽는 것을 즐겼다면 박수를 보내고 댓글을 남기거나 소프트웨어 엔지니어링, 클라우드 및 AI/ML 콘텐츠를 더 보기 위해 팔로우해 주시기 바랍니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음에 또 뵙겠습니다!\n","ogImage":{"url":"/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-WhatIsaNeuralNetAnyway_0.png","tag":["Tech"],"readingTime":19},{"title":"데이터 엔지니어링 로드맵 2024년 최신 가이드","description":"","date":"2024-07-09 19:48","slug":"2024-07-09-DataEngineeringRoadmap","content":"\n<img src=\"/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_0.png\" />\n\n## 1. Foundational Knowledge\n\n- Familiarize with database concepts (SQL and NoSQL)\n\n- SQL — SQL databases are commonly used in data engineering for structured data storage and querying, providing ACID compliance and strong consistency. — (1 week).\n- NoSQL — NoSQL databases are favored for their scalability and flexibility in handling unstructured or semi-structured data, often used in distributed systems for high-volume and high-velocity data processing. — (1 week).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 분산 컴퓨팅 원칙에 대한 지식 습득\n\n- 데이터 엔지니어가 확장 가능하고 내결함성이 있는 시스템을 설계하기 위해 분산 컴퓨팅 원칙을 이해하는 것은 중요합니다. 병렬 처리와 분산 저장를 활용하여 방대한 데이터세트를 효율적으로 관리하고 데이터 처리 작업에서 고가용성과 신뢰성을 보장합니다. — (1–2 주).\n\n![이미지](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_1.png)\n\n## 2. 데이터 모델링\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 다양한 데이터 모델링 기술에 대해 배우세요 (예: 관계형, 네트워크...)\n\n- 관계형 및 차원 모델링과 같은 데이터 모델링 기술은 데이터 엔지니어링에서 데이터를 구조화하여 특정 분석 및 보고 요구 사항을 충족시키기 위해 중요합니다. 최적의 성능과 데이터 검색 용이성을 보장합니다. — (1-2 주).\n\n- 정규화와 역정규화를 이해하세요\n\n- 정규화와 역정규화 원칙을 이해하면 데이터 엔지니어들이 데이터베이스를 설계할 때 중복을 최소화하고 데이터 무결성을 유지하는 균형을 맞추는 데 도움이 됩니다. 데이터 엔지니어링 파이프라인에서 저장 공간을 최적화하고 쿼리 성능을 최적화할 수 있습니다. — (1 주).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 다양한 사용 사례에 대한 스키마 디자인 탐색\n\n- 스키마 디자인 고려 사항은 데이터 엔지니어링에서 중요한 역할을 하며, 다양한 사용 사례에 걸쳐 데이터 저장, 검색 및 분석 효율에 영향을 미치며, 다양한 응용 프로그램 시나리오에서 데이터 시스템의 확장 가능성, 유연성 및 유지 관리 가능성을 보장합니다. — (1–2 주).\n\n![이미지](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_2.png)\n\n## 3. 데이터 저장\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 데이터베이스 관리 및 최적화 분야에서 전문 지식 습득하기.\n\n- 데이터베이스 관리 및 최적화 능력은 데이터 엔지니어들이 데이터 시스템의 효율성과 대응력을 극대화하기 위해 인덱싱, 쿼리 최적화 및 자원 할당 전략을 구현하여 데이터베이스 성능을 관리하고 세밀하게 조정하는 능력을 제공합니다. — (2–3 주).\n\n![이미지](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_3.png)\n\n## 4. 데이터 처리\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 배치 처리 프레임워크 (예: Apache Spark, Hadoop MapReduce)를 탐색해보세요.\n\n- Apache Spark 및 Hadoop MapReduce와 같은 배치 처리 프레임워크는 대규모 데이터를 효율적으로 처리하기 위한 데이터 엔지니어링에서 필수적이며 예약된 일괄 작업을 통해 데이터 집약적 작업에 대한 병렬 계산 및 장애 허용 기능을 제공합니다. - (1-2 주).\n\n- 스트림 처리 프레임워크 (예: Apache Kafka, Apache Flink)에 대해 배우세요.\n\n- Apache Kafka 및 Apache Flink와 같은 스트림 처리 프레임워크는 실시간 데이터 처리 및 분석을 가능하게 하며, 낮은 대기 시간 데이터 수신을 용이하게 하고 지속적인 데이터 스트리밍 애플리케이션을 지원하여 데이터 엔지니어링에서 중요한 역할을 합니다. - (1-2 주).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- ETL (Extract, Transform, Load) 프로세스 및 도구를 이해합니다.\n\n- ETL 프로세스 및 도구를 이해하는 것은 데이터 엔지니어링에서 매우 중요합니다. 이는 다양한 소스에서 데이터를 추출하고, 유용한 형식으로 변환한 뒤, 대상 데이터베이스나 데이터 웨어하우스에로드하여 데이터 품질, 일관성, 접근성을 보장하고 분석 및 보고 목적에 활용합니다. — (2–3 주).\n\n![Data Engineering Roadmap 4](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_4.png)\n\n## 5. 데이터 통합\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 다양한 소스(데이터베이스, API, 파일)에서 데이터 수집에 대한 전문 지식을 습득합니다.\n\n- 데이터 엔지니어링은 데이터베이스, API 및 파일과 같은 다양한 소스에서 데이터를 수집하여 데이터를 분석하기 위해 데이터를 모으고 중앙 집중화하는 전문 지식에 의존합니다. 이를 통해 포괄적인 데이터 범위와 접근성이 확보되며, (1~2주 소요됩니다).\n\n- 데이터 통합 패턴 및 모범 사례에 대해 학습합니다.\n\n- 데이터 엔지니어링에서 데이터 통합 패턴과 최상의 사례를 이해하는 것은 이질적인 데이터 소스를 조화롭게 하고 정확한 통찰력과 의사 결정을 위한 시스템 간의 데이터 흐름과 상호 운용성을 용이하게하기 위한 중요한 요소입니다. (2~3주 소요됩니다).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 데이터 통합 및 동기화 도구를 탐색해보세요.\n\n- 데이터 통합 및 동기화 도구를 탐색하는 것은 데이터 엔지니어에게 데이터 워크플로우를 자동화하고 플랫폼 간 데이터를 동기화하며 데이터 일관성과 무결성을 유지하는 능력을 제공하여 데이터 엔지니어링 파이프라인에서 효율성과 신뢰성을 향상시킵니다. — (2–4 주).\n\n![DataEngineeringRoadmap_5.png](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_5.png)\n\n## 6. 데이터 변환\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- SQL, Python 또는 전문 도구(예: Apache Beam)를 사용하여 마스터 데이터 변환 기술 습득\n\n- 데이터 엔지니어링에서 SQL, Python 또는 Apache Beam과 같은 전문 도구를 활용한 데이터 변환 기술에 능통한 것은 다양한 데이터 세트 간의 호환성과 일관성을 보장하기 위해 데이터를 조작하고 재구성하는 데 중요합니다. — (2~4 주)\n\n- 데이터 클렌징, 정규화 및 데이터 풍부화 과정을 이해\n\n- 데이터 엔지니어링에서 데이터 클렌징, 정규화 및 데이터 풍부화 과정을 이해하는 것은 데이터 품질, 무결성 및 사용 가능성을 향상시키는 데 중요합니다. 데이터를 자신 있고 정확하게 분석하고 의사 결정을 내릴 수 있도록 데이터를 준비합니다. — (1~2 주)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 데이터 파이프라인 조정 및 일정에 대해 배워보세요.\n\n- 데이터 파이프라인 조정 및 일정을 배우면 데이터 엔지니어들은 조직의 데이터 인프라 전반에 걸쳐 시간적이고 신뢰할 수 있는 데이터 처리 및 전달을 보장하며 복잡한 데이터 워크플로우를 자동화하고 관리할 수 있습니다. — (1–2 주).\n\n![이미지](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_6.png)\n\n## 7. 데이터 품질 및 거버넌스\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 데이터 품질 측정 및 모니터링 기술을 이해합니다.\n\n- 데이터 엔지니어링에서 데이터 품질 측정 및 모니터링 기술을 이해하는 것은 데이터의 정확성, 완전성 및 일관성을 평가하고 유지하는 데 중요합니다. 의사 결정을 지원하기 위한 믿을 수 있는 통찰력을 보장합니다. — (1-2 주).\n\n- 데이터 지배 원칙 및 프레임워크에 대해 배웁니다.\n\n- 데이터 지배 원칙 및 프레임워크를 배우는 것은 데이터 엔지니어링에서 핵심적이며 데이터 자산을 효과적으로 관리하기 위한 정책, 프로세스 및 통제를 수립하여 데이터 수명주기 전반에 걸쳐 준수, 보안 및 책임성을 증진하는 데 중요합니다. — (1-2 주).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 데이터 품질 점검 및 유효성 검사 프로세스를 구현하세요.\n\n- 데이터 품질 점검 및 유효성 검사 프로세스를 구현하는 것은 데이터 엔지니어가 데이터 이상과 불일치를 자동으로 감지하고 해결할 수 있도록 하여 분석 및 보고를 위한 고품질 데이터 입력을 보장하고 데이터 기반 통찰력의 전반적인 신뢰성을 향상시킵니다. — (3–4 주간).\n\n![Data Engineering Roadmap](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_7.png)\n\n## 8. 클라우드 기술\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 클라우드 플랫폼 (AWS, Azure, GCP)에 대한 숙련도 향상.\n\n- AWS, Azure 및 GCP와 같은 클라우드 플랫폼에 대한 능숙성은 대규모 데이터 세트의 비용 효율적인 저장, 처리 및 분석을 가능케 하기 위해 데이터 엔지니어링에서 중요합니다. — (3–4 주).\n\n- 클라우드 기반 데이터 저장 및 처리 서비스에 대해 배우기.\n\n- 클라우드 기반 데이터 저장 및 처리 서비스 학습을 통해 데이터 엔지니어들은 클라우드에서 확장 가능한 저장 솔루션과 분산 처리 프레임워크를 활용하여 효율적인 데이터 관리와 분석 워크플로우를 용이하게 할 수 있습니다. — (2–3 주).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 클라우드 보안 및 규정 요구사항을 이해합니다.\n\n- 데이터 엔지니어링에서 클라우드 보안과 규정 요구사항을 이해하는 것은 강력한 보안 조치를 시행하여 데이터의 기밀성, 무결성 및 가용성을 보장하고 규제 규준과 업계 모범 사례를 준수하는 데 중요합니다. — (4–5 주).\n\n![이미지](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_8.png)\n\n## 9. 빅데이터 기술\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 분산 저장 시스템(예: Hadoop HDFS, Amazon S3)을 탐색해보세요.\n\n- Hadoop HDFS 및 Amazon S3와 같은 분산 저장 시스템을 탐색하는 것은 데이터 엔지니어링에서 매우 중요합니다. 이를 통해 분산 환경에서 대량의 데이터를 저장하고 관리하여 고가용성과 확장성을 보장할 수 있습니다. - (1-2 주).\n\n- 분산 컴퓨팅 프레임워크(예: Apache Spark, Apache Flink)에 대한 전문 지식을 습득하세요.\n\n- Apache Spark 및 Apache Flink와 같은 분산 컴퓨팅 프레임워크에 전문 지식을 습득하면 데이터 엔지니어는 대규모 데이터 세트를 병렬로 처리하고 분산 컴퓨팅 자원을 활용하여 효율적인 데이터 처리 및 분석을 수행할 수 있습니다. - (4-5 주).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 컨테이너화 및 오케스트레이션 기술(Docker, Kubernetes 등) 이해하기\n\n- Docker 및 Kubernetes와 같은 컨테이너화 및 오케스트레이션 기술을 이해하는 것은 데이터 엔지니어링에서 중요합니다. 다양한 컴퓨팅 환경에 걸쳐 일관되게 데이터 기반 애플리케이션 및 워크플로를 패키징하고 배포하여 확장성, 이식성 및 자원 이용을 향상시킵니다. — (3–4 주).\n\n![이미지](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_9.png)\n\n## 10. 데이터 시각화 및 보고\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 데이터 시각화 도구 및 기술 (예: Tableau, Power BI)를 탐색해 보세요.\n\n- Tableau 및 Power BI와 같은 데이터 시각화 도구를 탐험하는 것은 복잡한 데이터셋을 통찰력 있는 시각적 표현으로 변환하는 데 필수적입니다. 이는 데이터 기반 의사 결정 및 커뮤니케이션을 용이하게 합니다. — (1–2 주).\n\n- 대시보드 디자인 및 데이터 스토리텔링에 대해 학습하세요.\n\n- 대시보드 디자인 및 데이터 스토리텔링에 대해 학습함으로써 데이터 엔지니어는 주요 통찰과 트렌드를 이해 관계자 및 의사 결정자에게 효과적으로 전달하는 매력적이고 유익한 대시보드를 만들 수 있습니다. — (1–2 주).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 상호 작용형 시각화 및 보고서 작성에 대한 전문 지식 습득하기.\n\n- 상호 작용형 시각화 및 보고서 작성에 대한 전문 지식을 갖는 것은 데이터 엔지니어가 동적이고 사용자 친화적인 데이터 제품을 개발하는 데 도움이 되며, 다양한 수준의 청중들에게 데이터 엔지니어링 프로젝트 전반에 걸쳐 데이터 기반 인사이트의 참여와 이해를 높일 수 있습니다. — (2–3 주).\n\n![이미지](/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_10.png)\n\n## 11. 고급 주제\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 실시간 분석, 데이터 레이크 및 그래프 데이터베이스와 같은 고급 주제를 탐험해보세요.\n\n- 복잡한 데이터 처리 문제를 해결하고 다양한 데이터 원본에서 새로운 통찰을 얻기 위해 데이터 엔지니어링에서 실시간 분석, 데이터 레이크 및 그래프 데이터베이스와 같은 고급 주제를 탐색하는 것이 중요합니다. — (2–4 주).\n\n- 분야의 새로운 기술 및 트렌드를 따라가세요.\n\n- 분야의 새로운 기술 및 트렌드를 파악함으로써 데이터 엔지니어는 최신 도구와 방법론을 활용하여 혁신을 이루고 데이터 엔지니어링 프로세스를 최적화하여 지속적인 개선을 추구하고 빠르게 변화하는 환경에서 선도할 수 있습니다. — (3–5 주).\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 12. Practical Projects and Experience\n\n- 실제 데이터 엔지니어링 프로젝트를 수행하여 여러분의 기술을 적용하세요.\n\n- 실제 데이터 엔지니어링 프로젝트를 수행하면, 산업 분야에서 데이터 처리, 통합 및 분석에 대한 실무 경험을 쌓아가며 실전 시나리오에서 기술을 적용할 수 있습니다. (5–6 주간 진행).\n\n- 오픈 소스 프로젝트에서 동료들과 협업하거나 해커톤에 참여하세요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 동료들과 오픈 소스 프로젝트에서 협업하거나 해커톤에 참여하는 것은 데이터 엔지니어들이 아이디어를 교환하고 복잡한 문제를 해결하며 혁신적인 데이터 엔지니어링 솔루션 개발에 기여할 수 있는 협력적인 환경을 조성합니다.\n\n- 데이터 엔지니어링 역할에서 실무 경험을 쌓기 위해 인턴십이나 취업 기회를 찾아보세요.\n\n- 인턴십이나 취업 기회를 찾는 것은 희망하는 데이터 엔지니어들에게 실무적인 경험을 쌓을 기회를 제공하여 이론적 지식을 적용하고 전문 기술을 개발하며 데이터 엔지니어링 역할과 책임에 대한 가치 있는 통찰력을 얻을 수 있습니다.\n\n# 앞으로 나아가기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위에서 나열된 전체 여정을 소비 가능한 크기의 기사로 나눠서 소개할 거에요. 시리즈에 대해 업데이트를 받으려면 저를 따라오세요. 이 여정에 동참하게 될 거에요. 즐거운 학습되세요!!!\n","ogImage":{"url":"/assets/img/2024-07-09-DataEngineeringRoadmap_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-DataEngineeringRoadmap_0.png","tag":["Tech"],"readingTime":14}],"page":"3","totalPageCount":19,"totalPageGroupCount":1,"lastPageGroup":19,"currentPageGroup":0},"__N_SSG":true}