{"pageProps":{"post":{"title":"Python으로 웹사이트에서 데이터를 쉽게 추출하는 방법","description":"","date":"2024-07-12 20:27","slug":"2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython","content":"\n\n<table>\n<tr>\n  <th>Library</th>\n  <th>Purpose</th>\n</tr>\n<tr>\n  <td>Requests</td>\n  <td>For sending HTTP requests</td>\n</tr>\n<tr>\n  <td>BeautifulSoup</td>\n  <td>For parsing HTML and XML</td>\n</tr>\n<tr>\n  <td>Tkinter</td>\n  <td>For building the GUI</td>\n</tr>\n</table>\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- **Pandas**: 추출된 데이터를 위한 데이터베이스를 생성하는 데 사용됩니다.\n- **Requests**: 웹사이트에 접근 권한을 요청하는 데 사용됩니다.\n- **BeautifulSoup**: 웹상에서 데이터를 찾는 데 사용됩니다.\n\n# 작업: 이메일 목록 추출 및 CSV로 변환하기\n\n여러 주제에서 많은 이메일을 가져와야 했습니다.\n\n\"수동으로는 절대 할 수 없어\" 라고 생각했습니다. 그렇게 하면 시간이 많이 걸리고 지루할 것이라고 생. 따라서 나는 파이썬 기술을 사용하기로 결정했습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n웹 사이트에는 다음과 같은 데이터가 있습니다:\n\n![Data Table](/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_1.png)\n\n네, 과목 이름과 이메일이 포함된 표가 있습니다.\n\n이 프로젝트의 목표는 이 데이터를 사용하여 CSV 파일을 생성하는 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 단계 1. 모듈 가져오기\n\n먼저 사용할 Python 라이브러리를 가져와 봅시다:\n\n- pandas.\n- requests.\n- BeautifulSoup.\n\n```js\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 단계 2. 데이터 찾기\n\n## 2.1. 웹 스크래핑은 어떻게 작동되나요?\n\n웹에서 데이터를 추출하는 것이 가능한 이유는 무엇인가요?\n\n답은 HTML(HyperText Markup Language)에 달려 있습니다. HTML은 웹 브라우저에서 표시할 문서의 표준 마크업 언어입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n웹사이트 어디에서든 마우스 오른쪽 버튼을 클릭하고 Inspect를 선택하면 웹의 코드가 오른쪽에 표시됩니다:\n\n![image](/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_2.png)\n\n파이썬은 (일부 라이브러리와 함께) 이 HTML 코드를 \"읽고\" 원하는 데이터를 찾는 것입니다.\n\n더 자세한 내용은 향후 기사에서 확인해보세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 2.2. HTML 가져오기 함수\n\n우선, 웹 사이트에서 HTML 코드를 가져와야 합니다.\n\nURL을 매개변수로 하는 get_html 함수를 생성하는 방법은 다음과 같습니다:\n\n```js\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_html(url):\n\n    try:\n        response = requests.get(url) # 웹 사이트에서 HTML을 요청합니다\n        return response.text\n\n    except Exception as e: # 가능한 오류를 처리하기 위한 예외 처리\n        print(f\"웹 페이지를 가져오는 데 실패했습니다: {e}\")\n        return \"\"emails = set() # 중복을 피하기 위한 코드입니다\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 단계 3. 데이터 추출\n\n다음 단계는 우리가 원하는 데이터를 추출하는 것입니다.\n\n우리는 이전 함수에서 HTML 코드를 가져오는 extract_data 함수를 만들 수 있습니다. 이는 다음 단계를 포함합니다:\n\n- BeautifulSoup 클래스 초기화.\n- 테이블을 찾는 변수 설정.\n- 데이터를 수집할 빈 리스트.\n- 데이터를 검색하는 for 루프.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_html(url):\n\n    try:\n        response = requests.get(url) # 웹사이트로부터 HTML을 요청합니다.\n        return response.text\n\n    except Exception as e: # 가능한 오류를 처리하기 위한 부분\n        print(f\"웹 페이지를 가져오는 데 실패했습니다: {e}\")\n        return \"\" # 중복을 피하기 위해 이메일 집합으로 설정\n\ndef extract_data(html):\n\n    soup = BeautifulSoup(html, 'html.parser') # BeautifulSoup 클래스를 초기화\n    table = soup.find('table') # 테이블을 찾습니다.\n    data = [] # 데이터를 수집할 빈 리스트\n    \n    if table:\n\n        rows = table.find_all('tr') # 모든 테이블을 찾습니다.\n\n        for row in rows[1:]:  # 헤더 행을 건너 뜁니다.\n            cols = row.find_all('td') # 테이블에서 셀을 찾습니다.\n\n            if len(cols) == 4:  # 항상 4개의 열이 있다고 가정\n                catedra_name = cols[0].text.strip() # 과목 이름\n                email = cols[1].text.strip() # 이메일\n                data.append({'catedra': catedra_name, 'email': email}) # 데이터 리스트에 추가\n    \n    return data\n```\n\n# 단계 4. 함수 호출 및 데이터 CSV로 저장\n\n이제 모든 준비가 되었으므로 함수를 호출해야 합니다.\n\n```js\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_html(url):\n\n    try:\n        response = requests.get(url) # 웹사이트에서 HTML 가져오기\n        return response.text\n\n    except Exception as e: # 가능한 오류 처리\n        print(f\"웹 페이지를 가져오는 데 실패했습니다: {e}\")\n        return \"\" # 중복을 피하기 위해 이메일 집합\n\ndef extract_data(html):\n\n    soup = BeautifulSoup(html, 'html.parser') # BeautifulSoup 클래스를 초기화\n    table = soup.find('table') # 테이블 찾기\n    data = [] # 데이터 수집을 위한 빈 리스트\n    \n    if table:\n\n        rows = table.find_all('tr') # 모든 테이블 찾기\n\n        for row in rows[1:]:  # 헤더 행 건너 띄기\n            cols = row.find_all('td')\n\n            if len(cols) == 4:  # 항상 4개의 열\n                catedra_name = cols[0].text.strip() # 과목 이름\n                email = cols[1].text.strip() # 이메일\n                data.append({'catedra': catedra_name, 'email': email})\n    \n    return data\n\nurl = \"https://edipsicouba.net.ar/uncategorized/listado-mails-materias-electivas/\"  # 여러분의 링크 설정\n\nhtml = get_html(url) # get_html() 함수 호출하여 내용을 변수에 저장\ndata = extract_data(html) # extract_data() 함수 호출하여 결과를 변수에 저장\n\ndf = pd.DataFrame(data) # 데이터를 데이터프레임으로 변환\ndf.to_csv('mail_info.csv', index=False) # 데이터프레임을 CSV 파일로 저장\n\nprint(\"데이터가 성공적으로 추출되어 mail_info.csv로 저장되었습니다\")\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그게 다에요!\n\n이렇게 하면 웹사이트의 테이블 안에서 데이터를 수집할 수 있어요.\n\n또한, 이렇게 하면 Python을 사용하여 지루한 작업을 자동화할 수 있어요 😉\n\n다음 글에서는 데이터 분석 프로젝트를 위해 슈퍼마켓에서 데이터를 수집하는 방법을 보여드릴게요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 도와드릴 수 있는 방법:\n\n- 새로운 무료 뉴스레터 'The Super Learning Lab'를 구독하세요.\n- 곧 무료 학습 이북과 이메일 코스가 출시될 예정입니다!\n\n![HowToEasilyExtractDataFromAWebsiteWithPython_3](/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_3.png)\n\n## 내 최고의 학습 기사들:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n안녕하세요!\n\n가져와주셔서 감사합니다! 아래는 이번 주 발간물 내용입니다:\n\n- Ultralearning으로 무엇이든 배우기\n- 초안 속 9가지 Ultra-learning 원칙\n- Ultralearning을 활용하여 2개월 만에 무료로 독일어 배우기\n- 학습을 슈퍼파워로 만들기\n- 이것을 하지 않고 책을 읽는 것을 그만두세요\n\n만날 날을 기대하며,\n\nAxel\n\n# 간단하고 쉬운 용어로 🚀\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nIn Plain English 커뮤니티에 참여해 주셔서 감사합니다! 떠나시기 전에:\n\n- 작가에게 박수를 보내고 팔로우해주세요 👏️️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문하기: CoFeed | Differ\n- PlainEnglish.io에서 더 많은 콘텐츠 확인하기","ogImage":{"url":"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_0.png","tag":["Tech"],"readingTime":9},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<table>\n<tbody><tr>\n  <th>Library</th>\n  <th>Purpose</th>\n</tr>\n<tr>\n  <td>Requests</td>\n  <td>For sending HTTP requests</td>\n</tr>\n<tr>\n  <td>BeautifulSoup</td>\n  <td>For parsing HTML and XML</td>\n</tr>\n<tr>\n  <td>Tkinter</td>\n  <td>For building the GUI</td>\n</tr>\n</tbody></table>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<ul>\n<li><strong>Pandas</strong>: 추출된 데이터를 위한 데이터베이스를 생성하는 데 사용됩니다.</li>\n<li><strong>Requests</strong>: 웹사이트에 접근 권한을 요청하는 데 사용됩니다.</li>\n<li><strong>BeautifulSoup</strong>: 웹상에서 데이터를 찾는 데 사용됩니다.</li>\n</ul>\n<h1>작업: 이메일 목록 추출 및 CSV로 변환하기</h1>\n<p>여러 주제에서 많은 이메일을 가져와야 했습니다.</p>\n<p>\"수동으로는 절대 할 수 없어\" 라고 생각했습니다. 그렇게 하면 시간이 많이 걸리고 지루할 것이라고 생. 따라서 나는 파이썬 기술을 사용하기로 결정했습니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>웹 사이트에는 다음과 같은 데이터가 있습니다:</p>\n<p><img src=\"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_1.png\" alt=\"Data Table\"></p>\n<p>네, 과목 이름과 이메일이 포함된 표가 있습니다.</p>\n<p>이 프로젝트의 목표는 이 데이터를 사용하여 CSV 파일을 생성하는 것입니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>단계 1. 모듈 가져오기</h1>\n<p>먼저 사용할 Python 라이브러리를 가져와 봅시다:</p>\n<ul>\n<li>pandas.</li>\n<li>requests.</li>\n<li>BeautifulSoup.</li>\n</ul>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">from</span> bs4 <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">BeautifulSoup</span>\n</code></pre>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>단계 2. 데이터 찾기</h1>\n<h2>2.1. 웹 스크래핑은 어떻게 작동되나요?</h2>\n<p>웹에서 데이터를 추출하는 것이 가능한 이유는 무엇인가요?</p>\n<p>답은 HTML(HyperText Markup Language)에 달려 있습니다. HTML은 웹 브라우저에서 표시할 문서의 표준 마크업 언어입니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>웹사이트 어디에서든 마우스 오른쪽 버튼을 클릭하고 Inspect를 선택하면 웹의 코드가 오른쪽에 표시됩니다:</p>\n<p><img src=\"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_2.png\" alt=\"image\"></p>\n<p>파이썬은 (일부 라이브러리와 함께) 이 HTML 코드를 \"읽고\" 원하는 데이터를 찾는 것입니다.</p>\n<p>더 자세한 내용은 향후 기사에서 확인해보세요.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h2>2.2. HTML 가져오기 함수</h2>\n<p>우선, 웹 사이트에서 HTML 코드를 가져와야 합니다.</p>\n<p>URL을 매개변수로 하는 get_html 함수를 생성하는 방법은 다음과 같습니다:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">from</span> bs4 <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">BeautifulSoup</span>\n\ndef <span class=\"hljs-title function_\">get_html</span>(url):\n\n    <span class=\"hljs-attr\">try</span>:\n        response = requests.<span class=\"hljs-title function_\">get</span>(url) # 웹 사이트에서 <span class=\"hljs-variable constant_\">HTML</span>을 요청합니다\n        <span class=\"hljs-keyword\">return</span> response.<span class=\"hljs-property\">text</span>\n\n    except <span class=\"hljs-title class_\">Exception</span> <span class=\"hljs-keyword\">as</span> <span class=\"hljs-attr\">e</span>: # 가능한 오류를 처리하기 위한 예외 처리\n        <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"웹 페이지를 가져오는 데 실패했습니다: {e}\"</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\"\"</span>emails = <span class=\"hljs-title function_\">set</span>() # 중복을 피하기 위한 코드입니다\n</code></pre>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>단계 3. 데이터 추출</h1>\n<p>다음 단계는 우리가 원하는 데이터를 추출하는 것입니다.</p>\n<p>우리는 이전 함수에서 HTML 코드를 가져오는 extract_data 함수를 만들 수 있습니다. 이는 다음 단계를 포함합니다:</p>\n<ul>\n<li>BeautifulSoup 클래스 초기화.</li>\n<li>테이블을 찾는 변수 설정.</li>\n<li>데이터를 수집할 빈 리스트.</li>\n<li>데이터를 검색하는 for 루프.</li>\n</ul>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">from</span> bs4 <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">BeautifulSoup</span>\n\ndef <span class=\"hljs-title function_\">get_html</span>(url):\n\n    <span class=\"hljs-attr\">try</span>:\n        response = requests.<span class=\"hljs-title function_\">get</span>(url) # 웹사이트로부터 <span class=\"hljs-variable constant_\">HTML</span>을 요청합니다.\n        <span class=\"hljs-keyword\">return</span> response.<span class=\"hljs-property\">text</span>\n\n    except <span class=\"hljs-title class_\">Exception</span> <span class=\"hljs-keyword\">as</span> <span class=\"hljs-attr\">e</span>: # 가능한 오류를 처리하기 위한 부분\n        <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"웹 페이지를 가져오는 데 실패했습니다: {e}\"</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\"\"</span> # 중복을 피하기 위해 이메일 집합으로 설정\n\ndef <span class=\"hljs-title function_\">extract_data</span>(html):\n\n    soup = <span class=\"hljs-title class_\">BeautifulSoup</span>(html, <span class=\"hljs-string\">'html.parser'</span>) # <span class=\"hljs-title class_\">BeautifulSoup</span> 클래스를 초기화\n    table = soup.<span class=\"hljs-title function_\">find</span>(<span class=\"hljs-string\">'table'</span>) # 테이블을 찾습니다.\n    data = [] # 데이터를 수집할 빈 리스트\n    \n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-attr\">table</span>:\n\n        rows = table.<span class=\"hljs-title function_\">find_all</span>(<span class=\"hljs-string\">'tr'</span>) # 모든 테이블을 찾습니다.\n\n        <span class=\"hljs-keyword\">for</span> row <span class=\"hljs-keyword\">in</span> rows[<span class=\"hljs-number\">1</span>:]:  # 헤더 행을 건너 뜁니다.\n            cols = row.<span class=\"hljs-title function_\">find_all</span>(<span class=\"hljs-string\">'td'</span>) # 테이블에서 셀을 찾습니다.\n\n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-title function_\">len</span>(cols) == <span class=\"hljs-number\">4</span>:  # 항상 <span class=\"hljs-number\">4</span>개의 열이 있다고 가정\n                catedra_name = cols[<span class=\"hljs-number\">0</span>].<span class=\"hljs-property\">text</span>.<span class=\"hljs-title function_\">strip</span>() # 과목 이름\n                email = cols[<span class=\"hljs-number\">1</span>].<span class=\"hljs-property\">text</span>.<span class=\"hljs-title function_\">strip</span>() # 이메일\n                data.<span class=\"hljs-title function_\">append</span>({<span class=\"hljs-string\">'catedra'</span>: catedra_name, <span class=\"hljs-string\">'email'</span>: email}) # 데이터 리스트에 추가\n    \n    <span class=\"hljs-keyword\">return</span> data\n</code></pre>\n<h1>단계 4. 함수 호출 및 데이터 CSV로 저장</h1>\n<p>이제 모든 준비가 되었으므로 함수를 호출해야 합니다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">from</span> bs4 <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">BeautifulSoup</span>\n\ndef <span class=\"hljs-title function_\">get_html</span>(url):\n\n    <span class=\"hljs-attr\">try</span>:\n        response = requests.<span class=\"hljs-title function_\">get</span>(url) # 웹사이트에서 <span class=\"hljs-variable constant_\">HTML</span> 가져오기\n        <span class=\"hljs-keyword\">return</span> response.<span class=\"hljs-property\">text</span>\n\n    except <span class=\"hljs-title class_\">Exception</span> <span class=\"hljs-keyword\">as</span> <span class=\"hljs-attr\">e</span>: # 가능한 오류 처리\n        <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"웹 페이지를 가져오는 데 실패했습니다: {e}\"</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\"\"</span> # 중복을 피하기 위해 이메일 집합\n\ndef <span class=\"hljs-title function_\">extract_data</span>(html):\n\n    soup = <span class=\"hljs-title class_\">BeautifulSoup</span>(html, <span class=\"hljs-string\">'html.parser'</span>) # <span class=\"hljs-title class_\">BeautifulSoup</span> 클래스를 초기화\n    table = soup.<span class=\"hljs-title function_\">find</span>(<span class=\"hljs-string\">'table'</span>) # 테이블 찾기\n    data = [] # 데이터 수집을 위한 빈 리스트\n    \n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-attr\">table</span>:\n\n        rows = table.<span class=\"hljs-title function_\">find_all</span>(<span class=\"hljs-string\">'tr'</span>) # 모든 테이블 찾기\n\n        <span class=\"hljs-keyword\">for</span> row <span class=\"hljs-keyword\">in</span> rows[<span class=\"hljs-number\">1</span>:]:  # 헤더 행 건너 띄기\n            cols = row.<span class=\"hljs-title function_\">find_all</span>(<span class=\"hljs-string\">'td'</span>)\n\n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-title function_\">len</span>(cols) == <span class=\"hljs-number\">4</span>:  # 항상 <span class=\"hljs-number\">4</span>개의 열\n                catedra_name = cols[<span class=\"hljs-number\">0</span>].<span class=\"hljs-property\">text</span>.<span class=\"hljs-title function_\">strip</span>() # 과목 이름\n                email = cols[<span class=\"hljs-number\">1</span>].<span class=\"hljs-property\">text</span>.<span class=\"hljs-title function_\">strip</span>() # 이메일\n                data.<span class=\"hljs-title function_\">append</span>({<span class=\"hljs-string\">'catedra'</span>: catedra_name, <span class=\"hljs-string\">'email'</span>: email})\n    \n    <span class=\"hljs-keyword\">return</span> data\n\nurl = <span class=\"hljs-string\">\"https://edipsicouba.net.ar/uncategorized/listado-mails-materias-electivas/\"</span>  # 여러분의 링크 설정\n\nhtml = <span class=\"hljs-title function_\">get_html</span>(url) # <span class=\"hljs-title function_\">get_html</span>() 함수 호출하여 내용을 변수에 저장\ndata = <span class=\"hljs-title function_\">extract_data</span>(html) # <span class=\"hljs-title function_\">extract_data</span>() 함수 호출하여 결과를 변수에 저장\n\ndf = pd.<span class=\"hljs-title class_\">DataFrame</span>(data) # 데이터를 데이터프레임으로 변환\ndf.<span class=\"hljs-title function_\">to_csv</span>(<span class=\"hljs-string\">'mail_info.csv'</span>, index=<span class=\"hljs-title class_\">False</span>) # 데이터프레임을 <span class=\"hljs-variable constant_\">CSV</span> 파일로 저장\n\n<span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"데이터가 성공적으로 추출되어 mail_info.csv로 저장되었습니다\"</span>)\n</code></pre>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>그게 다에요!</p>\n<p>이렇게 하면 웹사이트의 테이블 안에서 데이터를 수집할 수 있어요.</p>\n<p>또한, 이렇게 하면 Python을 사용하여 지루한 작업을 자동화할 수 있어요 😉</p>\n<p>다음 글에서는 데이터 분석 프로젝트를 위해 슈퍼마켓에서 데이터를 수집하는 방법을 보여드릴게요.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>도와드릴 수 있는 방법:</h1>\n<ul>\n<li>새로운 무료 뉴스레터 'The Super Learning Lab'를 구독하세요.</li>\n<li>곧 무료 학습 이북과 이메일 코스가 출시될 예정입니다!</li>\n</ul>\n<p><img src=\"/TIL/assets/img/2024-07-12-HowToEasilyExtractDataFromAWebsiteWithPython_3.png\" alt=\"HowToEasilyExtractDataFromAWebsiteWithPython_3\"></p>\n<h2>내 최고의 학습 기사들:</h2>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>안녕하세요!</p>\n<p>가져와주셔서 감사합니다! 아래는 이번 주 발간물 내용입니다:</p>\n<ul>\n<li>Ultralearning으로 무엇이든 배우기</li>\n<li>초안 속 9가지 Ultra-learning 원칙</li>\n<li>Ultralearning을 활용하여 2개월 만에 무료로 독일어 배우기</li>\n<li>학습을 슈퍼파워로 만들기</li>\n<li>이것을 하지 않고 책을 읽는 것을 그만두세요</li>\n</ul>\n<p>만날 날을 기대하며,</p>\n<p>Axel</p>\n<h1>간단하고 쉬운 용어로 🚀</h1>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>In Plain English 커뮤니티에 참여해 주셔서 감사합니다! 떠나시기 전에:</p>\n<ul>\n<li>작가에게 박수를 보내고 팔로우해주세요 👏️️</li>\n<li>팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter</li>\n<li>다른 플랫폼 방문하기: CoFeed | Differ</li>\n<li>PlainEnglish.io에서 더 많은 콘텐츠 확인하기</li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}