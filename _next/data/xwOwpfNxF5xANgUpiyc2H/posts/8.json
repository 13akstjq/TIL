{"pageProps":{"posts":[{"title":"파이썬 동시성 완벽 정복을 위한 12가지 필수 팁","description":"","date":"2024-07-13 19:35","slug":"2024-07-13-12EssentialTipsforMasteringPythonConcurrency","content":"\n\n<img src=\"/TIL/assets/img/2024-07-13-12EssentialTipsforMasteringPythonConcurrency_0.png\" />\n\n## 파이썬 동시성이 프로그래밍 병목 현상을 해결하는 방법\n\n오늘은 파이썬에서 동시성을 탐색할 거에요 — 프로그램을 더 빠르게 실행할 수 있는 마법 같은 열쇠!\n\n걱정하지 마세요, 초심자라도 동시성을 마스터할 수 있도록 단계별로 안내할게요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1. 스레딩 소개: 멀티 스레딩 기초\n\n카페에서 이메일 처리, 채팅 및 코딩을 동시에 하는 상황을 상상해보세요 — 그것이 멀티 스레딩입니다.\n\nPython에서는 `threading` 모듈이 여러분의 유용한 도우미입니다.\n\n```python\nimport threading\nimport time\n\ndef say_hello(name):\n    print(f\"Hello, {name}!\")\n    time.sleep(2)  # 시간이 오래 걸리는 작업을 모방\n\n# 스레드 생성\nthread1 = threading.Thread(target=say_hello, args=(\"World\",))\nthread2 = threading.Thread(target=say_hello, args=(\"Python\",))\n\n# 스레드 시작\nthread1.start()\nthread2.start()\n\n# 모든 스레드가 완료될 때까지 대기\nthread1.join()\nthread2.join()\n\nprint(\"모든 작업 완료.\")\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 코드는 서로 다른 인사말을 인쇄하는 두 개의 스레드를 만들고, 그들이 완료될 때까지 기다립니다. `join()`을 기억하세요, 스레드가 완료될 때까지 기다립니다.\n\n# 2. 동시성 함정: 전역 인터프리터 잠금(GIL)\n\n멀티스레딩을 논의할 때, 파이썬의 GIL에 대해 언급해야 합니다. CPU 코어가 파이썬 바이트코드를 실행하는 것에 차례를 가져가도록 하는 것인데, 이는 CPU 바운드 작업에 대해 멀티스레딩이 항상 더 빠르지는 않다는 의미입니다. 하지만 걱정하지 마세요, I/O 바운드 작업의 경우에는 멀티스레딩이 여전히 유용합니다!\n\n# 3. 병렬 처리: GIL 우회\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다중 코어 CPU를 최대한 활용하려면 `multiprocessing` 모듈을 사용하세요. 이 모듈은 각 프로세스에 대해 별도의 Python 해석기를 생성하여 GIL을 우회합니다.\n\n```python\nfrom multiprocessing import Process\nimport time\n\ndef worker(num):\n    print(f'Worker: {num}')\n    time.sleep(2)\n\nif __name__ == '__main__':\n    processes = []\n    for i in range(4):\n        p = Process(target=worker, args=(i,))\n        processes.append(p)\n        p.start()\n```\n\n각 `Process`는 GIL과 독립적으로 실행됩니다.\n\n# 4. 동시성이 모든 문제를 해결해 주지는 않습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n동시성은 데이터 동기화 문제와 함께 복잡할 수 있습니다. 자원 충돌을 피하기 위해 잠금을 사용하면 마치 주방에서 하나의 전자 레인지를 공유하는 것처럼 자원 충돌을 피할 수 있습니다.\n\n```python\nfrom threading import Lock\n\nlock = Lock()\n\ndef safe_print(number):\n    with lock:\n        print(f'Safe print: {number}')\n\nsafe_print(1)\nsafe_print(2)\n```\n\n`with`를 사용하면 잠금을 자동으로 관리하여 안전을 보장합니다.\n\n# 5. 큐의 지혜: `queue.Queue`\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n편리하게 생각해보면 공장 조립 라인과 비슷한데, `Queue`는 스레드/프로세스 간 데이터 교환을 조율하는 조정자입니다.\n\n```python\nfrom queue import Queue\nfrom threading import Thread\n\ndef producer(queue):\n    queue.put('Product')\n\ndef consumer(queue):\n    print(queue.get())\n\nq = Queue()\nproducer_thread = Thread(target=producer, args=(q,))\nconsumer_thread = Thread(target=consumer, args=(q,))\n\nproducer_thread.start()\nconsumer_thread.start()\n\nproducer_thread.join()\nconsumer_thread.join()\n```\n\n큐는 혼란을 방지하고 안전한 데이터 전송을 보장합니다.\n\n# 6. 비동기의 마법: `asyncio`\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기다리기 싫어요? `asyncio`가 `async`/`await`으로 비동기 프로그래밍 세계로 안내합니다. 당신의 코드를 날아다니게 만들어줍니다.\n\n```python\nimport asyncio\n\nasync def hello(i):\n    print(f'Hello {i}')\n    await asyncio.sleep(1)  # 비동기 대기\n\nasync def main():\n    tasks = [hello(i) for i in range(3)]\n    await asyncio.gather(*tasks)\n\n# Python 3.7+\nasyncio.run(main())\n```\n\n비동기 대기를 통해 다른 작업을 수행하면서 대기할 수 있어 효율성을 향상시킬 수 있어요.\n\n# 7. 비동기 프로그래밍에 대한 오해\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n`asyncio`는 강력하지만 하드웨어와 직접 상호 작용하는 저수준 API와 같은 모든 함수를 비동기적으로 실행할 수 없습니다. 올바른 방법을 선택하고 강제로 async를 적용하지 마세요.\n\n# 8. `concurrent.futures`: 간편한 Future 처리\n\n간단한 동시 작업의 경우, 동기적 또는 비동기적으로, `concurrent.futures`를 활용하세요.\n\n```js\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef worker(n):\n    return n * n\n\nwith ThreadPoolExecutor() as executor:\n    results = executor.map(worker, range(5))\n    print(list(results))  # 제곱 출력\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n ThreadPoolExecutor를 사용하여 스레드 풀을 쉽게 관리할 수 있습니다. 이를 통해 작업 실행이 음식 주문하는 것만큼 간단해집니다.\n\n# 9. 오류 처리의 기술: 예외 gracefully 처리하기\n\n동시성에서 오류 처리는 중요합니다. 코드를 보호하기 위해 `try-except`를 사용하여 한 작업의 실패가 전체 프로그램에 영향을 미치지 않도록합니다.\n\n```js\ntry:\n    # 실패할 수도 있는 동시성 코드\nexcept Exception as e:\n    print(f\"예외를 잡았습니다: {e}\")\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n침착하게 유지하고 오류를 세련되게 처리하여 견고한 프로그램을 만들어봐요.\n\n# 10. 리소스 관리: 컨텍스트 관리자와 `with`\n\n`with` 문은 파일, 락과 같은 리소스가 올바르게 해제되어 경쟁 상태에서 리소스 누출을 방지해줘요.\n\n```js\nwith Lock():\n    # 공유 리소스를 안전하게 조작해요\n```  \n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n표 태그를 마크다운 형식으로 변경해 드릴게요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n실제 예시를 통해 동시에 이미지를 다운로드하여 동시성의 힘을 느껴보는 연습을 해보세요.\n\n```python\nimport os\nimport requests\nfrom threading import Thread\n\ndef download_image(url, filename):\n    response = requests.get(url)\n    with open(filename, 'wb') as f:\n        f.write(response.content)\n    print(f'{filename} 다운로드 완료.')\n\nurls = ['img_url1', 'img_url2']  # 예시 URL\nthreads = []\n\nfor url in urls:\n    t = Thread(target=download_image, args=(url, os.path.basename(url)))\n    threads.append(t)\n    t.start()\n\nfor t in threads:\n    t.join()\n\nprint('모든 이미지 다운로드 완료.')\n```\n\n동시 다운로드는 프로세스를 크게 가속시킵니다!\n\n이 12가지 실용적인 팁으로 파이썬 동시성 능력을 향상시켰습니다. 진실을 확인하기 위해 연습해보세요. 프로그램을 실행시켜 빠르게 동작시켜 보세요!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSubstack에서 최신 AI 이야기를 따라가며 연락을 유지해보세요. 함께 AI의 미래를 함께 만들어요!\n\nSubstack에서 Python 이야기를 최신 상태로 유지하기 위해 연락을 유지해보세요. 함께 Python을 배워봐요!","ogImage":{"url":"/TIL/assets/img/2024-07-13-12EssentialTipsforMasteringPythonConcurrency_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-12EssentialTipsforMasteringPythonConcurrency_0.png","tag":["Tech"],"readingTime":8},{"title":"Python을 사용한 리스크 온 vs 리스크 오프 주식 시장 대시보드 만들기 - Part IV 동적 시간 왜곡 Dynamic Time Warping 방법","description":"","date":"2024-07-13 19:33","slug":"2024-07-13-HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping","content":"\n\n\n![그림](/TIL/assets/img/2024-07-13-HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping_0.png)\n\n코델 태니는 금융 서비스 분야에서 23년 이상의 경험을 가진 전문가로, 양적 금융을 전문으로 하고 있습니다. 코델은 이전에 캐나다 주요 기관에서 양적 분석가 및 포트폴리오 매니저로 일하며 20억 달러 규모의 다자산 소매 투자 프로그램을 지도했습니다.\n\n현재 코델은 Trend Prophets의 대표이사 및 공동창업자로 활동하고 있으며 양적 금융 및 AI 솔루션 기업인 DigitalHub Insights의 이사이기도 합니다. 그는 맥길 대학에서 생물학 학사 학위를 받았으며 CFA 차터홀더이며 금융 리스크 관리자 자격증을 보유하고 있으며 금융 데이터 전문가 차터를 보유하고 있습니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\ntrendprophets.com 웹사이트를 방문하여 더 많은 정보를 얻어보세요.\n\n모든 Python 코드는 기사 말미에 찾을 수 있습니다.\n\n이 연재의 이전 부분에 대한 링크:\n\nPython에서 리스크 온 대 리스크 오프 주식 시장 대시보드 만들기 - Part I\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n파이썬으로 리스크 온 대 리스크 오프 주식 시장 대시보드 만들기 - 파트 II: 상관 분석\n\n파이썬으로 리스크 온 대 리스크 오프 주식 시장 대시보드 만들기 - 파트 III: 업데이트\n\n## 소개\n\n안녕하세요, 여러분. 데이터 과학과 양적 금융 프로젝트를 향한 나의 여정에 다시 오신 것을 환영합니다. 항상처럼, 이 블로그의 목표와 간략한 요약부터 시작하겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 프로젝트의 목표는 두 가지입니다:\n\n1) 데이터 과학/양적 금융 프로젝트를 진행하면서 연구 과정과 논리를 공유하는 것입니다. 포함되어 있는 것은:\n\na. 아이디어 도출.\n\nb. 논리적 진행 및 흐름 다이어그램 작성 (여러 번 변경될 것입니다).\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nc. 필요한 자원, 데이터 및 기술 요구사항(프로그래밍 언어, 데이터베이스 설정, 기타)을 식별합니다.\n\n나는 전문 재무 관리자 및 양적 금융 전문가로 일한 경험과 지식을 공유하려 합니다.\n\n본 연구 프로젝트의 주요 목표는 리스크 온 대 리스크 오프 시장 회전을 식별하는 대시보드를 만드는 것입니다. 우리가 예측 모형을 구축할 수 있다면, 더할 나위 없겠죠.\n\n첫 두 기사는 리스크 자산과 리스크 오프 자산 간의 회전을 시각화할 수 있는 히트맵을 만드는 데 중점을 두었습니다. 우리는 전통적인 성과 지표, 백분위 측정 및 상관 관계를 사용하여 평가를 수행했습니다. 이 분석은 이러한 기본 도구를 사용하여도 꽤 잘 보였습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 리뷰 및 요약\n\n초안 이후 두 달이 지났으므로 백분위수와 상관 관계 열지도를 다시 살펴봅시다. 또한 시장에서 어떤 일이 벌어졌는지 살펴보겠습니다.\n\n11월에 시작된 주요 리스크온 회전은 12월 마지막 주까지 바로 이어졌습니다. 그런 다음 시장(S&P 500)에서 풀백이 발생하여 1월 첫 주까지 계속되었습니다. 그 후 우리는 약간 더 높은 변동성을 가진 측면 움직임을 이어갔습니다. SPY와 DIA는 새로운 최고치를 기록했지만, QQQ는 훨씬 더 변동성이 있었습니다. QQQ는 최근에 Meta와 Amazon의 대박 실적으로 새로운 최고치를 경신했습니다. 그러나 QQQ는 리스크온 프록시가 아닙니다. QQQ가 이제 상품 ETF의 최상위 보유 종목이기 때문에 QQQ가 리스크온인 것으로 말하기는 벅차니 권합니다! Meta는 이제 배당을 지급합니다 (뭐야??? 그것은 그들이 성장할 방법이 없다고 보는 게 의미하는 건가요, 아니면 그들이 너무 많은 현금을 가지고 있어서 그냥 버리기로 결정하고 주주들에게 돌려주는 건가요? 이런 건 다른 이야기입니다).\n\n이 시점에서 다시 한 번 강조해야 할 점은 나의 리스크온 프록시들이 좋은 프록시라고 난 장담할 수 없다는 것입니다. 이것이 우리가 알아내려고 하는 것입니다. 예를 들어, ARKK는 이상한 동물입니다. 특히 BTC 노출이 많기 때문에 그에 대한 구체적인 내용이 많아서 그것이 감정에 의해 주도되었는지 아니면 독특한 요인에 의해 주도되었는지 판단하기 어렵습니다. 리스크온 대 리스크오프는 감정, 기본 요인 및 가격을 움직이는 모든 정보를 포착할 수 있는 새로운 요인에 의해 지원되어야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가장 \"명백한\" 위험 증감 지표들의 상대 성능을 먼저 살펴봅시다.\n\n![image](/TIL/assets/img/2024-07-13-HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping_1.png)\n\n1월 1일부터 기술주 (XLK)만 SPY에 대해 양호한 상대 성과를 보이고 있습니다. 생명공학 (XBI)과 ARKK는 하락하고 있습니다. 금 (GLD)과 현금 (BIL)도 하락하고 있습니다. 고베타 주식 (SPHB)은 평평합니다. 그러므로 다시 한 번 대형 기술주가 시장을 이끌고 있는 것 같습니다. 그렇다면 이것은 위험 중립적 환경인가요? 나중에 대비하여 대시보드에 세 번째 상태를 추가하고 미래를 예측해야 할 수도 있습니다.\n\n이 시점에서 가능성은 열려 있어야 합니다. 이것은 여정입니다!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-13-HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping_2.png\" />\n\n그래서 우리가 해야 할 일에 대한 요약을 보여드리겠습니다. 초기 단계의 목표는 리스크온 및 리스크오프 프록시를 선택하는 것입니다 (다음 단계에 대한 모든 아이디어 요약은 부록 III도 참고해주세요):\n\n1) 이미 있는 롤링 상관 관계 기능을 보완하기 위해 가격 및 수익 데이터에서 추가 기능을 생성합니다.\n\n2) 클러스터링 알고리즘을 적용하여 우리의 프록시를 시각화하고 원하는 그룹 형성을 달성하고 있는지 확인합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3) 클러스터를 결정하는 데 가장 많은 기여를 하는 피처를 식별하기 위해 피처 중요도를 추출합니다.\n\n4) 대리 변수 및 설명력이 없는 피처를 제거합니다.\n\n재미를 좀 봅시다! 몇 가지 피처를 공학적으로 개발해 봅시다.\n\n상관 관계를 크게 선호하지 않고, 한 시점에서의 상관 관계 추정치를 살펴보는 연구에 대해서도 조심스럽습니다. 이것은 제가 쓰레기를 생성하는 확실한 방법이기 때문입니다. 그래서 우리는 이동 상관 관계를 사용했습니다. 상관 관계는 선형 관계만을 포착하며, 일부 자산의 관계가 선형적으로 연관되어 있지 않을 수도 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그래서, 변수 간의 관계를 설명하는 다른 방법을 찾아야 하며, 시간이 지남에 따라 어떻게 변하는지 파악하고 비선형성을 포착해야 합니다.\n\n## 동적 시간 왜곡(Dynamic Time Warping)을 소개합니다\n\n계속하기 전에 새로운 프로젝트를 진행하는 과정에서 제 사고 과정을 공유한다는 것을 강조해야 합니다. 저는 절대 모든 것을 알거나 답을 모두 알고 있는 것이 아니라는 점을 분명히 해야 합니다. 이것이 제가 배우는 방법이기 때문입니다. 필요한 작업을 수행하는 데 도움이 되는 양적 기법을 연구합니다. 그렇기 때문에 ChatGPT는 저와 같은 사람들에게는 놀라운 도구입니다. 저는 완전히 스스로 가르친 코더이며(이 글을 읽는 여러분 중 많은 분들처럼), 수학이나 컴퓨터 과학 학위가 없습니다. 그러나 제가 아주 빨리 배우는 경향이 있습니다. 그래서 동적 시간 왜곡의 발견이 제게 매우 의미 있는 것입니다. 새로운 것을 배울 수 있고, 그런 다음 이러한 새로운 기술을 활용하는 여러 가지 방법을 고안할 수 있습니다(제가 재무 분야에서 24년의 경험을 가지고 있다는 점을 기억해 주세요!).\n\n동적 시간 왜곡의 간단한 개요입니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDynamic Time Warping (DTW)는 두 개의 시계열 사이의 유사성을 측정하는 데 주로 사용되는 알고리즘입니다. 두 명의 사람이 두 개별 경로를 따라 걷고 있다고 상상해보세요. 각 사람마다 다른 보폭과 속도가 있습니다. 그들의 경로가 얼마나 비슷한지 비교하려면 각 초마다의 위치를 단순히 비교하는 것은 잘 작동하지 않을 것입니다. 왜냐하면 그들의 다른 속도로 인해 어느 순간에는 동기화되어 있고 다른 순간에는 동기화되어 있지 않을 수 있기 때문입니다. DTW는 각 시퀀스의 시간축을 \"왜곡\"하여 유사한 시간 포인트를 정렬함으로써 두 경로 사이의 유사성을 보다 의미 있게 제공하도록 도와줍니다.\n\n상관 계수와 어떻게 다른가요?\n\n상관 계수는 두 변수 간의 선형 관계를 측정하는 반면, DTW는 두 시계열의 형태와 패턴의 유사성을 측정합니다. 속도와 관계없이 말이죠. 이제 상관 계수에 비해 DTW의 장단점을 살펴보겠습니다:\n\n상관 계수에 비한 DTW의 장점:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n1. 유연성: DTW는 선형 관계의 가정에 제약을 받지 않으며, 시퀀스가 상이한 속도, 위상 또는 길이를 가지더라도 유사성을 포착할 수 있습니다.\n\n2. 패턴 매칭: 데이터의 전체적인 형태를 고려하여 시퀀스를 정렬하므로 유사성을 최대화하여 패턴 매칭과 인식에 특히 유용합니다.\n\n상관관계에 비한 단점:\n\n1. 계산 복잡성: 특히 긴 시퀀스의 경우 DTW는 계산적으로 상관관계를 계산하는 것보다 더 많은 자원이 필요하므로 대규모 데이터셋에는 제약이 될 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. 해석 가능성: 상관 관계는 선형 관계의 방향과 강도를 나타내는 명확한 지표(-1 ~ 1)를 제공하지만, DTW 유사성 점수는 직관적이지 않을 수 있고 크기에 대해 해석하기 어려울 수 있습니다.\n\n상관 관계와 마찬가지로, 우리는 각 자산 쌍에 대한 DTW 점수를 계산합니다. 이 경우에는 DTW 알고리즘을 사용하여 두 시퀀스 간의 거리를 측정하고 유사성을 평가합니다. 높은 DTW 점수는 높은 거리를 나타내며 따라서 두 시퀀스 간의 유사성이 낮음을 나타냅니다. 낮은 점수는 높은 유사성을 나타내며, 거리가 0이면 완전한 유사성을 의미합니다.\n\n우리는 롤링 상관 관계와 동일한 방법론을 사용할 것입니다. 2013년부터 시작된 수익 데이터를 가지고 롤링 12주 및 24주 창을 통해 평균 쌍별 DTW 점수를 측정할 것입니다. (참고: 12주와 24주 창에 대한 결과에 큰 차이가 없어 12주 창만 제시하겠습니다).\n\n결과 히트맵은 다음과 같습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping_3](/TIL/assets/img/2024-07-13-HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping_3.png)\n\nThe resulting heatmap might appear more complex than the correlation matrix. To facilitate interpretation, let’s visualize this as a cluster map, allowing us to examine the dendrogram for clusters based on these values.\n\n![HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping_4](/TIL/assets/img/2024-07-13-HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping_4.png)\n\nThis visualization provides slightly more insight. To understand this graph, follow the lines to observe which assets are grouped together. As you move up the dendrogram, smaller clusters aggregate into larger ones.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nUSO와 BTC가 명확한 클러스터를 형성하고 있으므로 분석 제외 대상으로 고려될 수 있습니다. 그러나 남은 자산들의 색상은 유의미한 차이를 나타내지 않아 DTW 방법론의 한계가 있을 수 있다고 생각됩니다. DTW 점수에 기반하여 모든 것을 일축할 필요는 없으며, 이는 DTW가 작동하는 방식의 결과물일 수도 있습니다. 다른 시기에 자료를 스케일링하거나 정규화하여 향상된 결과를 얻을 수도 있습니다.\n\n우리가 관찰한 주요 클러스터는 다음과 같습니다:\n\n- ARKK/XBI: 이는 두 가지 가장 변동성이 높은 자산이라는 점에서 우리에게 가장 좋은 후보들 중 하나입니다.\n\n- SPHB/SOXX: 고베타 주식 및 반도체. SOXX가 주기적인 특성을 가지고 있고 사업 주기에 민감하기 때문에 이 것을 본 것에 만족합니다. SPHB는 높은 위험으로 정의되어 있기 때문에 아마도 최고의 리스크 대리인 중 하나일 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- TLT/GLD: 장기 국채를 GLD와 그룹화하는 것은 완벽하게 이해되며, 저 또한 이를 기쁘게 생각합니다.\n\n대부분의 다른 클러스터는 처음에는 그렇게 많은 의미를 가지고 있지 않을 수 있습니다. EEM이 헬스케어, 저 변동성 및 소비재와 같이 그룹화된 것을 볼 수 있습니다. 그래, 우리는 아직 해야 할 일이 남아 있습니다. 왜냐하면 이것은 말이 되지 않기 때문이죠.\n\n기억하세요; 우리는 탐사 단계에 있으며, 모든 것을 SPY에 대한 수익을 기반으로 하고 있습니다 (참고:DTW를 절대 가격 움직임에 대해 실행했고 SPY와의 관련에서만 수행하지 않았습니다. 의미있는 차이점이 없었습니다).\n\n## 결론\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희는 DTW 점수와 상관 관계와 함께 계층적 클러스터링 알고리즘에 사용할 수 있어요. 저는 석유와 BTC를 제거할 수 있다고 확신해요. 전체 시장 모니터링 대시 보드에는 유지하지만, 일반적인 시장 위험 선호와 상관 관계가 없어 보입니다.\n\n이제 다른 기술 분석 지표를 시험해 보고 싶어요. MACD, ADX 선 및 상대적 강도가 제일 먼저 올라와요. 다시 말하지만, 각 티커에 대한 롤링 값을 측정한 다음 상호 비교해야 하며, 상관 관계 및 DTW와 마찬가지로 이를 해야 할 거예요. 기술 지표의 롤링 평균값에 DTW를 사용할 수 있을 거에요. DTW는 지금부터 이 프로젝트의 나머지 부분 동안 엄청 유용할 거에요 (제 직관).\n\n이 지표를 테스트할 예정이지만, 초기 직관은 반환을 기반으로 모든 것을 파생하는 한 비슷한 결과를 얻을 수 있다는 것을 시사해요. 그러므로, 평균 쌍별 측정만 사용하는 것은 시간에 따라 변하는 관계를 포착하지 못할 수 있음을 인식하는 것이 중요해요. 이 문제를 해결하기 위한 제 방법이 있고, 여러분은 고유한 해결책을 찾아보도록 도전해 보세요!\n\n## 다음 단계\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음에 시도해볼 것이 무엇인지 궁금하네요. 댓글로 알려주세요. 이 프로젝트를 \"오픈 소스\"로 만들고 싶어해요. 제 아이디어는 있지만, 이 시점에서는 누구에게도 편향을 주고 싶지 않아요. 그것은 다음 단계에 남겨둘게요.\n\n그래서 이제 시도해야 할 것은:\n\n- 평균 측정치를 사용하는 대신 측정치의 시간 변동성을 포함하기.\n- 추가 지표 추가하기 (기술적인 지표 및 기타 여러분이 고려해볼 것을 댓글에 남겨주세요!).\n- 군집 알고리즘으로 진행하기.\n\n이 여정의 일환으로, DTW를 발견한 것은 저에게 엄청 큰 일이었어요. 이제 이것은 시계열 분석에 자주 사용할 무기 중 하나가 되었어요. 그래서 가능한 많은 논문들을 읽어 봤어요. 하지만 DTW의 대부분 응용은 금융 분야 바깥에 있어요. 이것은 더 기쁜 일인데, 아마 다음 대단한 응용 프로그램을 찾아서 Trend Prophets 인벤토리에 추가할 수도 있을 거예요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n읽어주셔서 감사합니다! 그리고 이 테스트를 실행하는 데 시간이 걸리고 다음 단계를 시도하기 전에 많은 연구를 해야 한다는 점에 대한 여러분의 인내심과 이해에 감사드립니다. 의견이나 제안이 있으면 언제든지 남겨주시기 바랍니다. 코드를 모두 가지고 있으니 여러분도 테스트해보시고 이 흥미진진한 프로젝트에 더 추가할 수 있는 내용이 있는지 확인해보세요.\n\n아래는 Markdown 형식으로 변경된 표입니다.\n\n```js\nfrom dtaidistance import dtw\nfrom itertools import combinations\nimport pickle\nfrom joblib import Parallel, delayed\n\ndef plot_relative_performance(prices, start_date, end_date, benchmark='SPY'):\n    \"\"\"\n    주어진 날짜 범위에 대한 특정 벤치마크와 자산의 상대적 수익률을 그래프로 표시합니다.\n\n    매개변수:\n    - prices (DataFrame): 각 열이 자산 및 지정된 벤치마크를 나타내는 자산 가격을 포함한 DataFrame.\n    - start_date (str): 분석 시작 일자 (예: '2023-01-01').\n    - end_date (str): 분석 종료 일자 (예: '2023-12-31').\n    - benchmark (str): 비교할 벤치마크의 이름 (기본값은 'SPY').\n\n    반환:\n    - 없음: 이 함수는 그래프를 생성하여 표시합니다.\n    \"\"\"\n    # 지정된 벤치마크에 대한 상대적 수익률 계산\n    ...\n\n# 이하 모든 내용은 계속되도록 하겠습니다.\n```\n\n위의 코드를 번역해드렸습니다. 다른 질문이나 도움이 필요하시면 언제든지 말씀해주세요!","ogImage":{"url":"/TIL/assets/img/2024-07-13-HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-HowtoCreateaRisk-OnvsRisk-OffStockMarketDashboardinPythonPartIVDynamicTimeWarping_0.png","tag":["Tech"],"readingTime":14},{"title":"심볼릭 회귀로 데이터 속 숨겨진 법칙 찾는 방법","description":"","date":"2024-07-13 19:30","slug":"2024-07-13-FindHiddenLawsWithinYourDatawithSymbolicRegression","content":"\n\n<img src=\"/TIL/assets/img/2024-07-13-FindHiddenLawsWithinYourDatawithSymbolicRegression_0.png\" />\n\n기계 학습 전문가로서, 보통 데이터셋(X, y)을 갖고 있고, M이라고도 불리는 함수를 찾고 싶어합니다. M(X) ≈ y를 만족하는 함수입니다. 보통, 우리는 M의 함수 형태에 크게 신경 쓰지 않습니다. 우리 관점에서는, 모델이 신경망, 트리 기반 알고리즘 또는 완전히 다른 것이든 간에 테스트 세트에서 좋은 성능을 보이면 만족합니다.\n\n하지만, 이러한 복잡한 모델을 사용하면 흥미로운 패턴이나 때로는 데이터 내에 잠재된 물리학이나 경제법칙을 놓칠 수 있습니다. 더 나은 결과를 얻기 위해, Symbolic Regression을 사용하여 모델을 구축하는 방법을 보여드리겠습니다. 이러한 모델은 소수의 항만으로 구성되어 어디서든 쉽게 구현할 수 있습니다. 이것이 무엇인지 살펴볼까요?\n\n# 물리학 실험\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n실험 물리학자로서 지정한 높이 h에서 물체를 떨어뜨렸을 때 땅에 도달하는 데 얼마나 걸리는지 알아보고 싶습니다. 예를 들어, h = 1.5m의 높이에서 (공기 저항에 영향받지 않을만큼 충분히 무거운) 물체를 떨어뜨린다면, 땅에 도달하는 데 약 0.55초가 걸립니다. 한 번 시도해보세요!\n\n그러나 이는 지구나 중력 가속도가 9.8067m/s²인 다른 천체에만 해당됩니다. 예를 들어, 달은 1.625m/s²의 중력 가속도를 갖고 있어 같은 물체를 1.5m에서 떨어뜨리면 약 1.36초가 더 걸립니다. 영화에서 보던 것과 일치할 것입니다.\n\n이제, 우리의 작업은 땅에 도달하는 데 필요한 시간을 알려주는 일반적인 공식 t(h, g)를 찾는 것입니다. 이는 단순히 높이 h와 중력 가속도 g 값을 가져와 시간 t를 예측하는 모델을 만드는 것에 불과합니다. 나에게 참아주십시오, 친애하는 물리학자분들. 😃\n\n## 데이터 수집 및 모델 훈련\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우주선을 타고 날아다닌 다음 다양한 높이와 행성에서 몇 가지 물건을 떨어뜨렸고, 항상 땅에 도달하는 데 걸리는 시간을 측정했다고 가정해 봅시다. 측정값의 첫 번째 행들은 다음과 같습니다:\n\n| 높이 (h) | 중력 (g) | 시간 (t) |\n| ------- | ------- | ------- |\n| 10      | 9.81    | 1.43    |\n| 20      | 9.81    | 2.01    |\n| 30      | 3.72    | 2.67    |\n\n이제 이를 훈련 세트와 테스트 세트로 나누어 표준 기계 학습 모델을 훈련시켜 볼 수 있습니다.\n\n```python\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv(\"https://raw.githubusercontent.com/Garve/towards_data_science/main/Symbolic%20Regression/free_fall.csv\")\nX = data[[\"h\", \"g\"]]\ny = data[\"t\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n\nrf = RandomForestRegressor(random_state=123).fit(X_train, y_train)\nprint(rf.score(X_test, y_test))\n\n# 출력:\n# 0.9874788707086176\n```\n\n언제든지 궁금한 점이 있으면 물어봐 주세요!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n좋아요, 매우 잘 숨겨진 패턴을 학습하는 모델을 만들었네요. 근데... 그 패턴이 뭘까요?\n\n## 모델 해석\n\n실제로 모델 내부에 존재하는 복잡한 공식 때문에 알아내기 어렵습니다. Shapley 값들을 사용하여 모델이 무엇을 배웠는지 살펴볼 수 있습니다. 이 기사에서는 그들이 무엇인지 정말로 알 필요는 없지만, 여전히 관심이 있다면 제 다른 글을 확인하는 것을 추천합니다:\n\n기본적으로, 다양한 특징이 모델의 결과에 어떤 영향을 미치는지를 결정할 수 있게 해줍니다. 멋진 shap 라이브러리를 사용하여 다음을 할 수 있어요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# !pip install shap\nimport shap\n\nte = shap.TreeExplainer(rf, feature_names=[\"h\", \"g\"])\nshapley_values = te(X)\nshap.plots.scatter(shap_values=shapley_values)\n```\n\n![FindHiddenLawsWithinYourDatawithSymbolicRegression_2](/TIL/assets/img/2024-07-13-FindHiddenLawsWithinYourDatawithSymbolicRegression_2.png)\n\n왼쪽에서는 높은 h 값이 더 높은 모델 출력, 즉 더 높은 t 값을 초래한다는 것을 볼 수 있습니다. 오른쪽에서는 g 값이 낮을수록 모델에 따르면 더 높은 t 값을 얻는 것을 볼 수 있습니다. 두 관측 결과는 모두 이해하기 쉽습니다: 높은 곳에서 물체를 떨어뜨리면 땅에 닿을 때까지 더 오래 걸립니다. 그리고 지면 쪽으로 강한 힘으로 끌려오게 되면 그것은 더 빨리 땅에 닿을 것입니다.\n\n보통 이러한 결과가 나오면 만족하고 모델을 배포할 수 있습니다. 그럼에도 불구하고, 이 접근 방식에는 몇 가지 문제가 있다고 주장할 수도 있습니다:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 모델이 꽤 복잡하므로 이론적 통찰이 전혀 없습니다.\n- 그래서 우리는 scikit-learn 모델로 배포해야 하는데, 우리의 배포 서비스가 scikit-learn 모델을 좋아하지 않을 때 쉽게 다시 구현할 수 없습니다.\n\n이 두 문제를 해결하는 다른 모델을 어떻게 구축할 수 있는지 살펴봅시다.\n\n# 기호 회귀\n\n기호 회귀라는 기술을 활용할 수 있습니다. 이 기술은 데이터를 설명하는 간단한 대수적 표현을 찾으려고 합니다. 예를 들어, 특성 x₁, x₂ 및 x₃ 및 타겟 y로 구성된 데이터 세트에서 모델 학습 결과는 y = √x₁ + sin(x₂/(x₃+1)) 또는 y = exp(x₁²) - x₂ 와 같을 수 있습니다. \"자유 낙하\" 데이터 세트에서 이 모델이 어떻게 수행되는지 확인해봅시다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n심볼릭 회귀를 위한 많은 패키지가 있습니다. 예를 들어 gplearn과 PySR이 있어요. 여기서는 gplearn을 사용할 거에요. 살짝 더 쉽게 사용할 수 있어서요. 하지만 안타깝게도 2년 동안 업데이트되지 않았어요. PySR은 활발히 개발 중이지만 밑바닥에는 Julia를 사용하기 때문에 또 다른 종속성이 생기는 거에요.\n\n## 심볼릭 회귀 맞춤\n\n먼저 gplearn을 설치해볼게요. pip install gplearn을 통해 간단하게 설치할 수 있어요. 그리고 SymbolicRegressor를 정의하고, 덧셈이나 로그 취하기와 같은 연산을 공식 내에서 사용할 수 있도록 설정해보아요.\n\n```python\nfrom gplearn.genetic import SymbolicRegressor\n\nsr = SymbolicRegressor(\n    function_set=(\n        \"add\",\n        \"sub\",\n        \"mul\",\n        \"div\",\n        \"sqrt\",\n        \"log\",\n        \"abs\",\n        \"neg\",\n    ),\n    random_state=0,\n)\n\nsr.fit(X_train, y_train)\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금 모델은 다음과 같은 공식을 찾으려고 노력합니다:\n\n- 간단하면서도\n- 데이터를 잘 설명하는 즉, 손실이 적은 공식\n\n제 경우에는 다음과 같은 결과가 나왔어요:\n\n![이미지](/TIL/assets/img/2024-07-13-FindHiddenLawsWithinYourDatawithSymbolicRegression_3.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는\n\n\n![Physical laws rediscovered by PySR authors](/TIL/assets/img/2024-07-13-FindHiddenLawsWithinYourDatawithSymbolicRegression_4.png)\n\nsince x₀ = h and x₁ = g. Apart from having a test r² of over 0.999, this is actually the correct physics formula that describes falling objects without air resistance! You might also find the equivalent formula h = 0.5 · g · t² in literature.\n\nAnd don’t only take it from me. The authors of PySR published a paper in which they show how many more physical laws could be rediscovered. On page 16, you can see this table:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n표 태그를 Markdown 형식으로 변경하세요.\n\n열을 보면 심볼릭 회귀 라이브러리들이 나와 있어요. 왼쪽에는 물리 법칙이 있구요. 셀 안의 분수는 올바른 표현을 찾은 횟수를 전체 시도 횟수로 나눈 것이에요. 다음은 수식들이에요:\n\nPlanck의 법칙과 Rydberg 공식은 어떤 라이브러리도 발견하기 어려웠어요. 그래도 PySR만 다른 경우에 잘하고 있었어요. gnlearn은 비교 대상이 아니었어요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 어떻게 이 마법이 작동할까요?\n\n우리 모델의 기능 형태는 완전히 미친 것일 수 있습니다. 이는 신경망에서 일어나는 일과 근본적으로 다릅니다. 신경망에서는 공식 자체가 고정되어 있고 매개변수만 조정됩니다. 또는 그라디언트 부스팅과 같은 트리 기반 알고리즘에서는 결과가 언제나 조각별 상수 함수가 됩니다.\n\n길게 말하면, 이 기사에서 다루기에는 너무 길 것인 내재하는 진화 알고리즘을 사용합니다. 이들은 매우 무작위하고 휴리스틱한 프로세스이며, 극도로 분석하기 어렵습니다. 그래도 실전에서는 상당히 잘 작동할 수 있습니다. 만약 진화 알고리즘에 대해 초보자를 위한 기사를 읽고 싶다면, 제 다른 기사를 확인해 보세요:\n\n지금 읽기 싫다면, 현재 사용 사례에 대한 핵심 아이디어는 여기에 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 간단한 무작위 수식들로 시작해보세요, 예를 들어 t = h, t = g², t = g + h, t = √h, ...\n- 평가 지표로 예를 들어 평균 제곱 오차를 사용해 그들이 얼마나 좋은지 확인해보세요.\n- 가장 좋은 수식들을 선택하여 결합해보세요, 예를 들어 t = h와 t = g²를 결합하면 t = h + g²가 될 수 있습니다. 또는 t = √h와 t = h · g를 결합하면 t = √(h · g)가 될 수 있습니다.\n- 그들을 변형할 수도 있습니다. 예를 들어, t = √(h·g)를 약간 변경하여 t = √(h + g)로 변형할 수 있습니다.\n- 이제 새로운 수식 집합이 있으므로 다시 1단계로 돌아갈 수 있습니다. 또는 이미 아주 좋은 수식을 찾은 경우 중단할 수도 있습니다.\n\n이러한 절차를 구현하는 방법은 사용하는 라이브러리에 따라 다를 수 있습니다. 이러한 알고리즘을 작성하는 것이 정말 재미있는 일이 될 수 있도록 이러한 단계를 설계하는 데 많은 자유가 주어집니다. PySR 저자들은 논문에서 그들만의 진화 알고리즘 특정 버전을 설명하고 있습니다.\n\n# 결론\n\n이 글에서는 의미 있는 수식으로 모델을 구축하는 것이 얼마나 쉬운지 살펴보았습니다. 예를 들어, 우리의 예제에서는 테스트 세트의 성능뿐만 아니라, 더 나았습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어, SQL로 이동하여 다음과 같이 작성할 수 있어요:\n\n```js\nSELECT\n  h,\n  g,\n  SQRT(2 * h / g) AS t_pred\nFROM\n  your_table\n```\n\n그럼 이제 시작해봅시다! 이 공식을 선택하는 어떤 프로그래밍 언어에서도 쉽게 다시 구현할 수 있어요.\n\n물론 공식이 항상 간단하거나 데이터를 잘 설명하지는 않을 수 있어요. 이 경우에는 항상 사인, 지수 함수와 같은 다른 연산을 추가하거나, 자체 작은 빌딩 블록을 만들 수 있어요. 이것은 다시 명확한 공식을 만드는 데 도움이 될 수 있어요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오늘 새롭고 흥미로운, 가치있는 것을 배우셨기를 바랍니다. 읽어 주셔서 감사합니다!\n\n그리고 알고리즘의 세계로 더 깊이 파고들고 싶다면, 제 새로운 출간물 '알고리즘에 관한 모든 것'을 한 번 살펴보세요! 아직 작가를 모집 중입니다!","ogImage":{"url":"/TIL/assets/img/2024-07-13-FindHiddenLawsWithinYourDatawithSymbolicRegression_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-FindHiddenLawsWithinYourDatawithSymbolicRegression_0.png","tag":["Tech"],"readingTime":10},{"title":"Python과 OpenCV, FER을 사용한 실시간 감정 인식 방법","description":"","date":"2024-07-13 19:28","slug":"2024-07-13-Real-TimeEmotionRecognitioninPythonwithOpenCVandFER","content":"\n\n![이미지](/TIL/assets/img/2024-07-13-Real-TimeEmotionRecognitioninPythonwithOpenCVandFER_0.png)\n\n감정 인식 기술은 심리학, 인공지능 및 컴퓨터 과학의 흥미로운 교차점을 제시합니다. 우리는 영상 처리를 위해 OpenCV의 기능을 이용하고, 얼굴 감정 인식(FER) 라이브러리를 활용하여 비디오 피드에서 실시간 감정 검출을 제공합니다.\n\n이 방법은 얼굴 표정을 캡처하고, 딥러닝 모델을 사용하여 감정 상태를 해석하며, 이러한 감정을 동적으로 시각화하는 것을 포함합니다. 실용적인 응용 프로그램은 소프트웨어에서 사용자 경험을 향상시키는 것부터 감정 인식 AI 시스템에 대한 통찰력을 제공하는 것까지 다양합니다.\n\n이 기사는 실용적인, 처음부터 끝까지의 코드 구현을 제공합니다. 웹캠이나 화면 녹화, 비디오 파일 등을 통해 실시간으로 감정을 캡처하고 분석할 수 있는 플러그 앤 플레이 솔루션을 개발자 및 열성가 모두에게 제공합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1. 기술 스택\n\n## 1.1 FER (Facial Emotion Recognition)\n\nFER은 얼굴 표정에서 감정을 감지하는 데 중점을 둔 Python 라이브러리입니다. 사전 학습된 딥 러닝 모델을 활용하여 FER은 이미지와 비디오를 분석하여 분노, 혐오, 두려움, 행복, 슬픔, 놀라움, 중립 등 다양한 감정을 식별합니다.\n\n이는 사용 편의를 고려하여 설계되었으며, 감정 감지가 필요한 프로젝트에 간편하게 통합할 수 있습니다. 출처: PyPI — FER.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 1.2 OpenCV (오픈 소스 컴퓨터 비전 라이브러리):\n\nOpenCV는 컴퓨터 비전 분야에서 핵심적인 라이브러리입니다. 인텔에서 처음 개발되었으며, 이미지 및 비디오 처리에 널리 사용됩니다. OpenCV는 Python을 포함한 다양한 프로그래밍 언어를 지원하며, 실시간 응용 프로그램에서 높은 효율성으로 알려져 있습니다.\n\n이 라이브러리는 이미지 및 비디오 조작에서 중요한 역할을 하며, 웹캠 피드 캡처, 비디오 처리, 이미지 위에 주석 그리기와 같은 작업에 이상적입니다. 출처: OpenCV 문서.\n\n## 1.4 MediaPipe (여기에서 사용되지 않음)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희가 실시간 감정 인식 기술 스택에 대해 논의한 맥락에서, 이 구체적인 구현에는 사용되지는 않지만, MediaPipe를 언급할 가치가 있습니다. 독자들이 정보를 얻는 데 도움이 될 것이라고 생각합니다.\n\nMediaPipe는 Google이 개발한 프레임워크로서 멀티모달(오디오, 비디오, 시계열 등) 적용 기계 학습 파이프라인을 구축하는 데 사용됩니다. 실시간 및 스트리밍 미디어에 대한 사용자 정의 가능한 기계 학습 솔루션을 제공하며, 특히 얼굴 인식, 손 추적, 자세 추정 기능으로 잘 알려져 있습니다.\n\nMediaPipe는 실시간 이미지 및 비디오 처리에 대해 자세히 탐구하는 독자들이 가치 있는 도구로 여길 수 있습니다.\n\n특히 얼굴 감정 인식 이상의 더 복잡하거나 다양한 유형의 시각 데이터 처리 및 인식 작업이 요구되는 시나리오에서 특히 강력한 도구입니다. 출처: MediaPipe Github.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 2. 파이썬 구현\n\n구현은 간단하며 주로 네 가지 라이브러리가 필요합니다: FER, OpenCV, matplotlib 및 imageio.\n\n감정 인식 코드를 실행하기 위해 환경을 설정하려면 필요한 라이브러리를 설치해야 합니다. 명령 프롬프트 또는 터미널을 통해 다음 명령을 실행하세요:\n\n```js\npip install fer\npip install opencv-python\npip install matplotlib\npip install imageio\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 2.1 실시간 감정 감지\n\n파이썬을 사용하여 실시간 감정 감지의 기본 개념을 소개합니다. 지금은 간단하고 액세스하기 쉽도록 유지하기 위해 핵심 기능을 보여주는 기본 스크립트부터 시작합니다.\n\n이 초기 예제는 웹캠에서 비디오를 캡처하고 FER 라이브러리를 사용하여 실시간으로 감정을 감지하는 데 초점을 맞출 것입니다.\n\n우리의 예제에서는 라이브 웹캠 피드를 사용하지만, 이 스크립트를 다른 소스와 함께 사용할 수 있습니다. 예를 들어, 웹캠 피드를 비디오 파일이나 라이브 화면 녹화로 대체할 수도 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 웹캠 피드 시작: 먼저 웹캠에서 비디오를 캡쳐하기 위해 OpenCV를 사용합니다. OpenCV의 VideoCapture 함수는 웹캠 피드를 초기화합니다. 대부분의 경우, VideoCapture에 0을 전달하면 기본 웹캠이 선택됩니다.\n- 감정 감지: 그 다음으로는 비디오 프레임에서 감정을 감지하는 간단한 인터페이스를 제공하는 FER 라이브러리를 활용합니다. 웹캠에서 프레임이 캡쳐되면 FER는 프레임을 처리하여 얼굴과 해당 감정을 감지합니다.\n- 감지된 감정 강조: 감정이 감지되면 OpenCV 함수를 사용하여 비디오 프레임에서 감지된 얼굴에 경계 상자와 텍스트 주석을 그립니다. 텍스트 레이블은 감지된 감정과 해당 신뢰 수준을 표시합니다.\n\n```js\nfrom fer import FER\nimport cv2\n\n# 감정 감지기 초기화\ndetector = FER(mtcnn=True)\n\n# 웹캠 시작\ncap = cv2.VideoCapture(0)\n\ntry:\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # 프레임에서 감정 감지\n        result = detector.detect_emotions(frame)\n        for face in result:\n            # 값을 추출\n            box = face[\"box\"]\n            emotions = face[\"emotions\"]\n\n            x, y, w, h = box\n            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n            \n            # 가장 높은 점수의 감정 찾기\n            emotion_type = max(emotions, key=emotions.get)\n            emotion_score = emotions[emotion_type]\n\n            # 감정 유형과 신뢰 수준 표시\n            emotion_text = f\"{emotion_type}: {emotion_score:.2f}\"\n            cv2.putText(frame, emotion_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n        # 결과 프레임 표시\n        cv2.imshow('Emotion Detection', frame)\n\n        # 루프 종료\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\nexcept KeyboardInterrupt:\n    print(\"사용자에 의해 중지됨\")\nfinally:\n    # 모든 작업이 완료되면 캡처 해제\n    cap.release()\n    cv2.destroyAllWindows()\r\n```\n\n## 2.2 실시간 감정 시각화\n\n기본적인 실시간 감정 감지 스크립트를 기반으로, 실시간 감정 시각화 기능을 추가한 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 업데이트는 감정 감지 응용 프로그램에 더 다이내믹하고 상호작용 가능한 측면을 추가하여 데이터를 더 매력적이고 통찰력 있게 만듭니다.\n\n실시간 감정 막대 차트 생성: 각 프레임에서 감지된 감정을 시각화하기 위해, 우리는 파이썬의 강력한 플로팅 라이브러리인 matplotlib을 사용합니다. 다음은 설정하는 방법입니다:\n\n- 우리는 matplotlib 피겨를 초기화하고 각 감정에 대한 자리 표시자를 가진 막대 차트를 만듭니다.\n- 차트의 각 막대는 감정을 나타내며, FER에 의해 감지된 신뢰 수준을 실시간으로 업데이트하여 높이가 조정됩니다.\n\n```python\nimport matplotlib.pyplot as plt\n\nplt.ion()  # 대화형 모드를 활성화\nfig, ax = plt.subplots()\nemotion_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\nbars = ax.bar(emotion_labels, [0]*7, color='lightblue')\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMatplotlib의 대화형 모드: 대화형 모드를 활성화하면 (plt.ion()), matplotlib의 플롯이 실시간으로 업데이트됩니다. 이를 통해 바 차트가 감정 감지 알고리즘에 의해 처리된 각 새 프레임마다 동적으로 새로 고쳐질 수 있습니다.\n\n차트 업데이트: 감지된 감정을 가져와 각 막대의 높이를 업데이트하는 update_chart 함수를 만듭니다. 이 함수는 처리된 각 프레임에서 호출되어 차트가 현재 감지된 감정을 정확히 반영하도록 합니다.\n\n```js\ndef update_chart(detected_emotions, bars, ax, fig):\n    ax.clear()\n    ax.bar(emotion_labels, [detected_emotions.get(emotion, 0) for emotion in emotion_labels], color='lightblue')\n    ### [차트 서식의 나머지 부분]\n    fig.canvas.flush_events()\n```\n\n주요 루프에서 차트 업데이트 통합: 스크립트의 주요 루프에서 각 프레임에서 감정을 감지한 후, 최신 감정 데이터로 update_chart를 호출합니다. 이렇게 함으로써 시각화가 비디오 피드와 동기화되도록 유지됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\r\n# 감정 감지 및 시각화를 위한 주요 루프\nwhile True:\n    # [웹캠 캡처 및 감정 감지 코드]\n\n    if largest_face:\n        # [얼굴 처리 및 감정 점수 매기기]\n        \n        # 최신 감정 데이터로 실시간 막대 차트 업데이트\n        update_chart(current_emotions, bars, ax, fig)\r\n```\n\n모두 합쳐서 다음과 같은 포괄적인 Python 스크립트를 얻습니다.\n\n```js\r\nfrom fer import FER\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport imageio\nimport matplotlib\nimport time\n\n\"\"\"\n실시간 감정 감지 및 시각화\n\n이 스크립트는 웹캠에서 비디오를 캡처하고 실시간으로 얼굴의 감정을 감지하여 결과를 실시간으로 시각화하는 기능을 제공합니다. \n또한 감지된 감정과 함께 비디오 자체에도 표시된 상자와 감정 레이블을 저장합니다. 또한 실시간 감정 막대 차트를 GIF로, \n누적 감정 통계도 정적 차트로 저장합니다. 이 스크립트는 비디오 처리를 위해 OpenCV, 감정 감지를 위해 FER, 라이브 차트 시각화를 \n위해 matplotlib, GIF 제작을 위해 imageio를 사용합니다.\n\n주요 기능:\n- 웹캠에서 실시간 감정 감지.\n- 막대 차트에서 감정 확신 수준을 실시간으로 업데이트.\n- 얼굴 주위의 경계 상자 및 감정 레이블이 있는 비디오 캡처 저장.\n- 라이브 감정 막대 차트의 GIF 생성.\n- 시간에 따른 감정 통계의 누적 차트 저장.\n\"\"\"\n\n# matplotlib의 백엔드를 다양한 환경과 호환되도록 'TkAgg'로 설정\nmatplotlib.use('TkAgg')\n\n# MTCNN을 사용하는 FER (Face Emotion Recognition) 탐지기를 초기화\ndetector = FER(mtcnn=True)\n\n# 웹캠에서 비디오 캡처 시작 (장치 0)\ncap = cv2.VideoCapture(0)\n\n# 비디오 녹화용 프레임 속도 설정 (웹캠의 성능에 따라 조정)\nframe_rate = 4.3\n\n# 지정된 프레임 속도로 비디오를 저장하는 OpenCV의 VideoWriter 초기화\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter('emotion_video.avi', fourcc, frame_rate, (640, 480))\n\n# 라이브 감정 감지 결과를 표시할 matplotlib 피겨 설정\nplt.ion()  # 라이브 업데이트를 위한 대화형 모드 활성화\nfig, ax = plt.subplots()\nemotion_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\nbars = ax.bar(emotion_labels, [0]*7, color='lightblue')  # 각 감정을 위한 막대 초기화\nplt.ylim(0, 1)\nplt.ylabel('신뢰도')\nplt.title('실시간 감정 감지')\nax.set_xticklabels(emotion_labels, rotation=45)\n\n# 라이브 차트 업데이트를 GIF로 저장하기 위해 imageio 라이터 초기화\ngif_writer = imageio.get_writer('emotion_chart.gif', mode='I', duration=0.1)\n\n# 각 프레임에 대한 누적 감정 통계를 저장할 리스트\nemotion_statistics = []\n\n# 라이브 차트 업데이트 함수\ndef update_chart(detected_emotions, bars, ax, fig):\n    ax.clear()  # 현재 축 지우고 다시 막대 차트 설정\n    ax.bar(emotion_labels, [detected_emotions.get(emotion, 0) for emotion in emotion_labels], color='lightblue')\n    plt.ylim(0, 1)\n    plt.ylabel('신뢰도')\n    plt.title('실시간 감정 감지')\n    ax.set_xticklabels(emotion_labels, rotation=45)\n    fig.canvas.draw()\n    fig.canvas.flush_events()\n\n# 웹캠 작동 시간을 측정하기 위해 타이머 시작\nwebcam_start_time = time.time()\n\ntry:\n    while True:\n        ret, frame = cap.read()  # 웹캠에서 프레임 읽기\n        if not ret:\n            break  # 캡처된 프레임이 없으면 루프 종료\n\n        # 프레임에서 감정 감지\n        result = detector.detect_emotions(frame)\n        largest_face = None\n        max_area = 0\n\n        # 주요 감정 분석을 위해 프레임에서 가장 큰 얼굴 찾기\n        for face in result:\n            box = face[\"box\"]\n            x, y, w, h = box\n            area = w * h\n            if area > max_area:\n                max_area = area\n                largest_face = face\n\n        # 얼굴이 감지되면 감정 표시 및 차트 업데이트\n        if largest_face:\n            box = largest_face[\"box\"]\n            current_emotions = largest_face[\"emotions\"]\n\n            # 감정 데이터 저장\n            emotion_statistics.append(current_emotions)\n\n            x, y, w, h = box\n            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n            \n            emotion_type = max(current_emotions, key=current_emotions.get)\n            emotion_score = current_emotions[emotion_type]\n\n            emotion_text = f\"{emotion_type}: {emotion_score:.2f}\"\n            cv2.putText(frame, emotion_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n            update_chart(current_emotions, bars, ax, fig)\n\n            out.write(frame)  # 프레임을 비디오 파일에 씀\n\n            # 현재 막대 차트 상태를 GIF의 한 프레임으로 저장\n            fig.canvas.draw()\n            image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n            image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n            gif_writer.append_data(image)\n\n        cv2.imshow('감정 감지', frame)  # 프레임 표시\n\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n        \nexcept KeyboardInterrupt:\n    print(\"사용자에 의해 중단됨\")\n\nfinally:\n    webcam_end_time = time.time()  # 웹캠 창이 닫힐 때 타이머 종료\n    print(f\"웹캠 활동 시간: {webcam_end_time - webcam_start_time:.2f} 초\")\n\n    cap.release()\n    cv2.destroyAllWindows()\n    plt.close(fig)\n\n    out.release()\n    gif_writer.close()\n\n    emotion_df = pd.DataFrame(emotion_statistics)\n\n    plt.figure(figsize=(10, 10))\n    for emotion in emotion_labels:\n        plt.plot(emotion_df[emotion].cumsum(), label=emotion)\n    plt.title('시간에 따른 누적 감정 통계')\n    plt.xlabel('프레임')\n    plt.ylabel('누적 신뢰도')\n    plt.legend()\n    plt.savefig('cumulative_emotions.jpg')\n    plt.close()\r\n```\n\n## 2.3 보너스 — 결과 병합하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n감정 감지 기술의 진정한 힘은 데이터를 포괄적이고 매력적인 방식으로 시각화할 때 발휘됩니다. 이를 달성하기 위해 다양한 출력물을 하나의 시각적 프레젠테이션으로 효과적으로 결합하는 스크립트를 개발했습니다. 이 스크립트는 세 가지 요소를 효과적으로 조화시킵니다:\n\n- 실시간 비디오: 웹캠 피드에서 캡처한 감정 감지 결과가 'emotion_video.avi'로 저장됩니다.\n- 동적 막대 차트 GIF: 감지된 감정을 실시간으로 업데이트하는 차트가 'emotion_chart.gif'로 저장됩니다.\n- 정적 누적 감정 차트: 'cumulative_emotions.jpg'라는 이미지 파일에 시간에 따른 집계된 감정 데이터가 표시됩니다.\n\n스크립트에서 중요한 코드 일부:\n\n- 입력값 읽기 및 처리:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nstatic_chart = Image.open('cumulative_emotions.jpg')\nvideo = cv2.VideoCapture('emotion_video.avi')\nbar_chart_gif = imageio.mimread('emotion_chart.gif')\n```\n\n- Frames를 조합하는 로직:\n\n```js\ncombined_frame = Image.new('RGB', (3 * desired_width, desired_height))\ncombined_frame.paste(video_frame_resized, (0, 0))\ncombined_frame.paste(gif_resized, (desired_width, 0))\ncombined_frame.paste(static_chart_resized, (2 * desired_width, 0))\n```\n\n더 자세한 코드와 기술적인 세부 정보를 탐험하고 싶은 분들을 위해, AI, 데이터 과학 및 기술에 대한 다양한 기술 튜토리얼 및 실용적인 가이드가 포함된 리소스인 우리 웹사이트인 Entreprenerdly.com을 방문하시기를 권장합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 프로젝트와 다른 많은 프로젝트의 완전한 코드를 찾을 수 있습니다. 최신 기술 솔루션을 배우고 구현하는 실전적인 방법을 제공합니다.\n\n![이미지](/TIL/assets/img/2024-07-13-Real-TimeEmotionRecognitioninPythonwithOpenCVandFER_1.png)\n\n## 5. 실용적인 응용\n\n- 보안 시스템: 감정 인식은 보안 시스템에 추가적인 보호층을 추가할 수 있습니다. 감정 신호에 기반하여 의심스러운 또는 이례적인 행동을 식별할 수 있습니다.\n- 의료 및 정신 건강: 임상 환경에서 감정 인식은 환자의 정신 건강 상태를 모니터링하는 데 도움을 줄 수 있습니다. 특히 텔레치료 세션에서 유용하며, 환자의 감정 반응에 대한 추가적인 통찰을 제공하여 요법사에게 도움이 될 수 있습니다.\n- 사용자 경험 및 인터페이스 디자인: 웹사이트와 애플리케이션은 감정 인식을 사용하여 사용자 경험을 맞춤화할 수 있습니다. 혼란 또는 불만의 징후를 감지하여 유용한 프롬프트를 트리거하거나 사용자가 더 관련 있는 콘텐츠로 안내할 수 있습니다.\n- 로봇과 인공지능: 로봇 공학에서 감정 인식은 AI 및 로봇과의 상호 작용을 더 자연스럽고 직관적으로 만들 수 있습니다. 특히 요양이나 고객 서비스 로봇에서 유용합니다.\n- 접근성 기술: 언어 또는 청각 장애가 있는 사람들을 위해 감정 인식 기술은 화자의 감정 상태에 대한 추가적인 문맥을 제공하여 의사 소통을 용이하게 할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 6. 한계와 개선점\n\n## 6.1 한계\n\n- 정확도와 데이터 의존성: 감정 감지의 정확도는 FER 모델의 훈련 데이터에 크게 의존합니다. 이 데이터의 편견은 잘못된 또는 일관되지 않은 감정 인식으로 이어질 수 있으며, 특히 다양한 인구 통계군 사이에서 발생할 수 있습니다.\n- 맥락적 이해: 시스템은 감정의 맥락을 이해하기 항해 합니다. 얼굴 표정을 인식하지만 이러한 표정 뒤의 이유를 추론하거나 진짜 감정과 가짜 감정을 구별할 수 없습니다.\n- 조명 및 영상 품질: 웹캠 영상의 품질, 포함하여 조명 조건과 해상도는 감지 정확도에 큰 영향을 미칠 수 있습니다. 낮은 영상 품질은 신뢰할 수 없는 감정 인식으로 이어질 수 있습니다.\n- 개인정보 우려: 감정 인식 기술을 사용함에 있어, 특히 공개적 또는 준공개적 공간에서는 개인정보 문제가 우려됩니다. 이러한 시스템을 구현할 때는 동의와 윤리적 고려가 매우 중요합니다.\n\n## 6.2 개선 가능한 부분:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 향상된 머신러닝 모델: 더 발전된 머신러닝 모델을 통합하거나 기존의 FER 모델을 사용자 정의함으로써 정확성을 향상시키고 편향을 줄일 수 있습니다.\n- 맥락을 인지하는 알고리즘: 상황의 맥락을 고려하는 알고리즘을 개발하면 보다 세밀한 감정 분석을 제공할 수 있습니다.\n- 실시간 처리 최적화: 코드를 효율적으로 최적화하거나 더 강력한 처리 하드웨어를 사용함으로써 실시간 응용 프로그램에서의 대기 시간을 최소화할 수 있습니다.\n- 개인 정보 보호 대책: 엄격한 개인 정보 보호 규정을 시행하고 데이터 사용에 대한 투명성을 보장함으로써 개인 정보 보호 우려를 완화할 수 있습니다.\n\n# 결론\n\n이러한 강력한 도구들을 결합하여 감정을 실시간으로 감지할 뿐만 아니라 이러한 데이터를 매력적이고 유익한 방식으로 시각화할 수 있다는 것을 확인했습니다. 이 기술의 실용적인 응용은 건강 관리부터 마케팅에 이르기까지 다양하며 다양합니다. \n\n독자들에게는 이 기사가 현재 기술의 능력을 이해하고 그 잠재적인 응용 분야를 상상해 볼 수 있는 시작점으로 제공됩니다. 개발자, 연구자 또는 기술과 감정이 교차하는 부분에 관심이 있는 사람이라면 상상력만큼의 가능성이 넓게 열려 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Real-Time Emotion Recognition in Python with OpenCV and FER](/TIL/assets/img/2024-07-13-Real-TimeEmotionRecognitioninPythonwithOpenCVandFER_2.png)","ogImage":{"url":"/TIL/assets/img/2024-07-13-Real-TimeEmotionRecognitioninPythonwithOpenCVandFER_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-Real-TimeEmotionRecognitioninPythonwithOpenCVandFER_0.png","tag":["Tech"],"readingTime":17},{"title":"퀀트 트레이딩에 뛰어들기 전에 꼭 알아야 할 데이터 과학 분석의 비법","description":"","date":"2024-07-13 19:25","slug":"2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder","content":"\n\n의심에서 전략으로: 시장 동향, 거래 전술 및 데이터 과학 통찰력의 복잡한 망을 해체해보세요\n\n![이미지](/TIL/assets/img/2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_0.png)\n\n숫자와 화려한 수학 기교에 능숙하다는 것이 주식 시장에서 많은 돈을 벌 수 있는 열쇠라고 들어왔어요. 솔직히 말해서, 저도 그것에 대해 조금 의심스러웠어요. 그 이유는 여기 있어요.\n\n데이터 과학에 정말 관심이 많고 통계학 박사 학위도 가졌으며 여러 기업을 위한 예측에 많이 참여했고 일찍이 몇 번의 캐글 경연에서 우승한 경험이 있음에도 불구하고 주식 시장에 대해 모든 것을 알고 있다고 생각했어요. 경제와 주식이 어떻게 작동하는지에 대한 내 지식을 바탕으로 내가 잘할 거라고 확신했죠.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n하지만 내 아이디어를 시도할 때, 예상했던 대로 되지 않았어요. 꽤 충격적이었어요.\n\n#1: 주식 거래에서 이익과 손실 이해하기\n\n\"주식을 예측하는 것은 다른 사람들이 무엇을 생각하는지 추측하는 것과 같아요.\"\n\n주식 가격이 계속 상승하고 하락하는 것을 보면, 돈을 벌 생각이 자꾸 들어요. 그래프에서 가격이 급상승하는 것을 보면, 그 행동에 참여해서 그 기회로 돈을 벌 수 있을 것 같아요. 우리는 전에 일어난 일이 다시 일어날 것이라고 믿기 때문에, 과거에서 패턴을 찾아서 다음에 무엇이 일어날지 추측할 수 있다고 생각해요. 이건 마치 외출을 계획하기 전에 날씨를 확인하는 것과 비슷해요; 비가 올 걸 알면 우산을 가져가겠죠?\n\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n주식 가격을 예측하는 일은 날씨를 확인하는 것과는 다르지만, 그 아이디어는 비슷해요: 하나는 하루를 계획하는 데 관한 것이고, 다른 하나는 주식 시장에서 돈을 벌려고 하는 것이에요. 핵심은 과거 데이터의 추세를 파악하고 그 통찰을 이용해 앞으로 어떤 일이 일어날지 추측한 다음에는 그 예측에 따라 행동하는 거예요. 그러나 우리가 종종 놓치는 큰 문제가 있어요. 주식 가격을 예측하고 날씨를 예측하는 것은 다른 게임이에요. 날씨를 예측하는 것이 훨씬 간단하죠. 날씨에 대한 추측이 날씨를 어떻게 바꿀지에는 영향을 미치지 않아요. 날씨는 여러분이 맞추든 틀리든 자신의 길을 갈 거예요. 그러나 주식은 훨씬 복잡해요. 주식 시장은 빠르게 돈을 벌려고 하는 사람들로 가득 차 있고, 모두가 다음에 무엇이 일어날지 예측하려고 애를 쓰고 있어요. 문제는 이 모든 추측과 그것으로 이어지는 거래 행위가 예측을 망칠 수 있다는 거에요, 심지어 정말 똑똑한 알고리즘을 가지고 있더라도 말이에요. 여기서 '똑똑하다'는 것은 과거 데이터를 살펴본 결과에 의해 자기 자신을 증명한 것을 말해요. 이 문제는 간단해요: 여러분의 알고리즘은 절대로 다른 사람들이 어떻게 예측하고 그 예측에 따라 행동할지를 알 수 없다는 거죠.\n\n#2: 주식 시장: 빠른 매매 또는 장기 투자?\n\n\" 주식 예측: 단기간에 어려워 \"\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n알겠어요, 그럼 몇몇 똑똑한 경제학자들이 이에 대해 어떻게 생각하는지 살펴보겠습니다. 솔직히 말해서, 그들이 주장하는 모든 것에 난 전혀 납득이 되지 않아요. 하지만 한번 알아볼게요:\n\n2013년에 Eugene F. Fama, Lars Peter Hansen, Robert J. Shiller 세 명의 똑똑한 사람들이 경제학 노벨상을 수상했어요. 그들은 주식 시장의 움직임을 이해하고 이를 시장 효율성이라는 용어로 설명한 데서 이 상을 받았어요.\n\nEugene F. Fama는 효율적 시장 가설 (EMH)을 제시한 것으로 유명해요. 이 이론은 주식 가격에 이미 필요한 정보가 모두 담겨 있다고 주장하는데, 따라서 주식을 골라내거나 적절한 시기에 매수/매도하는 것으로 시장을 이기려는 것은 거의 불가능하다고 말해요. EMH에 따르면 장기적으로 주식 가격은 랜덤하게 움직이고, 그 이유는 새로운 정보에 따라 바뀌기 때문에 미리 예측할 수 없다고 해요.\n\n한편 Robert J. Shiller는 다른 견해를 가지고 있어요. 그는 시장이 항상 완벽하지 않을 수 있다고 생각하고, 주식 가격이 장기적으로 때때로 예측될 수 있다는 것을 발견한 것 같아요. 그 이유는 사람들의 행동, 변덕스러운 시장, 투자자들이 하는 심리전 등 때문이라고 해요. Shiller는 주식 가격이 실제 가치에서 벗어날 수 있다고 생각하며, 그럼으로서 멀리 앞을 내다보고 있다면 어디로 향하는지 추측할 수도 있다는 것이죠.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n내 이해에 따르면 두 사람 모두 어느 정도 동의합니다: 주식 가격을 예측하는 것은 특히 단기적으로는 랜덤한 추측이라는 점입니다. 주식 시장은 예측하기 어려운 플레이야죠. 그 의미는 오늘의 가격이 내일을 예측하기에 아무 가격이나 될 수 있다는 것이죠.\n\n거래자에게는 막다른 골목 같군요, 그렇죠? 하지만 진짜는 무엇일까요? 사실, 주식 시장에서 몇 가지 스마트한 지표만 가지고 있는 거래자들이 심각한 이익을 얻고 있다는 사실이 있습니다.\n\n#3: 거래자들은 어떻게 하는 걸까요?\n\n\"거래자 승리 뒤에 숨겨진 비밀 소스\"\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n나는 확실해, 노벨상 수상자들이 그들의 이론을 빛낼 때 어둠 속에서 다트를 던지지는 않았을 거야. 이런 사람들은 그저 어떤 경제학자들이 아닌 데이터 과학자들과 같은 사람들이라는 걸 명심해야 해. 그들은 충실한 데이터를 뒷받침하지 않고는 노벨상을 탈 수 없을 거야. 하지만 여기 백만 달러 질문이야: 현실 세계에서 우리가 본 것과는 어떻게 일치할까?\n\n길거리 소문에 따르면, 골드만삭스와 모간 스탠리와 같은 대형 투자은행의 트레이더들은 대박을 터트리는 경우가 훨씬 많다고 해. 주식 시장이 야생적이고 예측할 수 없는 야수라면, 이들이 어떻게 거대한 이익을 창출하고 있을까?\n\n이것이 의문을 품게 만들죠, 그렇지 않나요? 모든 것이 무작위적이고 예측할 수 없다면, 그들이 돈을 버는 비밀은 무엇일까요? 알려줄게요: 이 은행의 거래 고수들은 우리 대부분이 갖고 있지 않은 정보나 전략으로 게임을 하는 특별한 이점이 있다는 것이죠. 경제학자들이 말하는 주식 가격이 모두 무작위적이라는 이론은 대부분의 경우 일어나는 것과 더 관련이 있어요. 이러한 투자 은행은 다른 이들과 달리 게임을 즐기는 것이 아니에요. 일반 사람들이나 일간 트레이더들이 그들처럼 큰 돈을 벌고 싶다면, 그들과 마찬가지로 독특해져야 할 텐데, 그건 현실적으로 말이 쉽지 않아.\n\n그리고 만약 모두가 이 독특하고 굉장히 영리한 트레이더로 변한다면, 그럼 무엇이 생길까요? 더 이상 돈을 벌기 위한 비밀은 없어지겠죠, 그리고 그러면 누구도 이득을 내지 못할 거예요. 따라서 주식 시장은 결국 100% 효율적이지 않다는 거죠. 당신이 어디를 봐야 하는지, 다른 시간대, 산업, 변화나 거대 은행들이 가지고 있는 그런 기술과 도구를 갖추는 곳을 아는 등 추가 수익의 기회를 포착하고 활용하는 데 더 나은 기회를 갖는 것이죠.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼, 그들이 그 강력한 경쟁 우위를 얻는 방법은 무엇일까요?\n\n그래요, 간단히 말하자면:\n\n첫 번째로, 기관의 대형 트레이더들? 그들은 로봇과 함께 초고속 거래를 하거나 스스로 개입하기도 하는 것을 좋아해요. 이런 번개처럼 빠른 거래는 전체적인 \"주식 시장 규칙\" 아이디어를 교란시킬 수 있어요. 거리에서 걷고 있다면 모든 것이 질서 정연해 보이지만 비행기에서 본다면 모든 것이 혼돈스러울 수 있어요. 이 전문가들은 보통 사람들이 감지하지 못하는 가치 있는 것을 가까이서 발견할 수 있어요.\n\n그리고 기관 트레이더들은 하나의 주식이나 한 가지 방법에만 의지하지 않아요. 다양한 전략을 사용하면서 다른 주식에 대해 알아보고 데이터를 분석하며 산업 분위기를 점검하고 모든 것을 딱 맞게 타이밍해요. 하지만 이것을 이루기 위해서는 많은 정보, 시간, 에너지가 필요하죠. 한편, 일반 투자자들은 그냥 몇 가지 주식에 집중하고 최선을 다하기만을 희망할 수도 있어요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n세 번째, 대형 투자자들은 엄격한 규칙을 따르거나 기계들이 모든 일을 처리하도록 하는 등, 평범한 투자자들에겐 까다로운 작업이에요. 평범한 조(e)도가 이 특별한 양적 거래에 발을 담그려고 해봐도, 감정에 휩쓸려 실패할 수도 있어요. 주식 시장은 짐승과도 같고, 일반 투자자들에겐 단기 움직임을 추측하는 건 마치 벽에 젤리를 박는 것과 같아요. \n\n여기서 주목할 점은: 빠르게 현금을 벌고 있다면, 그 돈이 아마 다른 누군가의 지갑에서 나오는 것이고, 그 반대도 마찬가지에요. 통계적으로 보면, 이건 영(零)화 행위야. 단기간에 계속 이기는 사람이 있다면, 그들은 어떤 비밀 소스를 가지고 있거나, 대형 투자 은행과 같은 거대한 투자 은행일 거에요. 장기적으로 돈을 벌면, 이건 모두에게 좋을 수 있어요. 왜냐하면, 회사의 가치가 성장하는 것에 관한 거니까요. 하지만 장기 주가를 예측하기 쉽다고 생각하지 마세요 — 결국에는 회사의 성과를 어떻게 예상할 수 있는지에 달렸어요.\n\t\n#4: 일상 투자자들이 양적 거래로 승리할 수 있을까요?\n\n\"네, 하지만 모든 게 순조롭지는 않을 거예요...\"\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그래서, 당신은 매일 투자자로서 양적 거래를 통해 빠른 이익을 노리고 있는 거군요? 이렇게 준비하세요:\n\n- 먼저, 양적 거래 소프트웨어를 확보하거나 알고리즘을 만드세요. 기계가 완전히 대신하도록 하는 것이 아니라, 언제 사고 팔지에 대한 타이트한 조언을 얻는 것이 중요합니다.\n\n- 소매등을 걷어내고 알고리즘을 세밀하게 조정하는 준비를 하세요. 오늘 한 주식에서 성공을 거둬도, 내일에는 다른 주식에서 실패할 수도 있으며, 나중에 같은 주식에 대해서도 실패할 수 있습니다.\n\n- 당신이 벌어들이는 수익만큼이 아니라, 시장 지수에 비해 얼마나 잘 하는지를 기준으로 성과를 측정하세요. 시장을 능가하고 있다면, 올바른 길을 걷고 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 거래 비용과 세금을 주의 깊게 살펴보세요. 어떤 플랫폼들은 거래 수수료가 없는 것도 있지만, 거래를 많이 하면 세금을 내야합니다. 그렇게 되면 이익이 줄어들 수 있으니 주의하세요.\n\n#5: 데이터 과학 탐구: 거래의 엣지?\n\n“데이터 과학이 부자로 만들어주지는 않을지도 모르지만, 여러분의 거래 전략을 형성할 수는 있을 거예요…”\n\n그러니까, 솔직히 말해서 말이죠. 내가 양적 거래에 모든 것을 건다면 부자가 될 수 있을까요? 음, 정확히는 그렇지 않아요. 양적 거래를 저의 풀타임 직업으로 만드는 것이 제 계획은 아니에요. 저에게 궁금증을 자아내는 것은 데이터 과학이 일상적인 트레이더에게 어떤 이점을 제공할 수 있는지에 대한 것이에요. 또한, ChatGPT와 같은 고급 AI의 등장을 고려할 때, 데이터 과학자들을 대체할 수 있는 가능성이 있을까요?\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기 내 생각이야. 다음으로, 몇 가지 알고리즘 백테스팅에 뛰어들 거야. 이것에서 얻는 통찰력이 혹시 더 현명한 거래 결정으로 이어지기를 바랄게.\n\n#6: 거래 전략 디코딩\n\n\"코드로 뛰어들기 전에 양으로 거래 전략이 어떻게 작동하는지 이해하세요.\"\n\n세 가지 거래 전략을 살펴보자: '거북', 'RSI-Bollinger Bands', 그리고 직접적인 '매수 및 보유'. 마지막은 양적 방법이 아닌데요 — 이는 일반적인 지식이죠. 그러나 첫 두 가지는 지표를 활용하거나, 데이터 과학 용어로 말하자면, 통계 모델에 대한 예측자를 활용하고 있어. 새로운 예측자나 모델을 고안해볼까요? 음, 이러한 널리 사용되는 인디케이터와 방법은 거래자들에 의해 널리 사용되며 시장의 트렌드에 부합하고 성능을 향상시킬 수 있어요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n거북이 거래 방법\n\n이 접근법은 주식 거래를 예측의 게임으로 단순화합니다. 주식의 가격이 20일 최고점을 기록하면, 이는 추가 상승을 예상하여 매수 신호로 간주됩니다. 반대로, 20일 최저점으로 하락하면 매도 신호가 됩니다. 코드화된 전략은 이러한 규칙을 준수하여 거래 결정을 자동화하고, 시장 트렌드에 최적화하기 위해 각 움직임을 추적합니다.\n\nRSI-볼린저 밴드 전략\n\nRSI 및 볼린저 밴드라는 두 가지 도구로 이동 주식 가격을 대상으로 상상해보세요. RSI는 주식의 강도를 측정하여 성과가 부족한 주식에 대한 매수와 성과가 우수한 주식에 대한 매도를 제안합니다. 볼린저 밴드는 가격 경계를 설정하여, 가격이 이 한계를 넘을 때 조치를 취하도록 유도합니다. 코드화된 전략은 이러한 신호를 탐지하여 시장의 상승과 하락을 효과적으로 탐색하고 매수 또는 매도 결정을 내립니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nRSI(상대강도지수)는 주식의 건강도를 나타내는 미터와 같습니다. 이를 통해 주식이 강하거나 (상승할 가능성이 높음) 약한지 (하락할 가능성이 높음) 판단할 수 있습니다. 볼린저밴드는 과거 가격을 기반으로 설정된 경계선과 같습니다. 주식이 이러한 경계를 벗어나면, 그것은 행동할 시기일 수 있습니다.\n\n이러한 전략들을 잘 파악하면 거래자들이 시장의 움직임과 동기화할 수 있습니다. 이는 그들의 거래 방식을 업그레이드시켜, 더 스마트하고 명확한 거래를 할 수 있게 도와줄 수 있습니다.\n\n#6: 나의 주식 분석 게임 플랜 해설\n\n\"데이터 과학이 주식 퍼즐에서 당신의 길잡이가 되게 하라.\"\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금은 주식 분석에 대해 어떻게 다가가는지 알아보겠습니다. 저는 세 가지 핵심 전략인 – 거북이, RSI-Bollinger Bands, 그리고 클래식한 매수 및 보유 – 을 여러 가지 다른 섹터 ETF에서 실험 중이에요. 목표는 어떤 전략이 섹터에 상관없이 수익을 창출하고 손실을 피하는 데 능숙한지 찾는 것이에요. 게다가, 다양한 경제적 분위기에 부합하는 기간을 고려하여 상황을 파악하고 있답니다 – 번성하는, 위축되는, 또는 그냥 평온한 시장을 생각해보세요.\n\n여기서 처리할 일이 몇 가지 있어요: 전략들 자체, 탐험 중인 섹터, 그리고 경제적 시황 보고서까지도요. 왜 이렇게 번거롭게 하는 걸까요? 왜냐하면 주식 시장은 특히 단기간에는 난제이기 때문이죠. \"어떤 주식이 급등할까요? 마법같은 전략이 뭔가요?\"라는 질문으로 해결할 수 없어요. 올바른 움직임을 올바른 순간에 맞추는 게 중요한 거예요.\n\n이제 만날 시간이에요! (즉, ETF들을 의미하는) 주요 선수들을 살펴보겠습니다. 이들은 섹터별 ETF, 포괄적인 시장 개요, 그리고 금의 적당한 부분까지 혼합된 상태입니다.\n\n아래는 주식/ETF 티커들이 의미하는 내용에 대한 소개입니다. 이들은 섹터 ETF, 포괄적인 시장 ETF 및 상품 ETF의 혼합체입니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n탭을 변경하여 마크다운 형식으로 변경하세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- XLU: 전기공급업체에 중점을 둠\n- XLY: 소비자 물품에 초점을 맞춤\n- VIG: 성장하는 배당을 찾음\n- GLD: 금시세를 지켜봄\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- SPY: 미국 상위 500개 기업의 파동을 잡아요\n\n- DIA: 미국 주요 30개 기업을 살펴봐요.\n\n이러한 티커들이 내 필수품이에요. 너무 누락된 부분 없이 넓은 시야를 제공하기 때문이죠.\n\n그리고 시장을 시간여행하는 경우는 여기에요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 2020년 11월부터 2024년 2월까지: 시장 드라마를 다룬 40개월의 이야기\n\n- 2020년 11월부터 2022년 1월까지: 코로나19 대유행의 첫 번째 파도와 함께\n\n- 2021년 12월부터 2022년 10월까지: 코로나 후의 이자 인상 폭풍을 탐험하며\n\n- 2022년 2월부터 2023년 5월까지: 결정을 내리지 못하는 시장을 서핑하며\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 2020년 12월부터 2022년 12월까지: 상승장에서 하락장으로 변동하며 마지막에는 평평했어요.\n\n매 거래마다 $10,000을 거는 거예요. 이건 추적하고 결과를 비교하기 쉽게 하는 좋은 라운드 넘버예요. 이 모든 것을 내세웠으니, 코드를 실행해서 숫자가 우리에게 말해주는 것을 발견할 준비가 돼 있어요.\n\n#7: 결과 해석하기: 우리가 배운 것은 무엇인가요?\n\n“ 뛰어들기 전에, 이 통찰들을 면밀히 살펴보세요.”\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 2020년 11월부터 2024년 2월까지, 총 40개월 동안의 시장의 상승과 하락을 다룬 분석 결과를 확인해 보겠습니다:\n\n![analysis](/TIL/assets/img/2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_1.png)\n\n이게 무슨 의미가 있을까요? 여기에서 ChatGPT가 빛을 발합니다. 우리가 하는 것은 어떤 움직임을 해야 하는지 알려주는 것뿐만이 아니라, 그 움직임의 이유를 이해하는 데 중점을 둡니다. 코딩하는 것보다 ChatGPT에게 탐색적 데이터 분석(EDA) 결과를 제공하는 것이 더 유익할 수 있습니다. 제가 원하는 것은 이렇습니다:\n\n이 결과를 분석해 특정 기간과 전체적인 시장 분위기에 초점을 맞춘 교역 전략을 어떤식으로 사용할지 투자자들에게 힌트를 주는 것입니다. 그리고 이때 반드시 업종, 비즈니스 씬 그리고 각 섹터가 수익을 내는 방식과 관련하여 논리를 삽입해야합니다. 예를들어, 'XLE'이 최고의 선택인 경우에 대해 어떻게 이야기할 것인가요? 어떤 전략과 주식이 그들의 부문별 트랙 레코드와 함께 성공하는 이유에 대해 대략적으로 설명하십시오.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기 ChatGPT가 제공한 스니펫이에요:\n\n에너지 섹터 (XLE)\n\n- 추천 전략: 상승 시장에서는 터틀 전략; 하락 시장에서는 RSI 볼린저 밴드 전략.\n\n- 이유: 에너지 섹터의 순환적인 성격은 동적인 접근을 요구하며, 성장 단계에서는 추세를 활용하고, 쇠퇴 기간의 변동성을 관리해야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n금융 부문 (XLF)\n\n- 권장 방법: Buy Hold Sell 전략을 유지하세요.\n- 이유: 금융 부문은 금리와 경제 지표에 민감하기 때문에 적극적인 거래 방식을 통해 다양한 시장 단계에서 이익을 얻을 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nChatGPT는 매우 구체적이고 상세한 결과를 제공할 수 있습니다. 물론 길어지기도 하죠. ChatGPT에게 \"XLE를 제외하고 이 기간에 한 가지 ETF만 거래하려고 할 때 어떤 주식과 거래 방법을 사용해야 하는지 알려주세요\"와 같이 간단한 질문을 하실 수도 있어요.\n\n그리고 이러한 전략을 더 백테스트하고 정교화하기 위해 다양한 기간에서 더 많은 데이터를 가지고 있습니다:\n\n2020년 11월부터 2022년 01월까지: 코로나19로 인한 첫 번째 상승 시장입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_2.png](/TIL/assets/img/2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_2.png)\n\n2021–12부터 2022–10까지: 코로나 이후의 곰 시장을 통해:\n\n![2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_3.png](/TIL/assets/img/2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_3.png)\n\n2022–02부터 2023–05까지: 혼합 시장, 첫 곰 시장에서 시작하여 후에 황홀 시장으로 바뀜:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![이미지](/TIL/assets/img/2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_4.png)\n\n2020–12부터 2022–12까지: 상승에서 하락으로 바뀌는 혼합 시장, 결과는 호황:\n\n![이미지](/TIL/assets/img/2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_5.png)\n\n백테스팅을 위한 Python 스크립트는 제 깃허브 저장소에서 확인하실 수 있습니다:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nhttps://github.com/datalev001/stock_trading\n\n# 끝내는 중: 나의 마지막 생각\n\n우리의 데이터 탐구를 마무리 짓는 시간입니다. 솔직히 말하자면, ChatGPT가 도달한 결론마다 100% 동의하는 것은 아니지만, 내가 제공한 데이터를 기반으로 한 꽤 탄탄한 추론을 제시했기 때문에 일부는 인정할 필요가 있습니다. 에너지 지수 펀드를 예로 들자면, 서로 다른 부문과 거래 전략에 40개월이라는 꽤 긴 시간을 투자한 후, 시장 코드를 풀어내는 것이 제각각의 도전임이 분명해졌습니다. 하지만, 우리가 모은 통찰력은 충분히 가치가 있는데, 이를 통해 트레이더들을 특정 방향으로 이끌어주고 있습니다.\n\n요지는 여기에 있습니다: 양적 거래로 큰 파동을 일으킬 계획이라면, 전략을 선택하기 전에 집중해서 시장과 귀하가 활동하는 부문을 이해해야 합니다. 물론, 그저 곁에서 구경만 하고 있다가도 괜찮습니다. 내 연구 결과는 최소한 거대한 결정을 내릴 때 몇 가지 생각거리를 제공해줄 것입니다. 게다가, 이러한 전략들의 장기적인 지속 가능성을 고려하는 것도 매우 중요합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼 전략별로 평균 수익률에 대해 이야기해볼까요? 일반적으로, 간단한 매수 보유 전략이 대부분의 투자자에게 가장 좋은 선택일 수도 있어요. 양적 방법으로 평균을 넘어서는 것이 불가능하다는 뜻은 아니에요 — 진실하게 노력해야 할 뿐이에요.\n\n하나 확실한 것은, 이 분야에서의 경험이 나에게 데이터 과학이 양적 거래에 있어서 교섭 불가능한 요소임을 납득시켰어요. 그러나, 그리고 중요한데, AI가 인간의 통찰력을 곧 대체할 가능성은 아직 없어요.","ogImage":{"url":"/TIL/assets/img/2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-Beforeyouhitthequanttradingsceneswingbymydatascienceanalysisyoursecretweaponformakingthosetradesworkharder_0.png","tag":["Tech"],"readingTime":19},{"title":"6단계로 그래프 기반 이상 탐지 신경망 만드는 방법","description":"","date":"2024-07-13 19:22","slug":"2024-07-13-HowtoBuildaGraph-basedNeuralNetworkforAnomalyDetectionin6Steps","content":"\n\n\n![이미지](/TIL/assets/img/2024-07-13-HowtoBuildaGraph-basedNeuralNetworkforAnomalyDetectionin6Steps_0.png)\n\n본 글은 그래프 데이터를 활용한 이상 감지 모델을 구축하는 방법에 대해 자세히 설명한 기술적인 내용입니다. 이 모델은 다른 유형의 엔티티가 포함된 그래프 데이터(이질적 그래프 데이터)를 다룰 수 있습니다.\n\n이 글에서 다룰 모델은 Grab이라는 아시아 기술 회사가 2023년 IJCNN(IJCNN) 국제 합동 신경망 회의에서 발표한 \"Interaction-Focused Anomaly Detection on Bipartite Node-and-Edge-Attributed Graphs\"라는 논문에 기반합니다.\n\n이 Graph Convolutional Network (GCN) 모델은 이질적 그래프 데이터를 처리할 수 있어 노드와 엣지가 다른 유형일 수 있습니다. 이 그래프는 서로 다른 유형의 엔티티 또는 노드 간의 관계를 나타내므로 구조적으로 복잡합니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이를 Markdown 형식으로 변경하실 수 있으시다: \n\nGCNs가 이질적 그래프 데이터를 처리할 수 있는 것은 활발한 연구 분야입니다. 모델의 합성 연산은 다른 노드 유형과 이들 간의 관계를 처리하는 데 도전을 해소하기 위해 수정되었습니다.\n\n반면에 동질적 그래프는 동일한 유형의 노드와 엣지를 포함합니다. 이 유형의 그래프는 구조적으로 더 간단합니다. 동질적 그래프의 예로는 LinkedIn 연결이 있습니다. 여기서 모든 노드는 개인을 나타내고, 노드 간에 연결이 있습니다.\n\n여기서 볼 예제는 Grab의 GraphBEAN 모델(이분 그래프 노드 및 엣지 속성 네트워크)을 건강 보험 공급자 사기에 관한 Kaggle 데이터 세트에 적용합니다. (이 데이터 세트는 현재 Kaggle에서 CC0: Public Domain 라이선스로 사용 가능합니다. 이 데이터 세트가 정확하지 않을 수 있으니, 이 기사에서는 단순히 시연 목적으로 사용하였음을 주의하십시오). 해당 데이터 세트에는 입원 데이터, 외래 데이터, 수혜자 데이터의 청구 및 인사이트를 담은 여러 csv 파일이 포함되어 있습니다.\n\n저는 입원 데이터 세트를 사용하여 건강 보험 공급자 사기를 예측하기 위해 GCN을 구축하고, ProviderID와 레이블 열 (PotentialFraud)이 포함된 학습 세트를 사용하는 방법을 보여드리겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그래프 데이터는 표 형태로 시각화하기 어려울 수 있지만 csv 파일과 같은 형식으로 표현할 수 있습니다. 노드 간의 관계를 보여주는 흥미로운 대화형 시각화를 만들 수 있습니다. 제 이전 블로그 포스트인 '파이썬을 사용한 시계열 네트워크 그래프 시각화 방법'을 확인해보세요.\n\n# 그래프 컨볼루션 네트워크(GCN)의 활용\n\n이종 그래프를 사용한 GCN의 다양한 응용 분야는 서로 다른 엔티티 간의 복잡한 관계를 포착하고 모델링할 수 있기 때문에 다양합니다. 많은 사용 사례가 있으며 여기에 몇 가지 흥미로운 예시가 있습니다:\n\n- 사기 탐지: Grab은 사용자, 거래, 상인 등 사이의 관계를 모델링하여 의심스러운 거래를 식별하는 데 사용합니다.\n- 추천 시스템: 전자 상거래 플랫폼은 사용자와 제품 간의 관계를 모델링하여 개인화된 추천을 제공하기 위해 이종 그래프를 활용할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지도 학습 방법과 대조적으로, GCN은 이전에 본 적이 없는 이상 징후를 감지할 수 있어 사기 공격에 강하고 새로운 관계에 적응할 수 있습니다.\n\n# 모델 아키텍처\n\n이 모델은 노드와 엣지의 서로 다른 유형을 갖는 이분 그래프를 사용하고 각 노드와 엣지에 대한 이상 점수를 출력합니다.\n\n기본 모델 구조는 이종 그래프 데이터를 다루기 위해 인코더와 디코더에 맞춤형 아키텍처를 갖춘 오토인코더와 유사한 모델입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n입력 그래프는 노드 및 엣지 피쳐의 특성을 캡처하는 인코더로 전달됩니다. 다음으로, 이를 학습한 표현을 취하는 피쳐 디코더를 거쳐 노드 피쳐를 재구성합니다. 그런 다음 구조 디코더로 전달되는데, 이는 여러 개의 다중 레이어 퍼셉트론(MLP) 레이어로 구성되어 그래프 구조를 재구성하고 노드 사이에 엣지의 존재를 예측합니다.\n\n실제 대 재구성된 노드 및 엣지 어트리뷰트 간의 오류가 계산되고, 재구성된 오류는 각 노드 및 엣지에 대한 이상치 점수를 계산하는 데 사용됩니다.\n\n이제 고수준 모델 아키텍처에 대한 개괄을 이해했으니, 의료 공급자 사기 예측 모델을 구축하기 위한 여섯 단계를 자세히 알아봅시다.\n\n# 1) 데이터로부터 이분 그래프 생성\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째 단계는 이분 그래프 형식으로 탭 데이터를 인코딩하는 것입니다. 결과 그래프에는 노드, 엣지 및 이들의 속성에 대한 데이터가 포함됩니다.\n\n우리의 결과 그래프는 수혜자가 노드 u로, 의사가 노드 v로 인코딩되어야 하며, 엣지 e는 의사에 의해 수혜자를 위해 서비스를 제공하기 위해 청구된 경우에 존재합니다. 아래는 csv 파일을 이분 그래프로 준비, 생성 및 변환하는 단계입니다:\n\n## 1.1 데이터 준비\n\n이 함수는 세 개의 데이터프레임을 생성합니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 첫 번째 테이블은 수혜자를 노드 u로 한 집합의 데이터를 포함하고 있습니다. 집계 통계로 선택한 항목은 청구 건수, 병원을 방문한 의사 수, 총 보상액, 평균 보상액, 그리고 각 수혜자의 사기 비율을 인코딩했습니다.\n\n```js\ndf_bene = df.groupby(\"BeneID\").agg(\n  count_claims=(\"ClaimID\", \"nunique\"),\n  count_physicians=(\"AttendingPhysician\", \"nunique\"),\n  count_providers=(\"Provider\", \"nunique\"),\n  total_reimbursed=(\"InscClaimAmtReimbursed\", \"sum\"),\n  avg_reimbursed=(\"InscClaimAmtReimbursed\", \"mean\"),\n  pct_fraud=(\"PotentialFraud\", lambda x: round(x.mean() * 100))\n).reset_index()\n```\n\n- 두 번째 데이터프레임은 다른 노드 데이터인 의사를 노드 v로 포함하고 있습니다. 노드 속성에는 청구 건수, 병원을 방문한 수혜자 수, 제공한 서비스가 있는 병원 수, 총 보상액, 평균 보상액, 그리고 각 의사의 사기 비율이 포함되어 있습니다.\n\n```js\ndf_physician = df.groupby(\"AttendingPhysician\").agg(\n    count_claims=(\"ClaimID\", \"nunique\"),\n    count_beneficiaries=(\"BeneID\", \"nunique\"),\n    count_providers=(\"Provider\", \"nunique\"),\n    total_reimbursed=(\"InscClaimAmtReimbursed\", \"sum\"),\n    avg_reimbursed=(\"InscClaimAmtReimbursed\", \"mean\"),\n    pct_fraud=(\"PotentialFraud\", lambda x: round(x.mean() * 100))\n).reset_index()\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 마지막 데이터프레임에는 엣지 데이터가 포함되어 있습니다 — 수혜자와 의사 간 상호 작용을 캡처하며 총계 통계를 나타내는 엣지 속성을 갖습니다. 이러한 속성에는 각 수혜자와 의사 쌍에 대한 청구 횟수, 제공자 수, 총 환급액, 평균 환급액, 사기 비율이 포함됩니다.\n\n```js\ndf_edge = df.groupby([\"BeneID\", \"AttendingPhysician\"]).agg(\n    count_claims=(\"ClaimID\", \"nunique\"),\n    count_providers=(\"Provider\", \"nunique\"),\n    total_reimbursed=(\"InscClaimAmtReimbursed\", \"sum\"),\n    avg_reimbursed=(\"InscClaimAmtReimbursed\", \"mean\"),\n    pct_fraud=(\"PotentialFraud\", lambda x: round(x.mean() * 100))\n).reset_index()\n```\n\n## 1.2 Create_graph\n\n이 함수는 바이파티트 그래프를 생성하며 노드 및 엣지 데이터가 포함된 인접 행렬을 출력합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저, 수혜자 ID를 행으로, 의사 ID를 열로 하는 희소 행렬로 노드 데이터를 인코딩하세요.\n\n```js\n# 노드 데이터프레임에 ID로 인덱싱 설정\ndf_bene[\"bid\"] = df_bene.index\ndf_physician[\"pid\"] = df_physician.index\n\n# 수혜자 및 의사 노드에 대한 ID를 엣지 데이터프레임에 추가\ndf_edge_2 = df_edge.merge(\n  df_bene[[\"BeneID\", \"bid\"]],\n  on=\"BeneID\",\n).merge(\n  df_physician[[\"AttendingPhysician\", \"pid\"]], \n  on=\"AttendingPhysician\"\n)\n\n# 수혜자 및 의사 ID를 텐서로 인코딩\nbid = torch.tensor(df_edge_2[\"bid\"].to_numpy())\npid = torch.tensor(df_edge_2[\"pid\"].to_numpy())\n\n# 노드 데이터로 인접 행렬 생성\nadj = SparseTensor(row=bid, col=pid)\n```\n\n다음 단계는 노드와 엣지 속성을 추가하는 것인데, 이러한 속성은 sklearn의 표준 스케일러를 사용하여 표준화되었습니다. 이는 GCN 모델이 후속 단계에서 더 잘 학습할 수 있도록 도와줍니다. 이러한 속성들은 다음과 같이 텐서로 인코딩되어 있습니다:\n\n```js\n# 수혜자의 노드 속성을 텐서로 인코딩\nbene_attr = torch.tensor(\n  standardize(\n    # 관련 노드 속성이 있는 열을 선택합니다\n    df_bene.iloc[:, 1: -1].to_numpy() \n  )\n).float()\n\n# 의사의 노드 속성을 텐서로 인코딩\nphysician_attr = torch.tensor(\n  standardize(\n    # 관련 노드 속성이 있는 열을 선택합니다\n    df_physician.iloc[:, 1: -1].to_numpy() \n  )\n).float()\n\n# 엣지 속성을 텐서로 인코딩\nedge_attr = torch.tensor(\n  standardize(\n    # 관련 엣지 속성이 있는 열을 선택합니다\n    df_edge_2.iloc[:, 2: -2].to_numpy() \n  )\n).float()\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마침내 이중 부분 데이터 집합이 생성되었습니다. 이는 인접 행렬, 노드 속성 및 엣지 속성을 저장하는 사용자 지정 데이터 클래스로, Pytorch Geometric의 그래프 데이터 객체에서 상속받습니다.\n\n```js\nfrom models.data import BiPartiteData\n\ndata = BiPartiteData(\n  adj, \n  xu=bene_attr, \n  xv=physician_attr, \n  xe=edge_attr\n)\n```\n\n## 1.3 Inject_random_block_anomaly\n\n마지막이자 더 복잡한 단계는 이중 부분 그래프에 이상을 삽입하여 다양성을 더하는 것입니다. 이에 대해 다음 섹션에서 설명하겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 2 데이터에 무작위 이상 현상 주입하기\n\n데이터에 이상 현상을 주입하여 이를 통해 데이터의 변동성을 높일 수 있습니다. 모델을 훈련시키기 위해 더 다양한 데이터셋을 보유하면 모델이 이상 현상을 식별하는 방법을 더 잘 학습할 수 있습니다.\n\n복잡해보일 수 있지만, 데이터에 무작위 이상 현상을 삽입하는 함수는 다음과 같은 3가지 주요 단계로 나뉠 수 있습니다:\n\n2.1) 이상 현상 주입을 위한 매개변수 무작위화하기,\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2.2) 무작위 매개변수에 기반한 이상 삽입,\n\n2.3)원본 그래프 및 이상에서 얻은 데이터를 결합하여 새로운 이분 그래프 생성.\n\n## 2.1 이상 삽입을 위한 매개변수 무작위화\n\n본 단계는 데이터에 삽입될 이상의 유형을 선택하기 위해 사용될 매개변수를 선택하는 것을 포함합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 다른 종류의 블록 이상, 특징 이상, 노드 및 엣지 특징 이상을 나타내는 문자열 목록을 초기화하고, 각 이상의 가중치를 담은 부동소수점 목록을 초기화하는 것으로 시작합니다.\n\n```js\nblock_anomalies = [\"full_dense_block\", \"partial_full_dense_block\"]\nfeature_anomalies = [\"outside_ci\", \"scaled_gaussian\", \"none\"]\nnode_edge_feat_anomalies = [\"node_only\", \"edge_only\", \"node_edge\"]\n\nblock_anomalies_weight = [0.2, 0.8]\nfeature_anomalies_weight = [0.5, 0.4, 0.1]\nnode_edge_feat_anomalies_weight = [0.1, 0.3, 0.6]\n```\n\n다음으로, 이상을 주입할 그룹의 수에 대해 반복합니다. 이는 num_group 매개변수로 지정됩니다 (여기서는 20으로 선택했습니다).\n\n각 그룹에 대해, 블록, 특징, 노드 및 엣지 특징 이상에 대한 이전에 정의된 이상 유형 및 각 유형의 가중치에 기초하여 무작위로 매개변수 집합을 선택합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 2.2 이상 주입\n\n그 다음으로, num_node_range (나의 경우 1부터 20)와 num_node_range2 (나의 경우 1부터 6) 매개변수의 튜플 범위에 따라 삽입할 노드 수를 계산합니다.\n\n그런 다음 밀집 블록 함수를 호출하여 다음 중 하나의 조합을 주입합니다 —\n\n- 밀집 블록 및 특성 이상\n- 밀집 블록 이상만\n- 특성 이상만\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n밀집 블록 이상\n\n밀집 블록은 각 레이어가 정보 흐름을 강화하기 위해 각 후속 레이어에 직접 연결된 신경망 아키텍처로, 다층으로부터 정보를 효과적으로 제공하여 모델 훈련을 강화합니다.\n\n밀집 블록 이상 주입 함수는 입력 그래프와 지정된 매개변수를 매개변수로 사용하고 수정된 인접 행렬, 엣지 기능 및 레이블을 반환합니다.\n\n레이블은 그래프의 엣지가 여러 밀집 행렬의 일부인지를 나타내는 이진 레이블입니다. 각 엣지가 인접 행렬에서 발생하는 횟수를 세어, 그 엣지가 한 번 이상 발생하면 레이블 1을 부여하며, 그렇지 않으면 0을 부여합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다수의 밀집 블록 내 에지를 분석하면 네트워크 내 정보 흐름에 관한 중요한 정보를 알 수 있습니다.\n\n라벨이 1인 에지는 서로 다른 서브그래프의 특정 노드들 사이에 높은 연결성을 가지며, 이러한 노드들은 그래프 내에서 서로 다른 커뮤니티를 연결하는 중요한 역할을 합니다. 다수의 밀집 블록에 속한 노드들은 네트워크에서 정보 흐름을 중계하는 연결 요소로 작용하여 그래프의 여러 부분 간에 정보를 교환합니다.\n\n특징 이상 현상\n\n특징 이상 현상 매개변수가 활성화된 경우 (이는 단계 2.1에서 선택한 임의의 매개변수에 따라 달라집니다), 통계적 방법을 사용하여 엣지 특징에 특징 이상 현상을 주입하는 함수가 호출됩니다. 이 때, outside_confidence_interval() 또는 scaled_gaussian_noise() 방법을 선택합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이상점은 그 후 엣지 피처에 주입되어 새로운 수정된 그래프에 통합됩니다.\n\n## 2.3 새 이분 그래프 생성\n\n매 반복마다 새로운 이분 그래프가 생성됩니다. 새 그래프에는 새로운 인접행렬 엣지, 수정된 엣지 피처 xe_new, 결합된 엣지 레이블 ye_new, 그리고 엣지가 원래 그래프에서 온 것인지 이상점인지를 나타내는 이상점 레이블이 포함됩니다.\n\n# 3 모델 설정\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 단계는 모델을 초기화하는 것입니다. GraphBEAN 클래스는 다음 파라미터를 사용하는 사용자 정의 그래프 기반 신경망입니다:\n\n- In_channels: 사용자 노드 u, 상품 노드 v 및 엣지 e의 입력 채널 수를 지정하는 u_ch, v_ch, e_ch 요소가 있는 튜플입니다. 이는 입력 그래프의 각 노드 및 엣지 유형의 특징 공간 크기 또는 차원을 정의합니다.\n- Hidden_channels, latent_channels: 이 두 인수는 모델 아키텍처의 인코더 및 디코더 구성 요소 내의 숨겨진 채널 및 잠재 채널의 차원을 지정합니다.\n- Edge_pred_latent: 엣지 예측을 위한 잠재 공간의 크기 또는 차원을 나타내는 정수입니다. 이 값은 32로 설정했습니다. 다시 말해, 이는 엣지 예측을 위한 학습된 표현을 포착하는 길이가 32인 벡터입니다.\n- N_layers_encoder, n_layers_decoder, n_layers_mlp: 모델의 인코더, 디코더 및 다중 레이어 퍼셉트론(MLP) 레이어 구성 요소의 층 수입니다. MLP는 각 뉴런이 다음 레이어의 각 뉴런과 연결되는 다중 완전 연결 레이어로 구성됩니다.\n- Dropout_prob: 드롭아웃은 신경망에서 일반적으로 사용되는 정칙화를 위한 하이퍼파라미터입니다. 과적합을 방지하기 위해 훈련 과정 중에 개별 뉴런을 무작위로 삭제하거나 값을 0으로 만들 확률을 나타냅니다.\n\n이 Graph Convolutional Network는 오토인코더와 유사한 모델 아키텍처를 갖고 있습니다. 데이터의 차원을 낮은 차원의 표현으로 출력하는 인코더 부분(encoder_convs)과 데이터를 원래의 특징 공간으로 재구성하려는 디코더 부분(decoder_convs, u_mlp_layers 및 v_mlp_layers)으로 구성됩니다.\n\n인코더와 특징 디코더 내에서 모델은 이질적 데이터에서 작동하도록 설계된 사용자 정의 그래프 컨볼루션 레이어인 BeanCONV를 생성합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 오토인코더 유형의 아키텍처는 명시적 레이블을 제공하지 않고도 데이터로부터 복잡한 구조와 패턴을 학습할 수 있어서 비지도 학습 작업에서 뛰어납니다.\n\n`forward` 메서드는 신경망의 순전파를 정의합니다. 이 메서드는 기본적으로 입력 데이터가 훈련 및 추론 동안 네트워크의 다른 레이어를 통해 어떻게 처리되어 출력을 생성해야 하는지를 지정합니다.\n\n모델 아키텍처의 다른 부분을 살펴보며 모델이 입력 데이터를 학습하고 변환하는 방식을 이해해 봅시다.\n\n## 인코더\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n인코더는 사용자 노드 xu, 항목 노드 xv 및 엣지 xe로 구성된 입력 그래프를 가져와 그래프 합성 작업을 수행하여 잠재적 표현을 생성합니다.\n\n인코더는 BEANConv 레이어의 시리즈인 Pytorch 신경망 모듈이며, 이는 커스텀 그래프 합성 레이어입니다. BEANConv 레이어는 이웃 노드 및 엣지 사이에서 평균 및 최대 작업과 같은 데이터 집계를 수행하여 이질적 데이터(다른 유형의 데이터)에 작용하도록 설계되었습니다.\n\n인코더는 각 레이어에서 얼마나 많은 채널을 가지고 있고 각 레이어 내에서 어떤 작업을 수행할지를 정의하도록 구성됩니다. GraphBEAN에서의 코드 스니펫은 이 프로세스를 보여줍니다:\n\n```js\ndef create_encoder(self): \n  # 인코더는 일련의 레이어를 포함하는 Pytorch 신경망 모듈입니다.\n  self.encoder_convs = nn.ModuleList()\n\n  # 각 레이어를 생성합니다.\n  for i in range(self.n_layers_encoder):\n    # 첫 번째 레이어의 채널 정의\n    if i == 0: \n       in_channels = self.in_channels\n       out_channels = self.hidden_channels\n\n    # 마지막 레이어의 채널 정의\n    elif i == self.n_layers_encoder - 1:\n       in_channels = self.hidden_channels\n       out_channels = self.latent_channels\n\n    # 중간 레이어의 채널 정의\n    else:\n       in_channels = self.hidden_channels\n       out_channels = self.hidden_channels\n\n    # 각 레이어를 인코더 모듈 리스트에 추가합니다.\n    # 마지막 레이어\n    if i == self.n_layers_encoder - 1:\n        self.encoder_convs.append(\n            BEANConv(in_channels, out_channels, node_self_loop=False)\n        )\n    # 마지막 레이어를 제외한 모든 레이어는 합성 작업을 수행합니다.\n    else:\n        self.encoder_convs.append(\n            BEANConv(in_channels, out_channels, node_self_loop=True)\n        )\r\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n각 BEANConv 레이어의 출력은 원래의 feature space 로 매핑하기 위해 선형 변환을 거칩니다. 입력 피쳐에서 고차원 공간으로의 이 학습된 선형 매핑은 사실상 학습된 가중치와 편향의 집합입니다.\n\n그런 다음, 각 인코더 레이어의 출력에는 ReLU(Recitified Linear Unit) 활성화 함수와 드롭아웃이 적용됩니다. ReLU 활성화의 목적은 모델에 비선형성을 도입하여 더 복잡한 표현을 학습하고 데이터의 비선형적 패턴을 잡을 수 있도록 하는 것입니다.\n\nBeanCONV 레이어의 출력은 입력 데이터의 구조적 정보와 관계를 포착하는 낮은 차원의 학습된 표현입니다. 노드의 원시 잠재 변수를 나타내는 텐서를 반환합니다 (xu 및 xv).\n\n전진 패스의 인코더 부분은 아래와 같이 정의됩니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 인코더 내의 각 합성곱 레이어를 순환합니다.\nfor i, conv in enumerate(self.encoder_convs):\n\n    # 인풋 텐서는 인코더 내 각 합성곱 레이어를 통과합니다.\n    (xu, xv), xe = conv((xu, xv), adj, xe=xe)\n\n    # ReLU 활성화 및 드롭아웃을 각 인코더 레이어에 적용하지만 마지막 레이어가 아닙니다.\n    if i != self.n_layers_encoder - 1:\n        xu = apply_relu_dropout(xu, self.dropout_prob, self.training)\n        xv = apply_relu_dropout(xv, self.dropout_prob, self.training)\n        xe = apply_relu_dropout(xe, self.dropout_prob, self.training)\n```\n\n마지막 합성곱 연산에서 얻은 결과 `xu`와 `xv`는 잠재 변수로 간주됩니다. 이는 인코더에서 학습한 정보를 담고 있습니다.\n\n## 특징 디코더\n\n특징 디코더는 그래프 내 노드 특징을 재구성하는 데 중점을 둡니다. 인코더의 출력을 인풋으로 삼는데, 이는 노드의 잠재 표현(`xu`와 `xv`)입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n인코더와 유사하게, 피쳐 디코더는 노드 간의 관계를 캡처하기 위해 컨볼루션 작업을 수행하는 일련의 BEANConv 레이어 및 사용자 지정 컨볼루션 레이어로 구성됩니다. GraphBEAN에서 코드 스니펫은 다음과 같습니다:\n\n```js\ndef create_feature_decoder(self):\n  # 디코더는 일련의 레이어를 포함하는 Pytorch 신경망 모듈입니다\n  self.decoder_convs = nn.ModuleList()\n\n  # 각 레이어 생성\n  for i in range(self.n_layers_decoder):\n    # 첫 번째 레이어의 채널 정의\n    if i == 0:\n       in_channels = self.latent_channels\n       out_channels = self.hidden_channels\n\n    # 마지막 레이어의 채널 정의\n    elif i == self.n_layers_decoder - 1:\n       in_channels = self.hidden_channels\n       out_channels = self.in_channels\n\n    # 중간 레이어의 채널 정의\n    else:\n       in_channels = self.hidden_channels\n       out_channels = self.hidden_channels\n\n    # 각 레이어를 모듈 목록에 추가\n    self.decoder_convs.append(BEANConv(in_channels, out_channels))\r\n```\n\n이와 같이 각 디코더 레이어의 출력에는 비선형 변환과 정규화를 위해 ReLU 활성화 및 드롭아웃이 적용되지만, 출력 레이어는 제외됩니다.\n\n해당 신경망의 forward 메서드의 피쳐 디코더 부분은 아래에 정의되어 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n# 디코더 내 각 합성 층을 반복합니다.\nfor i, conv in enumerate(self.decoder_convs):\n  \n  # 피쳐 디코더의 입력으로 인코더의 출력을 사용합니다.\n  # 각 디코더 내 합성 층을 통과하는 입력 텐서입니다.\n  (xu, xv), xe = conv((xu, xv), adj, xe=xe)\n\n  # ReLU 활성화 및 드롭아웃을 적용합니다. 단, 마지막 디코더 층 제외\n  if i != self.n_layers_decoder - 1:\n    xu = apply_relu_dropout(xu, self.dropout_prob, self.training)\n    xv = apply_relu_dropout(xv, self.dropout_prob, self.training)\n    xe = apply_relu_dropout(xe, self.dropout_prob, self.training)\r\n\n\n피쳐 디코더의 출력은 이질 그래프에서 재구성된 노드 피쳐를 나타내는 텐서 쌍(zu 및 zv)입니다.\n\n## 구조 디코더\n\n구조 디코더는 에지 피쳐를 재구성하고 노드 사이에 존재하는 에지의 확률을 예측하기 위해 설계되었습니다. 재구성된 노드 피쳐 또는 피쳐 디코더의 출력(zu 및 zv)이 입력됩니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n구조 디코더는 입력된 잠재 노드 표현을 처리하여 엣지 예측을 생성하기 위한 Multi-Layer Perceptron (MLP) 레이어 (u_mlp_layers와 v_mlp_layers) 시리즈로 구성되어 있습니다. GraphBEAN에서 다음 코드 스니펫은 이를 보여줍니다:\n\n```js\ndef create_structure_decoder(self):\n  # MLP 레이어는 일련의 레이어를 포함하는 Pytorch 신경망 모듈입니다.\n  self.u_mlp_layers = nn.ModuleList()\n  self.v_mlp_layers = nn.ModuleList()\n\n  # 각 레이어 생성\n  for i in range(self.n_layers_mlp):\n    # 첫 번째 레이어의 채널 정의\n    if i == 0:\n        in_channels = self.latent_channels\n\n    # 첫 번째 레이어를 제외한 모든 레이어의 채널 정의\n    else:\n        in_channels = (self.edge_pred_latent, self.edge_pred_latent)\n        out_channels = self.edge_pred_latent\n  \n    # 각 레이어를 MLP 모듈 리스트에 추가\n    self.u_mlp_layers.append(Linear(in_channels[0], out_channels))\n    self.v_mlp_layers.append(Linear(in_channels[1], out_channels))\r\n```\n\n각 MLP 레이어의 출력은 선형 변환을 거친 후 ReLU 활성화 함수를 통해 비선형성을 도입합니다. 과적합을 방지하고 정칙화하기 위해 드롭아웃도 적용됩니다.\n\n포워드 패스의 구조 디코더 부분은 아래와 같이 정의됩니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# 피처 디코더에서 출력된 잠재 변수 가져오기\nzu2, zv2 = zu, zv\n\n# 각 MLP 레이어별로 반복\nfor i, layer in enumerate(self.u_mlp_layers):\n  \n  # u 노드용 출력 잠재 변수는 \n  # 스트럭처 디코더의 각 MLP 레이어를 통과합니다\n  zu2 = layer(zu2)\n\n  # ReLU 활성화 함수와 드롭아웃을 적용합니다. 마지막 레이어 제외\n  if i != self.n_layers_mlp - 1:\n    zu2 = apply_relu_dropout(zu2, self.dropout_prob, self.training)\n\n# 각 MLP 레이어별로 반복\nfor i, layer in enumerate(self.v_mlp_layers):\n  \n  # v 노드용 출력 잠재 변수는 \n  # 스트럭처 디코더의 각 MLP 레이어를 통과합니다\n  zv2 = layer(zv2)\n\n  # ReLU 활성화 함수와 드롭아웃을 적용합니다. 마지막 레이어 제외\n  if i != self.n_layers_mlp - 1:\n    zv2 = apply_relu_dropout(zv2, self.dropout_prob, self.training)\r\n```\n\n마지막으로 MLP 레이어에서 반환된 변환된 잠재 변수 (zu2 및 zv2)은 시그모이드 활성화 함수를 통해 0에서 1까지의 출력 값을 생성합니다.\n\n```python\n# 변환된 잠재 변수에서 행과 열 가져오기\nzu2_edge = zu2[edge_pred_samples.storage.row()]\nzv2_edge = zv2[edge_pred_samples.storage.col()]\n\n# 엣지 확률을 계산하기 위해 시그모이드 변환을 적용합니다\neprob = torch.sigmoid(torch.sum(zu2_edge * zv2_edge, dim=1))\r\n```\n\n이러한 출력은 노드 간 엣지의 예측 확률 (eprob)입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 옵티마이저 및 학습률\n\n모델을 정의한 후, 학습 과정 중에 모델 파라미터를 업데이트하는 Adam 옵티마이저를 구성합니다.\n\n게다가, 학습률 스케줄러를 설정하여 각 이정표에서 학습률을 조정하는 방식을 지정합니다 (0.2의 배율로 감소하도록 설정).\n\n```js\n# Adam 옵티마이저 정의\noptimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n\n# 학습률 스케줄러 정의\nscheduler = torch.optim.lr_scheduler.MultiStepLR(\n  optimizer, milestones=[], gamma=0.2\n)\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 4) 네거티브 클래스에서의 샘플 데이터\n\nGrab은 사기 탐지를 위해 GCN을 사용하며, 클래스 불균형은 이 분야에서 흔한 문제입니다. 이를 극복하기 위해, 음성 클래스의 샘플링을 통해 음성 및 양성 클래스의 비율을 더 잘 균형있게 맞춰 모델이 보다 효과적으로 학습하고 수렴 문제를 극복할 수 있도록 합니다.\n\nEdgePredictionSampler 클래스는 엣지 예측을 위한 음성 샘플을 생성하는 데 사용됩니다. 이를 위해 존재하지 않는 엣지를 무작위로 샘플링하여 음성 샘플로 만들고, 이를 기존 엣지의 양성 샘플과 연결하여 새로운 희소 텐서를 생성합니다.\n\n이러한 새로운 텐서의 값은 양성 샘플을 나타내는 1 또는 음성 샘플을 나타내는 -1입니다 (즉, 이 노드들 간에 엣지가 존재하지 않음). 생성된 희소 텐서인 edge_pred_samples는 모델 훈련 과정에서 사용됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 5) 모델 훈련\n\n모델 훈련 과정에서는 다음 단계를 거칩니다:\n\n- 부정 클래스를 샘플링하고 샘플된 부정 클래스와 양성 클래스를 연결하여 새로운 텐서를 생성합니다.\n- 옵티마이저 텐서의 그래디언트를 0으로 초기화합니다.\n- 모델 훈련 과정을 안내하기 위해 재구성 손실을 계산합니다.\n\n재구성 손실은 실제 입력과 예측 출력 간의 차이를 측정하며, 특징 손실과 구조 손실 두 가지 구성 요소로 구성됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n실제 피처와 예측된 피처 간의 차이를 포착하는 피처 손실은 모델이 그래프 내의 노드와 엣지 피처를 얼마나 잘 재구성할 수 있는지를 살펴봅니다.\n\n이 예제에서는 손실 함수로 MSE(평균 제곱 오차)를 사용하며, 피처 손실은 노드와 엣지에서 실제와 예측된 피처 간의 MSE 합입니다.\n\n엣지 손실의 MSE는 가중치(xe_loss_weight)가 적용됩니다. 엣지에 더 중요성을 두거나 덜 두고 싶은 경우를 위해 설정됩니다. 그러나 이 예제에서는 1로 설정되어 있습니다.\n\n```js\n# 노드 및 엣지 피처의 MSE 계산\nxu_loss = nn.functional.mse_loss(xu, out[\"xu\"])\nxv_loss = nn.functional.mse_loss(xv, out[\"xv\"])\nxe_loss = nn.functional.mse_loss(xe, out[\"xe\"]) \n\n# 피처 손실 계산을 위해 구성 요소를 합산\nfeature_loss = xu_loss + xv_loss + xe_loss_weight * xe_loss\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n구조 손실은 예측된 엣지의 확률과 실제 엣지 레이블 간의 차이를 측정합니다. 다시 말해, 모델이 그래프 구조와 엣지 연결을 얼마나 잘 재구성할 수 있는지를 캡처하는 것입니다.\n\n구조 손실에 사용된 손실 함수는 이진 교차 엔트로피이며, 큰 오차가있는 예측을 작은 오차보다 더 엄격하게 패널티를 주게 됩니다.\n\n```js\n# 실제 엣지 레이블 가져오기\nedge_gt = (edge_pred_samples.storage.value() > 0).float()\n\n# 예측된 확률과 실제 엣지 레이블 사이의 이진 교차 엔트로피 측정\nstructure_loss = nn.functional.binary_cross_entropy(out[\"eprob\"], edge_gt)\n```\n\n재구성 손실은 피처 손실과 구조 손실의 합이며, 각 손실의 중요성에 따라 가중치를 조절할 수 있습니다. 모델은 학습 과정에서 이 결합된 손실에 최적화됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n손실 = 피처 손실 + 구조 손실 가중치 * 구조 손실\n```\n\n다음으로, backpropagation이 수행되어 모델 매개변수에 관한 그래디언트가 계산되고, 옵티마이저는 계산된 그래디언트를 사용하여 모델 매개변수를 조정하여 손실을 최소화합니다.\n\n학습률은 필요에 따라 미리 정의된 스케줄러에 따라 조정됩니다. 스크립트에서는 학습률이 일정한 횟수 거칠 때마다 0.2 배로 감소하도록 설정됩니다.\n\n이 프로세스의 마지막 단계는 엣지 예측과 지면 실제 엣지 레이블을 비교하여 메트릭을 계산하는 것입니다. 스크립트에서 계산된 메트릭은 정확도, 정밀도, 재현율 및 F1 점수를 포함합니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nacc = accuracy_score(edge_gt, edge_pred)\nprec = precision_score(edge_gt, edge_pred)\nrec = recall_score(edge_gt, edge_pred)\nf1 = f1_score(edge_gt, edge_pred)\n```\n\n# 6) 모델 평가\n\n모델을 훈련한 후, 마지막 단계는 성능을 평가하는 것입니다. 예측을 하기 전에 편향되지 않도록 모델 매개변수가 업데이트되지 않도록 경사 하강이 비활성화됩니다.\n\n그런 다음 예측을 하고, 모델이 엣지 예측에 얼마나 잘하는지 측정하기 위해 재구성 손실과 지표가 함께 계산됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n평가 단계에는 학습 과정에서 사용되는 메트릭 이외에 더 포괄적인 오류 메트릭 계산이 포함됩니다. 이는 다음을 포함합니다:\n\n- 원본 그래프와 재구성된 출력 사이의 노드 (xu 및 xv) 및 엣지 (xe) 피처에 대한 RMSE,\n- 존재하는 ground truth 엣지 레이블의 음의 자연 로그를 취한 Cross-entropy 손실 (edge_ce) 및 이들 엣지를 예측하면서 예측된 확률을 비교,\n- 엣지 피처 RMSE (xe_error) 및 엣지 예측 크로스 엔트로피 손실 (edge_ce)의 가중 조합인 엣지 점수,\n- 각 노드에 대한 집계된 엣지 점수로, 해당 노드에 연결된 엣지의 최대값, 최소값 및 합계를 가져옵니다.\n\n# 결론\n\nGraphBEAN은 이상 감지를 위해 Grab에서 설계한 그래프 컨볼루션 네트워크입니다. 이 강력한 모델은 이종 데이터를 처리할 수 있어 노드와 엣지에서 서로 다른 유형의 데이터를 캡처할 수 있습니다. 이 문서는 링크 예측 GCN 모델을 구축하는 6단계를 설명했습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모델은 오토인코더와 유사한 아키텍처를 가지고 있습니다. 이는 인코더, 피처 디코더, 그리고 구조 인코더로 구성되어 있습니다.\n\n인코더는 입력된 그래프 데이터를 받아서, 더 낮은 차원의 공간에 학습된 표현을 출력합니다. 피처 디코더는 인코더에서 출력된 값을 사용하여 노드의 피처를 원래의 특징 공간으로 재구성합니다. 구조 디코더는 피처 디코더에서 출력된 값을 사용하여 엣지를 재구성합니다.\n\n재구성된 그래프 구조는 링크 예측에 사용되며, 시그모이드 변환을 거쳐 노드 쌍 사이에 엣지가 존재하는지 여부의 확률을 0부터 1 사이로 출력합니다.\n\n모델 예측은 그라운드 트루스 엣지 레이블과 비교되어 일련의 에러 메트릭을 계산하고, 이를 통해 이상을 식별하는 데 사용됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 이질적 데이터를 처리할 수 있는 GCN을 구축하는 방법을 알았으니, 이 모델을 적용할 수 있는 사용 사례에 대해 어떤 것이 생각나시나요? 실제 세계에서 GCN이 어떻게 활용되었는지 본 적이 있나요?\n\n## 인용문\n\nR. Fathony, J. Ng and J. Chen, “Interaction-Focused Anomaly Detection on Bipartite Node-and-Edge-Attributed Graphs,” 2023 International Joint Conference on Neural Networks (IJCNN), Gold Coast, Australia, 2023, pp. 1–10, doi: 10.1109/IJCNN54540.2023.10191331.\n\n## 리소스\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 노트북\n\n안녕하세요! 다른 사람들에게 이 주제를 가르치는 데 열정을 가진 데이터 과학자입니다. 주로 Medium에서 파이썬을 사용한 머신러닝, 데이터 과학 및 프로그래밍에 관해 꾸준히 글을 씁니다. 또한 Real Python의 기술 작가입니다.\n\n제 글을 지속적으로 확인하려면 Medium(@ds_claudia_)에서 저를 팔로우하고 무료 이메일 뉴스레터를 구독해주세요. 함께 공부하고 지식을 공유해요! 🚀","ogImage":{"url":"/TIL/assets/img/2024-07-13-HowtoBuildaGraph-basedNeuralNetworkforAnomalyDetectionin6Steps_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-HowtoBuildaGraph-basedNeuralNetworkforAnomalyDetectionin6Steps_0.png","tag":["Tech"],"readingTime":30},{"title":"파이썬 코딩 멀티스레딩으로 for 루프 속도 10배 향상시키는 방법","description":"","date":"2024-07-13 19:21","slug":"2024-07-13-PythonCodingMakeForLoops10xFasterwithMultithreading","content":"\n\n\n![Python Coding Make For Loops 10x Faster with Multithreading](/TIL/assets/img/2024-07-13-PythonCodingMakeForLoops10xFasterwithMultithreading_0.png)\n\nFor loops are essential in programming. They allow us to iterate over sequences efficiently. However, for time-consuming tasks, using threads can be more efficient. Learn when and how to use threads to optimize performance. You can check out code examples in my GIT repo. The link is in the footer.\n\nLet's look at an example. We will simulate a time-consuming task by squaring numbers using a Python script with a for loop:\n\n```python\nimport time\n\n# List of numbers to process\nnumbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n# Function to square a number\ndef square_number(number):\n    time.sleep(1)  # Simulate a time-consuming task\n    return number * number\n\n# Using a for loop to process each number\nsquared_numbers = []\nstart_time = time.time()\nfor number in numbers:\n    squared_numbers.append(square_number(number))\n\nend_time = time.time()\n\nprint(\"Squared numbers:\", squared_numbers)\nprint(\"Time taken:\", end_time - start_time, \"seconds\")\n# Time taken: 10.082990884780884 seconds\n```\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 스크립트는 square_number 함수 내의 time.sleep(1) 호출로 인해 각 숫자를 순차적으로 처리합니다. 전체 실행에는 10.1초가 소요됩니다.\n\n## 멀티스레딩으로 최적화\n\n다음으로, 처리 시간을 개선하기 위해 멀티스레딩 접근 방식으로 최적화할 것입니다. 멀티스레딩을 사용하여 위 예제를 최적화하려면 Python의 concurrent.futures 모듈을 사용할 수 있습니다. 이 모듈은 콜러블을 비동기적으로 실행하기 위한 고수준 인터페이스를 제공합니다.\n\n다음은 스크립트를 멀티스레딩을 사용하도록 수정하는 방법입니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\n\n# 처리할 숫자의 목록\nnumbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n# 숫자를 제곱하는 함수\ndef square_number(number):\n    time.sleep(1)  # 시간이 많이 소요되는 작업을 모방\n    return number * number\n\n# 멀티스레딩을 위해 ThreadPoolExecutor 사용\nsquared_numbers = []\nstart_time = time.time()\n\nwith ThreadPoolExecutor(max_workers=10) as executor:\n    results = executor.map(square_number, numbers)\n\n# 결과 수집\nsquared_numbers = list(results)\n\nend_time = time.time()\n\nprint(\"제곱된 숫자:\", squared_numbers)\nprint(\"소요 시간:\", end_time - start_time, \"초\")\n# 소요 시간: 2.0257720947265625 초\n```\n\n이 최적화된 스크립트에서 우리는 ThreadPoolExecutor를 사용해 스레드 풀을 생성합니다. executor.map 함수는 숫자를 병렬로 처리하는 스레드에 square_number 함수를 분배합니다. max_workers를 5로 설정하여 최대 5개의 스레드가 동시에 실행되도록 하여 총 처리 시간을 크게 줄일 수 있습니다.\n\n특정 사용 사례에 최적인 스레드 수를 찾으려면 max_workers 매개변수를 조정해보세요.\n\n# 멀티스레딩 사용 시기\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다중 스레딩은 다양한 시나리오에서 상당한 속도 향상을 제공할 수 있다는 것을 보셨을 것입니다. 그러나 모든 작업에 적합한 것은 아닙니다. 다음은 다중 스레딩이 특히 유익한 일반적인 사용 사례 몇 가지입니다:\n\n## 1. I/O-바운드 작업:\n\n- 파일 I/O: 파일 읽기 및 쓰기, 특히 크거나 많은 파일을 다룰 때.\n- 네트워크 I/O: 여러 네트워크 연결을 동시에 처리하는 경우, 예를 들어 웹 스크래핑, 파일 다운로드 또는 웹 서버의 요청 처리.\n- 데이터베이스 작업: I/O 바운드인 데이터베이스 쿼리 수행, 대용량 데이터 세트를 가져오거나 업데이트하는 작업 등.\n\n## 2. 동시 작업:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 실시간 데이터 처리: 여러 센서 또는 스트림에서 데이터를 실시간으로 처리하며, IoT 응용 프로그램에서 사용됩니다.\n- GUI 어플리케이션: 사용자 인터페이스를 반응적으로 유지하기 위해 시간이 많이 소요되는 작업을 백그라운드에서 실행합니다.\n\n## 3. 독립적인 작업의 병렬 처리:\n\n- 일괄 처리: 이미지 처리 또는 데이터 변환 작업과 같이 병렬로 실행할 수 있는 많은 독립적인 작업을 처리합니다.\n- 시뮬레이션: 여러 시뮬레이션 또는 몬테카를로 실험을 동시에 실행합니다.\n\n# 멀티스레딩을 사용하지 말아야 할 때:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n멀티스레딩은 상당한 속도 향상을 제공할 수 있지만 항상 모든 문제에 대한 최적의 해결책은 아닙니다. 멀티스레딩이 적합하지 않을 수 있는 몇 가지 시나리오는 다음과 같습니다:\n\n- CPU 바운드 작업: 작업이 CPU에 많은 부하를 주고 순수한 수학 계산처럼 대기 시간이 거의 없는 경우, 별도의 프로세스를 생성하기 위해 multiprocessing 모듈을 사용하는 것이 더 효과적일 수 있습니다.\n- 전역 인터프리터 잠금 (GIL): CPython에서 전역 인터프리터 잠금은 CPU 바운드 작업에 대한 멀티스레딩의 성능 향상을 제한할 수 있습니다. 이러한 경우에는 multiprocessing을 사용하거나 Jython이나 IronPython과 같은 GIL이 없는 구현을 사용하는 것이 효과적일 수 있습니다.\n- 복잡한 공유 상태: 여러 스레드간의 복잡한 공유 상태를 관리하는 것은 경합 조건, 데드락 및 스레드 안전성과 관련된 문제와 버그를 도입할 수 있습니다.\n\n작업의 성격과 잠재적인 병목 현상을 이해함으로써 멀티스레딩이 응용 프로그램에 적합한 해결책인지 결정할 수 있습니다.\n\n# 전문 팁 - 데코레이터 사용하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n데코레이터는 함수에 멀티스레딩을 더 우아하고 재사용 가능한 방식으로 추가할 수 있습니다. 데코레이터는 다른 함수를 받아들이고 그 동작을 명시적으로 수정하지 않고 확장하는 함수입니다.\n\n```python\nimport time\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# 멀티스레딩을 추가하는 데코레이터\ndef multithreaded(max_workers=5):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n                future_to_args = {executor.submit(func, arg): arg for arg in args[0]}\n                results = []\n                for future in as_completed(future_to_args):\n                    arg = future_to_args[future]\n                    try:\n                        result = future.result()\n                    except Exception as exc:\n                        print(f'{arg}에서 예외가 발생했습니다: {exc}')\n                    else:\n                        results.append(result)\n                return results\n        return wrapper\n    return decorator\n\n# 숫자를 제곱하는 함수\n@multithreaded(max_workers=5)\ndef square_number(number):\n    time.sleep(1)  # 시간이 오래 걸리는 작업 시뮬레이션\n    return number * number\n\n# 처리할 숫자 목록\nnumbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n# 데코레이터를 사용한 함수 실행\nstart_time = time.time()\nsquared_numbers = square_number(numbers)\nend_time = time.time()\n\nprint(\"제곱된 숫자:\", squared_numbers)\nprint(\"소요 시간:\", end_time - start_time, \"초\")\n```\n\n데코레이터를 사용하여 멀티스레딩을 처리하면 코드가 단순해지는 것뿐만 아니라 재사용성이 높아지고 코드가 더 깔끔해집니다. @multithreaded 데코레이터를 쉽게 적용하여 Python 코드를 최적화하는 유연하고 강력한 방법을 제공하여 병렬로 실행해야 하는 모든 함수에 데코레이터를 쉽게 적용할 수 있습니다.\n\n# 결론\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n멀티스레딩은 Python에서 루프를 최적화하는 강력한 도구입니다, 특히 I/O 바운드 및 동시성 작업에 대해. concurrent.futures 모듈을 활용하여 프로세스 시간을 크게 단축하고 프로그램의 효율성을 향상시킬 수 있습니다. 그러나 CPU 바운드 작업이나 복잡한 공유 상태를 다룰 때에는 멀티스레딩이 최선의 방법인지를 판단하기 위해 특정 사용 사례를 신중하게 평가하는 것이 중요합니다. 신중한 고려와 구현으로 멀티스레딩은 응용 프로그램의 성능을 크게 향상시킬 수 있습니다.\n\n# 연락하고 싶으시다구요?\n\n읽어 주셔서 감사합니다. 즐겁게 보셨기를 바라며 이 글에서 무언가를 얻을 수 있기를 바랍니다.\n\n- 만약 이 글이 마음에 드셨다면 아래에서 박수를 부탁드려요 👏👏👏...\n- 더 많은 AI 정보를 얻기 위해 팔로우해 주세요 🤖🤖🤖...\n- LinkedIn에서 저를 찾아보세요\n- GitHub에서 코드를 확인해 보세요\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n언제나 궁금한 점이나 아이디어, 추천 사항이 있으시면 언제든지 댓글로 질문해주세요.","ogImage":{"url":"/TIL/assets/img/2024-07-13-PythonCodingMakeForLoops10xFasterwithMultithreading_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-PythonCodingMakeForLoops10xFasterwithMultithreading_0.png","tag":["Tech"],"readingTime":8},{"title":"지구 이동 거리로 분포 비교하는 방법","description":"","date":"2024-07-13 19:19","slug":"2024-07-13-ComparisonofDistributionswithEarthMoversDistance","content":"\n\n이 글을 읽은 후에는 지구 이동 거리(또는 EMD 또는 Wasserstein 거리라고도 함)의 계산 방법에 대해 심층적으로 이해하게 될 것입니다. 이 지식을 통해 다양한 응용 분야에서의 장단점에 대한 좋은 아이디어를 갖게 될 것입니다.\n\n목차\n\n- 지구 이동 거리(EMD)의 정의와 직관\n- EMD의 응용\n- 처음부터 EMD 계산하기\n- scipy 패키지를 사용하여 EMD 계산하기\n- 결론\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지구 이동 거리의 정의와 직감\n\n지구 이동 거리는 두 분포 간의 차이를 측정하는 특정한 계산 방법입니다. \"지구 이동 거리\"라는 이름은 직관적인 해석에서 유래했습니다. 다른 위치에 있는 서로 다른 모양의 두 더미의 흙(또는 토얄)이 있다고 상상해보세요. EMD는 두 번째 더미를 첫 번째 더미처럼 보이도록 옮기는 데 필요한 작업량(총 토얄량 times 거리로 정의됨)을 의미합니다.\n\n이를 예시로 가장 잘 설명할 수 있다고 생각합니다: A와 B 두 분포가 있다고 가정해보겠습니다. 우리가 궁금한 것은 두 분포가 얼마나 다른지 입니다. EMD는 A를 B로 변환하고 변환을 완료하는 데 필요한 총 작업량(즉, 이동한 단위 수 X 이동 거리)을 측정하여 이 질문에 대답합니다. 아래 예시는 두 간단한 분포의 EMD를 계산하는 방법을 설명합니다:\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*Bh6F9kmrunqCnnkueSEidg.gif)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n한 분포를 다른 분포로 변환하기 위해 우리가 하는 움직임 집합을 '운송 계획'이라고 합니다 — 한 위치에서 물질이나 물품을 다른 위치로 운반하는 것을 상상해보세요.\n\n위의 그래픽에 대한 운송 계획은 다음과 같습니다:\n\n![이미지](/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_1.png)\n\n이 운송 계획은 우리에게 분포 A를 분포 B로 가장 효율적으로 변환하는 방법을 보여줍니다. 이 운송 계획의 총 작업량이 두 분포 간의 EMD입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지구 이동자 거리의 응용\n\n지구 이동자 거리는 물론 거리의 한 종류입니다! 따라서 그 응용 분야는 일반적으로 비교 중심입니다. 이 글에서는 지구 이동자 거리의 세 가지 응용을 살펴볼 텐데요. 지구 이동자 거리가 어떻게 유용하게 사용될 수 있는지 감을 잡을 수 있게 도와줄 거예요.\n\n지구 이동자 거리는 기계 학습에서 모델 모니터링에 사용될 수 있습니다. 모델 모니터링에서 데이터 과학자들은 모델 입력과 출력이 시간이 지남에 따라 어떻게 변화하는 지 관찰합니다. 지구 이동자 거리는 훈련 데이터셋과 프로덕션 데이터셋 간의 차이를 정량화하여 입력 또는 출력 변화를 정량화하는 데 사용될 수 있습니다. 큰 지구 이동자 거리 값은 모델을 수정하거나 재훈련해야 할 수도 있다는 것을 시사할 수 있습니다.\n\n지구 이동자 거리는 또한 이미지 비교/검색에 사용됩니다. 두 이미지 사이의 픽셀 분포를 비교하여 이들의 유사성을 계산할 수 있습니다. 이 유사성을 사용하여 이미지들이 얼마나 비슷한 지 비교나 검색에 활용할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nEMD는 문서를 비교하는 데 사용될 수 있습니다. 다양한 ETL 측정치 간의 분포를 비교하여 문서가 유사한지 확인할 수 있습니다. 이 애플리케이션을 사용하여 원본이어야 하는 문서가 다른 문서들과 유의한 유사성을 가지고 있는지 확인하여 표절을 식별할 수 있습니다.\n\n물론 이는 EMD의 응용 프로그램의 전체 목록은 아니지만, EMD가 실제로 어떻게 사용될 수 있는지에 대한 아이디어를 제공할 수 있기를 희망합니다.\n\n빈손에서 Earth Mover's Distance 계산하기\n\nEMD의 해석은 간단하고 직관적이지만, 계산은 다소 복잡합니다. 빈손에서 계산하는 것이 효과적인 학습 전략이라고 생각돼서 여기서 그렇게 할 것입니다! 이 섹션을 마치면 정확히 어떻게 Earth Mover's Distance가 계산되는지 이해하게 될 거예요!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 최적화\n\nEMD(지구 이동자 거리)의 정의 중 하나인 중요한 부분 중 하나는 지금까지 간과했던 사항으로, EMD는 가장 효율적인 운송 계획에 필요한 최소 작업량입니다. 최적화는 계산의 핵심입니다! 우리는 최적화를 실행하여 최상의 운송 계획을 찾고, 그 솔루션에 해당하는 작업량을 계산해야 합니다. 그 작업량이 바로 EMD입니다!\n\n만약 두 분포가 n개의 관찰을 가지고 있다고 가정하면 (몇 가지 예외 상황에 대해 조금 후에 논의하겠습니다), n!개의 고유한 운송 계획이 있습니다. 계승에 익숙하지 않다면, 계승은 신속하게, 정말 빨리 증가합니다. 예를 들어, 위 섹션에서의 소규모 예제의 경우, 크기가 8인 두 분포가 있습니다. 모두 8! = 40,320개의 고유한 운송 계획이 있습니다! 이는 그러한 소규모 분포에 대해 매우 많은 양이며, 분포 크기가 커질수록 빠르게 처리할 수 없게 됩니다.\n\n<img src=\"/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_2.png\" />\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n팩토리얼로 커지는 해결 공간 때문에 매우 작은 문제조차 가장 효율적인 운송 계획을 찾기 위한 모든 잠재적인 해결책을 살펴볼 수는 없어요. 다행히 EMD 운송 문제는 선형 프로그래밍 최적화 문제로 인코딩할 수 있어요. 선형 프로그래밍이 사용하는 '트릭' 덕분에 모든 잠재적인 해결책을 탐색하지 않고도 전역 최적해를 찾을 수 있어요.\n\n이제 EMD 운송 문제를 선형 프로그래밍 문제로 설정하는 방법에 대해 알아볼게요. 모든 최적화 문제에는 목표와 제약 조건이 있어요 - 아래에서 선형 프로그래밍 EMD 문제의 목표와 제약 조건을 살펴볼게요.\n\n목표:\n\n<img src=\"/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_3.png\" />\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n제약 사항:\n\n![Constraint 1](/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_4.png)\n\n![Constraint 2](/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_5.png)\n\n![Constraint 3](/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_6.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 최적화 구성 요소를 자세히 살펴봐요. 최적화 구성 요소를 살펴보면서, 예시로 두 개의 간단한 분포를 사용할 거에요. 이 분포들은 각각 3개의 관측값을 가지고 있어요: 분포 A = [1, 2, 3] 그리고 분포 B = [5, 6, 7].\n\n목적 함수\n\n가장 먼저 목적 함수에 대해 이야기해봐요. 목적 함수에는 두 부분, 즉 전송 계획 xᵢⱼ와 비용 행렬 dᵢⱼ이 포함되어 있어요.\n\n이전 섹션에서 긴 형식의 전송 계획을 보여줬어요. 선형 프로그래밍 최적화를 위해, 해당 전송 계획을 분포 A 값을 열로, 분포 B 값을 행으로 가지는 행렬로 이동할 거예요. 최적화 과정은 최적의 전송 계획을 생성해내요. 전송 계획은 두 분포 간의 관측값 조합마다 값을 가지고 있어요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![이미지](/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_7.png)\n\nCost matrix인 dᵢⱼ는 이동 계획의 각 셀에 관련된 작업량을 매핑합니다.\n\n![이미지](/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_8.png)\n\n최적화 함수는 이동 계획과 비용 행렬의 내적을 취하여 특정 이동 계획에 대한 총 작업량을 계산합니다. 최적화 프로세스는 작업을 최소화하는 이동 계획을 찾습니다. 이 최소 작업량이 지구 이동자 거리입니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 운송 계획이 포함된 상태에서 해당 비용 행렬을 통해 총 작업량이 어떻게 계산되는지 살펴봅시다.\n\n![image](/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_9.png)\n\n위의 행렬에 대한 점곱은 다음과 같이 계산됩니다:\n\n총 작업량 = (0*4) + (1*5) + (0*6) + (1*3) + (0*4) + (0*5) + (0*2) + (0*3) + (1*4)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n총 작업량 = (1*5) + (1*3) + (1*4) = 12\n\n우리의 목적 함수는 운송 계획과 비용 행렬의 내적을 최소화하려는 것입니다.\n\n규칙\n\n규칙은 조금 복잡해 보일 수 있지만 실제로는 매우 직관적입니다. 첫 번째 규칙은 각 관찰이 운송 계획에 포함되도록 하는 것입니다. 즉, 이 규칙은 첫 번째 분포의 각 관찰이 두 번째 분포로 딱 한 번 이동되도록 합니다. 두 번째 규칙은 최종 '변환된' 분포가 두 번째 분포와 일치하도록 하는 것을 보장합니다. 마지막 규칙은 최적화가 음의 수량을 이동하려고 시도하지 않도록 하여 이치에 맞지 않게 하는 것을 방지합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 세 가지의 무효한 운송 계획과 하나의 유효한 계획이 있습니다. 이 중 몇 가지를 살펴보고 제약 조건이 어떻게 비현실적인 운송 계획을 막는지 이해해 보겠습니다.\n\n![image](/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_10.png)\n\n왼쪽 상단: 위치 1에서 단위 하나가 위치 5로 이동하고 단위 하나가 위치 7로 이동합니다. 이는 위치 1에 단위 하나만 있는데 두 곳으로 한 단위를 이동시키는 것은 위배 사항입니다! 따라서 한 단위를 두 곳으로 이동시키는 것은 불가능합니다. 첫 번째 제약은 이런 일이 일어나지 않도록 합니다.\n\n위치 2에 있는 단위 하나가 위치 6으로 이동하는 것에는 문제가 없습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위치 3의 한 단위가 위치 7로 이동합니다. 이것은 또한 위반입니다. 왜냐하면 위치 7로 두 단위가 이동한다면 (위치 1에서의 한 단위와 위치 3에서의 한 단위), 우리가 A를 변환하는 배포는 B 배포와 같지 않습니다 (B는 위치 7에 단위 하나만 있는데 반해). 이 문제는 두 번째 제약으로 방지됩니다.\n\n오른쪽 상단: 오른쪽 상단 솔루션은 전혀 논리적인 의미가 없습니다. 어떻게 음수 단위를 이동할 수 있을까요? 그러나 이 계획은 첫 번째 두 제약을 모두 위반하지 않음을 주목하세요! 모든 행과 열이 해당 단위의 총합과 일치합니다 (이 예제에서 합은 1입니다). 기계는 이것이 비논리적임을 모르죠. 이런 종류의 헛소리 솔루션을 방지하기 위해 다음과 같은 세 번째 제약을 포함해야 합니다. 다른 두 제약은 이것을 잡아내지 못합니다!\n\n다른 두 운송 계획 해석은 독자에게 맡기겠습니다 (특히 왜 오른쪽 하단 계획이 유효한지).\n\n관찰 수가 다른 배포\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금까지는 두 분포가 관찰치의 수가 동일한 단순한 예제만 살펴보았습니다. 이렇게 하면 사소합니다. 왜냐하면 일대일 매핑이 작동하기 때문입니다(A 분포에서 한 관찰치가 B 분포의 한 위치로 이동합니다). 그러나 이것은 특수한 경우입니다. EMD의 많은 응용에서 분포의 크기가 다를 수 있습니다. 이런 경우에는 우리가 설정한대로 최적화가 작동하지 않을 것입니다!\n\n다행히도 수정하는 것은 그렇게 어렵지 않습니다. 최적화의 프레임워크(목적 함수와 제약 조건)는 사용 가능합니다—우리는 최적화를 실행하기 전에 몇 가지 수정을 해야 합니다.\n\n최적화에 숫자의 원시 목록을 입력하는 대신에 확률 분포를 입력합니다. 확률 분포는 관측치들의 개별 비율을 가지는 분포를 의미합니다.\n\n예를 들어, [1, 1, 2, 2, 2, 3, 3, 3] 분포가 있다고 가정해 봅시다. 이를 확률 분포로 변환하기 위해, 먼저 각 고유값의 개수를 얻습니다—이 경우 [2, 3, 3] (1이 두 개, 2가 세 개, 3이 세 개 있다). 확률 밀도는 항상 하나로 합쳐집니다(이 특성 덕분에 다른 크기의 분포를 비교할 수 있습니다)—우리의 빈도 수가 하나로 합치려면, 모든 빈도수의 합으로 각 빈도를 나누기만 하면 됩니다—[2/8, 3/8, 3/8] = [0.25, 0.375, 0.375]. 이제 우리의 분포가 변환되었으니 EMD 계산에 직접 입력할 준비가 되었습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n확률 분포에서 원시 분포로의 변환 후에는 관측치의 위치를 잃게 됩니다. 예를 들어, 0.25가 위치 1에 해당한다는 것을 알 수 없습니다. 이것이 거리 행렬이 필요한 이유입니다. 거리 행렬은 변환되지 않으며 최적화 프로세스에서 사용할 상대적인 위치 간 거리를 보존합니다. EMD의 정의도 약간 바뀝니다. 확률 분포로의 변환으로 인해 최소 작업에서 단위당 평균 최소 작업으로 변경됩니다.\n\n코딩\n\n설정을 이해했으니, 수동 계산을 위한 코딩을 진행해 보겠습니다. 선형 프로그래밍 최적화를 수행하기 위해 pulp 패키지를 사용할 것입니다.\n\nEMD를 수동으로 계산하는 코드는 다음과 같습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import wasserstein_distance\nimport pulp\n\n# 선형 프로그래밍을 사용하여 수동으로 emd 계산\ndef emd_manual(a, b):\n\n    '''\n        임의 크기의 두 분포가 주어졌을 때 EMD를 계산합니다\n        \n        입력:\n        a (list) : 첫 번째 분포에 대한 관측치 목록\n        b (list) : 두 번째 분포에 대한 관측치 목록\n      \n        출력:\n        emd_calc (float)      : EMD 계산값\n        transport_plan (dict) : transport plan의 행/열이 키이며\n                                해당 요소는 해당 위치로 이동하는 관측치 수입니다\n    '''\n\n    # 각 고유 값의 발생 횟수 계산\n    a_unique, a_counts = np.unique(a, return_counts=True)\n    b_unique, b_counts = np.unique(b, return_counts=True)\n\n    # 확률 분포로 변환\n    prob_dist_a = a_counts / np.sum(a)\n    prob_dist_b = b_counts / np.sum(b)\n    norm_a = prob_dist_a / np.sum(prob_dist_a)\n    norm_b = prob_dist_b / np.sum(prob_dist_b)\n  \n    # 확률 분포의 크기 가져오기\n    n = len(norm_a)\n    m = len(norm_b)\n\n    # pulp 선형 프로그래밍 문제 설정\n    emd_problem = pulp.LpProblem('EMD', sense=1)\n\n    # 결정 변수 정의\n    x = pulp.LpVariable.dicts(\"x\", [(i, j) for i in range(n) for j in range(m)],\n                              lowBound=0, cat='Continuous')\n\n    # 목적 함수 추가 (총 비용 최소화)\n    emd_problem += pulp.lpSum(x[i, j] * np.abs(a[i] - b[j])\n                              for i in range(n) for j in range(m))       \n\n    # 제약 조건 1\n    for i in range(n):\n        emd_problem += pulp.lpSum(x[i, j] for j in range(m)) == norm_a[i]\n    \n    # 제약 조건 2\n    for j in range(m):\n        emd_problem += pulp.lpSum(x[i, j] for i in range(n)) == norm_b[j]\n    \n    # 제약 조건 3\n    for i in range(n):\n      for j in range(m):\n        emd_problem += x[i, j] >= 0\n  \n    # 문제 풀이\n    emd_problem.solve()\n\n    if emd_problem.status == 1:\n        print('해결책 찾음!')\n    else:\n        print('가능한 해결책 없음')\n    \n    # 해결에서 emd 계산\n    emd_calc = pulp.value(emd_problem.objective)\n\n    # transport plan 조합\n    transport_plan = {(i, j): pulp.value(x[i, j]) for i in range(n) for j in range(m)}\n\n    # 정규화를 위한 transport plan 조정\n    for key in transport_plan:\n        transport_plan[key] *= len(a)\n        transport_plan[key] = round(transport_plan[key])\n\n    return emd_calc, transport_plan\n\n \n# 테스트 분포로 emd_manual 함수 실행\nif __name__ == \"__main__\":\n\n    a =  [1, 1, 2, 2, 2, 3, 3, 3]\n    b = [6, 6, 7, 8, 8, 8, 9, 9]\n\n    emd, transport_plan = emd_manual(a, b)\n    print(emd)\n    print(transport_plan)\r\n```\n\nScipy를 사용하여 EMD 계산\n\n물론, EMD를 계산할 때마다 이러한 코드를 작성하는 것은 아주 미친 짓일 것입니다. 한 번만 작성하고 재사용해도, 잘 검증된 Python 패키지의 함수만큼 견고하고 효율적일 수 없을테니요. 저는 순수 코드를 학술적인 연습으로 썼을 뿐입니다! 다행히도, 대부분의 일반적인 계산과 마찬가지로 이미 이를 위해 설치 가능한 패키지가 있습니다! scipy 패키지에는 stats 모듈 내의 wassertein_distance 함수가 있습니다. 아래 코드에서 볼 수 있듯이 사용하기 매우 쉽습니다!\n\n```js\nfrom scipy.stats import wasserstein_distance\n\nif __name__ == '__main__':\n\n    a =  [1, 1, 2, 2, 2, 3, 3, 3]\n    b = [6, 6, 7, 8, 8, 8, 9, 9]\n\n    emd = wasserstein_distance(a, b)\n    print(emd)\r\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 함수를 사용하여 손 계산 결과가 내장 계산 결과와 동일한지 확인할 수 있습니다.\n\n결론\n\n어스 이동 거리(Earth Mover's Distance)는 두 분포 간의 차이를 이해하는 데 도움이 되는 계산 방법입니다. 이는 두 분포를 서로 비교해야 하는 여러 응용 프로그램에서 유용합니다.\n\n자체적 계산은 첫 번째 분포를 두 번째로 변환하는 데 필요한 최소한의 총 이동량입니다. 최소한의 양을 찾고 있기 때문에 선형 프로그래밍을 활용하여 최적화를 수행합니다. 이를 파이썬으로 수동으로 계산할 수는 있지만 pulp 패키지를 사용하는 것은 그다지 실용적이지 않습니다. EMD는 scipy 패키지의 stats 모듈 내 wasserstein_distance 함수를 사용하여 쉽게 계산할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n깃허브 링크: [https://github.com/jaromhulet/emd_manual_calculations](https://github.com/jaromhulet/emd_manual_calculations)","ogImage":{"url":"/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-ComparisonofDistributionswithEarthMoversDistance_0.png","tag":["Tech"],"readingTime":15},{"title":"GeoPandas로 지리공간 데이터 분석 마스터하기","description":"","date":"2024-07-13 19:16","slug":"2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas","content":"\n\n데이터 과학 분야에서는 공간 데이터를 조작하고 분석하는 능력이 다양한 가능성을 열어줍니다. 배송 경로를 최적화하는 것부터 자연 자원을 관리하는 것까지 응용 분야는 광범위하고 다양합니다. GeoPandas는 파이썬의 강력한 라이브러리로, 파이썬에서 지리 데이터를 다루는 것을 쉽게 만들어줍니다.\n\nGeoPandas는 pandas가 사용하는 데이터 유형을 확장하여 기하학적 유형에 대한 공간 연산을 허용합니다. 기하학적 연산은 shapely에서 수행됩니다. GeoPandas는 파일 액세스를 위해 Fiona에, 플로팅을 위해 Matplotlib에 의존합니다.\n\n기본적으로 GeoPandas는 매우 인기 있는 pandas 라이브러리의 확장으로, 익숙한 pandas 프레임워크 내에서 지리 데이터를 직관적으로 처리할 수 있습니다. 이는 이미 pandas를 잘 알고 있다면 GeoPandas를 숙달하기에 절반 정도 되었다는 것을 의미합니다!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n하지만 GeoPandas를 독특하게 만드는 요소는 무엇일까요? 먼저, 지리 공간 데이터 작업을 간편화하여 pandas에서 다루는 다른 유형의 데이터를 조작하는 것만큼 지리 정보를 읽고 분석하며 시각화하는 작업을 간단하게 만듭니다. 점, 선 또는 다각형과 같은 데이터를 처리할 때도 GeoPandas가 모두 해결해 드립니다.\n\nGeoPandas의 응용 분야는 지리 정보 분석 분야 자체만큼 다양합니다. 도시 계획자들은 보다 효율적인 대중 교통 시스템을 설계하는 데 사용할 수 있고, 환경 과학자들은 토지 이용 변화를 시간이 지남에 따라 추적할 수 있으며, 기업은 지리 데이터를 기반으로 물류를 최적화할 수 있습니다. 가능성은 정말 무한합니다.\n\n이 블로그 포스트에서는 GeoPandas의 기본부터 고급 지리 분석 기술까지 다뤄볼 것입니다. 경험 많은 데이터 과학자이든 막 시작한 분이든, GeoPandas가 데이터 분석 도구상에서 어떻게 가치 있는 통찰을 제공하는지 알 수 있을 것입니다.\n\nPython pandas를 사용하는 다른 블로그 포스트도 확인해 보세요: [링크 추가]\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# GeoPandas 환경 설정하기\n\nGeoPandas를 사용하여 공간 분석의 흥미로운 세계로 들어가기 전에 제대로 된 환경을 설정하는 것이 중요합니다. 이는 GeoPandas가 올바르게 작동하기 위해 필요한 몇 가지 종속 항목과 함께 GeoPandas를 설치하는 것을 포함합니다. 걱정하지 마세요. 이 과정은 간단하며, 저가 단계별로 안내해 드리겠습니다.\n\n# 단계 1: Python 설치하기\n\n가장 먼저, 시스템에 Python이 설치되어 있는지 확인하세요. GeoPandas는 Python 라이브러리이므로 Python이 필수입니다. 아직 Python을 설치하지 않은 경우, 공식 Python 웹사이트에서 다운로드하고 사용 중인 운영 체제에 맞는 설치 지침을 따르세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 단계 2: 가상 환경 설정하기 (선택 사항이지만 추천됨)\n\n파이썬 프로젝트를 위해 가상 환경을 사용하는 것이 좋은 실천 방법입니다. 이렇게 하면 프로젝트의 종속성이 다른 프로젝트와 격리되며 잠재적인 충돌을 피할 수 있습니다. 다음 명령을 사용하여 터미널이나 명령 프롬프트에서 가상 환경을 만들 수 있습니다:\n\n```js\npython -m venv geopandas_env\n```\n\n가상 환경을 활성화하려면 다음 명령을 사용하세요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Windows에서:\n\n```js\ngeopandas_env\\Scripts\\activate\n```\n\n- macOS와 Linux에서:\n\n```js\nsource geopandas_env/bin/activate\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 단계 3: GeoPandas 및 종속성 설치\n\n환경이 설정되었으면 GeoPandas를 설치할 차례입니다. GeoPandas에는 파일 액세스를 위한 Fiona, 기하학적 작업을 위한 Shapely 및 플로팅을 위한 matplotlib과 같은 종속성이 몇 가지 있습니다. GeoPandas와 그 종속성을 모두 설치하는 가장 쉬운 방법은 Anaconda 또는 Miniconda를 설치한 경우 conda 명령을 사용하는 것입니다:\n\n```js\nconda install geopandas\n```\n\n만약 pip를 사용하고 싶다면, 다음 명령을 사용하여 GeoPandas를 설치할 수 있습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\npip install geopandas\n```\n\n참고: pip를 사용하여 GeoPandas를 설치할 때 Windows에서 작업하는 경우 일부 종속성을 수동으로 설치해야 할 수 있습니다. GeoPandas를 설치하고 발생할 수 있는 문제를 처리하는 세부 지침은 GeoPandas 설치 문서를 참조하십시오.\n\n# 단계 4: 설치 확인\n\n모든 것이 올바르게 설정되었는지 확인하려면 Python 인터프리터 또는 Jupyter Notebook을 열고 GeoPandas를 가져와보세요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport geopandas as gpd\n```\n\n만약 오류가 발생하지 않았다면, 축하합니다! 이제 GeoPandas를 사용하여 작업을 시작할 준비가 되었습니다.\n\n# GeoPandas의 기본: GeoSeries와 GeoDataFrame\n\nGeoPandas는 파이썬에서 지리 정보 데이터를 직관적이고 간단하게 다룰 수 있도록 pandas의 데이터 구조를 기반으로 합니다. GeoPandas의 핵심은 두 가지 주요 데이터 구조인 GeoSeries와 GeoDataFrame입니다. 이를 이해하는 것은 지리 정보 분석을 위해 GeoPandas의 전체 능력을 활용하는 데 필수적입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# GeoSeries: 기본 구성 요소\n\nGeoSeries는 본질적으로 각 항목이 도형 또는 기하 객체 세트인 벡터입니다. 이는 Shapely가 지원하는 포인트, 라인, 폴리곤 또는 다른 모양 유형일 수 있습니다. Shapely는 평면 기하 객체를 조작하고 분석하기 위한 Python 라이브러리입니다.\n\n이제 GeoSeries를 설명하기 위한 간단한 예제를 살펴보겠습니다:\n\n```python\nfrom shapely.geometry import Point, Polygon\nimport geopandas as gpd\n\n# 포인트 GeoSeries 생성\npoints = gpd.GeoSeries([Point(1, 1), Point(2, 2), Point(3, 3)])\n\n# 포인트 시각화\npoints.plot()\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_1.png\" />\n\n이 예제에서는 세 개의 점으로 이루어진 GeoSeries를 만들고, 이러한 점들을 .plot() 메서드를 사용하여 시각화합니다. 지오메트릭 데이터를 처리하고 시각화하는 간단함이 GeoPandas를 지리적 분석에 강력하게 만드는 이유입니다.\n\n# GeoDataFrame: 공간적으로 활성화된 DataFrame\n\nGeoDataFrame은 GeoSeries가 포함된 탭ular 데이터 구조입니다. 이는 pandas DataFrame과 유사하지만, 기하 정보가 포함된 추가적인 열을 가지고 있습니다. 일반적으로 'geometry'라는 이 특별한 열은 기하학적 객체(예: 점, 선, 다각형)를 보유하고 데이터 세트에서 공간 연산을 가능하게 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 Shapely 기하학 요소 목록에서 GeoDataFrame을 생성하는 방법입니다.\n\n```js\n# 몇 개의 점과 다각형을 정의\npolygon = Polygon([(0, 0), (1, 1), (1, 0)])\npoints = [Point(0.5, 0.5), Point(1.5, 1.5)]\n\n# GeoDataFrame 생성\ngdf = gpd.GeoDataFrame({'geometry': points + [polygon]})\n\n# GeoDataFrame 플로팅\ngdf.plot(alpha=0.5, linewidth=2, edgecolor='k', color='cyan')\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_2.png\" />\n\n이 예제에서 점과 다각형을 하나의 GeoDataFrame으로 결합한 후 그래픽으로 표시합니다. alpha, linewidth, edgecolor 매개변수를 사용하여 플롯의 모양을 사용자 정의할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 지리 공간 데이터 읽기\n\n지리 공간 분석에서 가장 흔한 작업 중 하나는 다양한 파일 형식에서 지리 공간 데이터를 읽는 것입니다. GeoPandas는 이를 지원하는 shapefile, GeoJSON 등 여러 형식을 포함한 read_file 함수를 통해 이를 쉽게 할 수 있습니다.\n\n```python\n# shapefile 읽기\ngdf = gpd.read_file(\"파일/경로/shapefile.shp\")\n\n# GeoJSON 파일 읽기\ngdf = gpd.read_file(\"파일/경로/파일.geojson\")\n\n# GeoDataFrame의 처음 몇 행 살펴보기\ngdf.head()\n```\n\n이러한 기본 사항을 알았으니 이제 지리 공간 데이터를 탐색하고 분석할 준비가 되었습니다. 다음 섹션에서는 공간 조인, 오버레이 분석, 지리 공간 데이터 시각화와 같은 고급 주제를 다룰 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n곧 GeoPandas를 사용하여 지리 정보 데이터를 활용하는 기본 작업 몇 가지를 살펴보겠습니다. 이 섹션에서는 지도 데이터를 조작하고 분석하는 방법에 대해 다룰 것이며, 플로팅, 필터링 및 기본적인 공간 작업을 포함합니다. 이러한 작업은 어떠한 지리 정보 분석에도 필수적이며, 더 고급 기술에 대한 튼튼한 기초를 제공할 것입니다.\n\n# GeoPandas에서 지리 정보 데이터 다루기\n\nGeoPandas는 지리 정보 데이터를 다루는 과정을 간소화하여 플로팅, 필터링 및 기본 공간 작업과 같은 작업을 직관적이고 효율적으로 수행할 수 있게 해줍니다. 이러한 작업 중 일부를 살펴보고, GeoPandas를 사용하여 지리 정보 데이터를 조작하고 분석하는 방법을 살펴봅시다.\n\n# 지리 정보 데이터 플로팅\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지리 데이터 시각화는 지리 분석에서의 기본적인 작업입니다. GeoPandas는 Matplotlib과 통합되어 데이터를 쉽게 시각화할 수 있습니다:\n\n```python\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# 샘플 지리 데이터 세트를 불러옵니다.\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\n# 전 세계 지도를 그립니다.\nworld.plot()\nplt.show()\n```\n\n![월드맵](/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_3.png)\n\n이 예제에서는 GeoPandas 내장 데이터 세트를 불러와 세계 각국의 지오메트리를 포함합니다. `.plot()` 메서드를 사용하여 데이터 세트를 지도로 시각화합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 데이터 필터링\n\nGeoPandas는 기하학적 및 속성 기반 조건을 기반으로 데이터를 쉽게 필터링할 수 있습니다. 예를 들어, 특정 지역이나 국가 집합에 초점을 맞추고 싶다면:\n\n```js\n# 북아메리카 국가를 위한 GeoDataFrame 필터링\nnorth_america = world[world['continent'] == 'North America']\n\n# 필터링된 GeoDataFrame 플롯\nnorth_america.plot()\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_4.png\" />\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 코드 스니펫은 세계 GeoDataFrame을 필터링하여 북아메리카 국가만 포함하고 필터링된 데이터를 플롯합니다.\n\n# 기본 공간 작업\n\nGeoPandas는 영역, 거리를 계산하고 기하학적 변환을 수행하는 등 다양한 공간 작업을 지원합니다.\n\n```js\n# 각 국가의 면적 계산\nworld['area'] = world.geometry.area\n\n# 지오메트리에 버퍼 작업 수행\nbuffered_point = south_america.geometry.buffer(1)\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_5.png\" />\n\n첫 번째 작업은 세계 GeoDataFrame의 각 나라에 대한 면적을 계산합니다. 두 번째 예는 버퍼 작업을 보여줍니다. 이 작업은 GeoDataFrame의 지오메트리 주변에 버퍼 영역을 생성합니다.\n\n# 공간 조인\n\n공간 조인은 GeoPandas의 강력한 기능 중 하나로, 두 GeoDataFrame을 공간적 관계를 기반으로 결합할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 도시의 GeoDataFrame 만들기\n도시 = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\n```\n\n```js\n# 도시와 국가 간의 공간 조인 수행\n국가별_도시 = gpd.sjoin(도시, world, op='within')\n# 결과 확인\n국가별_도시.head()\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_6.png\" />\n\n이 예시는 도시의 GeoDataFrame과 국가의 세계 GeoDataFrame 간의 공간 조인을 수행합니다. 결과는 도시와 각 도시가 속한 국가를 포함하는 새로운 GeoDataFrame입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기본 작업의 기반 위에 더 나아가, GeoPandas를 사용하여 고급 지리 공간 분석 기술을 알아보겠습니다. 이 섹션에서는 오버레이 분석, 버퍼 분석, 그리고 최근접 이웃 쿼리와 같이 더 복잡한 작업을 다룰 것입니다. 이러한 기술들은 더 나은 통찰력을 제공하며 복잡한 지리 공간 문제에 대응하기 위해 중요합니다.\n\n# GeoPandas를 활용한 고급 지리 공간 분석\n\nGeoPandas는 기본 지리 공간 작업을 단순화할 뿐만 아니라 고급 지리 공간 분석을 위한 강력한 도구도 제공합니다. 이 섹션에서는 이러한 고급 기술 중 일부를 살펴보며 지리 공간 데이터에서 더 심층적인 통찰력을 발견할 수 있도록 도와줍니다.\n\n# 오버레이 분석\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오버레이 분석은 두 개의 GeoDataFrames를 공간 관계에 따라 결합하여 교차점, 합집합 및 차집합과 같은 작업을 수행하는 데 사용됩니다. 이를 통해 공간 데이터의 서로 다른 레이어를 결합하여 새로운 통찰을 얻는 데 도움이 됩니다.\n\n```js\nimport geopandas as gpd\n# 서로 다른 레이어를 나타내는 두 개의 GeoDataFrame 로드\ngdf1 = gpd.read_file(\"경로/레이어1.shp\")\ngdf2 = gpd.read_file(\"경로/레이어2.shp\")\n# 교차점을 찾기 위해 오버레이 분석 수행\nintersection = gpd.overlay(gdf1, gdf2, how='intersection')\n# 결과를 플로팅\nintersection.plot()\n```\n\n이 예제에서는 gpd.overlay를 사용하여 두 공간 레이어간의 교차점을 찾는 데 사용되었는데, 이는 공원 및 도시 경계와 같은 서로 다른 지리적 특징을 나타낼 수 있습니다.\n\n# 버퍼 분석\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n버퍼 분석은 기하학 주변에 버퍼 영역을 만들어 근접성 분석에 유용합니다. 예를 들어, 강이나 도로로부터 특정 거리 내의 모든 지역을 찾고 싶을 수 있습니다.\n\n```js\n# GeoDataFrame의 각 지점 주변에 1 km 버퍼 생성\nbuffered_points = gdf1.geometry.buffer(1000)\n# 버퍼된 기하학 플롯\nbuffered_points.plot()\n```\n\n이 코드 스니펫은 gdf1의 각 지오메트리 주변에 1 km의 버퍼 영역을 생성하며, 이는 관심 지점과 같은 피처를 나타낼 수 있습니다.\n\n#최근접 이웃 쿼리\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n최근접 이웃 쿼리는 “각 학교의 가장 가까운 병원은 무엇인가요?”와 같은 질문에 중요합니다. GeoPandas를 scikit-learn과 같은 라이브러리와 결합하여 이러한 쿼리를 효율적으로 수행할 수 있습니다.\n\n```js\nfrom sklearn.neighbors import BallTree\nimport numpy as np\n\n# 지오메트리를 좌표의 넘파이 배열로 변환합니다\ncoordinates = np.array(gdf1.geometry.apply(lambda geom: (geom.x, geom.y)).tolist())\n# 효율적인 공간 쿼리를 위해 BallTree를 생성합니다\ntree = BallTree(coordinates, leaf_size=15, metric='haversine')\n# 특정 지점의 가장 가까운 이웃을 쿼리합니다\ndistance, index = tree.query([a_specific_point.coords[0]], k=1)\n# gdf1에서 가장 가까운 지오메트리를 찾습니다\nnearest_geometry = gdf1.iloc[index[0]]\n```\n\n이 스니펫은 scikit-learn의 BallTree를 사용하여 GeoDataFrame 내에서 특정 지점에 가장 가까운 이웃을 효율적으로 찾는 방법을 보여줍니다.\n\n# 고급 시각화 기법\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n고급 시각화 기술을 사용하면 지리 정보 데이터의 해석을 높일 수 있어요. GeoPandas는 contextily와 같은 라이브러리와 함께 사용하여 플롯에 베이스맵을 추가하고 matplotlib를 사용하여 더 많은 사용자 정의를 할 수 있어요.\n\n```js\nimport contextily as ctx\n# GeoDataFrame 그림 그리기\nax = gdf1.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')\n# 베이스맵 추가\nctx.add_basemap(ax, crs=gdf1.crs.to_string(), source=ctx.providers.Stamen.Terrain)\n```\n\n이 코드는 gdf1의 플롯에 베이스맵을 추가하여 공간 데이터의 시각적 맥락을 향상시킵니다.\n\n다음 섹션에서는 GeoPandas를 활용하여 실제 데이터를 분석하고 시각화하는 방법을 탐색할 거에요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 뉴욕 시의 공공 공원 분석\n\n뉴욕 시의 공공 공원의 분포와 특징을 분석하기 위해 GeoPandas를 사용할 거에요. 어떤 자치구에 가장 많은 공원 면적이 있는지, 공원들의 공간적 분포를 시각화하고 도시 내 공원과의 근접성을 조사할 거에요.\n\n## 단계 1: 데이터셋 불러오기\n\n먼저, GeoJSON 데이터셋을 GeoDataFrame으로 불러올 거에요:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nimport geopandas as gpd\n\n# GeoJSON 데이터를 GeoDataFrame으로 로드합니다.\nparks_gdf = gpd.read_file(\"https://data.cityofnewyork.us/api/geospatial/rjaj-zgq7?method=export&format=GeoJSON\")\n\n# 면적 계산을 위해 GeoDataFrame이 사영 좌표 체계를 사용하도록합니다.\nparks_gdf = parks_gdf.to_crs(epsg=2263)  \n# EPSG:2263는 뉴욕 롱 아일랜드(피트)를 위한 좌표 체계입니다.\n\n# 각 공원의 면적을 제곱 피트로 계산합니다.\nparks_gdf['area'] = parks_gdf.geometry.area\n\n# GeoDataFrame의 처음 몇 행을 검사합니다.\nparks_gdf.head()\n\n# 공원을 그래픽으로 표시합니다.\nparks_gdf.plot()\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_7.png\" />\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_8.png\" />\n\n이 코드는 URL에서 데이터 세트를 직접로드하고 GeoDataFrame을 만들어 데이터를 검사하고 구조를 이해하는 데 사용됩니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 2: 데이터 탐색 및 정리\n\n분석에 앞서 데이터를 탐색하고 정리하는 것이 중요합니다. 이 과정에는 결측값을 확인하고, 사용 가능한 속성을 이해하며, 지오메트리가 유효한지 확인하는 작업이 포함될 수 있습니다.\n\n```js\n# 결측값 확인\nprint(parks_gdf.isnull().sum())\n\n# 데이터 유형 및 속성 확인\nprint(parks_gdf.dtypes)\n\n# 모든 지오메트리가 유효한지 확인\nparks_gdf = parks_gdf[parks_gdf.is_valid]\n```\n\n## 단계 3: 자치구별 공원 분포 분석\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가정하에 데이터셋에는 각 공원이 속한 자치구를 나타내는 열이 포함되어 있다고 가정하면, 자치구별로 데이터를 집계해서 공원 면적의 분포를 분석할 수 있습니다.\n\n```js\n# 자치구별로 데이터를 집계하고 공원 면적을 합산합니다.\npark_areas_by_borough = parks_gdf.dissolve(by='borough', aggfunc='sum')\n# 결과를 시각화합니다.\npark_areas_by_borough.plot(column='area', legend=True, cmap='Greens')\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_9.png\" />\n\n## 단계 4: 공원의 공간 분포 시각화하기\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n도시 전체에 걸쳐 공원이 분포하는 공간적 분포를 이해하기 위해 지도상에 공원을 시각화할 수도 있습니다.\n\n```js\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n# 공원 플로팅\nax = parks_gdf.plot(figsize=(10, 10), color='green', alpha=0.5)\n# 베이스맵 추가\nctx.add_basemap(ax, crs=parks_gdf.crs.to_string())\n# 제목 설정\nax.set_title(\"뉴욕시의 공원의 공간 분포\")\nplt.show()\n```\n\n![링크](/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_10.png)\n\n이 시각화를 통해 뉴욕시의 도시 경관 내에서의 공원 밀도와 분포를 이해하는 데 도움이 될 것입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 5: 근접성 분석\n\n더 고급화된 분석을 위해, 우리는 공원에서 일정 거리 내에 있는 도시의 어느 지역들을 확인하는 근접성 분석을 수행할 수 있습니다. 이는 도시 계획 및 공중보건 연구에 유용합니다.\n\n```js\nfrom geopandas.tools import sjoin\nfrom shapely.geometry import Point\nimport numpy as np\n\n# 도시 전체에 대한 포인트 그리드 생성\nx = np.linspace(parks_gdf.bounds.minx.min(), parks_gdf.bounds.maxx.max(), num=100)\ny = np.linspace(parks_gdf.bounds.miny.min(), parks_gdf.bounds.maxy.max(), num=100)\nxx, yy = np.meshgrid(x, y)\ngrid_points = gpd.GeoDataFrame(geometry=gpd.points_from_xy(xx.flatten(), yy.flatten()), crs=parks_gdf.crs)\n\n# 각 공원 주변 500피트의 버퍼 생성 (필요에 따라 거리 조정 가능)\nparks_buffered = parks_gdf.buffer(500)\n\n# 버퍼된 지리 데이터 시리즈를 지리 데이터프레임으로 변환\nparks_buffered_gdf = gpd.GeoDataFrame(geometry=parks_buffered)\n\n# 그리드 포인트와 버퍼된 공원 간의 공간 조인 수행\npoints_near_parks = gpd.sjoin(grid_points, parks_buffered_gdf, how='inner', op='intersects')\n\n# 결과 시각화\nax = points_near_parks.plot(markersize=2, color='blue', alpha=0.5, label='Near Proximity to Parks')\n\nparks_gdf.plot(ax=ax, color='red', alpha=1, label='Parks')\n\nctx.add_basemap(ax, crs=parks_gdf.crs.to_string())\nax.set_title(\"뉴욕시의 공원에서 500m 내의 지역\")\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_11.png\" />\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 근접성 분석은 공원 주변 500m 내 영역을 강조하여 도시 개발 및 접근성 연구에 유용한 통찰력을 제공할 것입니다.\n\n# 구 당 공원 밀도\n\n공원의 분포를 더 세밀하게 이해하기 위해 구 당 공원 밀도를 계산할 수 있습니다. 이는 각 구 내의 공원 수를 세어 해당 구의 총 면적으로 나누는 것을 포함합니다.\n\n```js\n# parks_gdf에 'borough' 열이 있고 면적 계산을 위해 EPSG:2263으로 투영된 상태로 가정합니다\nborough_area = parks_gdf.dissolve(by='borough', aggfunc='sum')['area']\n\n# 각 구 내 공원 수 세기\npark_count = parks_gdf['borough'].value_counts()\n\n# 제곱 피트 단위의 면적을 마일 단위로 환산하여 공원 밀도 계산\npark_density = park_count / (borough_area / (5280**2))\n\n# 공원 밀도 그래프\npark_density.plot(kind='bar', title='구 당 공원 밀도 (제곱 마일당 공원 수)')\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Park](/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_12.png)\n\n# 가장 크고 작은 공원\n\n가장 크고 작은 공원을 식별하면 도시 내 중요한 녹지 공간 및 레크리에이션 공간이 부족할 수 있는 지역을 강조할 수 있습니다.\n\n```js\n# 가장 큰 공원\nlargest_park = parks_gdf.iloc[parks_gdf['area'].idxmax()]\n# 가장 작은 공원\nsmallest_park = parks_gdf.iloc[parks_gdf['area'].idxmin()]\nprint(f\"가장 큰 공원: {largest_park['name']} in {largest_park['borough']}, 면적: {largest_park['area']} 제곱피트\")\nprint(f\"가장 작은 공원: {smallest_park['name']} in {smallest_park['borough']}, 면적: {smallest_park['area']} 제곱피트\")\n```\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_13.png\" />\n\n# 공원으로부터 관심지점까지의 근접성\n\n학교, 병원 또는 주거 지역 등 다양한 관심지점들과 가장 가까운 공원까지의 근접성을 분석하는 것은 녹지 공간에 대한 대중 접근성에 대한 통찰을 제공할 수 있습니다.\n\n```js\nfrom shapely.geometry import Point\n\n# 위도 및 경도 좌표를 사용하여 관심지점을 정의합니다.\npoints_of_interest = {\n    '타임즈 스퀘어': (-73.9855, 40.7580),\n    '센트럴 파크': (-73.9654, 40.7829),\n    '브루클린 다리': (-73.9969, 40.7061)\n}\n# 관심지점을 GeoDataFrame으로 변환합니다.\npoi_gdf = gpd.GeoDataFrame(geometry=[Point(lon, lat) for lon, lat in points_of_interest.values()], crs=\"EPSG:4326\")\npoi_gdf = poi_gdf.to_crs(parks_gdf.crs)  # 정확한 거리 계산을 위해 parks_gdf와 동일한 CRS로 변환합니다.\n\npoi_gdf\n```  \n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_14.png\" />\n\n```js\n# parks_gdf은 공원 정보를 포함하는 GeoDataFrame입니다.\nif parks_gdf.sindex is not None:  # 공간 인덱스가 있는지 확인합니다.\n    for index, poi in poi_gdf.iterrows():\n        # 각 관심지점에 대해 가장 가까운 지오메트리를 공간 인덱스에서 쿼리합니다.\n        # 경계가 아닌 포인트 지오메트리를 직접 전달합니다.\n        nearest_index = list(parks_gdf.sindex.nearest(poi.geometry, return_all=True, max_distance=None))[0]\n        nearest_park = parks_gdf.iloc[nearest_index[0]]  # 여러 개의 공원이 있을 경우 첫 번째 가장 가까운 공원에 접근합니다.\n\n        # 가장 가까운 공원까지의 거리를 계산합니다 (CRS와 동일한 단위로)\n        distance = poi.geometry.distance(nearest_park.geometry)\n        print(f\"{index}에 가장 가까운 공원: {nearest_park.geometry}, 거리: {distance:.2f}\")\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_15.png\" />\n\n# 공원 특징 분석\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 데이터 세트에 공원 기능(놀이터, 스포츠 시설, 수면 등)에 대한 정보가 포함되어 있다면, 우리는 이러한 기능들의 도시 전체 분포를 분석할 수 있습니다.\n\n```js\nimport seaborn as sns\n\n# 'propname' 열은 공원에 대한 고유한 이름을 포함합니다.\nfeature_counts = parks_gdf['propname'].value_counts()\n\n# 가장 일반적인 속성 이름(공원) 상위 10개를 선택합니다.\ntop_10_parks = feature_counts.head(20).reset_index()\ntop_10_parks.columns = ['공원 이름', '개수']\n\n# 상위 10개 공원에 대한 Seaborn 막대 그래프를 생성합니다.\nplt.figure(figsize=(10, 6))\nsns.barplot(x='개수', y='공원 이름', data=top_10_parks, palette='viridis')\n\n# 플롯 제목 및 레이블 추가\nplt.title('뉴욕시의 상위 10개 공원 (총 개수 기준)')\nplt.xlabel('기능 개수')\nplt.ylabel('공원 이름')\n\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_16.png\" />\n\n# 공원 방문 시기에 대한 시간적 분석 (가상의 내용)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n방문 데이터를 생성하고 시간에 따른 공원 방문 여부를 분석하면 공원 이용 추세, 피크 시간 및 잠재적으로 활용되지 않는 공간을 확인할 수 있습니다.\n\n```js\nimport pandas as pd\nimport numpy as np\n\n# parks_gdf에 'park_id'와 같이 각 공원에 대한 고유 식별자가 있습니다.\npark_ids = parks_gdf.index + 1\nparks_gdf['park_id'] = parks_gdf.index + 1\n\n# 샘플 날짜 생성\ndates = pd.date_range(start='2021-01-01', end='2021-12-31', freq='D')\n\n# 방문 데이터를 보유할 DataFrame 생성\nvisitation_data = []\n\nfor park_id in parks_gdf['park_id']:\n    for date in dates:\n        # 각 공원과 날짜마다 방문자 수를 0에서 500 사이의 무작위 숫자로 생성\n        visitors = np.random.randint(0, 500)\n        visitation_data.append({'park_id': park_id, 'date': date, 'visitors': visitors})\n\n# 리스트를 DataFrame으로 변환\nvis_df = pd.DataFrame(visitation_data)\n\n# 적어도 1000개의 행이 있는지 확인\nassert len(vis_df) >= 1000\n\n# 방문 DataFrame의 처음 몇 행 보기\nvis_df.head()\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_17.png\" />\n\n# 공원 방문 시간에 대한 시간적 분석\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가정적인 방문 데이터가 준비되었으므로, 시간 분석을 진행할 수 있습니다. 전체 방문 추세를 탐색하고, 공원 간 방문을 비교하며, 방문 정점 기간을 식별할 것입니다.\n\n## 전반적인 방문 추세\n\n```js\n# 전체 추세를 확인하려면 날짜별로 방문자를 집계합니다.\noverall_trends = vis_df.groupby('date')['visitors'].sum()\n\n# 전체 방문 추이 플롯\noverall_trends.plot(title='2021년 전체 공원 방문 추이', ylabel='총 방문자 수', xlabel='날짜')\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_18.png\" />\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 그래프는 연중 공원 방문자 수의 변동을 보여줄 것이며, 계절 패턴이나 특정 일자에 발생하는 비정상적으로 높거나 낮은 방문을 식별하는 데 도움이 됩니다.\n\n## 공원별 방문 추이\n\n방문자 수에 따라 다른 공원의 성과를 비교하려면 선택한 공원의 방문 추이를 플로팅할 수 있습니다.\n\n```python\nimport matplotlib.pyplot as plt\n#비교를 위해 공원의 하위 집합 선택\nsample_parks = np.random.choice(park_ids, size=5, replace=False)\n#선택한 공원을 위해 방문 데이터 필터링\nsample_vis_df = vis_df[vis_df['park_id'].isin(sample_parks)]\n#플로팅을 위해 데이터 피벗\npivot_df = sample_vis_df.pivot(index='date', columns='park_id', values='visitors')\n#2021년 공원별 방문 추이 표시\npivot_df.plot(kind='area', figsize=(12, 8), stacked=True, title='2021년 공원별 방문 추이', alpha=0.5)\n\n#그래프 사용자 정의\nplt.ylabel('방문자 수')\nplt.xlabel('날짜')\nplt.legend(title='공원 ID', loc='right')\nplt.show()\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Visualization](/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_19.png)\n\n이 시각화는 가장 인기 있는 공원을 확인하는 데 도움이 되며, 각 공원의 방문량이 어떻게 시간이 지남에 따라 변하는지, 그리고 어떤 공원이 유사한 패턴을 보이는지를 확인할 수 있습니다.\n\n## 최대 방문 기간 식별\n\n우리는 데이터를 분석하여 전반적인 방문량이 가장 높은 날들을 찾고, 특정 이벤트나 휴일이 공원 이용 증가를 견인하는지 확인할 수 있습니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 방문자 수가 가장 많은 상위 10일을 찾습니다\npeak_days = overall_trends.nlargest(10)\n# 방문자 수가 많은 상위 날짜를 출력합니다\nprint(\"방문자가 많은 날짜:\")\nprint(peak_days)\n```\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_20.png\" />\n\n이 분석을 통해 공원 방문에 공휴일, 날씨 조건 또는 특별 행사가 미치는 영향에 대한 통찰을 얻을 수 있습니다.\n\n## 데이터 프레임 결합하기\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nJoin parks_gdf with vis_df: 두 데이터 프레임을 park_id 열을 기준으로 병합하여 각 공원의 공간 데이터와 방문 데이터를 모두 포함하는 병합된 데이터 프레임을 얻을 것입니다.\n\n```js\n# 'park_id' 열을 기준으로 parks GeoDataFrame와 visitation DataFrame을 병합합니다\ncombined_gdf = parks_gdf.merge(vis_df, on='park_id')\n\n# 병합된 GeoDataFrame을 확인합니다\ncombined_gdf.head()\n```\n\n## 방문 데이터 집계\n\n이 예제에서는 한 해 동안 각 공원별 총 방문자 수를 계산해 보겠습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 방문 데이터를 종합하여 각 공원당 총 방문객 수를 구합니다.\ntotal_visitors_per_park = combined_gdf.groupby('park_id')['visitors'].sum().reset_index()\n\n# 이 종합된 데이터를 공원 데이터와 병합하여 공간 데이터를 유지합니다.\nparks_with_visitors_gdf = parks_gdf.merge(total_visitors_per_park, on='park_id')\n```\n\n## 시각화\n\n이제 각 공원의 크기를 이용하여 총 방문객 수를 나타내는 방식으로 공원을 시각화할 수 있습니다. 또는 색상을 사용하여 이 데이터를 표현할 수도 있습니다.\n\n```js\n# 그림과 축 설정\nfig, ax = plt.subplots(1, 1, figsize=(15, 15))\n\n# 공원을 플로팅하고, 각 공원의 포인트 크기를 총 방문객 수에 따라 조절합니다.\n# 색상을 cmap에서 찾아보세요: https://matplotlib.org/stable/users/explain/colors/colormaps.html\nparks_with_visitors_gdf.plot(ax=ax, column='visitors', legend=True, legend_kwds={'label': \"총 방문객 수\"},\n                             markersize=parks_with_visitors_gdf['visitors'] / 100,  # 마커 크기 조정\n                             cmap='gnuplot2')  # 색상 지도 사용\n\n# 참고를 위해 배경지도 추가 (선택 사항, contextily 및 인터넷 접속 필요)\ntry:\n    import contextily as ctx\n    ctx.add_basemap(ax, crs=parks_with_visitors_gdf.crs.to_string(), source=ctx.providers.OpenStreetMap.Mapnik)\nexcept Exception as e:\n    print(f\"배경지도를 추가할 수 없습니다: {e}\")\n\n# 플롯 표시\nplt.show()\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_21.png\" />\n\n만약 Python을 사용하여 실제 데이터셋을 분석해보고 싶다면, 제 다른 블로그 포스트도 확인해보세요:\n\nPython을 사용하여 처음부터 챗봇을 만드는 흥미진진한 세계에 뛰어들어보세요. 포괄적인 가이드는 여기에서 확인할 수 있습니다:\n\n# 감사합니다!","ogImage":{"url":"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-MasteringGeospatialDataAnalysiswithGeoPandas_0.png","tag":["Tech"],"readingTime":32},{"title":"Python과 Streamlit으로 주식 등급 시스템 만들기","description":"","date":"2024-07-13 19:13","slug":"2024-07-13-StockgradesystemwithPythonandStreamlit","content":"\n\n![링크](/TIL/assets/img/2024-07-13-StockgradesystemwithPythonandStreamlit_0.png)\n\n주식 시장에 투자하고 싶다니 멋지네요. 어떤 것을 선택하시겠습니까? 투자에 좋은 것과 그렇지 않은 것을 어떻게 정의하겠습니까? 현재 주식 분류를 이해하기 위해 등급 시스템 또는 평가 시스템이 필요할 것입니다. 지금 개발된 해당 시스템의 한 예시를 살펴보죠.\n\n수천 가지의 주식 중에서 선택해야 하는데, 각각이 갖는 메트릭 및 성과 지표가 모두 다르기 때문에, 최상의 투자 기회를 식별하기 위해서는 견고한 분석과 정보에 기반한 의사 결정이 필요합니다. 초보자든 전문가든, 방대한 양의 데이터를 탐색하고 유망한 주식을 강조해 주는 신뢰할 수 있는 도구가 있으면 매우 가치 있을 것입니다.\n\n이 글에서는 기술적 및 기본적 지표를 활용하여 주식을 평가하는 파이썬 기반의 투자 분석 도구를 개발하는 과정을 안내하겠습니다. 이 도구는 장기 투자 가능성을 식별하는 데 도움을 주는 뿐만 아니라 단기 거래 기회를 찾아내도록 돕습니다. 이 안내서를 따라가면, 로컬 머신에서 실행할 수 있는 강력한 스크립트를 보유하게 되며, Streamlit을 사용하여 직관적인 대시보드에 결과를 표시할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희는 분석의 기반이 되는 점수 체계를 설명하여 다양한 지표가 각 주식의 잠재력을 평가하는 데 어떻게 사용되는지 자세히 설명하겠습니다. 이 시스템을 이해하는 것은 매우 중요합니다. 왜냐하면 이는 저희 도구의 기초를 형성하고 의사 결정 프로세스를 안내하기 때문입니다. 이제 각 주식의 점수 평가 방법과 해당 점수의 의미에 대해 구체적으로 살펴보겠습니다.\n\n# 점수 체계 설명\n\n점수 체계는 기술적 지표와 기본적 지표를 결합하여 각 주식의 잠재력을 평가하는 데 사용됩니다. 단기적 가격 변동과 장기적 재무 건강 상태를 고려함으로써 서로 다른 투자 전략에 부합하는 균형 잡힌 평가를 도출할 수 있습니다.\n\n기술적 분석은 주식의 가격 움직임과 패턴에 초점을 맞춥니다. 여기서 우리는 두 가지 주요 지표를 사용합니다: 50일 이동평균선(MA)과 상대강도지수(RSI). 주식의 종가가 50일 이동평균선 위에 있는 경우 상승 추세를 나타내므로 해당 주식은 한 점을 받게 됩니다. 또한 RSI가 70 미만인 경우, 해당 주식이 과매수 상태가 아니며 성장할 공간이 있다는 것을 시사하므로 또 한 점을 받게 됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n근본적 분석은 회사의 재정 건강 상태를 검토합니다. 우리는 순조 적받지 못한 (P/E) 비율과 부채 대 자본 비율을 살펴봅니다. 20 미만의 순조 P/E 비율은 주식에 1 점을 부여합니다. 이것은 주식이 미래 수익에 비해 저평가될 가능성이 있음을 나타냅니다. 마찬가지로, 1 미만의 부채 대 자본 비율은 회사가 처리 가능한 부채 수준을 갖고 있음을 시사하며, 또 다른 한 점을 획득합니다.\n\n이러한 지표를 결합하여, 점수 체계는 각 주식에 대해 1에서 4 사이의 등급을 지정합니다. 1의 점수는 최소한의 잠재력을 나타내고, 4의 점수는 우수한 잠재력을 나타냅니다. 이 이중 접근법을 통해 우리는 즉시의 시장 심리와 회사의 기본적인 재정 안정성을 동시에 포착하여, 각 주식의 투자 전망에 대해 잘 둘러싼 견해를 제공합니다.\n\n내가 아는 바로는 주식 신뢰도를 이해하는 데 도움이 되는 여러 지표들이 있습니다. 물론, 이 기사는 참된 지표 범위를 보여주는 유일한 것은 아닙니다. 결국, 이것은 실전을 연습하고, 훨씬 더 많은 지표 및 KPI와 함께 나중에 직접 개발한 시스템을 가지기 위한 연습입니다. 아마도 보다 유연하고 맞춤 설정할 수 있을 것입니다. 그러나 다음 빌드의 기초를 마련합시다.\n\n![StockgradesystemwithPythonandStreamlit_1](/TIL/assets/img/2024-07-13-StockgradesystemwithPythonandStreamlit_1.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 필요한 도구들\n\n이 투자 분석 도구를 구축하고 실행하기 위해, 우리는 몇 가지 강력한 Python 라이브러리를 활용할 것입니다. 우리가 사용할 주요 라이브러리는 yfinance, pandas, 그리고 streamlit입니다. 이 도구들 각각은 데이터 수집부터 시각화까지 우리 분석의 다양한 부분에서 중요한 역할을 합니다.\n\nyfinance는 인기 있는 라이브러리로, 우리에게 Yahoo Finance로부터 직접적으로 과거의 시장 데이터를 가져올 수 있는 기회를 제공합니다. 이는 주식 가격 기록, 재무 제표, 그리고 다른 중요한 지표에 쉬운 접근을 제공하여 기술적 및 기본적 분석에 꼭 필요한 자원이 됩니다. yfinance를 사용하여 우리는 각 주식을 평가하는 데 필요한 데이터를 프로그래밍적으로 수집할 수 있습니다.\n\npandas는 다재다능한 데이터 조작 라이브러리로, 우리가 가져온 데이터를 처리하고 분석하는 데 도움이 될 것입니다. pandas를 사용하면 대규모 데이터 세트를 쉽게 처리하고 기술 지표를 계산하며 점수화 프로세스를 관리할 수 있습니다. 강력한 DataFrame 구조를 통해 복잡한 데이터 작업을 간단히 수행할 수 있어 분석이 효율적이고 정확하도록 보장합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nstreamlit은 Python 스크립트에서 직접 인터랙티브 웹 애플리케이션을 만드는 혁신적인 라이브러리입니다. Streamlit을 사용하면 사용자 친화적인 대시보드를 구축하여 투자 제안을 표시할 수 있습니다. 이를 통해 우리는 분석 결과를 명확하고 직관적인 방식으로 시각화하고 데이터를 해석하고 통찰력 있는 결정을 내릴 수 있게 됩니다.\n\n# 모니터링할 메트릭스\n\n우리의 분석에서는 4가지 주요 메트릭스에 집중할 것입니다: 50일 이동평균선(MA), 상대 강도 지수(RSI), 전방 P/E 비율, 그리고 부채 비율입니다. 각 메트릭스는 해당 주식의 성과와 재무 건강 상태에 대한 유용한 통찰을 제공합니다.\n\n50일 이동평균선(MA): 50일 이동평균선은 일별 가격 변동을 완화하여 기본 트렌드를 드러내는 기술적 지표입니다. 주식의 현재 종가를 50일 이동평균선과 비교함으로써 주식이 상승 트렌드인지 하향 트렌드인지 판단할 수 있습니다. 이동평균선 위의 가격은 상승 흐름을 나타내며 성장 잠재력이 있다는 것을 시사합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n상대강도지수 (RSI): RSI는 주식의 가격 움직임 속도와 변화를 측정하는 모멘텀 오실레이터입니다. 값은 0부터 100까지이며, 70 이상의 값은 주식이 과매수 상태에 있을 수 있음을 나타내고, 30 미만의 값은 과매도 상태일 수 있음을 시사합니다. RSI 추적을 통해 주식이 추세 반전을 겪을지 또는 현재 추세를 이어갈지에 대한 판단을 할 수 있습니다.\n\n정방향 주가 이익 비율 (P/E Ratio): 정방향 P/E 비율은 현재 주가를 예상된 미래 주당 순이익과 비교합니다. 낮은 정방향 P/E 비율은 주식이 미래 수익 잠재력에 비해 저평가되어 있을 수 있다는 것을 나타낼 수 있어 투자 가능성이 있는 기회로 여겨질 수 있습니다. 이 지표를 통해 주식의 가치 평가와 성장 가능성을 평가할 수 있습니다.\n\n부채-자본 비율: 이 기본적인 지표는 기업의 총 부채를 지분 자본과 비교합니다. 낮은 부채-자본 비율은 기업이 빌린 자금에 대한 의존도가 낮고 부채를 관리할 재정적 여력이 있는 것을 시사합니다. 이 비율을 분석함으로써 기업의 재정 안정성과 위험을 평가할 수 있습니다.\n\n![이미지](/TIL/assets/img/2024-07-13-StockgradesystemwithPythonandStreamlit_2.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 코드 시작하기\n\n투자 분석 도구를 만들기 위해, 논리적으로 섹션화된 파이썬 스크립트를 작성할 것입니다. 각 섹션은 데이터 수집, 분석 및 시각화의 다른 측면을 다룰 것입니다. 선호하는 파이썬 IDE에서 investment_analysis.py라는 새로운 파이썬 파일을 생성하는 것부터 시작해봅시다.\n\n- 우선, import부터 시작해보겠습니다\n\n```python\nimport yfinance as yf\nimport pandas as pd\nimport time\nimport datetime\nimport os\nimport streamlit as st\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nyfinance: Yahoo Finance에서 주식 시장 데이터를 가져 오는 데 사용됩니다\npandas: 데이터 조작 및 분석에 사용됩니다\ntime: API 요청 간의 지연을 추가하여 요율 제한을 피하기위해 사용됩니다.\ndatetime: 날짜 조작에 사용됩니다\nos: 파일 작업을 처리하는 데 사용됩니다.\nstreamlit: 결과를 표시하는 대화형 웹 대시 보드를 만드는 데 사용됩니다.\n\n2. Get and count: 주식 정보 가져 오기 및 기술 지표 계산\n\n```js\n# 지난 5 일간의 주식 가격 데이터를 가져 오기위한 함수\ndef get_stock_data(ticker):\n    stock = yf.Ticker(ticker)\n    hist = stock.history(period=\"5d\")  # 현재 및 이전 거래일을 포함하는 지난 5 일간의 데이터만 가져옵니다\n    if hist.empty:\n        raise ValueError(f\"{ticker} 에 대한 데이터를 찾을 수 없습니다.\")\n    return hist\n\n# 50일 이동 평균을 계산하는 함수\ndef calculate_moving_average(data, window):\n    data[f\"MA_{window}\"] = data['Close'].rolling(window=window).mean()\n    return data\n\n# 상대 강도 지수(RSI)를 계산하는 함수\ndef calculate_rsi(data, window=14):\n    delta = data['Close'].diff(1)\n    gain = delta.mask(delta < 0, 0)\n    loss = -delta.mask(delta > 0, 0)\n    avg_gain = gain.rolling(window=window).mean()\n    avg_loss = loss.rolling(window=window).mean()\n    rs = avg_gain / avg_loss\n    rsi = 100 - (100 / (1 + rs))\n    data[f\"RSI_{window}\"] = rsi\n    return data\n```\n\nget_stock_data: Yahoo Finance에서 지난 5 일간의 주식 가격 데이터를 가져 옴\ncalculate_moving_average: 지정된 창 기간(이 경우 50 일) 동안 종가의 이동 평균을 계산\ncalculate_rsi: 가격 움직임의 속도와 변화를 측정하는 모멘텀 오실레이터 인 RSI를 계산\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 기초 지식 습득\n\n```js\n# 기초 데이터를 가져오는 함수\ndef get_fundamentals(ticker):\n    stock = yf.Ticker(ticker)\n    fundamentals = stock.info\n    return fundamentals\n```\n\n여기서 AAPL 주식에 대한 기초 데이터 범위를 얻고, 추가적인 필터링을 위해 준비해 봅시다.\n\n4. 시작점을 정해봅시다!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 기술 및 기본 분석에 기반한 주식 평가 함수\ndef score_stock(data, fundamentals):\n    score = 0\n    # 기술적 분석\n    if data['Close'].iloc[-1] > data['MA_50'].iloc[-1]:\n        score += 1\n    if data['RSI_14'].iloc[-1] < 70:\n        score += 1\n    # 기초분석 및 오류 처리\n    try:\n        if fundamentals.get('forwardPE', None) is not None and fundamentals['forwardPE'] < 20:\n            score += 1\n        if fundamentals.get('debtToEquity', None) is not None and fundamentals['debtToEquity'] < 1:\n            score += 1\n    except KeyError as e:\n        print(f\"Key error: {e}\")\n    return score\n```\n\nscore_stock: 주식을 점수화하며, 종가가 50일 이동평균(MA_50)을 초과하고 RSI가 70보다 낮으며, 순방향 P/E 비율이 20 미만이거나 부채 비율이 1 미만인 경우 1을 추가하여 주식에 대한 점수를 매깁니다. 이것이 주식에 대한 점수를 평가하는 척도가 됩니다.\n\n5. 이렇게 분석하고, 저렇게 분석하고, 주식을 분석합니다.\n\n```js\ndef analyze_stock(ticker):\n    try:\n        data = get_stock_data(ticker)\n        data = calculate_moving_average(data, 50)\n        data = calculate_rsi(data)\n        fundamentals = get_fundamentals(ticker)\n        score = score_stock(data, fundamentals)\n        return data, fundamentals, score\n    except (IndexError, ValueError) as e:\n        print(f\"Skipping {ticker} due to error: {e}\")\n        return None, None, None\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nanalyze_stock: 주가 분석을 위해 과거 데이터를 가져오고 기술적 지표를 계산하며 기본 데이터를 가져와서 주식에 점수를 매깁니다. 오류가 발생하면 해당 주식은 건너뜁니다.\n\n6. 상당한 가치평가.\n\n```js\n# 분석된 주식에 기반하여 투자 제안하는 기능\ndef suggest_investments(tickers):\n    suggestions = []\n    for ticker in tickers:\n        data, fundamentals, score = analyze_stock(ticker)\n        if data is not None and fundamentals is not None:\n            suggestions.append((ticker, score, data['Close'].iloc[-1], str(datetime.date.today())))\n        time.sleep(0.25)  # HTTP 429 오류를 피하기 위해 지연 추가\n    suggestions.sort(key=lambda x: x[1], reverse=True)\n    save_suggestions(suggestions)\n    return suggestions\n\n# 제안을 CSV 파일에 저장하는 기능\ndef save_suggestions(suggestions):\n    df = pd.DataFrame(suggestions, columns=['Ticker', 'Score', 'Price', 'Date'])\n    df.to_csv('suggestions.csv', mode='a', header=not os.path.exists('suggestions.csv'), index=False)\n\ndef get_stock_list():\n    # 해당 예시에서는 S&P 500 리스트를 사용하였으나 다른 소스를 사용할 수 있음\n    sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n    return sp500['Symbol'].tolist()\r\n```\n\nsuggest_investments: 주식의 점수를 기준으로 투자할 주식을 제안하며 요청 사이에 지연을 추가하고 제안을 CSV 파일에 저장합니다.\nsave_suggestions: 미래 참고를 위해 제안을 CSV 파일에 저장합니다.\nget_stock_list: S&P500에 포함된 주식 목록을 가져옵니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n7. 우리가 가진 내용을 보여줍시다.\n\n```js\ndef display_dashboard(suggestions):\n    st.title(\"투자 제안 대시보드\")\n    for ticker, score, price, date in suggestions:\n        color = \"green\" if score >= 3 else \"red\"\n        st.markdown(f\"<div style='color:{color}'>티커: {ticker}, 점수: {score}, 가격: {price}, 날짜: {date}</div>\", unsafe_allow_html=True)\n\n# 단기 분석을 수행하는 함수\ndef short_term_analysis(tickers):\n    short_term_suggestions = []\n    for ticker in tickers:\n        data, fundamentals, score = analyze_stock(ticker)\n        if data is not None and fundamentals is not None and data['RSI_14'].iloc[-1] < 30:  # 단기 기회를 위한 예시 기준\n            short_term_suggestions.append((ticker, score, data['Close'].iloc[-1], str(datetime.date.today()))\n        time.sleep(0.25)  # HTTP 429 오류를 피하기 위한 지연 추가\n    short_term_suggestions.sort(key=lambda x: x[1], reverse=True)\n    save_suggestions(short_term_suggestions)\n    return short_term_suggestions\n\n# 지난 제안 성과를 평가하는 함수\ndef evaluate_performance():\n    df = pd.read_csv('suggestions.csv')\n    df['평가_날짜'] = pd.to_datetime(df['Date']) + pd.DateOffset(weeks=1)  # 1주 후 평가\n    evaluation_results = []\n    \n    for index, row in df.iterrows():\n        ticker = row['Ticker']\n        initial_price = row['Price']\n        evaluation_date = row['평가_날짜']\n        \n        try:\n            stock = yf.Ticker(ticker)\n            hist = stock.history(start=str(evaluation_date), end=str(evaluation_date + pd.DateOffset(days=1)))\n            final_price = hist['Close'][0]\n            price_change = (final_price - initial_price) / initial_price * 100\n            evaluation_results.append((ticker, row['Date'], initial_price, final_price, price_change))\n        except IndexError:\n            # 평가 일자에 데이터가 없는 경우 처리\n            evaluation_results.append((ticker, row['Date'], initial_price, None, None))\n    \n    eval_df = pd.DataFrame(evaluation_results, columns=['티커', '제안_날짜', '초기_가격', '최종_가격', '가격_변화 (%)'])\n    eval_df.to_csv('evaluation_results.csv', index=False)\r\n```\n\ndisplay_dashboard: 색상으로 구분된 점수를 사용하여 투자 제안을 Streamlit 대시보드에 표시합니다.\nshort_term_analysis: RSI 및 기타 기준에 기반하여 단기 투자 기회를 식별합니다.\nevaluate_performance: 초기 및 최종 가격을 비교하여 지난 투자 제안의 성과를 평가합니다.\n\n8. 작동하도록 만들기 — 스크립트 실행\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nif __name__ == \"__main__\":\n    try:\n        # 주식 분석을 위한 티커 목록 정의\n        tickers = get_stock_list()\n        \n        # 투자 제안서 가져오기\n        suggestions = suggest_investments(tickers)\n        display_dashboard(suggestions)\n\n        # 단기 투자 제안\n        short_term_suggestions = short_term_analysis(tickers)\n        st.title(\"단기 투자 제안\")\n        display_dashboard(short_term_suggestions)\n\n        # 과거 제안의 성능 평가\n        evaluate_performance()\n        evaluation_results_df = pd.read_csv('evaluation_results.csv')\n        st.title(\"평가 결과\")\n        st.write(evaluation_results_df)\n        \n    except KeyboardInterrupt:\n        st.write(\"사용자에 의해 스크립트가 중단되었습니다.\")\n```\n\n마지막으로, 주식 티커 가져오기, 투자 제안, 대시보드 표시 및 성능 평가를 포함한 주요 실행 흐름을 정의합니다.\n사용자에 의해 스크립트가 중단된 경우, 중단을 우아하게 처리하고 메시지를 표시합니다.\n평가 방식:\n\n- 3 또는 4점: 강력한 잠재성이 있음을 나타냅니다. 이러한 주식은 대부분의 기준을 충족하며 좋은 선택지로 간주됩니다.\n- 2점: 중간적인 잠재성이 있음을 나타냅니다. 이러한 주식은 일부 기준을 충족하지만 일부 리스크나 약한 지표가 있을 수 있습니다.\n- 1점: 최소한의 잠재성이 있음을 나타냅니다. 이러한 주식은 매우 적은 기준을 충족하며 상당한 리스크가 있을 수 있습니다.\n- 0점: 우리의 기준에 따라 잠재성이 없음을 나타냅니다. 이러한 주식은 주요 지표 중 어떤 것도 충족하지 않습니다.\n\n이제 다음 명령으로 실행해봅시다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nstreamlit run .\\test.py\n```\n\n![Image](/TIL/assets/img/2024-07-13-StockgradesystemwithPythonandStreamlit_3.png)\n\n결과를 확인하세요:\n\n![Image](/TIL/assets/img/2024-07-13-StockgradesystemwithPythonandStreamlit_4.png)\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n7월 12일 2024일의 경우, 우리의 기준에 맞는 주식이 없어요: SP500의 주식 중에는 아무런 높은 등급의 주식이 존재하지 않아요.\n\n다음에 무엇을 할 수 있을까요?\n\n- 기술지표 조정: RSI나 이동평균에 대해 다양한 임계값을 고려해보세요. 예를 들어, 200일 이동평균을 사용하는 것이 더 나은 신호를 제공할 수도 있습니다.\n- 추가 지표 통합: 수익 성장률, 배당 수익률 또는 다른 기술적 패턴과 같은 더 많은 기본적 또는 기술적 지표를 분석에 추가하세요.\n- 평가: 주식의 성능을 분석하고 실제 재무 결과를 바탕으로 주식을 등급화하여 점수를 매기기 위해 현실적인 등급 시스템을 갖도록 하세요.\n\n일반적인 코드…\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nimport yfinance as yf\nimport pandas as pd\nimport time\nimport datetime\nimport os\nimport streamlit as st\n\ndef get_stock_data(ticker):\n    stock = yf.Ticker(ticker)\n    hist = stock.history(period=\"5d\")  \n    if hist.empty:\n        raise ValueError(f\"{ticker}에 대한 데이터를 찾을 수 없습니다.\")\n    return hist\n\ndef calculate_moving_average(data, window):\n    data[f\"MA_{window}\"] = data['Close'].rolling(window=window).mean()\n    return data\n\ndef calculate_rsi(data, window=14):\n    delta = data['Close'].diff(1)\n    gain = delta.mask(delta < 0, 0)\n    loss = -delta.mask(delta > 0, 0)\n    avg_gain = gain.rolling(window=window).mean()\n    avg_loss = loss.rolling(window=window).mean()\n    rs = avg_gain / avg_loss\n    rsi = 100 - (100 / (1 + rs))\n    data[f\"RSI_{window}\"] = rsi\n    return data\n\ndef get_fundamentals(ticker):\n    stock = yf.Ticker(ticker)\n    fundamentals = stock.info\n    return fundamentals\n\ndef score_stock(data, fundamentals):\n    score = 0\n    if data['Close'].iloc[-1] > data['MA_50'].iloc[-1]:\n        score += 1\n    if data['RSI_14'].iloc[-1] < 70:\n        score += 1\n    try:\n        if fundamentals.get('forwardPE', None) is not None and fundamentals['forwardPE'] < 20:\n            score += 1\n        if fundamentals.get('debtToEquity', None) is not None and fundamentals['debtToEquity'] < 1:\n            score += 1\n    except KeyError as e:\n        print(f\"Key error: {e}\")\n    return score\n\ndef analyze_stock(ticker):\n    try:\n        data = get_stock_data(ticker)\n        data = calculate_moving_average(data, 50)\n        data = calculate_rsi(data)\n        fundamentals = get_fundamentals(ticker)\n        score = score_stock(data, fundamentals)\n        return data, fundamentals, score\n    except (IndexError, ValueError) as e:\n        print(f\"{ticker}을(를) 분석하는 도중 오류가 발생했습니다: {e}\")\n        return None, None, None\n\ndef suggest_investments(tickers):\n    suggestions = []\n    for ticker in tickers:\n        data, fundamentals, score = analyze_stock(ticker)\n        if data is not None and fundamentals is not None:\n            suggestions.append((ticker, score, data['Close'].iloc[-1], str(datetime.date.today())))\n        time.sleep(0.25)   \n    suggestions.sort(key=lambda x: x[1], reverse=True)\n    save_suggestions(suggestions)\n    return suggestions\n\ndef save_suggestions(suggestions):\n    df = pd.DataFrame(suggestions, columns=['주식 코드', '점수', '가격', '날짜'])\n    df.to_csv('suggestions.csv', mode='a', header=not os.path.exists('suggestions.csv'), index=False)\n\ndef get_stock_list():\n    sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n    return sp500['Symbol'].tolist()\n\ndef display_dashboard(suggestions):\n    st.title(\"투자 제안 대시보드\")\n    for ticker, score, price, date in suggestions:\n        color = \"green\" if score >= 3 else \"red\"\n        st.markdown(f\"<div style='color:{color}'>주식 코드: {ticker}, 점수: {score}, 가격: {price}, 날짜: {date}</div>\", unsafe_allow_html=True)\n\ndef short_term_analysis(tickers):\n    short_term_suggestions = []\n    for ticker in tickers:\n        data, fundamentals, score = analyze_stock(ticker)\n        if data is not None and fundamentals is not None and data['RSI_14'].iloc[-1] < 30:  # 단기 기회 조건 예시\n            short_term_suggestions.append((ticker, score, data['Close'].iloc[-1], str(datetime.date.today())))\n        time.sleep(0.25)   \n    short_term_suggestions.sort(key=lambda x: x[1], reverse=True)\n    save_suggestions(short_term_suggestions)\n    return short_term_suggestions\n\ndef evaluate_performance():\n    df = pd.read_csv('suggestions.csv')\n    df['평가 날짜'] = pd.to_datetime(df['날짜']) + pd.DateOffset(weeks=1)  # 1주 후에 평가\n    evaluation_results = []\n    \n    for index, row in df.iterrows():\n        ticker = row['주식 코드']\n        initial_price = row['가격']\n        evaluation_date = row['평가 날짜']\n        \n        try:\n            stock = yf.Ticker(ticker)\n            hist = stock.history(start=str(evaluation_date), end=str(evaluation_date + pd.DateOffset(days=1)))\n            final_price = hist['Close'][0]\n            price_change = (final_price - initial_price) / initial_price * 100\n            evaluation_results.append((ticker, row['날짜'], initial_price, final_price, price_change))\n        except IndexError:\n            # 평가 날짜에 데이터가 없는 경우 처리\n            evaluation_results.append((ticker, row['날짜'], initial_price, None, None))\n    \n    eval_df = pd.DataFrame(evaluation_results, columns=['주식 코드', '제안 일자', '초기 가격', '최종 가격', '가격 변동 (%)'])\n    eval_df.to_csv('evaluation_results.csv', index=False)\n\nif __name__ == \"__main__\":\n    try:\n        tickers = get_stock_list()\n        \n        suggestions = suggest_investments(tickers)\n        display_dashboard(suggestions)\n\n        short_term_suggestions = short_term_analysis(tickers)\n        st.title(\"단기 투자 제안\")\n        display_dashboard(short_term_suggestions)\n\n        evaluate_performance()\n        evaluation_results_df = pd.read_csv('evaluation_results.csv')\n        st.title(\"평가 결과\")\n        st.write(evaluation_results_df)\n        \n    except KeyboardInterrupt:\n        st.write(\"사용자에 의해 스크립트가 중단되었습니다.\")\n```\n\n… 그리고 면책 조항.\n\n# 면책 조항\n\n이 글과 함께 제공된 코드는 교육 목적으로만 사용됩니다. 스크립트가 제공하는 제안은 자동 분석의 기능을 보여주기 위한 것이며, 사용자는 제안된 조치를 모니터링하고 시간이 지남에 따라 성공률을 평가해야 합니다. 이 콘텐츠는 행동 요령이 아니며, 재정 자문으로 해석해서는 안 됩니다. 언제든지 본인의 연구를 수행하고 거래 결정을 내리기 전에 전문가와 상의하십시오.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n이러한 단계를 따르면 기술적 및 기본적인 지표를 모두 사용하여 주식을 평가하는 견고한 투자 분석 도구를 만들 수 있습니다. 결과는 인터랙티브 한 Streamlit 대시 보드에 표시되어 분석을 해석하고 조치를 취하기가 쉬워집니다. 즐거운 코딩투자를 하세요!","ogImage":{"url":"/TIL/assets/img/2024-07-13-StockgradesystemwithPythonandStreamlit_0.png"},"coverImage":"/TIL/assets/img/2024-07-13-StockgradesystemwithPythonandStreamlit_0.png","tag":["Tech"],"readingTime":22}],"page":"8","totalPageCount":33,"totalPageGroupCount":2,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}