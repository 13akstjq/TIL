{"pageProps":{"post":{"title":"Zero-Shot Learning 알려진 것과 미지의 것을 잇는 방법","description":"","date":"2024-07-12 19:50","slug":"2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown","content":"\n\n# 요약\n\n**문맥:** 제로샷 러닝(Zero-shot learning, ZSL)은 머신 러닝에서 cutting-edge한 방법론으로, 모델이 사전 노출 없이 새로운 객체를 인식할 수 있게 하여 인간 추론 능력을 모방합니다.\n\n**문제:** 기존 모델은 각 클래스에 대해 방대한 레이블 데이터가 필요하며, 이는 종종 실용적이지 않으며 확장 가능성을 제한합니다.\n\n**접근:** 본 보고서는 합성 데이터셋을 활용한 ZSL의 실용적 구현을 탐구하며, 특성 엔지니어링, 모델 훈련, 하이퍼파라미터 최적화 및 평가 지표에 대해 자세히 다룹니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n결과: 모델은 99.5%라는 높은 정확도를 달성하여, 혼동 행렬, 예측 분포도, 교차 검증 결과를 통해 보이지 않은 데이터를 분류하는 데 우수한 성능을 나타냈습니다.\n\n결론: 제로샷 학습은 전통적인 지도 학습의 제약을 극복하는 데 강력한 도구로 작용하며, 강력한 일반화 능력과 다양한 실제 응용 가능성을 보여줍니다.\n\n키워드: 제로샷 학습, 머신러닝 모델, 합성 데이터셋, 피처 엔지니어링, 하이퍼파라미터 최적화.\n\n# 소개\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n박물관에 들어가 새로운 동물을 그린 그림을 보게 된다면 어떤 기술들을 가지고 있는지를 살펴보면서, 비늘, 날개, 그리고 뱀 모양의 몸 등의 특징을 보고, 이것이 바로 용이라는 것을 유추할 수 있습니다. 용을 한번도 본 적이 없더라도 설명을 토대로 추론하고 인식하는 인간의 능력은 바로 인공 지능의 Zero-shot learning (ZSL)이 목표로 하는 것입니다. 데이터가 풍부하지만 항상 레이블이 되어있지 않은 세계에서, ZSL은 기계가 학습하는 방식의 한계를 뛰어넘어, 그동안 본 적 없는 물체를 식별하고 분류할 수 있도록 가능하게 합니다.\n\n![그림](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png)\n\n# Zero-Shot Learning의 이해\n\nZero-shot learning은 기계 학습에서 혁신적인 방법으로, 모델이 직접적으로 그러한 특정 클래스에 대해 훈련을 받지 않아도 새로운 객체 클래스를 인식하도록 설계됩니다. 기존의 기계 학습 모델은 인식해야 하는 각 카테고리에 대해 많은 레이블이 달린 데이터가 필요합니다. 그러나 ZSL은 속성, 텍스트 설명 또는 임베딩과 같은 의미 정보를 활용하여 새롭고 보지 못한 클래스에 대해 합리적인 추측을 할 수 있도록합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 제로샷 러닝은 어떻게 작동하나요?\n\n- 특성 추출: 모델은 훈련 단계에서 알려진 클래스에서 특성을 추출합니다. 이는 주로 이미지 인식 작업에는 사전 훈련된 합성곱 신경망(CNNs) 또는 텍스트에는 트랜스포머 모델을 사용하여 수행됩니다.\n- 의미 임베딩: 보여지거나 보이지 않는 각 클래스는 의미 벡터와 연관됩니다. 이러한 벡터는 속성(예: 호랑이를 줄무늬가 있는 동물, 네 다리가 있고 날카로운 이빨을 가진 동물로 설명)에서 파생되거나 Word2Vec 또는 GloVe와 같은 단어 임베딩을 통해 처리된 텍스트 설명에서 얻을 수 있습니다.\n- 매핑 함수: ZSL의 핵심은 시각적 특성을 의미 임베딩에 연결하는 매핑 함수에 있습니다. 모델이 새로운 이미지나 텍스트를 만나면 추출된 특성을 가장 가까운 의미 벡터에 매핑하여 보이지 않는 클래스를 인식하고 분류할 수 있게 합니다.\n\n# 제로샷 러닝의 적용 분야\n\n- 이미지 인식: ZSL은 야생 동물 모니터링과 같은 분야에서 설명적 속성을 기반으로 새로운 종을 식별하는 데 도움을 줄 수 있습니다. 예를 들어, 일반 동물에 대해 훈련된 모델은 해당 특성을 이해하여 새로 발견된 종을 인식할 수 있습니다.\n- 자연어 처리(NLP): 설명에서 맥락적 정보를 사용하여, ZSL은 모델이 명시적으로 훈련받지 않은 주제에 대한 텍스트 분류나 감정 분석과 같은 작업을 처리할 수 있게 합니다.\n- 추천 시스템: ZSL은 훈련 데이터에 없는 항목을 제안하여 사용자 경험과 참여를 향상시키는 방식으로 추천 시스템을 개선합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 도전과 향후 방향\n\n제로샷 학습은 엄청난 잠재력을 제공하지만 도전도 있습니다:\n\n- 의미적 간극: 시각적 특징과 의미적 표현 간의 불일치는 잘못된 매핑으로 이어질 수 있습니다. 이 간극을 줄이는 것은 정확도 향상에 중요합니다.\n- 속성 종속성: ZSL의 효과성은 의미적 특성이나 설명의 품질과 포괄성에 크게 의존합니다.\n- 확장성: 많은 클래스를 인식하는 것은 계산적인 도전으로 남아 있으며, 효율적인 알고리즘과 견고한 매핑 함수가 필요합니다.\n\n연구자들은 이러한 도전에 대한 해결책을 적극적으로 탐구하고 있습니다. 개선된 임베딩 기술, 제로샷 및 퓨샷 학습을 결합한 하이브리드 모델, 그리고 보다 견고한 매핑 함수는 개발 중인 전략 중 일부입니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 실용 예시\n\n아래에는 합성 데이터셋을 활용한 제로샷 러닝을 보여주는 포괄적인 파이썬 코드 블록이 있습니다. 예시에는 특성 기술, 특성 엔지니어링, 하이퍼파라미터 최적화, 교차 검증, 모델 예측, 메트릭, 플롯 및 결과 해석이 포함되어 있습니다. 이 코드는 scikit-learn, numpy, pandas, matplotlib 및 seaborn 라이브러리를 사용합니다.\n\n```python\n# 필요한 라이브러리 가져오기\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 합성 데이터셋 생성\ndef create_synthetic_data():\n    np.random.seed(42)\n    n_samples = 1000\n    features = np.random.rand(n_samples, 5)\n    labels = (np.sum(features, axis=1) > 2.5).astype(int)\n    \n    # DataFrame으로 변환\n    df = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(1, 6)])\n    df['label'] = labels\n    \n    # 제로샷 러닝을 위한 의미 정보 추가\n    semantic_info = {\n        0: 'low_sum',\n        1: 'high_sum'\n    }\n    \n    df['semantic_label'] = df['label'].map(semantic_info)\n    return df\n\n# 합성 데이터셋 생성\ndf = create_synthetic_data()\n\n# 특성 엔지니어링: 특성 표준화\nscaler = StandardScaler()\nX = scaler.fit_transform(df.drop(['label', 'semantic_label'], axis=1))\ny = df['label']\n\n# 데이터를 학습 및 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 제로샷 러닝 설정\nsemantic_labels = df['semantic_label'].unique()\nsemantic_embeddings = {\n    'low_sum': np.array([0.2, 0.2, 0.2, 0.2, 0.2]),\n    'high_sum': np.array([0.8, 0.8, 0.8, 0.8, 0.8])\n}\n\n# GridSearchCV를 사용한 하이퍼파라미터 최적화\nparam_grid = {\n    'C': [0.1, 1, 10],\n    'solver': ['liblinear']\n}\n\nmodel = LogisticRegression()\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\n# Grid search에서 최적의 모델\nbest_model = grid_search.best_estimator_\n\n# 예측\ny_pred = best_model.predict(X_test)\n\n# 평가 메트릭\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"정확도:\", accuracy)\nprint(\"분류 보고서:\\n\", classification_report(y_test, y_pred))\n\n# 혼동 행렬\nconf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('예측 라벨')\nplt.ylabel('실제 라벨')\nplt.title('혼동 행렬')\nplt.show()\n\n# 결과 시각화\nplt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap='viridis', marker='o')\nplt.title('제로샷 러닝 예측')\nplt.xlabel('특성 1')\nplt.ylabel('특성 2')\nplt.show()\n\n# 결과 해석\n# 합성 데이터를 사용하여 제로샷 러닝 모델의 성능을 확인할 수 있습니다.\n# 혼동 행렬 및 분류 보고서를 통해 정확도 및 분류 성능을 파악할 수 있습니다.\n\n# 교차 검증 결과\nresults = pd.DataFrame(grid_search.cv_results_)\nresults.plot(kind='bar', x='param_C', y='mean_test_score', yerr='std_test_score', capsize=4)\nplt.xlabel('C (정규화 매개변수)')\nplt.ylabel('평균 테스트 점수')\nplt.title('교차 검증 결과')\nplt.show()\n\n# 마무리\n# 제로샷 러닝은 의미 정보를 기반으로 보이지 않는 클래스를 예측할 수 있는 모델을 만듭니다.\n# 합성 예시는 제로샷 러닝 모델이 제공된 속성을 기반으로 일반화할 수 있는 능력을 보여줍니다.\n```\n\n이 코드는 합성 데이터셋을 활용하여 제로샷 러닝의 실용적인 예시를 제공하며, 데이터 생성부터 평가 및 결과 시각화까지의 전체 머신 러닝 파이프라인을 다룹니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 결과 해석\n\n혼동 행렬: 혼동 행렬은 분류 모델의 성능을 시각적으로 보여줍니다. 제공된 혼동 행렬에서:\n\n- 모형은 0 클래스의 경우 89개 및 1 클래스의 경우 110건을 정확하게 분류했습니다.\n- 1 클래스의 하나의 사례가 0 클래스로 분류되는 잘못된 분류가 있었습니다.\n- 0 클래스가 1 클래스로 잘못 분류된 경우는 없었습니다.\n\n이는 모델의 예측 정확도가 높음을 나타냅니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![image](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_1.png)\n\n정확도: 0.995 모델은 99.5%의 정확도를 달성했습니다. 이는 예측 중 99.5%가 정확했음을 나타냅니다. 이 뛰어난 정확도 점수는 모델이 이 데이터셋에서 매우 잘 수행한다는 것을 시사합니다.\n\n분류 보고서: 분류 보고서는 각 클래스에 대한 정밀도, 재현율 및 f1-점수를 포함한 상세한 지표를 제공합니다:\n\n- 정밀도: 두 클래스 모두에 대한 정밀도가 매우 높습니다 (클래스 0의 경우 0.99, 클래스 1의 경우 1.00), 이는 모델이 매우 낮은 오검출률을 가지고 있다는 것을 나타냅니다.\n- 재현율: 두 클래스 모두에 대한 재현율도 매우 높습니다 (클래스 0의 경우 1.00, 클래스 1의 경우 0.99), 이는 모델이 매우 낮은 오물체률을 가지고 있다는 것을 나타냅니다.\n- f1-점수: 정밀도와 재현율의 조화 평균인 f1-점수는 클래스 0의 경우 0.99, 클래스 1의 경우 1.00으로, 두 클래스에 대한 균형 잡힌 정확한 모델 성능을 시사합니다.\n- 지원: 지원 값(클래스 0의 경우 89, 클래스 1의 경우 111)은 테스트 데이터셋의 각 클래스에 대한 실제 인스턴스를 나타냅니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n제로샷 러닝 예측 산점도: 산점도는 제로샷 러닝 예측을 시각화합니다. 각 포인트는 테스트 인스턴스를 나타내며, 다른 색상은 예측된 클래스를 나타냅니다. 포인트들의 명확한 군집화는 모델이 특징에 기반하여 두 클래스를 구별하는 능력을 나타냅니다.\n\n![Zero-Shot Learning Predictions Scatter Plot](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_2.png)\n\n교차 검증 결과: 막대 차트는 정규화 매개변수 CCC의 다른 값에 대한 교차 검증에서의 평균 테스트 점수를 보여줍니다:\n\n- 모델은 모든 테스트된 CCC 값에 대해 일관된 우수한 성능을 보이며, 평균 테스트 점수는 1.0에 가깝습니다.\n- 오차 막대는 최소 테스트 점수의 표준 편차를 나타내며, 모델의 성능이 안정적이고 CCC의 선택에 지나치게 민감하지 않음을 시사합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Zero-Shot Learning Approach](/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_3.png)\n\n최종 생각:\n\n- 모델은 뛰어난 성능을 보여주며 높은 정확도, 정밀도, 재현율 및 F1 점수를 가지고 있습니다.\n- 혼동 행렬과 산점도는 모델의 능력을 추가로 확인하여 테스트 인스턴스를 최소 오류로 올바르게 분류합니다.\n- 교차 검증 결과는 견고한 모델이 다양한 하이퍼파라미터 설정에서 잘 수행되는 것을 나타냅니다.\n\n이 zero-shot 학습 접근 방식은 합성 데이터셋을 사용하더라도 훌륭한 결과를 보여주며 의미 정보를 기반으로 보이지 않는 클래스를 정확하게 일반화하고 예측할 수 있는 모델의 능력을 강조합니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n제로샷 학습은 머신 러닝에서 큰 발전을 의미하며 직접적인 경험 없이 새로운 개념을 일반화하고 인식하는 인간의 능력을 반영합니다. 우리가 제로샷 학습 기술을 계속 발전시키고 향상시킬수록, 더 유연하고 확장 가능하며 동적인 현실 세계 환경에서 작동할 수 있는 AI 시스템을 만들기에 더 근접해집니다. AI의 미래는 배우고 적응하는 능력에 있으며, 제로샷 학습은 이 방향으로의 중요한 한걸음입니다.\n\n여러분의 의견을 듣고 싶습니다! 제로샷 학습이 귀하의 산업에서 AI의 미래를 어떻게 변화시킬 것으로 보십니까? 아래 댓글에 의견과 경험을 공유해주시고, 이 혁신적인 기술의 끝없는 가능성에 대한 대화를 이끌어봅시다!\n\n# 참고문헌","ogImage":{"url":"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png","tag":["Tech"],"readingTime":11},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h1>요약</h1>\n<p><strong>문맥:</strong> 제로샷 러닝(Zero-shot learning, ZSL)은 머신 러닝에서 cutting-edge한 방법론으로, 모델이 사전 노출 없이 새로운 객체를 인식할 수 있게 하여 인간 추론 능력을 모방합니다.</p>\n<p><strong>문제:</strong> 기존 모델은 각 클래스에 대해 방대한 레이블 데이터가 필요하며, 이는 종종 실용적이지 않으며 확장 가능성을 제한합니다.</p>\n<p><strong>접근:</strong> 본 보고서는 합성 데이터셋을 활용한 ZSL의 실용적 구현을 탐구하며, 특성 엔지니어링, 모델 훈련, 하이퍼파라미터 최적화 및 평가 지표에 대해 자세히 다룹니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>결과: 모델은 99.5%라는 높은 정확도를 달성하여, 혼동 행렬, 예측 분포도, 교차 검증 결과를 통해 보이지 않은 데이터를 분류하는 데 우수한 성능을 나타냈습니다.</p>\n<p>결론: 제로샷 학습은 전통적인 지도 학습의 제약을 극복하는 데 강력한 도구로 작용하며, 강력한 일반화 능력과 다양한 실제 응용 가능성을 보여줍니다.</p>\n<p>키워드: 제로샷 학습, 머신러닝 모델, 합성 데이터셋, 피처 엔지니어링, 하이퍼파라미터 최적화.</p>\n<h1>소개</h1>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>박물관에 들어가 새로운 동물을 그린 그림을 보게 된다면 어떤 기술들을 가지고 있는지를 살펴보면서, 비늘, 날개, 그리고 뱀 모양의 몸 등의 특징을 보고, 이것이 바로 용이라는 것을 유추할 수 있습니다. 용을 한번도 본 적이 없더라도 설명을 토대로 추론하고 인식하는 인간의 능력은 바로 인공 지능의 Zero-shot learning (ZSL)이 목표로 하는 것입니다. 데이터가 풍부하지만 항상 레이블이 되어있지 않은 세계에서, ZSL은 기계가 학습하는 방식의 한계를 뛰어넘어, 그동안 본 적 없는 물체를 식별하고 분류할 수 있도록 가능하게 합니다.</p>\n<p><img src=\"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_0.png\" alt=\"그림\"></p>\n<h1>Zero-Shot Learning의 이해</h1>\n<p>Zero-shot learning은 기계 학습에서 혁신적인 방법으로, 모델이 직접적으로 그러한 특정 클래스에 대해 훈련을 받지 않아도 새로운 객체 클래스를 인식하도록 설계됩니다. 기존의 기계 학습 모델은 인식해야 하는 각 카테고리에 대해 많은 레이블이 달린 데이터가 필요합니다. 그러나 ZSL은 속성, 텍스트 설명 또는 임베딩과 같은 의미 정보를 활용하여 새롭고 보지 못한 클래스에 대해 합리적인 추측을 할 수 있도록합니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>제로샷 러닝은 어떻게 작동하나요?</h1>\n<ul>\n<li>특성 추출: 모델은 훈련 단계에서 알려진 클래스에서 특성을 추출합니다. 이는 주로 이미지 인식 작업에는 사전 훈련된 합성곱 신경망(CNNs) 또는 텍스트에는 트랜스포머 모델을 사용하여 수행됩니다.</li>\n<li>의미 임베딩: 보여지거나 보이지 않는 각 클래스는 의미 벡터와 연관됩니다. 이러한 벡터는 속성(예: 호랑이를 줄무늬가 있는 동물, 네 다리가 있고 날카로운 이빨을 가진 동물로 설명)에서 파생되거나 Word2Vec 또는 GloVe와 같은 단어 임베딩을 통해 처리된 텍스트 설명에서 얻을 수 있습니다.</li>\n<li>매핑 함수: ZSL의 핵심은 시각적 특성을 의미 임베딩에 연결하는 매핑 함수에 있습니다. 모델이 새로운 이미지나 텍스트를 만나면 추출된 특성을 가장 가까운 의미 벡터에 매핑하여 보이지 않는 클래스를 인식하고 분류할 수 있게 합니다.</li>\n</ul>\n<h1>제로샷 러닝의 적용 분야</h1>\n<ul>\n<li>이미지 인식: ZSL은 야생 동물 모니터링과 같은 분야에서 설명적 속성을 기반으로 새로운 종을 식별하는 데 도움을 줄 수 있습니다. 예를 들어, 일반 동물에 대해 훈련된 모델은 해당 특성을 이해하여 새로 발견된 종을 인식할 수 있습니다.</li>\n<li>자연어 처리(NLP): 설명에서 맥락적 정보를 사용하여, ZSL은 모델이 명시적으로 훈련받지 않은 주제에 대한 텍스트 분류나 감정 분석과 같은 작업을 처리할 수 있게 합니다.</li>\n<li>추천 시스템: ZSL은 훈련 데이터에 없는 항목을 제안하여 사용자 경험과 참여를 향상시키는 방식으로 추천 시스템을 개선합니다.</li>\n</ul>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>도전과 향후 방향</h1>\n<p>제로샷 학습은 엄청난 잠재력을 제공하지만 도전도 있습니다:</p>\n<ul>\n<li>의미적 간극: 시각적 특징과 의미적 표현 간의 불일치는 잘못된 매핑으로 이어질 수 있습니다. 이 간극을 줄이는 것은 정확도 향상에 중요합니다.</li>\n<li>속성 종속성: ZSL의 효과성은 의미적 특성이나 설명의 품질과 포괄성에 크게 의존합니다.</li>\n<li>확장성: 많은 클래스를 인식하는 것은 계산적인 도전으로 남아 있으며, 효율적인 알고리즘과 견고한 매핑 함수가 필요합니다.</li>\n</ul>\n<p>연구자들은 이러한 도전에 대한 해결책을 적극적으로 탐구하고 있습니다. 개선된 임베딩 기술, 제로샷 및 퓨샷 학습을 결합한 하이브리드 모델, 그리고 보다 견고한 매핑 함수는 개발 중인 전략 중 일부입니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>실용 예시</h1>\n<p>아래에는 합성 데이터셋을 활용한 제로샷 러닝을 보여주는 포괄적인 파이썬 코드 블록이 있습니다. 예시에는 특성 기술, 특성 엔지니어링, 하이퍼파라미터 최적화, 교차 검증, 모델 예측, 메트릭, 플롯 및 결과 해석이 포함되어 있습니다. 이 코드는 scikit-learn, numpy, pandas, matplotlib 및 seaborn 라이브러리를 사용합니다.</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-comment\"># 필요한 라이브러리 가져오기</span>\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">from</span> sklearn.model_selection <span class=\"hljs-keyword\">import</span> train_test_split, GridSearchCV\n<span class=\"hljs-keyword\">from</span> sklearn.metrics <span class=\"hljs-keyword\">import</span> classification_report, confusion_matrix, accuracy_score\n<span class=\"hljs-keyword\">from</span> sklearn.preprocessing <span class=\"hljs-keyword\">import</span> StandardScaler, LabelEncoder\n<span class=\"hljs-keyword\">from</span> sklearn.linear_model <span class=\"hljs-keyword\">import</span> LogisticRegression\n<span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt\n<span class=\"hljs-keyword\">import</span> seaborn <span class=\"hljs-keyword\">as</span> sns\n\n<span class=\"hljs-comment\"># 합성 데이터셋 생성</span>\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">create_synthetic_data</span>():\n    np.random.seed(<span class=\"hljs-number\">42</span>)\n    n_samples = <span class=\"hljs-number\">1000</span>\n    features = np.random.rand(n_samples, <span class=\"hljs-number\">5</span>)\n    labels = (np.<span class=\"hljs-built_in\">sum</span>(features, axis=<span class=\"hljs-number\">1</span>) > <span class=\"hljs-number\">2.5</span>).astype(<span class=\"hljs-built_in\">int</span>)\n    \n    <span class=\"hljs-comment\"># DataFrame으로 변환</span>\n    df = pd.DataFrame(features, columns=[<span class=\"hljs-string\">f'feature_<span class=\"hljs-subst\">{i}</span>'</span> <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">6</span>)])\n    df[<span class=\"hljs-string\">'label'</span>] = labels\n    \n    <span class=\"hljs-comment\"># 제로샷 러닝을 위한 의미 정보 추가</span>\n    semantic_info = {\n        <span class=\"hljs-number\">0</span>: <span class=\"hljs-string\">'low_sum'</span>,\n        <span class=\"hljs-number\">1</span>: <span class=\"hljs-string\">'high_sum'</span>\n    }\n    \n    df[<span class=\"hljs-string\">'semantic_label'</span>] = df[<span class=\"hljs-string\">'label'</span>].<span class=\"hljs-built_in\">map</span>(semantic_info)\n    <span class=\"hljs-keyword\">return</span> df\n\n<span class=\"hljs-comment\"># 합성 데이터셋 생성</span>\ndf = create_synthetic_data()\n\n<span class=\"hljs-comment\"># 특성 엔지니어링: 특성 표준화</span>\nscaler = StandardScaler()\nX = scaler.fit_transform(df.drop([<span class=\"hljs-string\">'label'</span>, <span class=\"hljs-string\">'semantic_label'</span>], axis=<span class=\"hljs-number\">1</span>))\ny = df[<span class=\"hljs-string\">'label'</span>]\n\n<span class=\"hljs-comment\"># 데이터를 학습 및 테스트 세트로 분할</span>\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class=\"hljs-number\">0.2</span>, random_state=<span class=\"hljs-number\">42</span>)\n\n<span class=\"hljs-comment\"># 제로샷 러닝 설정</span>\nsemantic_labels = df[<span class=\"hljs-string\">'semantic_label'</span>].unique()\nsemantic_embeddings = {\n    <span class=\"hljs-string\">'low_sum'</span>: np.array([<span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.2</span>]),\n    <span class=\"hljs-string\">'high_sum'</span>: np.array([<span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.8</span>])\n}\n\n<span class=\"hljs-comment\"># GridSearchCV를 사용한 하이퍼파라미터 최적화</span>\nparam_grid = {\n    <span class=\"hljs-string\">'C'</span>: [<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>],\n    <span class=\"hljs-string\">'solver'</span>: [<span class=\"hljs-string\">'liblinear'</span>]\n}\n\nmodel = LogisticRegression()\ngrid_search = GridSearchCV(model, param_grid, cv=<span class=\"hljs-number\">5</span>, scoring=<span class=\"hljs-string\">'accuracy'</span>)\ngrid_search.fit(X_train, y_train)\n\n<span class=\"hljs-comment\"># Grid search에서 최적의 모델</span>\nbest_model = grid_search.best_estimator_\n\n<span class=\"hljs-comment\"># 예측</span>\ny_pred = best_model.predict(X_test)\n\n<span class=\"hljs-comment\"># 평가 메트릭</span>\naccuracy = accuracy_score(y_test, y_pred)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"정확도:\"</span>, accuracy)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"분류 보고서:\\n\"</span>, classification_report(y_test, y_pred))\n\n<span class=\"hljs-comment\"># 혼동 행렬</span>\nconf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(conf_matrix, annot=<span class=\"hljs-literal\">True</span>, fmt=<span class=\"hljs-string\">'d'</span>, cmap=<span class=\"hljs-string\">'Blues'</span>)\nplt.xlabel(<span class=\"hljs-string\">'예측 라벨'</span>)\nplt.ylabel(<span class=\"hljs-string\">'실제 라벨'</span>)\nplt.title(<span class=\"hljs-string\">'혼동 행렬'</span>)\nplt.show()\n\n<span class=\"hljs-comment\"># 결과 시각화</span>\nplt.scatter(X_test[:, <span class=\"hljs-number\">0</span>], X_test[:, <span class=\"hljs-number\">1</span>], c=y_pred, cmap=<span class=\"hljs-string\">'viridis'</span>, marker=<span class=\"hljs-string\">'o'</span>)\nplt.title(<span class=\"hljs-string\">'제로샷 러닝 예측'</span>)\nplt.xlabel(<span class=\"hljs-string\">'특성 1'</span>)\nplt.ylabel(<span class=\"hljs-string\">'특성 2'</span>)\nplt.show()\n\n<span class=\"hljs-comment\"># 결과 해석</span>\n<span class=\"hljs-comment\"># 합성 데이터를 사용하여 제로샷 러닝 모델의 성능을 확인할 수 있습니다.</span>\n<span class=\"hljs-comment\"># 혼동 행렬 및 분류 보고서를 통해 정확도 및 분류 성능을 파악할 수 있습니다.</span>\n\n<span class=\"hljs-comment\"># 교차 검증 결과</span>\nresults = pd.DataFrame(grid_search.cv_results_)\nresults.plot(kind=<span class=\"hljs-string\">'bar'</span>, x=<span class=\"hljs-string\">'param_C'</span>, y=<span class=\"hljs-string\">'mean_test_score'</span>, yerr=<span class=\"hljs-string\">'std_test_score'</span>, capsize=<span class=\"hljs-number\">4</span>)\nplt.xlabel(<span class=\"hljs-string\">'C (정규화 매개변수)'</span>)\nplt.ylabel(<span class=\"hljs-string\">'평균 테스트 점수'</span>)\nplt.title(<span class=\"hljs-string\">'교차 검증 결과'</span>)\nplt.show()\n\n<span class=\"hljs-comment\"># 마무리</span>\n<span class=\"hljs-comment\"># 제로샷 러닝은 의미 정보를 기반으로 보이지 않는 클래스를 예측할 수 있는 모델을 만듭니다.</span>\n<span class=\"hljs-comment\"># 합성 예시는 제로샷 러닝 모델이 제공된 속성을 기반으로 일반화할 수 있는 능력을 보여줍니다.</span>\n</code></pre>\n<p>이 코드는 합성 데이터셋을 활용하여 제로샷 러닝의 실용적인 예시를 제공하며, 데이터 생성부터 평가 및 결과 시각화까지의 전체 머신 러닝 파이프라인을 다룹니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h2>결과 해석</h2>\n<p>혼동 행렬: 혼동 행렬은 분류 모델의 성능을 시각적으로 보여줍니다. 제공된 혼동 행렬에서:</p>\n<ul>\n<li>모형은 0 클래스의 경우 89개 및 1 클래스의 경우 110건을 정확하게 분류했습니다.</li>\n<li>1 클래스의 하나의 사례가 0 클래스로 분류되는 잘못된 분류가 있었습니다.</li>\n<li>0 클래스가 1 클래스로 잘못 분류된 경우는 없었습니다.</li>\n</ul>\n<p>이는 모델의 예측 정확도가 높음을 나타냅니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p><img src=\"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_1.png\" alt=\"image\"></p>\n<p>정확도: 0.995 모델은 99.5%의 정확도를 달성했습니다. 이는 예측 중 99.5%가 정확했음을 나타냅니다. 이 뛰어난 정확도 점수는 모델이 이 데이터셋에서 매우 잘 수행한다는 것을 시사합니다.</p>\n<p>분류 보고서: 분류 보고서는 각 클래스에 대한 정밀도, 재현율 및 f1-점수를 포함한 상세한 지표를 제공합니다:</p>\n<ul>\n<li>정밀도: 두 클래스 모두에 대한 정밀도가 매우 높습니다 (클래스 0의 경우 0.99, 클래스 1의 경우 1.00), 이는 모델이 매우 낮은 오검출률을 가지고 있다는 것을 나타냅니다.</li>\n<li>재현율: 두 클래스 모두에 대한 재현율도 매우 높습니다 (클래스 0의 경우 1.00, 클래스 1의 경우 0.99), 이는 모델이 매우 낮은 오물체률을 가지고 있다는 것을 나타냅니다.</li>\n<li>f1-점수: 정밀도와 재현율의 조화 평균인 f1-점수는 클래스 0의 경우 0.99, 클래스 1의 경우 1.00으로, 두 클래스에 대한 균형 잡힌 정확한 모델 성능을 시사합니다.</li>\n<li>지원: 지원 값(클래스 0의 경우 89, 클래스 1의 경우 111)은 테스트 데이터셋의 각 클래스에 대한 실제 인스턴스를 나타냅니다.</li>\n</ul>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>제로샷 러닝 예측 산점도: 산점도는 제로샷 러닝 예측을 시각화합니다. 각 포인트는 테스트 인스턴스를 나타내며, 다른 색상은 예측된 클래스를 나타냅니다. 포인트들의 명확한 군집화는 모델이 특징에 기반하여 두 클래스를 구별하는 능력을 나타냅니다.</p>\n<p><img src=\"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_2.png\" alt=\"Zero-Shot Learning Predictions Scatter Plot\"></p>\n<p>교차 검증 결과: 막대 차트는 정규화 매개변수 CCC의 다른 값에 대한 교차 검증에서의 평균 테스트 점수를 보여줍니다:</p>\n<ul>\n<li>모델은 모든 테스트된 CCC 값에 대해 일관된 우수한 성능을 보이며, 평균 테스트 점수는 1.0에 가깝습니다.</li>\n<li>오차 막대는 최소 테스트 점수의 표준 편차를 나타내며, 모델의 성능이 안정적이고 CCC의 선택에 지나치게 민감하지 않음을 시사합니다.</li>\n</ul>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p><img src=\"/TIL/assets/img/2024-07-12-Zero-ShotLearningBridgingtheGapBetweenKnownandUnknown_3.png\" alt=\"Zero-Shot Learning Approach\"></p>\n<p>최종 생각:</p>\n<ul>\n<li>모델은 뛰어난 성능을 보여주며 높은 정확도, 정밀도, 재현율 및 F1 점수를 가지고 있습니다.</li>\n<li>혼동 행렬과 산점도는 모델의 능력을 추가로 확인하여 테스트 인스턴스를 최소 오류로 올바르게 분류합니다.</li>\n<li>교차 검증 결과는 견고한 모델이 다양한 하이퍼파라미터 설정에서 잘 수행되는 것을 나타냅니다.</li>\n</ul>\n<p>이 zero-shot 학습 접근 방식은 합성 데이터셋을 사용하더라도 훌륭한 결과를 보여주며 의미 정보를 기반으로 보이지 않는 클래스를 정확하게 일반화하고 예측할 수 있는 모델의 능력을 강조합니다.</p>\n<!-- TIL 수평 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"1549334788\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>결론</h1>\n<p>제로샷 학습은 머신 러닝에서 큰 발전을 의미하며 직접적인 경험 없이 새로운 개념을 일반화하고 인식하는 인간의 능력을 반영합니다. 우리가 제로샷 학습 기술을 계속 발전시키고 향상시킬수록, 더 유연하고 확장 가능하며 동적인 현실 세계 환경에서 작동할 수 있는 AI 시스템을 만들기에 더 근접해집니다. AI의 미래는 배우고 적응하는 능력에 있으며, 제로샷 학습은 이 방향으로의 중요한 한걸음입니다.</p>\n<p>여러분의 의견을 듣고 싶습니다! 제로샷 학습이 귀하의 산업에서 AI의 미래를 어떻게 변화시킬 것으로 보십니까? 아래 댓글에 의견과 경험을 공유해주시고, 이 혁신적인 기술의 끝없는 가능성에 대한 대화를 이끌어봅시다!</p>\n<h1>참고문헌</h1>\n</body>\n</html>\n"},"__N_SSG":true}