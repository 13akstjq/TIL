{"pageProps":{"posts":[{"title":"오늘 배운 사실  왜 속성에 바다코끼리 연산자를 사용할 수 없을까","description":"","date":"2024-07-12 19:35","slug":"2024-07-12-TodayILearntWeCantUseTheWalrusOperatorOnAttributes","content":"\n\n\n![Example of the walrus operator](/TIL/assets/img/2024-07-12-TodayILearntWeCantUseTheWalrusOperatorOnAttributes_0.png)\r\n\r\nThe walrus operator := can condense 2 lines of code into one.\r\n\r\n```javascript\r\n// without walrus operator\r\n\r\nlet x = 'apple';\r\nif (x == 'apple') {\r\n    console.log('ok');\r\n}\r\n```\r\n\r\n```javascript\r\n// with walrus operator\r\n\r\nif ((x := 'apple') === 'apple') {\r\n    console.log('ok');\r\n}\r\n```\r\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n(x := `apple`)라는 구문에서 2가지 작업이 발생합니다:\n\n- x가 `apple`에 할당됩니다.\n- (x := `apple`) 자체가 `apple` 값을 반환합니다.\n\n# 배악 체이너와 속성\n\n하지만 객체 속성으로 이 작업을 시도할 때 오류가 발생합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nclass Dog:\n    pass\n\ndog = Dog()\n\nif (dog.age = 5) == 5:\n    print('ok')\n\n# SyntaxError: cannot use assignment expressions with attribute\n```\n\n그래서 우리는 dog.age와 같은 속성에 월러스 연산자 :=을 사용할 수 없다는 것을 알 수 있습니다. 저에게는 좀 이상한 것 같네요.\n\n그렇다면 어떻게 한 줄의 코드로 여전히 동일한 효과를 얻을 수 있을까요?\n\n# 해결책\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 속성을 설정하는 방법에 대해 알아봅시다\n\n```js\ndog.name = 'rocky'\n```\n\n```js\n# 위와 동일합니다\nsetattr(dog, 'name', 'rocky')\n\n# setattr()은 None을 반환합니다\n```\n\n다음으로 x 또는 `hello` 구문을 살펴보겠습니다\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# x은 Truthy 값입니다. 예: 5, 'apple'\n\nx = 'apple'\ny = x 또는 'hello'\n\nprint(y)  # apple\n```\n\n```js\n# x은 Falsy 값입니다. 예: None, 0, ''\n\nx = None\ny = x 또는 'hello'\n\nprint(y)  # hello\n```\n\n^ x 또는 `hello`에서:\n\n- x가 Truthy 값이면, 이 식은 x의 원래 값 반환\n- x가 Falsy 값이면, 이 식은 `hello`를 반환합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기서 이점을 취할 수 있어요:\n\n```js\n# 우리가 이루려고 하는 것 (이건 불법입니다)\n\nif (dog.name := 'rocky') == 'rocky':\n    # 작업\r\n```\n\n```js\n# 우리의 해결책\n\nif (setattr(dog, 'name', 'rocky') or 'rocky') == 'rocky':\n    # 작업\r\n```\n\n# 결론\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 건은 하나의 줄로 코드를 작성하길 원하는 경우에만 필요합니다. 그게 아니라면 2줄로 작성하세요.\n\n참고 - 프로덕션 코드에서는 사용하지 마세요\n\n# 만약 제가 크리에이터로서를 지원하길 원한다면\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 제 책을 구매해주세요! — 파이썬에 대해 전혀 몰랐던 101가지 이야기\n- 찾을 수 있는 곳: [여기를 클릭해주세요](https://payhip.com/b/vywcf)\n- 이 이야기를 칭찬해주세요. 50번!\n- 자신의 생각을 남겨주세요.\n- 이야기 중에서 가장 마음에 드는 부분을 강조해주세요.\n\n감사합니다! 이런 작은 행동들이 큰 변화를 만듭니다. 정말 감사드립니다!\n\nYouTube: [여기를 클릭해주세요](https://www.youtube.com/@zlliu246)\n\nLinkedIn: [여기를 클릭해주세요](https://www.linkedin.com/in/zlliu/)","ogImage":{"url":"/TIL/assets/img/2024-07-12-TodayILearntWeCantUseTheWalrusOperatorOnAttributes_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-TodayILearntWeCantUseTheWalrusOperatorOnAttributes_0.png","tag":["Tech"],"readingTime":4},{"title":"Yang-Zhang 방법으로 정확한 변동성 추정하기","description":"","date":"2024-07-12 19:34","slug":"2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator","content":"\n\n\n![Yang-Zhang volatility estimator](/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_0.png)\n\n양-장 변동성 추정자는 초고값 점프나 밤사이 갭을 가진 자산에 특히 유용한 역사적 변동성 측정값입니다. 이 추정자는 이전 게시된 로젤스-사첼과 가만-클라스 추정자의 장점을 결합해 단순한 변동성 측정값에서 발생하는 편향과 오류를 줄이도록 설계되었습니다.\n\n이 기사에서는 이 변동성 측정치를 자세히 소개하고, 파이썬을 사용하여 시계열에 대한 롤링 계산 코드를 어떻게 작성하는지 보여줍니다.\n\n# 양-장 변동성 이해하기\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n복잡한 변동성 모델에 대해 논의하기 전에, 항상 가장 기본적인 변동성 모델(또는 계산) 즉, 역사적 표준 편차에 대해 잘 이해하는 것이 좋습니다. 역사적 방법을 사용한 표준 편차는 금융 상품의 변동성을 측정하는 일반적인 방법으로, 과거 가격 데이터를 기반으로 합니다.\n\n이는 일련의 값들의 변동이나 분산량을 정량화합니다. 금융에서는 일반적으로 일일 수익률이 그들의 평균 주변에서 얼마나 퍼져있는지를 측정합니다. 표준 편차를 계산하는 단계는 다음과 같습니다:\n\n- 차분(첫 번째 함수) 또는 로그 방법(두 번째 함수)을 사용하여 수익률을 계산합니다.\n\n![image](/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_1.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![이미지](/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_2.png)\n\n- 수익률의 평균(평균)을 계산하세요:\n\n![이미지](/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_3.png)\n\n- 일일 수익률의 분산을 계산하세요:\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![이미지](/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_4.png)\n\n- 표준 편차는 분산의 제곱근이다:\n\n![이미지](/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_5.png)\n\n어떤 통계적 측정 값처럼 장단점이 있습니다. 역사적 표준 편차는 쉽게 계산할 수 있습니다. 스프레드시트 및 프로그래밍 언어에서 쉽게 구현할 수 있는 기본 통계 작업이 필요합니다. 변동성에 대한 공식적인 측정 방법으로 이해되며, 깊은 통계 배경을 갖지 않을 수 있는 이해관계자들에게 쉽게 설명할 수 있습니다. 많은 금융 모델 및 위험 지표(예: 샤프 비율)는 리스크 측정 값으로서 표준 편차를 의존합니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n샘플 크기가 작은 경우, 역사적 표준 편차는 실제 변동성을 과소평가하는 경향이 있습니다. 이 편향은 자산의 리스크에 대한 잘못된 결론으로 이어질 수 있습니다. 이 방법은 분석 기간 동안 자산의 기저 변동성이 일정하다고 가정합니다. 실제로 변동성은 시간이 지남에 따라 변할 수 있으므로 이 가정은 현실적이지 않습니다.\n\n게다가, 금융 수익은 종종 꼬리가 두꺼운 경향(leptokurtosis)과 비뚤림을 나타내며, 이는 정규 분포를 따르지 않음을 의미합니다. 표준 편차는 이러한 특성을 포착하지 못하며, 결과적으로 리스크를 과소평가할 수 있습니다.\n\nNvidia의 일일 수익에 대한 롤링 5일 변동성 측정치를 계산하기 위해 Python에서 다음 코드를 사용해보세요:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\ndef calculate_rolling_historical_volatility(data, window):\n    # 수익률 계산 (차분 방법 사용)\n    returns = data['Close'] - data['Close'].shift(1).dropna()\n    \n    # 수익률의 롤링 표준 편차 계산\n    rolling_volatility = returns.rolling(window=window).std()\n    \n    # 표준 편차 측정 값을 포함하는 변수 반환\n    return rolling_volatility\n\n# Nvidia의 역사적 값 다운로드\ndf = yf.download(\"NVDA\", start=\"2022-01-01\", end=\"2024-06-30\")\n\n# 롤링 윈도우 크기 정의\nwindow_size = 5\n\n# 공식 적용 및 변동성 데이터프레임 얻기\nrolling_volatility = calculate_rolling_historical_volatility(df, window=window_size)\n\n# 시간에 따른 변동성 플로팅\nplt.plot(rolling_volatility, color='black', label='5일 주기 역사적 표준 편차')\nplt.legend()\nplt.grid()\nplt.axhline(y=np.mean(rolling_volatility), color='red', linestyle='dashed')\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nYang-Zhang 변동성 추정기는 Rogers-Satchell 및 Garman-Klass 추정기의 장점을 결합한 과거 변동성 측정치이다. 이는 특히 고개를 넘는 높은 가격 변동이나 야간 갭이 있는 자산에 유용하다. 이 추정기는 더 간단한 변동성 추정기에 존재하는 편향 및 오차를 줄이도록 설계되었다.\n\nYang-Zhang 변동성 추정기는 다음 공식을 사용하여 계산된다:\n\n![equation](/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_6.png)\n\n참고:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_7.png\" />\n\n첫 번째 표준 편차 용어는 open-close 변동성을 나타내고, 두 번째는 close-close 변동성을 나타내며, 세 번째는 Rogers-Satchell 변동성 추정값입니다.\n\nK factor는 open-close 변동성과 close-close 변동성의 기여도를 균형 있게 조정하며, 표본 크기 n에 대한 보정을 합니다. 양-장(Estimators) 추정자는 다른 추정자들과 비교하여 개시 가격의 급등과 종가 변동에 덜 민감하며, 상당한 야간 갭을 경험하는 자산에 대해 더 견고합니다.\n\n더 많은 작업을 보려면, 그림에 첨부된 링크를 따라 가면 PDF 책 카탈로그를 찾을 수 있는 제 웹사이트를 방문해주세요!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![image](/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_8.png)\n\n# Python에서 Yang-Zhang 변동성 계산하기\n\n이제 Python을 사용하여 Yang-Zhang 변동성을 계산해 보겠습니다. 같은 예시를 사용할 것입니다 (즉, lookback 기간이 5인 Nvidia의 일일 수익률):\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\nimport math\n\ndef yang_zhang(price_data, window_size=30, periods=252, clean=True):\n\n    log_ho = (price_data[\"High\"] / price_data[\"Open\"]).apply(np.log)\n    log_lo = (price_data[\"Low\"] / price_data[\"Open\"]).apply(np.log)\n    log_co = (price_data[\"Close\"] / price_data[\"Open\"]).apply(np.log)\n\n    log_oc = (price_data[\"Open\"] / price_data[\"Close\"].shift(1)).apply(np.log)\n    log_oc_sq = log_oc ** 2\n\n    log_cc = (price_data[\"Close\"] / price_data[\"Close\"].shift(1)).apply(np.log)\n    log_cc_sq = log_cc ** 2\n\n    rs = log_ho * (log_ho - log_co) + log_lo * (log_lo - log_co)\n\n    close_vol = log_cc_sq.rolling(window=window_size, center=False).sum() * (\n        1.0 / (window_size - 1.0)\n    )\n    open_vol = log_oc_sq.rolling(window=window_size, center=False).sum() * (\n        1.0 / (window_size - 1.0)\n    )\n    window_rs = rs.rolling(window=window_size, center=False).sum() * (1.0 / (window_size - 1.0))\n\n    k = 0.34 / (1.34 + (window_size + 1) / (window_size - 1))\n    result = (open_vol + k * close_vol + (1 - k) * window_rs).apply(\n        np.sqrt\n    ) * math.sqrt(periods)\n\n    if clean:\n        return result.dropna()\n    else:\n        return result\n\n# Nvidia의 과거 값 다운로드\ndf = yf.download(\"NVDA\", start=\"2020-01-01\", end=\"2024-06-30\")\n# Rolling window 크기 정의\nwindow_size = 5\n# 식 적용 및 변동성 데이터 프레임 가져오기\nrolling_volatility = yang_zhang(df)\n# 시간대별 변동성 플롯\nplt.plot(rolling_volatility, color='black', label='5-period Yang-Zhang 변동성')\nplt.legend()\nplt.grid()\nplt.axhline(y=np.mean(rolling_volatility), color='red', linestyle='dashed)\n```\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_9.png)\n\n과거 표준 편차는 변동성의 유용하고 널리 채택된 측정 방법이며, 간단함, 계산의 용이성 및 금융 산업에서의 일반적인 수용으로 인해 가치가 있습니다. 그러나 작은 표본 크기, 비정상적 변동성 및 수익의 비정규 분포를 처리하는 데 있어서 특히 한계가 있어 조심해서 사용해야 합니다.\n\n정확성이 중요하거나 표본 크기가 작은 경우, 대안적인 변동성 모델이 더 나은 리스크 평가를 제공할 수 있습니다.","ogImage":{"url":"/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-Yang-ZhangasanAccurateVolatilityEstimator_0.png","tag":["Tech"],"readingTime":8},{"title":"파이썬으로 GenAI 사용하기 LLM과 에이전트 비교","description":"","date":"2024-07-12 19:31","slug":"2024-07-12-GenAIwithPythonLLMvsAgents","content":"\n\n\n![2024-07-12-GenAIwithPythonLLMvsAgents_0.png](/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_0.png)\n\n이 글에서는 제너레이티브 인공지능(GenAI) 최첨단 기술인 에이전트를 로컬에서 구축하는 방법을 소개하겠습니다. 일반 LLM과의 차이를 설명하면서요.\n\n![2024-07-12-GenAIwithPythonLLMvsAgents_1.png](/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_1.png)\n\n일반적으로, 지능형 에이전트는 환경을 인식할 수 있는 충분한 이해력으로 행동하는 존재로, 특정 목표를 달성하기 위해 자율적으로 행동하고 지식을 습득하며(사람과 같이) 개선합니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기술 분야에서 AI 에이전트는 작업을 수행하고 결정을 내리며 다른 개체와 통신하는 자율 프로그램입니다. 보통, 에이전트에게는 작업을 완료하는 동안 사용할 수 있는 도구 세트가 제공됩니다. 이 개념은 보상을 극대화하기 위해 정의된 일련의 작업 중에서 선택하는 강화 학습을 확장한 것입니다.\n\n대형 언어 모델(LLM)은 에이전트가 아닙니다. LLM은 단어 임베딩과 트랜스포머 아키텍처를 활용하여 고급 자연어 처리를 수행하는 신경망입니다. 인간 언어에 대한 막대한 이해력을 갖고 있지만, 지식 범위를 넘어서는 행동은 수행하지 않습니다.\n\nGenAI에서 에이전트는 순차적 추론을 처리하기 위해 설계된 AI 시스템으로, LLM의 일반 지식이 충분하지 않은 경우 외부 도구(예: 데이터베이스 쿼리, 웹 검색)를 실행할 수 있습니다. 간단히 말해, 일반적인 AI 챗봇은 답변할 수 없는 경우 무작위 텍스트를 생성하지만, 에이전트는 공백을 채우고 구체적인 응답을 제공하기 위해 도구를 활성화합니다.\n\n에이전트가 수행할 수 있는 가장 일반적인 작업은:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 대화 - 일반적인 지식 베이스와 대화하는 것을 의미합니다\n- RAG - 문서와 대화하는 것을 의미합니다\n- 쿼리(즉, SQL 생성) - 데이터베이스와 대화하는 것을 의미합니다\n- 웹 검색 - 인터넷 전체와 대화하는 것을 의미합니다\n\n그러나 가장 매혹적인 측면은 코딩이 가능하다면 어떤 것이든 도구가 될 수 있다는 것입니다. 따라서 에이전트의 기능과 응용 프로그램은 무한합니다.\n\n이 튜토리얼에서는 여러 개의 에이전트를 만들 것입니다. 다른 유사한 경우에 쉽게 적용할 수 있는 유용한 Python 코드를 제시하고 각 코드 라인에 대해 설명이 담긴 주석을 달아 이 예시를 복제할 수 있도록 안내하겠습니다(아래의 전체 코드 링크 참조).\n\n특히 다음을 다룰 것입니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 설정: LangChain + CrewAI + DuckDuckGo.\n- LLM: LLM을 사용하여 데이터를 읽고 시각 작업을 수행합니다.\n- Agent: 단일 Agent으로 동일한 작업 수행.\n- 여러 에이전트: 여럿이 팀을 이루어 동일한 작업 수행.\n\n## 설정\n\n현재, 가장 똑똑한 클로즈드 소스 인공지능(AI) Agents로는 OpenAI의 ChatGPT, Anthropic의 Claude, 그리고 Google의 Gemini가 있습니다. 오픈 소스 쪽에는 많은 초기 단계 라이브러리가 있지만, 시장 리더는 아직 없는 것으로 보입니다(이 주제는 정말 정선 기술이기 때문입니다). 주요 라이브러리는 다음과 같습니다:\n\n- LangChain — 거의 모든 LLM 기능을 포함하는 매쉬업 프레임워크입니다. Agent가 낮은 수준에서 코딩되어야 하는 경우(즉, 어떻게 메모리를 사용할지 결정해야 하는 경우), LangGraph 모듈을 추천드립니다.\n- CrewAI — \"크루\"로 함께 작업할 수 있는 여러 에이전트를 만들기 위해 특별히 설계된 라이브러리입니다.\n- AutoGen — Microsoft에서 개발한 로우코드(거의 노코드) 인터페이스 AutoGen Studio가 함께 제공되는 라이브러리입니다.\n- AnythingLLM — 가장 일반적인 작업을 수행할 수 있는 전혀 노코드 플랫폼입니다.\n- HuggingFace — 첫 번째 LLM 라이브러리이자 모델 저장소입니다.\n- LlamaIndex — Meta의 LLM 라이브러리와 새로운 에이전트 모듈 LLamaAgents가 포함되어 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLangChain (LLM을 위한)과 CrewAI (에이전트를 위한)의 조합이 매우 사용자 친화적이고 효과적이라고 생각해요.\n\n우선, LLM과 에이전트 사이의 차이를 이해해야 해요. 좋은 예를 보여드릴게요. LLM이 \"간단\"하지만 구체적인 질문에 어떻게 답변하는지 보여줄게요. 언어 모델 실행에 대해선 Ollama 모듈과 Phi3 모델을 사용하는 것을 선호해요. 설정 방법은 이 글을 참고할 수 있어요.\n\n```js\n!pip install langchain #0.1.20\n!pip install langchain-community #0.0.38\n\nfrom langchain_community.llms import Ollama \n\nllm = Ollama(model=\"phi3\")\nres = llm.invoke(input=[\"What day is today?\"]).split(\"\\n\")[0]\nprint(res)\n```\n\n![이미지](/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_2.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n당연히 언어 모델은 오늘의 날짜를 알 수 없습니다. 답을 얻는 한 가지 방법은 인터넷에서 검색하는 것입니다. Python에서는 유명한 비공개 브라우저 DuckDuckGo를 사용하여 쉽게 할 수 있습니다.\n\n```python\n!pip install duckduckgo-search #6.1.7\n\nfrom langchain.tools import DuckDuckGoSearchResults \n\nDuckDuckGoSearchResults().run(\"오늘은 무슨 요일인가요?\")\n```\n\n<img src=\"/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_3.png\" />\n\n... 또는 메타데이터 없이 텍스트만 원하면요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nfrom langchain_community.tools import DuckDuckGoSearchRun\n\nDuckDuckGoSearchRun().run(\"What day is today?\")\n```\n\n<img src=\"/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_4.png\" />\n\n이제 첫 번째 에이전트를 만들어봅시다. LLM에게 우리가 방금 한 것처럼 웹을 탐색할 수 있는 기능을 제공하여. 그러면 인공지능은:\n\n- LLM 지식으로는 해당 질문에 대답할 수 없다는 것을 이해해야 합니다.\n- 추가 정보를 얻기 위해 도구를 사용해야 합니다.\n- 결과를 LLM을 통해 처리하고 답변을 생성해야 합니다.\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n말씀드렸듯이, 어떤 것이든 Tool 객체가 될 수 있으며 CrewAI 라이브러리를 사용하여 함수에 데코레이터를 간단히 추가할 수 있습니다.\n\n```js\n!pip install \"crewai[tools]\" #0.4.0\n\nfrom crewai_tools import tool \n\n@tool\ndef tool_browser(q: str) -> str:\n    \"\"\"DuckDuckGo 브라우저\"\"\"\n    return DuckDuckGoSearchRun().run(q)\n```\n\n에이전트 객체를 만들기 위해서는 목표(작업의 간단한 설명)와 배경 이야기(작업에 대한 자세한 설명)를 정의하여 일부 프롬프트 엔지니어링을 해야 합니다. 도구 및 LLM도 지정해야 합니다.\n\n```js\n!pip install crewai #0.35.0\n\nimport crewai\n\nagent = crewai.Agent(\n            role=\"Calendar\", \n            goal=\"오늘의 요일을 확인하세요\",\n            backstory=\"당신은 달력 도우미입니다. 날짜에 관한 정보를 알려줍니다.\",\n            tools=[tool_browser], \n            llm=llm,\n            allow_delegation=False, verbose=False)\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼, 다시 한 번 목표를 지정하여 Task 객체를 생성해야 합니다.\n\n```js\ntask = crewai.Task(description=\"오늘은 무슨 요일인지 알아내기\",\n                   agent=agent,\n                   expected_output=\"오늘 날짜\")\n```\n\n마지막으로, 이 경우에는 Agent가 한 명뿐인 Crew를 실행해야 합니다.\n\n```js\ncrew = crewai.Crew(agents=[agent], tasks=[task], verbose=False)\nres = crew.kickoff()\nprint(res)\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![GenAIwithPythonLLMvsAgents_5](/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_5.png)\n\n보시다시피, 에이전트는 LLM이 대답하지 못한 질문에 대답할 수 있어요. 개요를 파악하셨으니, 다음 단계로 넘어가볼까요?\n\n## LLM\n\n이 수영복 브랜드(White Water Atelier)에서는 AI를 활용한 소셜 미디어 전략을 만들어 달라고 했어요... 에이전트에게 딱 맞는 사례죠. 특히, 인스타그램 포스트 작성 프로세스를 자동화할 거에요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저, 데이터(이미지)를 읽어봅시다:\n\n```js\nfrom matplotlib import image, pyplot\nimport os\n\npath = 'data/'\nfolder = [x for x in os.listdir(path) if x.endswith(('.png','.jpg','.jpeg'))]\n\nfig, ax = pyplot.subplots(nrows=1, ncols=len(folder), sharex=False, sharey=False, figsize=(4*len(folder),10))\nfor n,file in enumerate(folder):\n    ax[n].imshow(image.imread(path+file))\n    ax[n].set(title=file)\n```\n\n<img src=\"/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_6.png\" />\n\nLLM에게 게시물을 생성하도록 요청하려면(사진 하나를 선택하고 캡션을 작성하도록 하기 위해서), 이미지는 모델이 처리할 수 있도록 문자열로 인코딩되어야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\r\nimport base64\n\ndef encode_image(path):\n    with open(path, \"rb\") as file:\n        return base64.b64encode(file.read()).decode('utf-8')\n\nlst_imgs = [encode_image(path+i) for i in folder]\r\n```\n\n적절한 비전 LLM을 사용할 것입니다. Microsoft의 LLaVa는 GPU 없이도 작동할 수 있는 효율적인 선택입니다 (여기에서 시도해보세요).\n\n```js\r\nprompt = '''먼저 인스타그램에서 어떤 사진이 좋아요를 더 많이 받을지 결정해야 합니다. 그리고 선택한 이미지에 기반하여 변환율을 극대화할 캡션을 작성해야 합니다.'''\n\nvision_llm = Ollama(model=\"llava\")\n\nres = vision_llm.invoke(input=[prompt], images=lst_imgs)\nprint(res)\r\n```\n\n<img src=\"/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_7.png\" />\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n꽤 잘했어요. LLM이 두 가지 작업을 완료했고 좋은 설명도 추가했어요. 하지만 캡션이 해시태그가 빠져있어 조금 오래된 것 같아요.\n\n## 에이전트\n\n이전 예제와 마찬가지로, 특정 검색 도구가 제공된 에이전트에게 동일한 작업을 넘길 거에요.\n\n```js\n@tool(\"instagram\")\ndef tool_instagram(q: str) -> str:\n    '''Instagram 검색'''\n    return DuckDuckGoSearchRun().run(f\"site:instagram.com {q}\")\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n과거 에이전트와의 윯 한 가붕, 이번에는 입력 데아터를 전달할 때입니다. 특히, 이미지를 설명하기 위해 비전 LLM을 활용하고 텍스트를 입력으로 사용할 것입네다.\n\n```js\nvision_llm = Ollama(model=\"llava\")\n\ndes = \"\"\nfor n,img in enumerate(lst_imgs):\n    res = vision_llm.invoke(input=[\"이미지를 정확하게 설명하세요\"], images=[img])\n    des = des.strip() + \"\\n\\n\" + f\"이미지{n+1}: \"+res.replace('\\n',' ')\n\nprint(des)\n```\n\n![이미지](/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_8.png)\n\nCrewAI에서는 에이전트 실행 시 입력을 제공해야 하며, 'inputs'를 이용하여 프롬프트에서 참조할 수 있습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nprompt = '''먼저 {images}에서 어떤 이미지가 인스타그램에서 좋아요를 더 많이 받을지 결정해야 합니다. 해당 이미지를 선택한 이유를 설명한 후, 해당 이미지를 기반으로 전환율을 극대화할 캡션을 작성해야 합니다. 현재 계절, 오늘의 날짜, 이번 달의 특별한 이벤트, 트렌드 있는 해시태그 및 이모티콘을 고려하여 완벽한 캡션을 만들어보세요.'''\n\n## Agent\nagent = crewai.Agent(\n            role=\"인플루언서\", \n            goal=prompt,\n            backstory=\"모든 게시물의 전환율을 극대화하는 인플루언서입니다.\",\n            tools=[tool_instagram], \n            llm=llm,\n            allow_delegation=False, verbose=True)\n\n## Task\ntask = crewai.Task(description=prompt, agent=agent,\n                   expected_output='''인스타그램 게시물을 위한 최고의 사진과 캡션''')\n\n## Crew\ncrew = crewai.Crew(agents=[agent], tasks=[task], verbose=True)\nres = crew.kickoff(inputs={\"images\":des})\nprint(\"Res:\", res)\r\n```\n\n로그를 분석하기 위해 verbose=True로 설정했습니다. 에이전트는 요청을 처리하면서 필요한 도구인… \n\n![이미지](/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_9.png)\n\n…을 사용해 작업을 시작합니다. 요청 결과를 검토하는 것으로 계속됩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_10.png\" />\n\n... 그러고 나면 최종 답변이 나옵니다.\n\n<img src=\"/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_11.png\" />\n\n그래서 Agents는 LLM과 같은 이미지를 선택하고 더 나은 캡션을 생성했습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 다중 에이전트\n\n성능을 극대화하기 위해 각 에이전트에게 단일 작업을 할당하는 것이 일반적입니다. 따라서 작업을 두 부분(이미지 선택 및 캡션 생성)으로 분할하고 전체 프로세스를 자동화하기 위해 여러 에이전트로 구성된 팀을 만들겠습니다:\n\n- 사진작가 — 입력 설명을 기반으로 최적의 이미지를 선택하는 작업을 맡습니다 (웹에서 검색 가능)\n- 소셜 미디어 매니저 — 사진작가의 결과를 기반으로 최적의 캡션을 작성하는 작업을 맡습니다 (웹에서 검색 가능)\n- 매니저 — 전체 프로세스를 담당하는 작업을 맡습니다. 요청을 이해하고 다른 에이전트에 일을 할당하며 최종 결과가 올바른지 확인해야 합니다 (최종 검증을 위해 사람에게 요청 가능).\n\n각 작업이 실행되는 동안 출력을 확인하기 위해 콜백 함수를 추가하는 것이 유용할 수 있습니다 (이를 Task 객체에 추가해야 함).\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ndef callback_function(output):\n    print(f\"작업 완료: {output.raw_output}\")\n```\n\n처음 두 명의 에이전트는 이전에 코딩한 것과 유사합니다. 그러나 이번에는 각 에이전트가 특정한 하나의 작업만 수행하므로 프롬프트 지침에 더 자세히 설명하겠습니다.\n\n```js\n######################## 1-사진작가 #########################\nprompt = '''{images} 중에서 인스타그램에서 더 많은 좋아요를 받을 사진을 선택하세요.'''\n\n## 에이전트\n에이전트_사진작가 = crewai.Agent(\n    role=\"사진작가\",\n    goal=prompt,\n    backstory='''사진작가로써, 인스타그램에서 더 많은 좋아요를 받을 사진을 이해해야 합니다.\n     게시물로 더 많은 사람들이 상호작용하도록 하고, 전환율을 극대화해야 합니다.\n     현재 계절, 오늘 날짜, 이번 달의 특별한 이벤트에 대해 조사해보세요.\n     ''',\n    tools=[tool_browser, tool_instagram], \n    llm=llm,\n    allow_delegation=False, verbose=False)\n\n## 작업\n작업_사진작가 = crewai.Task(\n    description=prompt,\n    agent=에이전트_사진작가,\n    callback=callback_function,\n    expected_output='''선택한 이미지 및 왜 그것이 가장 좋다고 생각하는지 설명''')\n\n\n######################## 2-소셜 미디어 매니저 ##################\nprompt = '''이미지를 기반으로 인스타그램 게시물의 전환율을 극대화할 캡션을 작성하세요.'''\n\n## 에이전트\n에이전트_소셜 = crewai.Agent(\n    role=\"소셜 미디어 매니저\",\n    goal=prompt,\n    backstory='''소셜 미디어 매니저로서, 사진작가의 결과물을 기반으로 짧은 캡션을 생성해야 합니다.\n     인스타그램에서 더 많은 좋아요를 받고, 게시물로 더 많은 사람들이 상호작용하며 전환율을 극대화해야 합니다. \n     트렌디한 주제, 해시태그 및 이모지 등에 대해 조사해보세요. \n     ''',\n    tools=[tool_browser, tool_instagram], \n    llm=llm,\n    allow_delegation=False,\n    verbose=False)\n\n## 작업\n작업_소셜 = crewai.Task(\n    description=prompt,\n    agent=에이전트_소셜,\n    expected_output='''인스타그램 게시물을 위한 짧은 캡션''')\r\n```\n\n다음 에이전트는 최종 출력물을 감시하고 인간의 검증을 요청해야 합니다. 따라서 프롬프트 설명에서 매우 정확해야 하며 에이전트 객체에서 allow_delegation=True 및 작업 객체에서 human_input=True 매개변수를 사용해야 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n######################## 3-다른 에이전트들의 매니저 #############\nprompt = '''게시물 생성 프로세스를 감독하고, 게시물 좋아요를 극대화하는 최고의 사진을 선택하고, 게시물의 전환율을 극대화하는 최고의 캡션을 작성합니다.'''\n\n## Agent\nagent_manager = crewai.Agent(\n    role=\"다른 에이전트들의 매니저\",\n    goal=prompt,\n    backstory='''프로세스의 매니저로서, 완벽한 인스타그램 게시물을 만들기 위해 모든 단계를 따릅니다:\n     1- 사진작가와 함께 더 많은 인스타그램 좋아요를 받을 사진을 선택합니다.\n     2- 이미지를 기반으로 인스타그램에서 전환율을 극대화할 게시물 캡션을 작성합니다.\n     프로세스의 끝에는 반드시 인간의 최종 승인을 요청해야 합니다. 인간 입력 도구를 사용하세요.\n     ''',\n    llm=llm,\n    allow_delegation=True, verbose=True)\n\n## Task\ntask_manager = crewai.Task(\n    description=prompt, agent=agent_manager,\n    human_input=True,\n    expected_output='''최상의 이미지와 짧은 캡션, 기본적으로 전체 인스타그램 게시물''')\r\n```\n\n마지막으로, 모든 것을 Crew 객체에 넣을 수 있습니다. 이번에는 하나의 에이전트만 프로젝트 전체를 담당해야 한다는 것을 지정할 수 있습니다. 순차 프로세스는 작업이 선형적으로 진행되어 한 작업이 다음 작업을 따르는 것을 보장하며, 계층적 프로세스는 효율적인 작업 위임 및 실행을 위해 전통적인 조직적 계층 구조를 모방합니다.\n\n```js\ncrew = crewai.Crew(agents=[agent_photograper, agent_social], \n                   tasks=[task_photograper, task_social, task_manager], \n                   process=crewai.Process.hierarchical,\n                   manager_agent=agent_manager,\n                   verbose=True)\n\nres = crew.kickoff(inputs={\"images\":des})\r\n```\n\n<img src=\"/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_12.png\" />\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n로그에서 확인할 수 있듯이, 매니저가 요청을 처리하고 첫 번째 작업을 첫 번째 에이전트에게 위임했습니다. 첫 번째 결과는 완벽합니다. AI가 최근 소셜 미디어 트렌드와 인스타그램 알고리즘 논리를 분석했습니다.\n\n![첫 번째 결과](/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_13.png)\n\n그러나 두 번째 결과는 약간 납득하기 어렵습니다. 에이전트가 제품에 대한 \"할인\"을 언급했습니다. 요금 및 판매와 같은 주제는 지시에 포함되어 있지 않으며 인간 감독자가 승인해야 합니다 (human_input 매개변수 덕분에).\n\n![두 번째 결과](https://miro.medium.com/v2/resize:fit:1064/1*Ogf4BPBBKolftQIQXd-EQg.gif)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nGitHub에서 전체 코드를 확인할 수 있어요.\n\n## 결론\n\n본 글은 다양한 작업을 수행할 수 있는 에이전트를 구축하는 방법을 보여주는 튜토리얼이었습니다. LLM, LangChain 및 CrewAI를 사용하여 다양한 유형의 데이터를 처리할 수 있는 AI 팀을 만들었습니다. 에이전트는 매우 유연하므로 어떤 용도에도 사용자 정의할 수 있도록 프로세스를 가능한 일반적으로 설명했어요.\n\n즐겁게 읽으셨기를 바랍니다! 궁금한 점이나 피드백이 있으시다면 언제든지 연락해 주시거나 흥미로운 프로젝트를 공유해 주세요.","ogImage":{"url":"/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-GenAIwithPythonLLMvsAgents_0.png","tag":["Tech"],"readingTime":18},{"title":"RAG에서 성능 및 효율성을 달성하는 방법","description":"","date":"2024-07-12 19:29","slug":"2024-07-12-HowAchievingPerformanceandEfficiencyinRAG","content":"\n\n## | LLM | RAG | BENCHMARK |\n\n<img src=\"/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_0.png\" />\n\nLLM들은 답을 모를 때 환각을 일으키곤 합니다. 연구자와 기업에게 가장 큰 머리아픔 중 하나입니다. 특히 민감한 분야를 다룰 때 환각은 참사적인 결과를 초래할 수 있습니다.\n\n그래서 새로운 패러다임인 검색 증강 생성(Retrieval Augmented Generation, RAG)이 발전했습니다. 이 새로운 시스템에서 LLM은 검색된 문맥을 활용하여 응답을 생성합니다. 따라서 RAG는 필요한 문맥을 찾아주며 LLM이 매개변수를 업데이트할 필요가 없도록 합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러나 모델에는 고유한 매개 변수 메모리가 있습니다. 때로는 이 매개 변수 메모리와 컨텍스트 간에 충돌이 발생하여 모델은 매개 변수 내의 답변과 RAG에서 제안된 답변 중에서 선택해야 합니다. 이러한 이유로 시스템을 최적화하는 데 사용되는 다양한 기술이 개발되었습니다.\n\n사실, RAG는 여러 부분으로 구성되어 있고, 우리는 능숙하고 최적화된 시스템을 만들고 싶습니다. 따라서 모델이 쿼리를 문맥적으로 설정하는 방법, 가장 유사한 청크를 찾는 방법, 중요도 순서 등을 최적화해야 합니다. 시간이 흐름에 따라 몇 가지 전문 구성 요소가 발전해 왔습니다.\n\n<img src=\"/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_1.png\" />\n\n각 단계에 대해 다른 방법들이 있기 때문에 복잡성이 증가합니다. 게다가, 더 정교한 RAG 패러다임은 여러 구성 요소로 구성되어 있으며, 각 단계마다 여러 가지 해결책이 가능합니다. 예를 들어, 다양한 종류의 청크화와 수십 가지 패턴의 임베더가 있습니다. 따라서 실무자는 여러 가지 결정을 내려야 합니다. 이러한 각각의 결정은 검색과 생성 단계에 모두 영향을 미칩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n최근 연구에서는 실증적으로 다양한 구성 요소가 RAG에 미치는 영향을 테스트했습니다.\n\n이 연구에서는 각 단계가 어떻게 영향을 미치는지를 분석하고 각 시나리오에 가장 적합한 전략이 무엇인지 조사했습니다.\n\n이 연구에서는 컴퓨팅 비용을 줄이기 위해:\n\n- 각 RAG 단계에 대한 대표적인 방법을 비교하고 세 가지 최상의 방법을 선택합니다.\n- 그런 다음 다른 구성 요소를 일정하게 유지하면서 각 방법을 개별적으로 테스트합니다.\n- 마지막으로 일부 시나리오에 대해 구성 요소 세트를 테스트합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![image](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_2.png)\n\n모든 쿼리가 검색을 요구하지는 않습니다(이는 LLM이 매개 변수화 메모리를 가지고 있기 때문입니다). RAG도 지연 시간을 늘리고 계산 비용이 발생합니다. 따라서 LLM으로 직접 응답할 쿼리와 RAG가 필요한 쿼리를 선택하는 흥미로운 방법이 있습니다. 실제로, 검색은 모델 매개 변수 이상의 지식 및 작업이 요구하는 것에 대해서만 수행되어야 합니다.\n\n따라서 이 연구에서 저자들은 매개 변수 모델 메모리가 충분한 작업과 충분하지 않은 작업(따라서 검색이 필요할 수 있음)으로 작업을 분류합니다. 저자들은 의사 결정 프로세스를 자동화하기 위해 분류기를 훈련시킵니다.\n\n![image](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_3.png)\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다양한 종류의 청킹과 관련된 다양한 하이퍼파라미터가 있습니다. 본 연구에서 저자들은 다음을 탐구했습니다:\n\n- 청킹 유형. 토큰 수준 청킹은 가장 간단하지만 종종 성능이 좋지 않습니다. 의미 수준 청킹은 LLMs를 사용하여 분기점을 결정하며 컨텍스트를 보존하지만 계산 비용이 높습니다. 저자들은 문장 수준 청킹이 단순성과 효율성을 균형잡기 때문에 이를 사용합니다.\n- 청킹 크기. 큰 청크는 더 많은 컨텍스트를 제공하지만 처리 시간을 증가시킵니다. 반면, 작은 청크는 검색 재현율을 향상시키지만 올바른 컨텍스트를 부족할 수 있습니다. 올바른 청크를 검색하는 것은 충실성 및 관련성과 같은 메트릭을 균형 있게 맞추어야 합니다.\n- 청킹 기술. 작은 것에서 큰 것으로, 슬라이딩 윈도우와 같은 고급 기술은 블록 간의 관계를 식별할 수 있게 함으로써 검색 품질을 향상시킵니다. 일반적으로 질문과 일치하기 위해 작은 블록이 사용되는 반면, 컨텍스트 정보가 필요한 경우에는 더 큰 블록이 사용됩니다.\n\n의도적으로 너무 크거나 작은 블록은 유익하지 않습니다. 512가 가장 적당한 크기로 보입니다.\n\n![그림](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_4.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n슬라이딩 윈도우는 최상의 결과를 제공하는 기법인 것 같아요.\n\n![이미지](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_5.png)\n\n작가들은 임베딩을 위해 여러 모델을 시험한 후, 성능과 크기의 균형 때문에 LLM-Embedder를 선택했어요.\n\n![이미지](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_6.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n벡터 데이터베이스도 중요합니다. 이 연구에서는 여러 기준을 고려합니다: 다양한 데이터 유형을 지원하는 여러 인덱스 유형, 십억 단위의 벡터 지원 (확장성), 하이브리드 검색 및 클라우드 네이티브 기능을 고려합니다. 보통은 이러한 기준을 선택하여 유연성, 확장성 및 배포 용이성에 미치는 영향을 평가합니다. 그들에게 가장 좋은 것은 Milvus입니다:\n\n![이미지](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_7.png)\n\n검색을 위해 임베딩이 수행되면 상위 k개의 문서가 선택되어 생성에 사용됩니다. 원본 쿼리가 최적이 아닐 수 있으므로 쿼리 변환 시스템이 사용됩니다:\n\n- 쿼리 재작성. 이 방법은 쿼리를 다시 작성하여 관련 문서와 더 잘 일치하도록 합니다. LLM이 쿼리를 다시 작성하고 성능을 향상시키는 데 사용됩니다.\n- 쿼리 분해. 대신, 쿼리를 하위 쿼리로 분해하여 문서와 일치하도록 합니다.\n- 의사 문서 생성. 이 방법은 쿼리를 기반으로 가상 문서를 생성하고 해당 임베딩을 사용하여 유사한 문서를 찾습니다 (예: HyDE).\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저자들은 이러한 방법들과 혼합 검색을 테스트하기도 합니다. 여러 가짜 문서를 원본 쿼리와 함께 연결하면 검색 성능을 크게 향상시킬 수 있습니다. 물론 이렇게 하면 지연 비용이 증가하지만, 가상 문서 하나만으로도 충분한 것 같습니다.\n\n[해당 이미지](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_8.png)를 확인해보세요.\n\n또한, 저자들은 혼합 검색에 대한 다양한 값들을 테스트합니다 (희소 검색 대 밀집 검색 비율). 결과는 α 값이 0.3일 때 가장 좋은 성능을 보인다는 것을 보여줍니다 (희소 검색의 중요도를 조절하는 하이퍼파라미터).\n\n[해당 이미지](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_9.png)도 확인해보세요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n검색 결과를 건내 받은 후 문서 재랭킹은 검색 결과의 관련성을 향상시켜줍니다. 저자들은 두 가지 접근 방식을 고려합니다:\n\nmonoT5는 성능과 효율성을 균형 있게 유지하는 것으로 보이며, TILDEv2가 가장 빠릅니다.\n\n![이미지](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_10.png)\n\n저자들은 또한 재랭킹 후 문서를 다시 정렬하는 repacking에 대해 고려합니다. 관련성 순서는 생성 성능에 영향을 미칩니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n검색은 LLM을 혼란스럽게 만들 수 있는 중복되고 불필요한 정보를 포함하는 문서를 찾을 수 있습니다. 또한, 긴 프롬프트는 효율적이지 않습니다. 저자들은 요약에 대해 탐구합니다(관련 단락을 추출하는 추출적 방식과 정보를 압축하여 요약을 생성하는 추상적 방식 모두):\n\n- Recomp. 추출 압축기는 유용한 문장을 선택하고, 추상적 압축기는 여러 문서에서 정보를 종합합니다.\n- 선택적 콘텍스트. 중복된 정보를 콘텍스트에서 제거합니다.\n\nRecomp이 가장 잘 수행하는 모델로 보입니다:\n\n![이미지](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_11.png)\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n작가들은 또한 RAG에 대한 LLM의 세밀한 조정을 탐구합니다. 결과는 모델이 세밀하게 조정되면 특히 교육 중 몇 가지 관련성 있는 문서와 임의로 선택된 문서들로 세밀하게 조정된 경우에 더 잘 작동함을 보여줍니다.\n\n![이미지](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_12.png)\n\n이 시점에서, 작가들은 다양한 구성 요소 선택과 관련하여 다양한 도메인인 사실 확인, 다중 점프 및 특수 도메인과 비교를 실시합니다. 또한 더 포괄적인 평가를 위해 여러 지표를 측정합니다.\n\n결과는 다음과 같습니다:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Query Classification Module은 정확도 뿐만 아니라 시스템의 평균 대기 시간도 줄입니다 (모든 쿼리가 RAG로 답변되지는 않습니다).\n- HyDE 하이브리드는 검색에 대한 최고의 성능을 보여주지만 상대적으로 높은 계산 비용이 발생하므로 저자들은 하이브리드나 하이브리드 없는 검색을 권장합니다.\n- 다시 순위 매기는 중요하며 주요 성능 하락으로 이어집니다. MonoT5가 최고의 방법으로 확인됩니다.\n- 재포장은 영향을 미칠 것으로 보이며 문서를 오름차순의 관련성 점수로 정리하는 것이 최선인 해결책입니다.\n- 요약은 결과를 향상시키지만 대기 시간 비용이 듭니다. 요약과 유사한 성능은 여전히 얻을 수 있습니다.\n\n![이미지](/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_13.png)\n\n재현성을 위해 코드는 여기에 있습니다:\n\nRAG에 대해 깊이 있는 벤치마킹을 수행하는 연구는 거의 없습니다. 이 작업의 가치는 최적의 구성 요소와 시스템을 체계적으로 연구함으로써 다양한 구성 요소에 대해 심층 연구를 수행했다는 점입니다. 저자에게 결론은:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 최상의 성능 실천 방법. 최상의 성능을 위한 조합은 쿼리 분류 모듈, HyDE와의 하이브리드, monoT5, 역 패킹 및 Recomp을 포함합니다. 이 방법은 계산적으로 많은 리소스를 요구할 수 있어 더 높은 대기 시간을 야기할 수 있습니다.\n- 균형있는 효율성 실천. 저자들은 계산 비용을 줄이기 위해 Hybrid with HyDE 및 TILDEv2를 사용하지 않고 재순위 작업을 하지 않는 것을 제안하며 성능에 큰 영향을 끼치지 않습니다.\n\n이 연구는 두 가지 훌륭한 처방을 제시합니다. 계산 비용 문제로 모든 가능한 조합을 탐색하는 것은 불가능할 수 있습니다. 또한 하나의 레시피가 모든 경우에 적용되지 않을 수 있습니다. 서로 다른 레시피가 더 나은 결과를 얻을 수 있는 특정 경우도 있습니다. 또한, 저자들은 RAG 및 생성기의 공동 세밀 조정을 탐구하지 않았으며 이는 성능 (및 환각 감소)에 주목할 만한 영향을 줄 수 있습니다.\n\n## 어떻게 생각하시나요? 두 가지 레시피 중 하나를 시도해 보시겠습니까? 의견을 남겨 주세요.\n\n# 이 흥미로운 내용을 찾으셨다면:\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저의 다른 글을 읽어보시고 LinkedIn에서 저와 연결하거나 연락하실 수도 있어요. 매주 업데이트되는 머신 러닝 및 인공 지능 뉴스가 포함된 이 저장소를 확인해보세요. 협업 및 프로젝트에 대해 열려 있으며 LinkedIn을 통해 저에게 연락할 수 있어요. 또한 새로운 이야기를 게시할 때 알림을 받으려면 무료로 구독할 수도 있어요.\n\n저의 GitHub 저장소 링크는 여기 있어요. 거기에는 머신 러닝, 인공 지능 등과 관련된 코드 및 다양한 리소스가 수집되어 있어요.\n\n또는 최근 글 중 하나에 관심이 있을 수도 있어요:\n\n# 참고\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 글을 작성할 때 참고한 주요 참고 자료 목록입니다. 각 문장의 이름은 한 번만 인용됩니다.\n\n- 고우, 2024, 대형 언어 모델을 위한 검색 증강 생성: 조사, 링크\n- 왕, 2024, 검색 증강 생성에서의 최상의 실천법 찾기, 링크\n- 노게이라, 2020, 사전 훈련된 시퀀스-투-시퀀스 모델을 사용한 문서 순위 매김, 링크","ogImage":{"url":"/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-HowAchievingPerformanceandEfficiencyinRAG_0.png","tag":["Tech"],"readingTime":11},{"title":"로컬 LLMs 실행이 생각보다 더 유용하고 쉬운 이유","description":"","date":"2024-07-12 19:27","slug":"2024-07-12-RunningLocalLLMsisMoreUsefulandEasierThanYouThink","content":"\n\n![image](/TIL/assets/img/2024-07-12-RunningLocalLLMsisMoreUsefulandEasierThanYouThink_0.png)  \n\n# #1 로컬 LLM을 사용해야 하는 이유  \n\nChatGPT은 정말 멋지죠. 그런데 한 가지 치명적인 단점이 있습니다: 작성하거나 업로드하는 모든 것이 OpenAI의 서버에 저장됩니다. 이는 많은 경우에는 문제가 되지 않을 수 있지만, 민감한 데이터를 다룰 때 문제가 될 수 있습니다.  \n\n그래서 저는 개인 컴퓨터에서 로컬로 실행할 수 있는 오픈소스 LLM을 탐구하기 시작했습니다. 실제로 그것들이 왜 훌륭한지에 대해 많은 이유가 있다는 것을 발견했습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n1. 데이터 개인 정보 보호: 귀하의 정보는 귀하의 기기에 유지됩니다.\n\n2. 비용 효율적: 가입비나 API 비용이 없으며 무료로 사용할 수 있습니다.\n\n3. 맞춤화: 모델은 귀하의 특정 시스템 프롬프트나 데이터 세트로 세밀하게 조정할 수 있습니다.\n\n4. 오프라인 기능: 인터넷 연결이 필요하지 않습니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n5. 제약 사항이 없는 사용: 외부 API에서 부과된 제한이 없습니다.\n\n시작해 봅시다!\n\n## 2. Ollama 설치 및 Llama 3 실행하기\n\nOllama는 개인 컴퓨터에서 쉽게 대형 언어 모델(LLM)을 로컬에서 실행할 수 있게 해주는 오픈 소스 프로젝트입니다. 사용자 친화적이고 매우 가벼우며 Meta(럼마 3)와 구글(젬마 2)의 최신 및 최고의 사전 학습 모델을 포함한 다양한 모델을 제공하는 것으로 알려져 있습니다. 이러한 회사들이 이러한 모델을 교육하는 데 수백만 달러를 투자하여 우리가 자신의 기기에서 재미있게 사용할 수 있도록 했습니다. 대단하지 않나요?\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nOllama는 그 자체로는 빈 껍데기에 불과하며 작동하려면 LLM이 필요합니다.\n\n설치 프로세스에 들어가기 전에 사용 가능한 모델들을 살펴보겠습니다:\n\n![](/TIL/assets/img/2024-07-12-RunningLocalLLMsisMoreUsefulandEasierThanYouThink_1.png)\n\n그리고 더 많은 모델이 있습니다!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 글에서는 Meta사의 최신 모델인 Llama 3에 초점을 맞추어 놀라운 성능을 약속하는 이 모델이 이 플랫폼에서 가장 인기 있는 모델이라고 합니다. 이 글을 작성하는 시점에 이 모델은 440만 회 이상의 다운로드를 기록하고 있습니다.\n\n![이미지](/TIL/assets/img/2024-07-12-RunningLocalLLMsisMoreUsefulandEasierThanYouThink_2.png)\n\n다음 단계에서는 컴퓨터에 Ollama를 설치하고 Llama3로 공급하여 마침내 그 모델을 ChatGPT처럼 사용하는 방법을 보여줍니다.\n\n단계 1/2:\n1. ollama.com에 가서 \"다운로드\"를 클릭합니다. 저는 macOS를 사용하고 있으므로 이후 튜토리얼에서 이 옵션에 초점을 맞출 것이지만, Linux나 Windows에서 할 때도 크게 다르지 않을 것입니다.\n2. \"macOS용 다운로드\"를 클릭합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마크다운 형식의 표를 사용해보세요.\n\nSTEP 3/4/5:\n다른 앱들과 마찬가지로 매우 간단한 설치 단계를 따르기만 하면 됩니다.\n1. \"설치\"를 클릭합니다.\n2. \"다음\"을 클릭합니다.\n3. 터미널에서 \"ollama run llama3\"을 실행합니다.\n\n마지막 단계에서는 먼저 llama3의 8B 버전(약 4.7GB)을 컴퓨터에 다운로드한 다음 실행됩니다. 이렇게 간단합니다!\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\n![Running Local LLM is More Useful and Easier Than You Think](/TIL/assets/img/2024-07-12-RunningLocalLLMsisMoreUsefulandEasierThanYouThink_5.png)\n\nAnd this article could stop right here. A few clicks and a line of code later, here we are running an LLM locally!\n\nYou can ask it anything, like explaining the differences between the 8 billion and 70 billion parameters versions of Llama 3.\n\n![Running Local LLM is More Useful and Easier Than You Think](/TIL/assets/img/2024-07-12-RunningLocalLLMsisMoreUsefulandEasierThanYouThink_6.png)\n\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n해당 모델의 응답 시간은 일반적으로 컴퓨터의 GPU / RAM에 의존합니다.\n\n## #3 몇 가지 유용한 명령어\n\n터미널 내에서 계속 LLMs를 사용하고 싶다면 몇 가지 기본 명령어가 필요하다고 생각됩니다:\n\n- ollama run llama3\n이 경우 llama3 모델을 실행합니다.\n- ollama list\n로컬로 이미 설치된 모든 모델을 나열합니다.\n- ollama pull mistral\n플랫폼에서 다른 사용 가능한 모델을 가져옵니다. 이 경우 mistral 모델을 가져옵니다.\n- /clear (모델이 실행 중일 때)\n세션의 컨텍스트를 지워 처음부터 시작합니다.\n- /bye (모델이 실행 중일 때)\nollama를 종료합니다.\n- /? (모델이 실행 중일 때)\n사용 가능한 모든 명령어를 나열합니다.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n더 복잡한 사용 사례를 위해 더 많은 명령이 존재합니다. 새로운 미세 조정 모델을 생성하는 것과 같은 경우가 있습니다. \n\nOllama의 Github 저장소에는 매우 완벽한 설명서가 있습니다.\n\n기본 사용 사례에 대해서는 CLI가 충분할 수도 있지만 더 많은 기능이 있습니다...\n\n# #4 Jupyter Notebook에서 Llama 3\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n터미널을 통해 LLMs를 사용하는 것도 좋지만 파이썬 코드를 통해 모델과 상호 작용하면 더 많은 가능성이 열립니다.\n\n이를 위해 langchain_community 라이브러리를 pip으로 설치해야 합니다 (pip install langchain_community) 그리고 Ollama 패키지를 가져와야 합니다.\n\n예를 들어, 어떤 사람의 이름, 나이, 직업을 제공하여 짧은 자기소개를 만들고 싶다고 가정해봅시다. 이 예제에서는 다음과 같이 코드가 작성됩니다:\n\n```js\n# !pip install langchain_community\n\n# 필요한 패키지 가져오기\nfrom langchain_community.llms import Ollama\n\n# 모델 인스턴스 생성\nllm = Ollama(model=\"llama3\")\n\n# 프롬프트와 함께 모델 사용\nllm.invoke(\"Alice의 나이가 25세이고 엔지니어로 일하는 짧은 2문장 자기소개 생성\")\n```\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n친근한 톤으로 번역해 드릴게요.\n\n조금 더 다듬어보면 더 완벽해질거에요.\n\n단일 인물을 위한 소개를 터미널에서 쉽게 만들 수 있지만, 많은 사람들의 경우엔 파이썬 없이 같은 작업을 반복해야 할 수도 있어요. 파이썬을 사용하면 프롬프트를 매개변수화시키고, 많은 사람들에 대해 자동화된 프로세스를 실행할 수 있어요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어:\n\n```python\nimport pandas as pd\n\n# 샘플 DataFrame 생성\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [25, 30, 35],\n    'occupation': ['Engineer', 'Teacher', 'Artist']\n})\n\n# DataFrame에 적용할 수 있는 함수 생성\ndef generate_bio(name, age, occupation):\n    prompt = f\"{name}님에 대한 간단한 2문장 소개 생성, {age}세이고 {occupation}로 근무 중\"\n    return llm.invoke(prompt)\n\n# DataFrame에 함수 적용\ndf['bio'] = df.apply(lambda row: generate_bio(row['name'], row['age'], row['occupation']), axis=1)\n\ndf.head()\n```\n\n이제 DataFrame의 각 행에 대해 모델이 바이오를 생성합니다!\n\n# 5번째 단계 최종 소견\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사의 목적은 Ollama 덕분에 로컬에서 완전히 기능적인 LLM(Large Language Model)을 구현하는 간편함을 강조하는 것이었습니다.\n\n간단한 요청을 위해 터미널을 통해 이 모델을 사용하거나 Python을 사용하여 더 복잡하거나 자동화된 작업을 수행할 수 있습니다. 프로세스는 간단합니다.\n\nOpen WebUI와 같은 오픈 소스 프로젝트 덕분에 우리만의 ChatGPT와 같은 그래픽 인터페이스를 구현할 수도 있습니다.\n\n저는 그저 몇 번의 클릭과 몇 줄의 코드로 이렇게 유용한 것을 얻을 수 있다는 것이 놀라워요! 여러분도 즐기셨으면 좋겠네요.\n\n<!-- TIL 수평 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기사 끝까지 읽어 주셔서 감사합니다.\n더 많은 내용을 보려면 팔로우해주세요!\n질문이나 의견이 있으시면 아래에 메시지를 남겨 주시거나 LinkedIn / X를 통해 연락해 주세요!","ogImage":{"url":"/TIL/assets/img/2024-07-12-RunningLocalLLMsisMoreUsefulandEasierThanYouThink_0.png"},"coverImage":"/TIL/assets/img/2024-07-12-RunningLocalLLMsisMoreUsefulandEasierThanYouThink_0.png","tag":["Tech"],"readingTime":9},{"title":"코드 변경을 안전하게 하는 커스텀 pre-commit 훅 사용하는 방법","description":"","date":"2024-07-09 21:03","slug":"2024-07-09-Custompre-commithooksforsafercodechanges","content":"\n## 첫 번째 pre-commit 훅을 작성하는 단계별 가이드\n\n![이미지](/TIL/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_0.png)\n\n대부분의 소프트웨어는 코드를 업데이트하고 배포하기 위해 git 버전 관리 시스템을 사용하여 개발됩니다. 코드를 협업하여 작성하는 한 가지 어려움은 각 참여자가 깨끗한 코드로 간주되는 것에 대한 자기 스타일과 의견이 있을 때 특정한 표준을 보장하는 것입니다.\n\npre-commit 훅은 코드 변경을 커밋하기 전에 자동으로 실행되는 스크립트나 명령어입니다. 이들은 스타일 가이드를 강제하고 커밋되기 전에 오류를 잡을 수 있으며 더 다양하게 배포할 수 있습니다. 주요한 훅은 구문 오류를 확인하고, import를 정렬하며, 따옴표를 정규화하는 것이 있습니다. 이러한 훅들은 많은 참여자가 있는 오픈 소스 프로젝트를 포함한 모든 프로젝트에 필수적인 도구입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 사용자 정의 pre-commit 훅을 만드는 이유\n\n저는 Python 라이브러리 Hamilton을 위해 데이터플로우 정의를 검증하기 위한 pre-commit 훅을 만드려고 했지만, 대부분의 온라인 자료가 분산되어 있고 기본 사용법에 한정되어 있다는 것을 발견했습니다.\n\n이 게시물에서는 다음을 찾아볼 수 있습니다:\n\n- 프로젝트에서 pre-commit 훅을 사용하기 시작하는 방법\n- 사용자 정의 pre-commit 훅을 개발하기 위한 단계별 튜토리얼\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n토론을 바탕으로, Hamilton을 위해 개발한 사전 커밋 후크를 포함하는 이 GitHub 저장소를 살펴보겠습니다.\n\n# 사전 커밋 후크 사용 시작하기\n\n후크(Hooks)는 git 버전 관리 시스템에 직접 내장된 메커니즘입니다. .git/hooks 디렉토리 아래에서 프로젝트의 후크를 찾을 수 있습니다(기본적으로 숨겨질 수 있습니다). 일반적으로 \"사전 커밋 후크\"라고 불리지만, git 후크는 전체 git 수명 주기를 다룹니다. 예를 들어, 커밋 직후나 푸시하기 직전에 후크를 트리거할 수 있습니다. 또한, 후크는 어떤 프로그래밍 언어로도 작성할 수 있습니다. 흥미롭게도, Ruff 라이브러리는 성능 향상을 위해 많은 Python 기반 후크를 Rust로 재구현했습니다.\n\n코드 동작에 집중하는 소프트웨어 테스트와 비교해볼 때, 후크는 각 파일 저장 시 수행하는 가벼운 체크로 생각할 수 있습니다. 테스트가 코드베이스와 함께 변화하고 진화하는 것을 기대할 수 있는 반면, 코드 작성 가이드라인과 사전 커밋 후크는 고정될 가능성이 높습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 프로젝트 설정\n\n새로운 파이썬 프로젝트를 시작하거나 기존 프로젝트를 사용하는 것으로 가정해 봅시다. 디렉토리 /my-project 에서 작업하려면 pre-commit 후크를 사용하는 선호하는 방법은 pre-commit Python 라이브러리를 사용하는 것입니다. 다음 단계로 설정할 수 있습니다:\n\n- 프로젝트를 위해 git init으로 git 저장소를 만듭니다.\n- pre-commit 라이브러리를 설치하려면 pip install pre-commit을 사용합니다.\n- 저장소에 .pre-commit-config.yaml 파일을 추가합니다. 다음은 예시입니다:\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  # 후크 정의가 있는 저장소\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v2.3.0 # 저장소의 릴리스 버전\n    hooks: # 이 프로젝트에 포함할 저장소의 후크 목록\n      - id: end-of-file-fixer\n      - id: trailing-whitespace\n      - id: check-yaml\n        args: [\"--unsafe\"] # `check-yaml`에 인수 추가\n\n    # 후크가 있는 다른 저장소 다운로드\n  - repo: https://github.com/psf/black\n    rev: 22.10.0\n    hooks:\n      - id: black\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n4. `pre-commit install` 명령어를 사용하여 훅을 설치하세요. 이 몤령어는 .pre-commit-config.yaml 파일에서 지시 사항을 읽고, .git/hooks/pre-commit 폴더 아래 로컬로 훅을 설치합니다.\n\n5. 커밋을 만들거나 `pre-commit run --all-files` 명령어를 수동으로 실행하여 훅을 작동시킬 수 있습니다.\n\n### 사용자 정의 pre-commit 훅 만들기\n\n커뮤니티가 유지보수하는 훅은 유연성을 제공하며 선호하는 코딩 가이드라인에 맞게 맞춤화할 수 있습니다. 이러한 훅은 대부분의 경우 98%의 요구를 충족해야 할 것입니다. 그러나 기본 제공 솔루션은 사용 중인 도구나 팀의 내부 규칙을 알지 못합니다. 예를 들어, 내부 구성을 유효성 검사하거나 프로젝트의 디렉토리 구조를 강제로 지정하는 것과 같은 조치를 취하려고 할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리 케이스에서는, 그들의 Hamilton 데이터 플로우 정의에 대한 Python 코드를 검증하기 위한 후크를 생성하려고 합니다. 우리의 후크 스크립트는 검증을 수행하기 위해 hamilton CLI 도구를 활용하여 간단한 코드 예제를 따라할 수 있게 됩니다.\n\n## 1. pre-commit 후크 저장소 설정\n\n프로젝트 설정 섹션에서 소개된 대로, pre-commit 후크는 .pre-commit-config.yaml에 있어야 하며, 프로젝트가 해당 후크를 참조하고 pre-commit install로 로컬에 설치할 수 있도록 공개 저장소에 존재해야 합니다.\n\n이전에는 프로젝트 디렉토리 /my-project에 있었으며 .pre-commit-config.yaml을 정의하고 후크를 설치했습니다. 이제, /my-hooks 디렉토리를 생성하여 사용자 정의 후크를 정의할 것입니다. 우리의 hamilton-pre-commit 저장소를 참조하여 일반적인 구조를 확인할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_1.png\" />\n\n## 2. 훅 로직 작성\n\nhooks/ 디렉토리 아래에는 해당 디렉토리를 파이썬 모듈로 찾을 수 있도록 하는 파일 **init**.py와 cli_command.py 스크립트가 있습니다. cli_command.py에는 하나의 main() 함수가 포함되어 있으며, 이 함수는 sys.argv에서 햄릴턴 CLI 명령의 목록을 읽습니다. 그런 다음, 예외 처리가 적용된 서브프로세스로 감싸져 하나씩 실행합니다.\n\n```js\n# hooks/cli_command.py\nimport sys\nimport json\nimport subprocess\n\nPASS = 0\nFAIL = 1\n\ndef main() -> int:\n    \"\"\"햄릴턴 CLI를 사용하여 명령 목록 실행\"\"\"\n    commands = sys.argv[1:]\n\n    if len(commands) == 0:\n        return PASS\n\n    exit_code = PASS\n    for command in commands:\n        try:\n            args = command.split(\" \")\n            # `--json-out`를 삽입하여 적절한 stdout 구문 분석\n            args.insert(1, \"--json-out\")\n            result = subprocess.run(args, stdout=subprocess.PIPE, text=True)\n            response = json.loads(result.stdout)\n\n            if response[\"success\"] is False:\n                raise ValueError\n\n        except Exception:\n            exit_code |= FAIL\n\n    return exit_code\n\nif __name__ == \"__main__\":\n    raise SystemExit(main())\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n처음에는 exit_code를 PASS로 설정하지만, 어떤 예외나 실행되지 못한 명령이 있다면 exit_code를 FAIL로 설정합니다. main() 함수는 exit 코드를 SystemExit 예외에 반환합니다. pre-commit 훅이 성공하려면 모든 명령이 성공한 후에 PASS를 반환해야 합니다. PASS가 0이고 FAIL이 1인 것이 직관적이지 않을 수 있지만, 이 값들은 표준 시스템의 종료 코드를 가리킵니다.\n\n우리는 편의성을 위해 Python을 사용했지만, 이 간단한 논리는 Bash와 같은 가벼운 스크립팅 언어에서도 적용될 수 있습니다. pre-commit 팀이 유지 관리하는 후크를 방문하여 더 많은 예제를 확인할 수 있습니다.\n\n## 3. 후크 진입점 정의하기\n\n이제, 당신의 후크 저장소(/my-hooks)는 설치된 후에 사용할 수 있는 후크들과 그 실행 방법을 지정하는 .pre-commit-hooks.yaml 파일을 포함해야 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- id: cli-command\n  name: '`hamilton` CLI 명령 실행'\n  description: '이 후크는 `hamilton` CLI를 사용하여 명령을 실행합니다.'\n  entry: cli-command\n  language: python\n  types: [python]\n  stages: [pre-commit, pre-merge-commit, manual]\n  pass_filenames: false\n\n우리의 경우, id: cli-command 및 entry: cli-command를 설정하고 몇 가지 메타데이터를 추가하며 프로그래밍 언어는 Python으로 지정했습니다. 중요한 점은 파일 속성이 설정되어 있지 않아 후크가 커밋 당 한 번 실행되게하려면 파일: \"\\*.py\"를 설정해야합니다. 예를 들어 각 수정된 Python 파일에서 후크를 실행하도록 할 수 있습니다 (사용 가능한 옵션에 대해 알아보세요).\n\n지금까지 hooks/cli_command.py 아래 Python 스크립트를 만들고 .pre-commit-hooks.yaml에 cli-command 진입점이있는 후크를 추가했습니다. 그러나 Python 프로젝트 파일 pyproject.toml에서 명시적으로 두 가지를 연결해야합니다.\n\n[project.scripts]\ncli-command = \"hooks.cli_command:main\"\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 줄은 \"입력 지점 cli-command은 hooks.cli_command의 main 함수를 가리킵니다.\"라고 읽습니다.\n\n## 4. 로컬에서 훅을 테스트하는 방법\n\n먼저, 단위 테스트로 훅의 로직을 유효성 검사해야 합니다. 그러나 테스팅에 대해 자세히 다루지는 않겠습니다. 현재 hamilton-pre-commit 저장소에는 이 main Hamilton 저장소에서 테스트 된 기본 CLI가 없기 때문에 테스트가 없습니다. 테스트 예제용으로 공식으로 유지되는 pre-commit 훅을 방문할 수 있습니다.\n\n두 번째로, .pre-commit-hooks.yaml 및 입력 지점이 올바르게 구성되었는지 확인하기 위해 로컬에서 pre-commit 훅을 시도해야 합니다. 이상적으로는 변경 사항을 테스트하기 위해 훅을 실행할 때마다 커밋을 추가하는 것을 피하고 싶습니다. pre-commit 라이브러리는 이 프로세스를 용이하게 하기 위한 유틸리티를 제공하지만 pre-commit GitHub 문제에서 자세히 설명 된 몇 가지 수동 단계가 필요합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 훅을 테스트하고 싶은 디렉토리 /my-project로 이동하세요.\n- pre-commit try-repo ../LOCAL/PATH/TO/my-hooks 명령을 실행하고, 로컬 초기화 메시지가 표시되어야 합니다.\n\n![이미지](/TIL/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_2.png)\n\n한 가지 제한 사항은이 명령을 통해 훅에 직접 매개변수를 전달할 수 없다는 것입니다.\n\n3. Using config: 하위의 구성을 복사하여 로컬 파일에 추가하고 args 섹션을 추가하세요. 우리는 .local-pre-commit-config.yaml를 생성했지만 원하는 이름을 사용할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\nrepos:\n  - repo: ../../dagworks/hamilton-pre-commit\n    rev: e4b77a499ba0ff3446a86ebbe4c2cbca82eb54f8\n    hooks:\n      - id: cli-command\n        args: [hamilton build my_func2.py]\n```\n\n4. `pre-commit run --config .local-pre-commit-config.yaml --all-files` 명령어를 사용하여 로컬 후크를 실행하세요. `--all-files` 플래그를 사용하면 현재 스테이징된 파일뿐만 아니라 저장소의 모든 파일에 후크가 적용됩니다.\n\n![Custom Pre-Commit Hooks](/TIL/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_3.png)\n\n## 5. Pre-Commit 후크 공개하기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n거의 다 왔어요! 동작하는 후크 스크립트를 테스트하고 git 저장소에 패키징했군요. 이제 그것을 온라인으로 사용할 수 있도록 만들어야 합니다. GitHub 호스팅 프로젝트를 위한 단계를 보여드리겠지만, 당신의 pre-commit 후크는 git clone을 통해 접근 가능한 어디에나 저장할 수 있어요.\n\n- GitHub 저장소에서 Releases 섹션으로 이동하세요\n\n![image](/TIL/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_4.png)\n\n2. 새 릴리스 초안 작성을 클릭하세요\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/TIL/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_5.png)\n\n3. 새 릴리스 페이지에서는 버전 태그, 제목 및 설명을 추가해야 합니다. 첫 번째 릴리스인 경우, GitHub에서 권장하는 시맨틱 버전을 따르기 위해 태그를 v0.1.0으로 설정하는 것이 좋습니다.\n\n변경 사항을 만들고 실험 버전을 배포하려는 경우 버전을 v0.1.1-rc로 설정하고 \"릴리스 후보\"로 표시하려면 확인란을 사용하세요.\n\n![이미지](/TIL/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_6.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n.pre-commit-config.yaml 파일에서 rev 값은 설정한 버전 태그와 일치해야 합니다.\n\n```js\nrepos:\n- repo: https://github.com/DAGWorks-Inc/hamilton-pre-commit\n  rev: v0.1.3rc\n  hooks:\n    - id: cli-command\n      # ...\n```\n\n# 마무리 맺기\n\n축하합니다! 이 글을 읽어나가셨군요! 이제 프로젝트에서 코드 품질을 향상시키기 위해 pre-commit 훅을 사용할 수 있게 되었습니다. 그 내부 원리를 이해했으니 이제 여러분만의 훅을 작성할 수 있습니다!\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n바퀴를 다시 발명하기 전에 커뮤니티에서 유지보수하는 많은 후크들을 확인하시기 바랍니다: [https://pre-commit.com/hooks.html](https://pre-commit.com/hooks.html)\n\n파이썬에서 데이터플로우를 작성하기 위해 Hamilton 라이브러리를 확인해보세요!\nLinkedIn에서 저를 찾아보고 DAGWorks 블로그에서 더 많은 포스트를 읽어보세요\n","ogImage":{"url":"/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-Custompre-commithooksforsafercodechanges_0.png","tag":["Tech"],"readingTime":13},{"title":"Hugging Face 시작을 위한 종합 가이드","description":"","date":"2024-07-09 21:02","slug":"2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace","content":"\n![Hugging Face](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png)\n\n대규모 언어 모델들의 급격한 발전으로 다양한 작업을 해결하기 위해 적용되는 경우가 많아졌으며, Hugging Face에 대한 지식은 반드시 알아둬야 할 필수요소가 되었습니다.\n\n왜 Hugging Face를 사용해야 할까요? Hugging Face는 다양한 오픈 소스 모델에 대한 접근성을 제공하는 데 중요한 역할을 합니다. 이 플랫폼 덕분에 데이터 과학자, 개발자 및 연구자들은 최신 모델을 쉽게 탐색하고 활용할 수 있습니다.\n\n본문에서는 Hugging Face의 잠재력, 이를 활용하는 방법 및 가능한 사용 사례에 대해 설명하겠습니다. 시작해봅시다!\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n목차:\n\n- Hugging Face란 무엇인가요?\n- Hugging Face의 기본 구성 요소\n- Open LLM Leaderboard란 무엇인가요?\n- Hugging Face에 접근하는 방법\n- Hugging Face로 놀기 시작하기\n- Transformers 라이브러리 활용하기\n\n## Hugging Face란 무엇인가요?\n\n<img src=\"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_1.png\" />\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n허깅페이스는 다양한 작업을 위한 사전 훈련 모델에 민주적인 접근을 제공하는 허브입니다. 번역, 요약, 질의응답, 객체 감지, 이미지 분할 등 다양한 작업에 사용됩니다. 사용자들이 오픈 소스 모델에 기여할 것을 장려합니다.\n\n이 중심화된 저장소의 매력은 허깅페이스 트랜스포머(Hugging Face Transformers)로, 모델을 쉽게 다운로드하고 불러오며 미세 조정할 수 있는 매우 인기 있는 파이썬 라이브러리입니다.\n\n모델뿐만 아니라 데이터셋과 기계 학습 데모인 허깅페이스 스페이스(Hugging Face Spaces)도 호스팅합니다.\n\n## 허깅페이스의 기본 구성요소\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n허깅페이스에는 모델, 데이터셋 및 스페이스 세 가지 주요 구성 요소가 있어요.\n\n![image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_2.png)\n\n모델 페이지에 들어가보면 수많은 오픈소스 모델로 인해 압도될 수 있지만 걱정 마세요. 먼저 해결하고자 하는 작업을 식별한 후 해당 작업으로 필터링하는 것이 권장됩니다. 작업을 선택한 후에는 인기도와 다운로드 횟수 같은 다양한 기준에 따라 모델을 정렬할 수 있어요.\n\n![image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_3.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모델과 마찬가지로, 다양한 종류의 데이터셋이 있어서 다양한 작업에 활용할 수 있습니다. 이전과 마찬가지로 최종 목표에 따라 작업별로 필터링하고 결과를 정렬하는 것이 중요합니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_4.png)\n\n마지막으로, Hugging Face 스페이스라는 기계 학습 데모를 빠르게 살펴볼 수 있습니다. Hugging Face 스페이스에서는 Streamlit, Gradio, 그리고 FastAPI를 기반으로 한 대화형 애플리케이션을 통해 모델을 실행할 수 있습니다. 다시 말해, Hugging Face 스페이스를 통해 직관적인 인터페이스를 통해 간접적으로 모델과 상호 작용할 수 있습니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_5.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위에는 입력 텍스트로부터 이미지를 생성하는 전문 공간 예시가 있습니다. 이 데모인 PixArt-Sigma는 4K 해상도에서 이미지를 생성할 수 있는 PixArt-Sigma 1024px 확산 변환 모델을 활용합니다.\n\n## 오픈 LLM 리더보드란?\n\n![image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_6.png)\n\nHugging Face의 또 다른 중요한 기여는 오픈 LLM 리더보드입니다. 이는 오픈 소스 LLMs와 챗봇을 추적하고 평가할 수 있는 머신 러닝 데모 또는 Hugging Face 공간입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모델 페이지와 마찬가지로 사용 가능한 모델이 너무 많습니다. 과업을 해결하기 위해 필요한 모델 유형을 식별한 후 이를 기반으로 결과를 필터링하는 것이 좋습니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_7.png)\n\n예를 들어, 처음부터 훈련된 모델만 추적하길 원한다고 가정해 봅시다. 이 경우 \"사전 훈련된 모델\"을 선택하여 필터링해야 합니다.\n\n필터를 수정하면 리더보드 상단의 모델 대부분이 Meta 및 Databricks와 같은 대규모 기술 회사에서 나온 것을 알 수 있을 것입니다. 이것은 모든 회사가 이러한 대규모 모델을 훈련시키기에 컴퓨팅 능력을 갖추지 못한 이유입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Hugging Face에 접속하는 방법\n\n![hugging-face-image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_8.png)\n\n노트북에서 Hugging Face의 모델과 데이터셋에 액세스하려면 먼저 Hugging Face API 키가 필요합니다. 계정이 아직 없다면 만들어야 합니다. 계정이 생성되면 Settings`Access Tokens`을 클릭하고 \"New token\" 버튼을 누릅니다.\n\n![hugging-face-image](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_9.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n토큰의 이름인 HF_TOKEN과 해당 토큰의 유형을 결정하세요. 이 유형은 read 또는 write 중 하나로 선택할 수 있습니다. 모델을 다운로드하거나 모델에서 추론을 실행하는 경우 read를 선택하면 가장 일반적인 선택지입니다. 모델을 훈련시키려면 write를 선택하는 것이 좋습니다.\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_10.png)\n\n그걸로 끝입니다! 우리는 Hugging Face에서 첫 번째 액세스 토큰을 생성했습니다. 액세스 토큰에 대해 더 깊이 알아보고 싶다면, Hugging Face 문서를 살펴보세요.\n\n## Hugging Face와 놀기 시작\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*2AywAoMAEN5v8VG8wIFU7Q.gif\" />\n\nHugging Face의 개념이 명확해지면, 이제는 자습서의 실제 부분으로 넘어가는 시간입니다. 영어에서 이탈리아어로 텍스트를 번역하는 모델을 찾고 싶다고 가정해 봅시다. 다음은 다음과 같은 단계입니다:\n\n- 모델 페이지로 이동\n- 번역을 작업으로 선택\n- 이탈리아어를 언어로 선택\n\n우리는 트렌딩 순으로 정렬된 첫 번째 결과 중에서 나타나는 모델 NLLB-200을 선택하기로 결정했습니다. 모델의 웹 페이지에는 프로젝트 목적에 따라 유용할 수 있는 다양한 버튼도 포함되어 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_11.png)\n\n이 경우에는 모델을 로드하는 코드 라인을 얻기 위해 \"Transformers에서 사용\" 버튼을 클릭하면 됩니다.\n\n## Transformers 라이브러리 활용\n\n실험을 진행할 경우, Google Colab을 사용하는 것을 추천드립니다. Google Colab은 코드를 웹 브라우저에서 실행하며 CPU 또는 GPU 리소스에 액세스할 수 있는 클라우드 기반 플랫폼입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n또한, 이 환경은 이전에 얻은 허깅페이스의 액세스 키와 같은 환경 변수를 간단히 가져오는 것을 가능하게 합니다.\n\n구글 코랩을 열고, Secrets로 이동하여 “새로운 비밀”을 클릭하고 허깅페이스 액세스 토큰의 이름과 값을 복사하면 됩니다. 또한, 노트북 액세스를 토글하는 것을 잊지 마세요!\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*Td3lFpVFua1VnP8vsogu3g.gif)\n\n설치해야 할 라이브러리가 있습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\npip install transformers\n```\n\n이 Python 라이브러리를 시작하려면 파이프라인()을 사용하여 추론, 모델 로드, 및 학습을 하는 것이 좋습니다. 이 경우에는 모델 NLLB-200을 로드하려고 합니다.\n\n간단히 \"Transformers에서 사용하기\" 버튼에서 찾은 코드를 복사하면 됩니다. 아래는 약간의 수정이 필요한 코드입니다:\n\n```js\nfrom transformers import pipeline\nimport torch\n\ntranslator = pipeline(task=\"translation\",\n                      model=\"facebook/nllb-200-distilled-600M\",\n                      torch_dtype=torch.bfloat16\n                      )\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\npipeline()은 번역 작업용 모델 NLLB-200을 다운로드하고 캐시합니다. 이러한 매개변수들 외에도, 모델을 압축하는 데 성능이 감소하지 않는 torch의 유형을 지정합니다.\n\n이제 이를 사용하여 텍스트를 번역할 수 있습니다:\n\n```js\ntext = \"\"\"\nChatGPT 개발자 OpenAI는 단 한 번의 짧은 오디오 샘플만 있으면 인간의 목소리를 재현할 수 있는 새로운 도구를 소개했다.\\\n이 도구는 고도의 정확도로 음성을 복제하려는 기술 회사들이 개발한 여러 도구 중 하나이다.\\\n시스템의 이름은 Voice Engine입니다. OpenAI는 3월 29일 Voice Engine에 관한 세부 정보를 공개했다.\\\n\"\"\"\n\ntext_translated = translator(text,\n                             src_lang=\"eng_Latn\",\n                             tgt_lang=\"ita_Latn\")\n\nprint(text_translated[0]['translation_text'])\n```\n\n이것이 출력 내용입니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nOpenAI의 ChatGPT 개발자가 새로운 도구를 소개했어요!\n그 도구는 짧은 음성 샘플을 사용하여 인간의 목소리를 재현할 수 있다고 해요.\n이 도구는 음성을 높은 정확도로 복제하기 위해 기술 기업들이 개발한 여러 도구 중 하나에요.\n이 시스템의 이름은 Voice Engine이에요. OpenAI는 3월 29일 Voice Engine에 대한 세부 정보를 공개했어요.\n```\n\n좋아요! 우리가 과제를 해결했네요. 쉬웠죠?\n\n## 최종 생각\n\n이것은 Hugging Face를 시작하는 데 도움이 되는 입문 가이드였어요. Transformers는 상위 모델, 특히 NLP 모델에 쉽게 액세스할 수 있게 해주는 파이썬 라이브러리에요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 플랫폼과 파이썬 라이브러리에 대해 더 깊이 파고들고 싶다면, 아래에서 제안하는 리소스를 살펴보세요.\n\n이 글이 유용하게 느껴졌으면 좋겠어요. 즐거운 하루 보내세요!\n\n유용한 리소스:\n\n- Hugging Face 문서\n- Hugging Face 무료 강좌\n- Hugging Face와 함께하는 오픈소스 모델 강좌\n","ogImage":{"url":"/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-AComprehensiveGuideforGettingStartedwithHuggingFace_0.png","tag":["Tech"],"readingTime":11},{"title":"2024년 최신 LangChain, Python, Heroku 사용 방법 실제 사용 사례와 팁","description":"","date":"2024-07-09 20:59","slug":"2024-07-09-LangChainPythonandHeroku","content":"\n<img src=\"/TIL/assets/img/2024-07-09-LangChainPythonandHeroku_0.png\" />\n\n## 커피숍에서 코딩하기\n\n2022년 말 이후 ChatGPT의 출시 및 널리 사용되면서 대형 언어 모델(LLM) 및 생성적 AI(GenAI)에서 비롯된 도구, 제품 및 혁신에 대한 뉴스 폭풍이 몰려왔습니다. 많은 기술 유행이 몇 년 내에 사라지는 반면, LLM 및 GenAI가 여기에 남아있음이 분명합니다.\n\n이러한 새로운 도구와 제품의 배경에 이어지는 다양한 도구들과 제품들에 대해 궁금한 적이 있나요? 또한 개발자와 최종 사용자 모두가 활용하는 이러한 도구들이 어떻게 운영되는지 궁금해할 수도 있습니다. 이러한 도구와 응용 프로그램 중 많은 경우, LangChain, Python 및 Heroku를 알 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 문서에서는 다룰 조각들입니다. 인공 지능/기계 학습 개발자들이 이들을 사용하여 복잡한 LLM 파이프라인 구성 요소를 구축하고 쉽게 배포하는 실제 예시를 살펴보겠습니다.\n\n# LLM 워크플로우와 파이프라인 해독하기\n\n기계 학습 파이프라인과 워크플로우는 AI 세계에 입문한 이들에게는 불투명해 보일 수 있습니다. 특히 LLM과 그와 관련된 도구에서는 더 그렇습니다. 왜냐하면 이들은 (비교적으로) 새로운 기술들이기 때문입니다. LLM을 처리하는 것은 도전적일 수 있습니다. 특히 엔지니어링이 강화되고 제품용으로 준비된 파이프라인, 워크플로 및 배포를 만들려고 할 때입니다. 새로운 도구들, 빠르게 변화하는 문서 및 제한된 지침들로 인해 어디서부터 시작하거나 무엇을 사용해야 할지를 알기 어려울 수 있습니다. 그래서 LangChain과 Heroku의 기본부터 시작해 봅시다.\n\nLangChain의 문서에는 다음과 같이 나와 있습니다: \"LangChain은 언어 모델을 기반으로 한 애플리케이션을 개발할 수 있는 프레임워크입니다.\"\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n한편, Heroku는 다음과 같이 자신을 설명합니다: \"Heroku는 회사가 앱을 구축, 전달, 모니터링 및 확장할 수 있는 클라우드 플랫폼입니다. 아이디어에서 URL로 이동하는 가장 빠른 방법입니다. 모든 인프라 문제를 우회합니다.\"\n\n이를 LLM 애플리케이션 구축의 맥락으로 놓으면, LangChain과 Heroku는 최고의 조합입니다. 우리는 LLM 애플리케이션을 구축하기 위해 테스트된 쉬운 프레임워크(LangChain)가 필요하고, 그 애플리케이션을 배포하고 호스팅할 방법(Heroku)이 필요합니다.\n\n이제 각 기술에 대해 자세히 살펴보겠습니다.\n\n## LangChain 탐구하기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLangChain을 사용하는 방법에 대해 간단히 이야기해 봅시다. LangChain은 LLM 모델과 사용 사례를 기반으로 한 애플리케이션을 개발하는 개발자들을 지원하는 프레임워크입니다. Python, JavaScript, TypeScript를 지원합니다. 예를 들어, 사용자 입력에 기반을 둔 보고서를 생성하거나 고객 지원 응답을 자동화하는 도구를 개발 중이라고 가정해 봅시다. LangChain은 프로젝트의 골조로 작용하여 언어 모델을 효율적으로 솔루션에 통합할 수 있는 도구와 구조를 제공합니다.\n\nLangChain 내에는 몇 가지 주요 구성 요소가 있습니다:\n\n- 에이전트: 에이전트는 우리의 요구 사항에 따라 작업을 수행하기 위해 언어 모델과 상호 작용하는 구성 요소입니다. 이것은 우리 애플리케이션의 두뇌로, 언어 모델의 기능을 활용하여 텍스트를 이해하고 생성합니다.\n- 체인: 에이전트가 작업을 수행하는 데 따르는 동작이나 프로세스의 시퀀스입니다. 예를 들어, 고객 지원을 자동화한다면 체인은 고객 질문 수락, 관련 정보 찾기, 그리고 응답 작성 등의 단계를 포함할 수 있습니다.\n- 템플릿: 템플릿은 언어 모델의 출력을 구조화하는 방법을 제공합니다. 예를 들어, 애플리케이션이 보고서를 생성하는 경우, 모델의 출력을 기반으로 이러한 보고서를 일관되게 포맷하는 데 도움이 되는 템플릿을 활용할 것입니다.\n- LangServe: 개발자가 LangChain 애플리케이션을 REST API로 배포하고 제공할 수 있도록 합니다.\n- LangSmith: 이 도구는 언어 모델 애플리케이션의 상호 작용을 평가, 테스트 및 정제하여 제품을 상용화할 준비를 얻도록 도와줍니다.\n\nLangChain은 인기 있는 AI 및 LLM 애플리케이션을 구축하기 위한 프레임워크이며, 그 이유를 쉽게 이해할 수 있습니다. LangChain은 제품을 끝까지 구축하고 배포하는 데 필요한 기능을 제공합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Heroku를 탐험해보세요\n\nHeroku는 클라우드 플랫폼 서비스(PaaS)로서 애플리케이션을 클라우드에 간단하게 배포할 수 있게 해주어 가장 잘 알려져 있습니다. 개발자들은 주로 코드와 구현에만 집중하고 싶어합니다. 이미 복잡한 데이터 파이프라인과 LLM 기반 애플리케이션을 다루고 있을 때는 서버, 네트워크, 지속적인 저장소와 같은 인프라 문제를 다루는데 필요한 자원이나 전문지식이 부족할 수 있습니다.\n\nHeroku를 통해 애플리케이션을 쉽게 배포할 수 있기 때문에 프로젝트를 제품화하는 주요 장벽이 손쉽게 처리됩니다.\n\n# LangChain으로 빌드하기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLangChain이 LLM 애플리케이션에서 어떻게 사용되는지 더 잘 이해하기 위해 몇 가지 예제 문제를 통해 과정을 명확하게 알아보겠습니다. 일반적으로, LLM 체인을 구성하기 위해 다음 항목을 연결하여 단일 워크플로우를 형성합니다:\n\n- 사용자의 매개 변수를 기반으로 프롬프트를 생성하는 프롬프트 템플릿으로 시작합니다.\n- 언어 모델이 원래 훈련되지 않은 데이터를 검색하는 리트리버를 체인에 추가합니다(예: 문서 데이터베이스에서).\n- 더 나은 응답을 형성하기 위해 언어 모델에 맥락을 제공하기 위해 채팅 기록을 포함하는 회화 검색 체이닝을 추가합니다.\n- 실제 LLM과 상호 작용하는 에이전트를 추가합니다.\n\nLangChain을 사용하면 LLM 애플리케이션의 기본을 형성하는 프로세스를 연결할 수 있습니다. 이는 우리의 구현을 쉽고 친근하게 만듭니다. 간단한 예제를 통해 함께 살펴보겠습니다.\n\n이 예시에서는 OpenAI와 함께 작업하겠습니다. 프롬프트를 이렇게 작성해 보겠습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n안녕하세요! LangChain을 사용하고 계시다니 멋지네요! 여기 저희 훌륭한 가상 트레이너, OpenAI에게 문의하시면 됩니다. 사용자의 질문을 입력해 주세요. 요청하신 내용에 따라 OpenAI가 도움을 들어드리겠습니다. 함께 성공적인 코딩 여정을 시작해봐요!\n\nMarkdown 형식을 사용해 표를 만들어보세요:\n\n| 컬럼1   | 컬럼2   |\n| ------- | ------- |\n| 데이터1 | 데이터2 |\n\n그럼 좋은 하루 보내세요!\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nmain.py라는 새 파일을 만들겠습니다. 우리의 기본 Python 코드는 다음과 같습니다:\n\n```python\nimport os\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\nmy_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a friendly and encouraging fitness trainer.\"),\n    (\"user\", \"{input}\")\n])\n\nllm = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"])\n\nchain = my_prompt | llm\n```\n\n여기서 그만입니다! 이 기본 예제에서는 LangChain을 사용하여 프롬프트 템플릿과 OpenAI 에이전트를 연결했습니다.\n\n이를 명령줄에서 사용하려면 다음 코드를 추가해야합니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nuser_input = input(\"피트니스 목표와 관련된 질문을 하세요.\\n\");\nresponse = chain.invoke({\n  input: user_input,\n});\n\nprint(response);\n```\n\n위에서 코드블록을 보면 우리 애플리케이션을 명령줄에서 테스트할 수 있습니다.\n\n```js\n(venv) $ OPENAI_API_KEY=insert-key-here python3 main.py\n피트니스 목표와 관련된 질문을 하세요.\n60초 동안 플랭크를 유지하는 방법은 무엇인가요?\ncontent=\"60초 동안 플랭크를 유지하는 것은 좋은 목표입니다! 60초 동안 플랭크를 유지하기 위해선 올바른 자세로 시작하고 천천히 플랭크를 유지하는 시간을 늘려나가는 것이 중요합니다. 진행하는 데 도움이 될 몇 가지 팁을 드리겠습니다:\\n\\n1. 짧은 시간으로 시작하기: 자세를 잘 유지한 채로 플랭크를 유지할 수 있는 시간부터 시작해보세요. 몇 초만이라도 괜찮으니 강해지면서 시간을 늘려가세요.\\n\\n2. 올바른 자세에 집중하기: 머리부터 발끝까지 직선으로 몸을 유지하고 복부 근육을 사용하며 어깨를 팔꿈치 바로 위에 유지하세요.\\n\\n3. 꾸준히 연습하기: 매주 몇 번씩 플랭크를 운동 루틴에 포함시키도록 노력해보세요. 꾸준함이 힘과 인내를 키우는 데 중요합니다.\\n\\n4. 다양한 플랭크 도전하기: 사이드 플랭크나 다리를 들거나하는 등 다양한 플랭크 변형을 시도하여 다른 근육 꾸러미에 작용하고 운동을 도전스럽게 유지하세요.\\n\\n5. 몸의 신호를 듣기: 자신을 밀어내는 것도 중요하지만 자신의 한계를 알아야 합니다. 통증이나 불편함을 느낀다면 멈추고 휴식을 취하세요.\\n\\n기억하세요, 발전에는 시간과 인내가 필요합니다. 새로운 플랭크 기법을 마스터하거나 몇 초 더 플랭크를 유지한다든지하는 모든 단계를 축하하세요. 당신은 할 수 있어요!\"\n```\n\n(가독성을 위해 위에서 줄 바꿈을 추가했습니다.)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그것은 훌륭한 시작이에요. 하지만 출력물을 조금 더 사람이 읽기 쉬운 형식으로 포맷팅하는 것이 좋겣죠. 이를 위해 단순히 체인에 출력 파서를 추가하면 됩니다. StrOutputParser를 사용할 거에요.\n\n```js\nimport os\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser\n\nmy_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"당신은 친절하고 격려하는 피트니스 트레이너입니다.\"),\n    (\"user\", \"{input}\")\n])\n\nllm = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\noutput_parser = StrOutputParser()\n\nchain = my_prompt | llm | output_parser\n\nuser_input = input(\"당신의 피트니스 목표에 관한 질문을 해주세요.\\n\")\nresponse = chain.invoke({\n  \"input\": user_input\n})\n\nprint(response)\n```\n\n이제 명령행에서 우리의 애플리케이션이 이렇게 보일 거에요:\n\n```js\n(venv) $ OPENAI_API_KEY=insert-key-here python3 main.py\n당신의 피트니스 목표에 관한 질문을 해주세요.\n피스톨 스쿼트를 어떻게 배우나요?\n그것은 훌륭한 목표에요! 피스톨 스쿼트는 도전적일 수 있지만, 연습과 인내로 꼭 배울 수 있어요.\n\n피스톨 스쿼트를 연습하기 위해 다음 단계를 따라가보세요:\n\n1. 스쿼트, 런지, 스텝업과 같은 운동으로 하체 근력을 키워보세요.\n2. 단일다리 균형 운동을 통해 균형과 안정성을 향상시켜보세요.\n3. 벤치나 의자 위로 몸을 내려친다는 부분적인 피스톨 스쿼트를 연습한 후 점차 전체적인 피스톨 스쿼트를 수행할 수 있게 되세요.\n4. TRX 밴드나 막대기와 같은 지원 도구를 사용하여 균형 유지와 몸을 내려치는 데 도움을 받아, 충분한 근력을 쌓아 무도도 수행할 수 있도록 하세요.\n\n피스톨 스쿼트를 시도하기 전에 반드시 웜업을 실시하고 부상을 피하기 위해 몸의 신호를 들어주는 것을 잊지 마세요. 그리고 가장 중요한 것은, 이 도전적인 운동을 마스터하는 데 노력하는 동안 긍정적이고 인내심을 가지세요. 당신은 할 수 있어요!\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLLM 응담은 가독성을 향상시키기 위해 형식화되었습니다.\n\n강력한 LLM 애플리케이션을 구축하기 위해, 우리의 체인은 이보다 훨씬 더 복잡할 것입니다. 그렇지만 그것이 LangChain의 강점이자 간결함입니다. 프레임워크는 당신의 필요에 맞는 로직을 모듈화할 수 있도록 해줘서 복잡한 워크플로우를 쉽게 연결할 수 있습니다.\n\n간단한 LLM 애플리케이션을 만들었으니, 여전히 우리 애플리케이션을 배포하고 호스팅하며 서비스하기 위한 능력이 필요합니다. 인프라보다 앱 빌드에 초점을 맞춘 개발자로써, LangServe와 Heroku에 의존합니다.\n\n# LangServe로 서비스 하기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLangServe는 LangChain 체인과 상호 작용할 수 있도록 REST API를 통해 도와줍니다. LangChain LLM 애플리케이션의 서빙 부분을 작성하기 위해 세 가지 주요 구성 요소가 필요합니다:\n\n- 유효한 체인 (우리가 위에서 구축한 것과 같이)\n- API 애플리케이션 프레임워크 (예: FastAPI)\n- 라우트 정의 (REST API를 구축할 때와 같이)\n\nLangServe 문서에는 시작하는 방법에 대한 유용한 예제가 제공됩니다. 우리 예제에서는 FastAPI를 사용하여 API 서버를 시작하고 LangServe의 add_routes()를 호출하여 체인을 API 엔드포인트를 통해 접근 가능하게 만들면 됩니다.\n\n이와 함께 기존 코드를 약간 수정해야합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 우리는 StrOutputParser의 사용을 제거할 것입니다. 이렇게 하면 API를 호출하는 사용자들이 출력을 어떻게 형식화하고 사용할지에 대해 유연성을 가질 수 있습니다.\n- 명령 줄에서 사용자 입력을 요청하지 않을 것입니다. API 호출 요청이 사용자의 입력을 제공할 것입니다.\n- chain.invoke()를 호출하지 않을 것입니다. LangServe가 API 요청 처리의 일부로 이를 처리할 것입니다.\n\n우리는 프로젝트에 FastAPI와 LangServe 패키지를 추가했음을 확인합니다:\n\n```js\n(venv) $ pip install langserve fastapi\n```\n\n우리의 최종 main.py 파일은 다음과 같습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nimport os\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom fastapi import FastAPI\nfrom langserve import add_routes\n\nmy_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a friendly and encouraging fitness trainer.\"),\n    (\"user\", \"{input}\")\n])\n\nllm = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n\nchain = my_prompt | llm\n\napp = FastAPI(title=\"Fitness Trainer\")\n\nadd_routes(app, chain)\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"localhost\", port=8000)\n```\n\n내 로컬 머신인 우분투 20.04.6 LTS에서는 Python 3.8.10을 실행 중이었는데, 몇 가지 경고 메시지를 제거하기 위해 추가 패키지를 설치해야 했습니다. 당신의 머신에서는 이 작업이 필요하지 않을 수도 있어요.\n\n```shell\n(venv) $ pip install sse_starlette pydantic==1.10.13\n```\n\n이제 서버를 시작해 볼까요?\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n(venv) $ OPENAI_API_KEY=insert-key-here python3 main.py\n\nINFO: 서버 프로세스 시작 [629848]\nINFO: 애플리케이션 시작을 기다리는 중.\n\nLANGSERVE: \"/\" 경로의 Playground이 활성화되었습니다:\nLANGSERVE: │\nLANGSERVE: └──> /playground/\nLANGSERVE:\nLANGSERVE: 사용 가능한 모든 경로는 /docs/에서 확인할 수 있습니다.\n\nINFO: 애플리케이션 시작 완료.\nINFO: Uvicorn이 http://localhost:8000에서 실행 중 (종료하려면 CTRL+C를 누르세요)\n\n와아... 멋져요!\n\n브라우저에서 http://localhost:8000/docs 로 이동할 수 있어요. 여기에서 확인할 수 있는 내용은:\n\n<img src=\"/TIL/assets/img/2024-07-09-LangChainPythonandHeroku_1.png\" />\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLangServe는 Swagger UI를 사용하는 API 문서 페이지를 제공합니다! 이제 LangServe를 통해 사용 가능한 엔드포인트들이 있습니다. 우리는 invoke/ 엔드포인트로 POST 요청을 보낼 수 있습니다. 하지만 LangServe는 우리에게 chain을 직접 다룰 수 있는 웹 인터페이스가 있는 playground/ 엔드포인트도 제공합니다.\n\n![이미지](/TIL/assets/img/2024-07-09-LangChainPythonandHeroku_2.png)\n\n우리는 입력을 제공하고 시작을 클릭합니다. 결과는 다음과 같습니다:\n\n![이미지](/TIL/assets/img/2024-07-09-LangChainPythonandHeroku_3.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLLM 애플리케이션 워크플로의 맥락에서 API의 중요성을 강조하는 것이 중요합니다. LLM 및 해당 애플리케이션의 대부분 사용 사례를 생각해보면, 로컬 모델 및 자원에 의존할 수 없습니다. 이것은 합리적이지 않고 확장성이 떨어집니다.\n\nLLM 애플리케이션의 실제 파워는 이전까지 설명한 복잡한 워크플로를 추상화하는 능력에 있습니다. 우리는 수행한 모든 것을 API 뒤에 숨겨 사용 사례가 확장되고 다른 사람들이 통합할 수 있도록 하려고 합니다. 이는 API를 호스팅하고 제공할 수 있는 쉬운 옵션이 있다면에만 가능합니다. 그리고 바로 그것이 Heroku에서 할 수 있습니다.\n\n# Heroku에 배포\n\nHeroku는 LLM 애플리케이션 구현의 중요한 마지막 부분입니다. 우리는 LangChain을 사용하여 워크플로를 조합하고 LangServe를 사용하여 유용한 REST API로 제공합니다. 이제 복잡한 자원을 수동으로 설정하여 트래픽을 호스팅하고 제공하는 대신, Heroku를 사용하여 애플리케이션을 간단히 배포할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n헤로쿠 계정을 설정한 후에, 이제 거의 배포할 준비가 끝났어요. 함께 순서대로 진행해볼게요.\n\n## 새로운 헤로쿠 앱 생성하기\n\n헤로쿠 CLI를 사용해서 로그인하고 새로운 앱을 생성해요.\n\n```js\n$ heroku login\n$ heroku create my-langchain-app\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 설정 변수 설정하기\n\n이제 Heroku 앱 환경에서 OPENAI_API_KEY 환경 변수를 설정해야 합니다.\n\n```js\n$ heroku config:set OPENAI_API_KEY=여러분의-openai-api-key로-대체하세요\n```\n\n## Python 애플리케이션 배포를 위한 설정 파일 만들기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n헤로쿠가 우리의 파이썬 애플리케이션을 실행하기 위해 필요한 것을 알 수 있도록 하려면 세 가지 간단한 파일을 만들어야 합니다:\n\n- Procfile: 헤로쿠가 앱을 시작하는 데 사용해야 하는 명령을 선언합니다.\n- requirements.txt: 헤로쿠가 설치해야 하는 Python 패키지 종속성을 지정합니다.\n- runtime.txt: 앱에 사용하려는 정확한 Python 런타임 버전을 지정합니다.\n\n이 파일들은 빠르고 쉽게 만들 수 있습니다. 각각은 프로젝트의 루트 폴더에 들어갑니다. Procfile을 만들려면 다음 명령을 실행하면 됩니다:\n\n```bash\n$ echo 'web: uvicorn main:app --host=0.0.0.0 --port=${PORT}' > Procfile\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이것은 Heroku에게 Python에서 웹 서버 구현인 uvicorn을 실행하도록 지시합니다.\n\nrequirements.txt에 대해, pip freeze 명령을 사용하여 설치된 패키지 목록을 출력할 수 있습니다.\n\n```js\n$ pip freeze > requirements.txt\n```\n\n마지막으로, runtime.txt에는 Python 3.11.8을 사용할 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n$ echo 'python-3.11.8' > runtime.txt\n```\n\n이 파일들이 준비된 상태에서 프로젝트 루트 폴더는 다음과 같이 보일 것입니다:\n\n```js\n$ tree\n.\n├── main.py\n├── Procfile\n├── requirements.txt\n└── runtime.txt\n\n0 directories, 4 files\n```\n\n이 파일들을 모두 GitHub 저장소에 커밋합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Heroku와 GitHub 저장소 연결하기\n\n마지막으로 할 일은 GitHub 저장소에 대한 Heroku 원격을 생성한 다음 코드를 해당 원격으로 푸시하는 것입니다. Heroku는 새 코드를 푸시하면 해당 코드를 응용 프로그램에 배포합니다.\n\n```js\n$ heroku git:remote -a my-langchain-app\n$ git push heroku main\n```\n\n우리의 코드가 Heroku 원격으로 푸시되면, Heroku는 애플리케이션을 빌드하고 종속성을 설치한 다음 Procfile에서 지정된 명령을 실행합니다. git push 명령어의 최종 결과는 다음과 같습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n…\n\nremote: -----> 프로세스 유형 검색 중\nremote:        Procfile이 다음 유형을 선언함 -> web\nremote:\nremote: -----> 압축 중...\nremote:        완료: 71.8M\nremote: -----> 배포 중...\nremote:        v4 버전이 릴리스됨\nremote:        https://my-langchain-app-ea95419b2750.herokuapp.com/ 에 배포됨\nremote:\nremote: 배포 확인... 완료.\n```\n\n우리의 Heroku 앱 URL이 표시됩니다. 브라우저에서 https://my-langchain-app-ea95419b2750.herokuapp.com/playground을 방문해주세요.\n\n![이미지](/TIL/assets/img/2024-07-09-LangChainPythonandHeroku_4.png)\n\n또한 Swagger UI 문서 페이지를 확인하려면 https://my-langchain-app-ea95419b2750.herokuapp.com/docs를 방문해주세요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/TIL/assets/img/2024-07-09-LangChainPythonandHeroku_5.png)\n\n그리고 그렇게해서 우리는 시작했어요!\n\n이 프로세스는 LangChain과 함께 작업할 때 개발 시간과 오버헤드를 줄이는 최상의 방법입니다. LangChain으로 작성된 API를 쉽게 몇 가지 간단한 명령어로 Heroku에 배포할 수 있는 기능은 LangChain과 Heroku를 결합하는 것을 당연하게 만듭니다.\n\n# 결론\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오늘의 기업과 개발자들은 AI와 LLM(언어 모델)의 파도를 타기에 올바른 선택을 했습니다. 이들 영역에서 혁신과 새로운 개발 가능성이 많습니다. 그러나 성공과 실패의 차이는 그들이 애플리케이션을 구축하고 배포하는 데 사용하는 도구 체인에 많이 달렸습니다.\n\nLangChain 프레임워크를 사용하면 LLM 기반 애플리케이션을 만드는 프로세스가 접근 가능하고 반복 가능해집니다. 그러나 구현은 전투의 반이에 불과합니다. 애플리케이션이 만들어지면, 이러한 애플리케이션 API를 클라우드에 쉽고 빠르게 배포할 수 있는 능력이 필요합니다. 그 곳에서 더 빠른 반복과 개발의 장점을 가질 수 있고, Heroku를 통해 그 길에 도달할 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-07-09-LangChainPythonandHeroku_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-LangChainPythonandHeroku_0.png","tag":["Tech"],"readingTime":20},{"title":"파이썬으로 코딩 시작하기 5 딕셔너리 part II  반복문 사용법","description":"","date":"2024-07-09 20:57","slug":"2024-07-09-StartCodingwithPython5DictionariespartIIlooping","content":"\n딕셔너리를 순회하는 방법을 배울 거에요. 딕셔너리는 여러 가지 방법으로 정보를 저장할 수 있기 때문에 이를 순회하는 다양한 방법이 있어요. 주어진 딕셔너리의 키, 값 또는 모든 키-값 쌍을 순회할 수 있어요.\n\n## 키-값 쌍을 순회하기\n\n세 개의 키-값 쌍을 포함하는 scientist_0 딕셔너리를 고려해봐요:\n\n```js\n# 파일 이름: scientist.py\n\nscientist_0 = {\n    'username': 'rfeynman',\n    'first name': 'richard',\n    'last name': 'feynman',\n    }\n\nfor key, value in scientist_0.items():\n    print(f\"\\n키: {key}\")\n    print(f\"값: {value}\")\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n루프에 대한 예시를 보면, 코드를 실행하면 다음과 같이 결과가 나옵니다\n\n```js\n$ python3 scientist.py\n\nKey: username\nValue: rfeynman\n\nKey: first name\nValue: richard\n\nKey: last name\nValue: feynman\n```\n\n이후에 자세히 설명하겠습니다.\n\n키와 값에 대해 간단히 k와 v를 사용할 수 있습니다. 따라서 아래와 같이 코드를 작성하면 (특히 루프 부분을 참조하십시오), Python이 이전 코드와 정확히 동일하게 이해합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 파일 이름: scientist.py\n\nscientist_0 = {\n    'username': 'rfeynman',\n    'first name': 'richard',\n    'last name': 'feynman',\n    }\n\nfor k, v in scientist_0.items():\n    print(f\"\\nKey: {k}\")\n    print(f\"Value: {v}\")\n```\n\n위의 for 문에서 scientist_0 사전의 이름 뒤에 items() 메서드가 따라옵니다. 이 메서드는 키-값 쌍을 반환합니다. 그런 다음 각 키-값 쌍이 여기에서 Key와 Value로 정의된 두 변수에 할당됩니다.\n\n## 키값만 루핑\n\nitems() 메서드 대신 keys() 메서드를 사용하면 사전의 키만을 순회할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# file name: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': '바이올린',\n    'feynman': '봉고',\n    'dirac': '사색',\n    }\n\nfor name in scientist_hobby.keys():\n    print(name.title())\n```\n\n위 코드에서는 scientist_hobby라는 사전이 정의되어 있습니다. 이 사전은 이름이 과학자의 이름이고 값이 과학자의 취미인 세 개의 키-값 쌍으로 이루어져 있습니다. 만약 여기서 값이 아닌 과학자들의 이름인 키만 필요하다면, keys() 메서드를 사용하면 됩니다.\n\n```js\n$ python3 scientist_hobby.py\nEinstein\nFeynman\nDirac\n```\n\n위 코드를 실행하면 사전의 키만을 반환합니다. 여기서 간단히 언급하고 싶은데, 이러한 상황(값이 아닌 키만 반환하는 것)은 keys() 메서드를 특별히 지정하지 않을 때의 기본 동작입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# 파일명: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': '바이올린',\n    'feynman': '봉고',\n    'dirac': '사색',\n    }\n\nfor anything in scientist_hobby:\n    print(anything.title())\n```\n\n위 코드에서 .keys()를 제외하였지만, 이 코드를 실행하면 과학자들의 이름만 반환하여 결과는 똑같이 나올 것입니다.\n\n알파벳 순서로 키를 순회하고 싶다면 sorted() 메서드를 사용할 수 있습니다:\n\n```python\n# 파일명: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': '바이올린',\n    'feynman': '봉고',\n    'dirac': '사색',\n    }\n\nfor name in sorted(scientist_hobby.keys()):\n    print(name.title())\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위의 코드를 실행하면 다음과 같이 됩니다\n\n```js\n$ python3 scientist_hobby.py\nDirac\nEinstein\nFeynman\n```\n\n## 값만 반복\n\n상담하신 것처럼, 우리는 키가 없는 값의 순서를 반환하기 위해 위에서 논의한 keys() 메소드와 대조해서 values() 메소드를 사용할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 파일 이름: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': 'violin',\n    'feynman': 'bongo',\n    'dirac': 'pondering',\n    'heisenberg': 'violin',\n    }\n\nprint(\"이러한 취미가 언급되었습니다:\")\nfor hobby in scientist_hobby.values():\n    print(hobby.title())\n```\n\n위의 코드를 실행하면 다음이 반환됩니다:\n\n```js\n$ python3 scientist_hobby.py\n이러한 취미가 언급되었습니다:\nViolin\nBongo\nPondering\nViolin\n```\n\n여기서 바이올린은 두 명이 동일한 취미를 가지고 있기 때문에 반복됩니다. 이러한 종류의 반복을 방지하고 싶은 경우 아래에 표시된 대로 set() 메소드를 사용할 수 있습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# file name: scientist_hobby.py\n\nscientist_hobby = {\n    'einstein': 'violin',\n    'feynman': 'bongo',\n    'dirac': 'pondering',\n    'heisenberg': 'violin',\n    }\n\nprint(\"These hobbies have been mentioned:\")\nfor hobby in set(scientist_hobby.values()):\n    print(hobby.title())\n```\n\n```python\n$ python3 scientist_hobby.py\nThese hobbies have been mentioned:\nViolin\nPondering\nBongo\n```\n\nNow Violin is returned only once.\n\nOne can also make a set using braces ({}). However, in contrast to a dictionary where a set of key-value pairs are given inside '{}', in a set each single element should be separated by a comma.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n>>> 취미 = {'바이올린', '봉고', '사색', '바이올린', '봉고'}\n>>> 취미\n{'사색', '바이올린', '봉고'}\n```\n\n딕셔너리와 집합 사이의 차이를 알아두면 혼란을 방지할 수 있어요.\n\n![이미지](/TIL/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_0.png)\n\n![이미지](/TIL/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_1.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/TIL/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_2.png)\n","ogImage":{"url":"/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-StartCodingwithPython5DictionariespartIIlooping_0.png","tag":["Tech"],"readingTime":7},{"title":"Ruff로 파이썬 코드를 강화하는 방법","description":"","date":"2024-07-09 20:56","slug":"2024-07-09-SuperchargeyourPythonCodewithRuff","content":"\n## PYTHON\n\n![Python Image](/TIL/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_0.png)\n\n아직 프로젝트에서 Black, isort, 그리고 Flake8을 사용하고 계신가요? 업그레이드할 때입니다.\n\n새로운 도구가 나왔습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 러프\n\n러프는 찰리 마시의 열정 프로젝트로 시작되었습니다.\n\n그는 더 빠른 Python 린터를 만들기로 결심했습니다.\n\n가장 큰 Python 프로젝트 중 일부가 그것을 사용하기 시작하자, Python 생태계를 더 생산적으로 만들기 위해 고성능 개발자 도구를 구축하여 소프트웨어를 더 빨리 출시할 수 있도록 하는 기회를 보았습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nRuff는 러스트로 작성된 매우 빠른 Python 린터 및 코드 포매터입니다.\n\n그 얼마나 빠른지 궁금하신가요? 이 이미지가 모두를 알려줍니다.\n\n![Supercharge your Python Code with Ruff](/TIL/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_1.png)\n\nRuff는 Flake8(그리고 수십 개의 플러그인), Black, isort, pydocstyle, pyupgrade, autoflake 등을 대체할 수 있으며, 10~100배의 속도 향상을 자랑합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nVS Code 및 다양한 다른 통합을 위한 일등 서비스 편집기 통합을 제공합니다.\n\nRuff는 Airflow, Hugging Face, Pandas와 같은 주요 오픈 소스 프로젝트에서 활발히 사용됩니다.\n\n## 사용자들이 말하는 것\n\nFastAPI 창시자 Sebastián Ramírez:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n닉 쉬록은 Elementl의 창립자이자 GraphQL의 공동 창시자입니다.\n\n# 빠른 속도의 비결\n\n럼프의 놀라운 속도는 주로 러스트 기반의 아키텍처 덕분에 가능합니다. 러스트는 성능과 안정성으로 유명하여, 럼프가 다른 도구들보다 빠른 린팅 및 포매팅 서비스를 제공할 수 있게 해줬습니다.\n\n이 효율성은 러스트의 성능 능력을 통해 이루어지며, 변경되지 않은 파일의 재분석을 방지하는 내장 캐싱 시스템과 개발 과정 전반에 걸쳐 성능 최적화에 초점을 맞춘 덕분입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n대규모 코드베이스에서도 하위 초 반응 루프를 제공하도록 설계된 Ruff는 린팅 및 형식 지정 작업을 기다리는 시간을 줄여 개발자들의 삶의 질을 크게 향상시킵니다.\n\n궁금하시다면, 웹사이트에서 Ruff가 코드를 파싱하는 방식을 탐색할 수 있는 플레이그라운드가 준비되어 있습니다.\n\n![Ruff Playground](/TIL/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_2.png)\n\n해당 페이지에는 AST, 토큰, 형식 지정 IR(중간 표현), 그리고 형식 지정 주석을 보여줍니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n하지만 더 이상 말이 필요 없어요. 직접 해보는 것이 최선이죠!\n\n# 테스트 드라이브\n\n## 설치\n\nRuff는 PyPI에서 ruff로 사용할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\npip install ruff\n```\n\n마니매 진행 및 확인하기 Manim, the animation engine 3blue1brown이 수학 비디오에서 사용하는 엔진입니다.\n\n<img src=\"/TIL/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_3.png\" />\n\n## 코드 분석\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n코드에 린터를 실행하려면, 다음과 같이 사용합니다.\n\n```js\nruff check .\n```\n\n하나의 파일에 대해 실행하려면, 다음과 같이 하세요.\n\n```js\nruff check <filename.py>\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n총 415개의 오류가 있었어요. 이 중 33개는 수정할 수 있어요!\n\n![이미지](/TIL/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_4.png)\n\n해결하기 위해선 다음과 같이 --fix 플래그를 사용해요\n\n```js\nruff check --fix .\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_5.png\" />\n\n알 수 있듯이, 33개가 수정되었고, 383개가 남아 있습니다.\n\n## 포맷팅\n\n포맷팅을 위해 ruff 형식을 사용합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nformat을 변경하십시오.\n```\n\n<img src=\"/TIL/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_6.png\" />\n\n아마도 당신은 이렇게 Ruff를 사용하지 않을 것이며, 에디터를 사용하고 있기 때문에, 이제 설정하는 방법을 살펴봅시다!\n\n# VS Code에서 사용하기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nVSCode 확장 프로그램을 설치해보세요.\n\n이제 \"모든 자동 수정 가능한 문제 해결\"만으로 쉽게 해결할 수 있어요!\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/0*kF8S-U62dWreNT6M.gif)\n\n게다가 더 좋은 점은 저장할 때도 이 작업을 할 수 있다는 거예요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 저장 시 형식 지정\n\n만약 Ruff가 lint 위반을 자동으로 수정하고, import를 정리하며 저장할 때 형식을 지정하길 원한다면, 설정 파일인 settings.json으로 이동하세요.\n\n다음을 추가하세요.\n\n```js\n\"[python]\": {\n  \"editor.formatOnSave\": true,\n  \"editor.codeActionsOnSave\": {\n    \"source.fixAll\": \"explicit\",\n    \"source.organizeImports\": \"explicit\"\n  },\n  \"editor.defaultFormatter\": \"charliermarsh.ruff\"\n}\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 태그를 마크다운 형식으로 변경하실 수 있습니다.\n\nRuff가 유형 또는 저장 시 실행되기를 원하는지에 따라 다릅니다. 기본적으로 유형에 실행되지만, 저는 저장 시에 실행되기를 선호합니다.\n\n```js\n\"ruff.lint.run\": \"onSave\",\n```\n\n## 주피터 노트북\n\n이 확장 프로그램으로 노트북에서 서식 지정, 린팅, 그리고 가져오기 정리를 위한 명령어를 사용할 수 있습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오른쪽 코드 조작으로 변경하세요.\n\n![사진](https://miro.medium.com/v2/resize:fit:1400/0*0qBmSIfB0VVP2au_.gif)\n\n저장 시에도 이를 사용하려면 아래 코드를 추가하세요.\n\n```js\n\"notebook.formatOnSave.enabled\": true,\n\"notebook.codeActionsOnSave\": {\n  \"source.fixAll.ruff\": true,\n  \"source.organizeImports.ruff\": true\n}\n```\n\n# pre-commit 사용하기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프리 커밋을 사용하려면 Ruff의 프리 커밋 후크를 추가하는 방법입니다.\n\n```js\n- repo: https://github.com/astral-sh/ruff-pre-commit\n  # Ruff 버전.\n  rev: v0.2.2\n  hooks:\n    # 린터 실행.\n    - id: ruff\n      types_or: [ python, pyi, jupyter ]\n      args: [ --fix ]\n    # 포매터 실행.\n    - id: ruff-format\n      types_or: [ python, pyi, jupyter ]\n```\n\n# CLI로 Jupyter 노트북 사용\n\n만약 노트북을 위해 CLI를 사용 중이라면, pyproject.toml이나 ruff.toml 중 하나에 이 줄을 추가해야 합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nextend-include = [\"*.ipynb\"]\n```\n\n# 더 많은 통합 기능\n\n많은 다른 통합 기능들을 지원합니다. Vim도 포함돼요!\n\n<img src=\"/TIL/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_7.png\" />\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Ruff에 대해 더 알아보기\n\n여기까지입니다! Ruff에 관한 더 많은 콘텐츠를 원한다면 아래 링크를 확인해보세요 👇\n\n- Matt Layman이 Python 프로젝트를 Ruff로 전환하는 라이브 스트림 시청하기\n- Flake8 및 PyLint를 작별하고 Ruff로 더 빠른 린팅하기\n- Ruff: 빠른 Python 린터 [LWN.net]\n- Ruff로 업그레이드할 때입니다 — Eric J. Ma의 개인 사이트\n- 코드 품질을 향상시키는 가장 빠른 방법: Ruff 린터 사용하기\n\n# 읽어 주셔서 감사합니다\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nbitgrit 데이터 과학 게시물을 구독하고 최신 소식을 받아보세요!\n\n다른 데이터 과학자들과 최신 데이터 과학 및 인공지능 개발에 대해 함께 이야기하고 싶나요? 저희 디스코드 서버에 가입해보세요!\n\n워크숍 및 다가오는 대회 소식을 받아보려면 Bitgrit를 팔로우해주세요!\n\nDiscord | 웹사이트 | 트위터 | 링크드인 | 인스타그램 | 페이스북 | 유튜브\n","ogImage":{"url":"/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-SuperchargeyourPythonCodewithRuff_0.png","tag":["Tech"],"readingTime":10}],"page":"16","totalPageCount":34,"totalPageGroupCount":2,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}