{"pageProps":{"posts":[{"title":"PyCon US 2024 인사이트, 배움, 그리고 커뮤니티","description":"","date":"2024-07-09 09:11","slug":"2024-07-09-PyConUS2024InsightsLearningsandCommunity","content":"\n![이미지](/TIL/assets/img/2024-07-09-PyConUS2024InsightsLearningsandCommunity_0.png)\n\n파이썬 프로그래밍 언어가 크리스마스 휴가동안의 취미 프로젝트로 출생했다는 사실을 아셨나요? 그러니까 이제 제가 크리스마스 휴가에 사용하는 것에 대해 의문을 품게 되네요 🤭😂.\n\n올해 2024년 5월 15일부터 5월 23일까지 피츠버그, 펜실베이니아의 데이비드 L. 로렌스 컨벤션 센터에서 PyCon US(파이선 레이디스 주관)에 참석했습니다.\n\n이 글에서는 아래와 같은 내용을 강조할 것입니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 소개\n- 이벤트 전 준비\n- 행사 중\n- 행사 후(알림)\n- 마무리\n- 개인 팁\n- 자원\n\n## 소개\n\nPyCon US는 교육, 문서 및 기타 다양한 행사들(교육, 문서 등)인 써밋, 오픈 스페이스, PyLadies 경매(경험해볼 가치가 있습니다), 엑스포 쇼케이스, 랩 이벤트, 취업 박람회, 부가 행사 등 다양한 행사로 구성된 컨퍼런스입니다. 이 이벤트는 전 세계의 파이썬 개발자들이 모여 함께 공부하고 공유하며 네트워킹을 하며 즐거운 시간을 보낼 수 있도록 합니다.\n\n## 이벤트 전 준비\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이벤트 시작 전에 조금 일찍 도착해서 마스크를 쓰고 현장에서 친구들을 만났어요. 자가 체크인을 위해 등록 부스를 지나가서 라너드와 태그를 받았죠. 세팅이 진행 중이던 엑스포홀을 구경했어요.\n\n참고: 마스크 착용 의무\n\nPSF 부스 셀피 월 세팅을 도와서 멋지게 마무리했어요. 그리고 나서, Black Python Devs와 PyLadies 부스를 방문해서 지원하기로 결정했어요.\n\n## 이벤트 중간에\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이벤트 기간 동안 PyCon US 앱을 통해 선보인 훌륭한 강연(주제별 강연, 워크샵, 튜토리얼), 정상회의 및 활동 등이 모두 있었어요.\n\n이 링크에서 컨퍼런스 이벤트 일정을 확인해보세요: https://us.pycon.org/2024/schedule/\n\n저는 Black Python Devs와 PyLadies 부스에서 봉사했고, 정상회의에 참석하며 엑스포홀의 모든 부스를 방문했어요. Ansys PyGeometry Lab, MongoDB 퀴즈 등의 랩 및 퀴즈에 참여했으며, 다양한 기관의 대표자들과 소통했어요.\n\n또한, Black Python Devs는 제트브레인즈 부스에서 첫 번째 생일을 축하했어요! 🎉🚀\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n또한, Jay Miller의 키노트를 듣고 Black Python Devs 웹사이트를 확인해보세요: [링크](https://www.youtube.com/watch?v=jYZBpoYjxLo)\n\n![이미지 1](/TIL/assets/img/2024-07-09-PyConUS2024InsightsLearningsandCommunity_1.png)\n\nPyLadies 경매\n이곳은 실제 경매장에 처음 와본 적이 있어서 즐거웠고 재미난 경험이었습니다. 다음 PyCon US에 참석한다면 이 행사에 참가하는 것을 추천합니다.\n\n![이미지 2](/TIL/assets/img/2024-07-09-PyConUS2024InsightsLearningsandCommunity_2.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 행사 후기\n\n컨퍼런스 마지막 날에는 폐막식이 열렸고 최종 작별을 나눴습니다. 본 행사 이후로는 월요일부터 목요일까지 이어지는 스프린트가 있었는데, 이는 오픈 소스 저장소에 기여할 수 있는 기회입니다.\n\n나는 알지 못했던 사람들과 예기치 못한 훌륭한 경험을 했고, 이 모든 일들이 일어나야 했다고 느꼈습니다. 특히, Jim, Victor, Velda에게 감사드립니다 — 산만한 상황 속에서도 너희들과 함께한 최고의 시간 소중했어; 너희들 진짜 최고야 ❤️\n\n저와 상호작용하거나 재연락을 취한 모든 분들, 봉사하거나 질문에 답변하거나 문제해결을 제공하거나 퀴즈/실습 과제에 개선 제안을 해주신 분들, 전시장에서 제품에 대해 이야기를 해주신 분들 그리고 기타 다른 분들께 진심으로 감사드립니다. 다시 만날 수 있기를 소망합니다. 항상 좋은 일만 가득하길 기원합니다 🫶🏾\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 스프린트\n\n컨퍼런스가 끝난 후, 처음으로 Sprints 세션에 참여했습니다. 거기서 Beeware 및 CPython 저장소를 로컬에 설정하고 BeeWare에 오픈 소스 기여를 했습니다(Russell, 감사합니다-당신은 멋져요 ✨).\n\nVelda와 저는 CPython 내부를 이해하기 위한 여정을 시작했고, Anthony Shaw의 CPython Internals 책을 구해서 여정을 시작했습니다.\n\n## 흥미로운 발표들\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아비게일 M. 독베가 우수한 PyLady로 선정되었고, 벨다 키아리는 파이썬 스티어링 콘솔에 제안을 받았어요 🎉\n\nBPD 회원들이 높은 수준에 도달하고 자신들의 업적을 인정받는 것을 보는 것이 멋있어요.\n\n## 요약\n\n되돌아보면, 전체적으로 멋진 경험이었어요. 더 많이 배우게 되었고, 새로운 멋진 사람들을 만나고, 오랜만에 다시 만나는 다른 파이썬 개발자들과 연결되어 톡톡 튀는 대화를 나누었으며, 파이썬 및 기술 도구의 업데이트를 접하며 더 깊은 커뮤니티 의식을 키울 수 있었어요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/TIL/assets/img/2024-07-09-PyConUS2024InsightsLearningsandCommunity_3.png\" />\n\n## 개인 팁\n\n다음 PyCon을 위해 추천하는 몇 가지 팁입니다:\n\n- 컨퍼런스는 압도적일 수 있으므로 일정을 확인하고 계속 확인해야 합니다. 일정이 변경될 수 있기 때문이죠.\n- 행사 등록은 조기에 대시 보드에서 진행해 주세요. 매진되기 전에 미리 등록해 두세요.\n- 정상에 참석하도록 노력해주세요. 녹화되지 않은 정보가 많기 때문에 참석하지 않으면 많은 것을 놓칠 수 있습니다.\n- 메일링 리스트를 유심히 지켜보세요.\n- 당당하게 나가세요. 도움을 받을 수 있는 친절한 사람들을 만나거나 다시 만날 수 있습니다. 그것이 최고의 경험이었죠.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 자료\n\nPyCon US에 대한 더 많은 정보를 얻을 수 있는 멋진 자료들이 있어요:\n\n- Kati의 포스트 (Katherine Michael): [여기](https://katherinemichel.github.io/portfolio/pycon-us-2024-recap.html)\n- Hugo가 여기에 목록을 만들었어요: [여기](https://dev.to/hugovk/pycon-us-2024-a-roundup-of-writeups-26hj)\n\n시간이 좀 걸렸지만, 제 경험의 하이라이트를 즐겨주셨으면 좋겠어요 :)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가장 좋은 일만 있길 바래요.\n\n#Python PyConUS #Tech\n","ogImage":{"url":"/assets/img/2024-07-09-PyConUS2024InsightsLearningsandCommunity_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-PyConUS2024InsightsLearningsandCommunity_0.png","tag":["Tech"],"readingTime":7},{"title":"인터뷰 질문 apple과 a3e 문자열 매칭 방법","description":"","date":"2024-07-09 09:10","slug":"2024-07-09-InterviewQnMatchingStringsa3eWithapple","content":"\n![image](/TIL/assets/img/2024-07-09-InterviewQnMatchingStringsa3eWithapple_0.png)\n\n함수 match(string, pattern)을 작성하세요. 이 함수는 2개의 문자열을 입력받고, 문자열이 값과 일치하면 True를 반환하고 그렇지 않으면 False를 반환합니다.\n\n- string은 사과(apple) 오렌지(orange)와 같은 문자만 포함하는 일반 문자열입니다.\n- pattern은 a3e와 같은 문자와 숫자를 포함하는 문자열입니다.\n\n일부 예시:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- a3e은 apple과 일치합니다. 3은 ppl 3자리와 일치합니다.\n- a4e는 apple과 일치하지 않습니다. apple에서 a와 e 사이에 4개의 문자가 아닌 3개의 문자가 있기 때문입니다.\n- a2e는 apple과 일치하지 않습니다. apple에서 a와 e 사이에 2개의 문자가 아닌 3개의 문자가 있기 때문입니다.\n\n```js\ndef match(string: str, pattern: str) -> bool:\n    \"\"\"\n    string: 문자열 예: 'apple', 'orange'\n    pattern: 예: 'a2e', 'a3e'\n    \"\"\"\n    # 할 일\n\ntestcases = [\n    ('apple', 'a3e', True),\n    ('apple', '4e', True),\n    ('apple', 'a1p1e', True),\n    ('apple', '5', True),\n    ('apple', 'a4e', False),\n    ('apple', 'a2x', False),\n    ('apple', '4', False),\n    ('apple', '6', False),\n    ('appleorangepear', '15', True),\n    ('appleorangepear', 'a12ar', True),\n    ('appleorangepear', 'a13r', True),\n    ('appleorangepear', '14r', True),\n    ('appleorangepear', 'a13ar', False),\n    ('appleorangepear', '16'…\n```\n","ogImage":{"url":"/assets/img/2024-07-09-InterviewQnMatchingStringsa3eWithapple_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-InterviewQnMatchingStringsa3eWithapple_0.png","tag":["Tech"],"readingTime":2},{"title":"Python으로 LoRa 모듈레이션 시뮬레이션 하는 방법","description":"","date":"2024-07-09 09:09","slug":"2024-07-09-HowtoSimulateLoRaModulationWithPython","content":"\n# 소개\n\nLoRa (Long Range) 변조는 저전력 소비로 장거리 데이터 전송이 가능하게 하는 무선 통신 기술로, 사물 인터넷(IoT) 응용 프로그램에 이상적입니다. 치르프 스프레드 스펙트럼(CSS) 기술을 활용하여, LoRa 변조는 신호를 넓은 주파수 범위에 퍼뜨려 간섭에 대한 저항성을 향상시키고 데이터 전송의 견고성을 향상시킵니다. 이 변조 방법은 다른 통신 기술이 장애물이나 소음으로 인해 어려움을 겪는 환경에서 특히 효과적입니다. 멀리 떨어진 네트워크를 구축하고 확장 가능한 IoT 네트워크를 지원하기 위해 장거리 기능과 최소한의 에너지 요구 사항을 결합한 LoRa 변조는 스마트 시티, 농업 모니터링 및 산업 자동화와 같은 응용 프로그램을 용이하게합니다.\n\n# 매개변수 정의\n\n코드의 첫 번째 섹션은 LoRa 조작에 사용되는 매개변수를 정의합니다. 대역폭 B는 125 kHz (125e3)로 설정되고 샘플링 주기 T는 대역폭의 역수로 계산됩니다. 즉, T = 1 / B 입니다. 확산 계수(SF)는 7로 정의되어 있으며 LoRa 변조를 위한 전형적인 값으로 7에서 12 사이의 값으로 변할 수 있습니다. 이 계수는 심볼 주기 T_s를 결정하며, T_s = (2\\*_SF) _ T로 계산됩니다. 이러한 매개변수는 LoRa 시스템에서 심볼의 시간적 행동과 전송 속도를 정의하는 데 필수적입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\nB = 125e3  # (125 kHz) bandwidth\nT = 1 / B  # sampling period\nSF = 7  # spreading factor {7,8,9,10,11,12}\nT_s = (2**SF) * T  # symbol period\n```\n\n# 심볼 계산\n\n이 코드 부분에서, 일곱 개 요소로 구성된 비트 벡터 w가 Spreading Factor (SF) 값에 해당하는 값으로 정의됩니다. 그런 다음 벡터 w는 10진수 값으로 변환됩니다. 먼저 변수 symbol이 0으로 설정됩니다. 그런 다음, for 루프는 w 벡터의 각 비트를 반복하며, 각 비트를 해당하는 `2**h` 값(여기서 h는 비트 인덱스)으로 곱한 다음 결과를 symbol 변수에 추가합니다. 이 프로세스는 이진 벡터를 변조할 심볼을 나타내는 10진수 값으로 변환합니다. 이 계산은 LoRa 변조에 있어서 중요하며, 디지털 정보를 전송에 적합한 형식으로 변환합니다.\n\n```python\nw = [1, 1, 0, 1, 0, 1, 1]\n\nsymbol = 0\n\nfor h in range(SF):\n    symbol += w[h] * (2**h)\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 시간 및 시간 인덱스 벡터 생성 및 Chirp 계산하기\n\n코드의 세 번째 부분은 Chirp 신호를 생성하는 데 필요한 시간 벡터를 만듭니다. t 벡터는 np.linspace 함수를 사용하여 생성되며, 이 함수는 0부터 T_s까지 num 개의 동일 간격으로 나누어진 점을 생성합니다. 점의 개수 num은 int(T_s / T)로 계산되어 샘플링 주기 T에 따라 점이 적절히 간격을 두고 생성됩니다. 그다음, k 벡터는 np.arange를 사용하여 생성되는데, len(t)까지 0.01의 간격으로 동일하게 나뉜 값을 생성합니다. 그리고 Chirp 신호는 chirp = np.exp(1j _ 2 _ np.pi _ ((symbol + k) % (2**SF)) / (2**SF) _ k) 공식을 사용하여 계산됩니다. 여기서, 1j는 허수 단위를 나타냅니다.\n\n```js\nt = np.linspace(start=0, stop=T_s, num=int(T_s / T))\n\nk = np.arange(start=0, stop=len(t), step=0.01)\n\n# Chirp 공식\nchirp = np.exp(1j * 2 * np.pi * ((symbol + k) % (2**SF)) / (2**SF) * k)\n```\n\n# Chirp 신호들의 플로팅\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n코드의 마지막 부분은 생성된 Chirp 신호를 시각화하는 부분입니다. 새로운 그림이 plt.figure(figsize=(10, 6))를 사용하여 10x6 인치 크기로 만들어집니다. Chirp 신호는 두 개의 서브플롯에 플로팅됩니다. 첫 번째 서브플롯(plt.subplot(2, 1, 1))은 plt.plot(k, chirp.real, label='실수부', color='blue') 함수를 사용하여 Chirp 신호의 실수부를 플로팅합니다. 제목, 축 레이블, 그리드 및 범례가 플롯에 추가되어 가독성과 데이터 해석이 향상됩니다. 두 번째 서브플롯(plt.subplot(2, 1, 2))은 plt.plot(k, chirp.imag, label='허수부', color='orange') 함수를 사용하여 Chirp 신호의 허수부를 플로팅하며, 마찬가지로 제목, 레이블, 그리드, 범례가 추가됩니다. 마지막으로 plt.tight_layout()은 서브플롯을 자동으로 조절하여 그림에 맞게 조절하고, plt.show()는 그림을 표시합니다. 이 시각화를 통해 Chirp 신호의 특성을 분석할 수 있습니다. 실수 및 허수부 모두를 통해 변조된 신호에 대한 완전한 이해를 제공합니다.\n\n```js\n# Chirp 신호 플로팅\nplt.figure(figsize=(10, 6))\n\n# Chirp 실수부 플로팅\nplt.subplot(2, 1, 1)\nplt.plot(k, chirp.real, label='실수부', color='blue')\nplt.title('LoRa 신호 - s(t)의 실수부')\nplt.xlabel('시간 색인 [k]')\nplt.ylabel('진폭 [mW]')\nplt.grid(True)\nplt.legend()\n\n# Chirp 허수부 플로팅\nplt.subplot(2, 1, 2)\nplt.plot(k, chirp.imag, label='허수부', color='orange')\nplt.title('LoRa 신호 - s(t)의 허수부')\nplt.xlabel('시간 색인 [k]')\nplt.ylabel('진폭 [mW]')\nplt.grid(True)\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n<img src=\"/TIL/assets/img/2024-07-09-HowtoSimulateLoRaModulationWithPython_0.png\" />\n\n의견과 피드백은 댓글에서 환영합니다. 여기 테스트 용 전체 코드가 있습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\nB = 125e3  # (125 kHz) 대역폭\nT = 1 / B  # 샘플링 주기\nSF = 7  # 확산 계수 {7,8,9,10,11,12}\nT_s = (2**SF) * T  # 심볼 주기\n\nw = [1, 1, 0, 1, 0, 1, 1]\n\nsymbol = 0\n\nfor h in range(SF):\n    symbol += w[h] * (2**h)\n\nt = np.linspace(start=0, stop=T_s, num=int(T_s / T))\n\nk = np.arange(start=0, stop=len(t), step=0.01)\n\n# 칩 신호 공식\nchirp = np.exp(1j * 2 * np.pi * ((symbol + k) % (2**SF)) / (2**SF) * k)\n\n# 칩 신호 플롯\nplt.figure(figsize=(10, 6))\n\n# 칩의 실수부 플롯\nplt.subplot(2, 1, 1)\nplt.plot(k, chirp.real, label='실수부', color='blue')\nplt.title('LoRa 신호 - s(t)의 실수부')\nplt.xlabel('시간 인덱스 [k]')\nplt.ylabel('진폭 [mW]')\nplt.grid(True)\nplt.legend()\n\n# 칩의 허수부 플롯\nplt.subplot(2, 1, 2)\nplt.plot(k, chirp.imag, label='허수부', color='orange')\nplt.title('LoRa 신호 - s(t)의 허수부')\nplt.xlabel('시간 인덱스 [k]')\nplt.ylabel('진폭 [mW]')\nplt.grid(True)\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n# 참고 자료\n\nVANGELISTA, Lorenzo. Frequency shift chirp modulation: The LoRa modulation. IEEE signal processing letters, v. 24, n. 12, p. 1818–1821, 2017.\n","ogImage":{"url":"/assets/img/2024-07-09-HowtoSimulateLoRaModulationWithPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-HowtoSimulateLoRaModulationWithPython_0.png","tag":["Tech"],"readingTime":6},{"title":"Garman-Klass를 사용해 시계열 변동성 측정하는 방법","description":"","date":"2024-07-09 09:09","slug":"2024-07-09-MeasureTimeSeriesVolatilityUsingGarman-Klass","content":"\n![Garman-Klass volatility estimator](/TIL/assets/img/2024-07-09-MeasureTimeSeriesVolatilityUsingGarman-Klass_0.png)\n\n가만-클라스(Grarman-Klass) 변동성 추정기는 고가, 저가, 시가 및 종가를 사용하여 금융 자산의 변동성을 추정하는 방법입니다. 이 방법은 종가만 사용하는 기존 방법보다 변동성을 더 정확하게 추정하는 데 설계되었습니다.\n\n이 기사에서는 이 변동성 측정 방법을 자세히 설명하고 Python을 사용하여 시계열에 대한 롤링 계산을 코드화하는 방법을 보여줍니다.\n\n# 가만-클라스(Grarman-Klass) 변동성 이해하기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n복잡한 변동성 모델을 논의하기 전에, 먼저 기본적인 변동성 모델(또는 계산)인 역사적 표준 편차에 대해 완벽히 이해하는 것이 좋습니다. 역사적 방법을 사용한 표준 편차는 과거 가격 데이터를 기반으로 금융 상품의 변동성을 측정하는 일반적인 방법입니다.\n\n이는 값들의 변동이나 분산의 양을 측정합니다. 금융 분야에서는 보통 일일 수익률의 평균 주변의 분산을 측정합니다. 표준 편차를 계산하려면 다음 단계를 따르세요:\n\n- 차분(첫 번째 함수) 또는 로그 방법(두 번째 함수)을 사용하여 수익을 계산합니다.\n","ogImage":{"url":"/assets/img/2024-07-09-MeasureTimeSeriesVolatilityUsingGarman-Klass_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-MeasureTimeSeriesVolatilityUsingGarman-Klass_0.png","tag":["Tech"],"readingTime":1},{"title":"Python을 사용한 간단한 ETL 프로젝트 실습 방법","description":"","date":"2024-07-09 09:08","slug":"2024-07-09-Hands-onSimpleETLProjectwithPython","content":"\n# 개요\n\nExtract, Transform, and Load (ETL)은 다양한 소스에서 데이터를 추출하고 적절한 형식으로 변환한 다음 추가적인 분석을 위해 목적지 데이터베이스나 데이터 웨어하우스에로드하는 작업을 의미합니다. 이 블로그 포스트에서는 Python을 사용하여 실무 ETL 프로젝트를 수행하는 과정에 대해 알아보겠습니다.\n\n![Hands-on ETL Project with Python](/TIL/assets/img/2024-07-09-Hands-onSimpleETLProjectwithPython_0.png)\n\n# 단계 1: 필요한 라이브러리 가져오기\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 Markdown 형식으로 변경한 내용입니다.\n\n![Step 2: Get File Using Url](/TIL/assets/img/2024-07-09-Hands-onSimpleETLProjectwithPython_1.png)\n\n![Step 3: Extract Data from Files](/TIL/assets/img/2024-07-09-Hands-onSimpleETLProjectwithPython_2.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희 ETL 파이프라인의 첫 번째 단계는 데이터가 포함된 파일에서 데이터를 추출하는 것입니다. 우리는 pandas 라이브러리를 사용하여 파일을 DataFrame으로 읽을 것입니다.\n\n![이미지](/TIL/assets/img/2024-07-09-Hands-onSimpleETLProjectwithPython_3.png)\n\n![이미지](/TIL/assets/img/2024-07-09-Hands-onSimpleETLProjectwithPython_4.png)\n\n# 단계 4: 데이터 변환\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 단계는 추출된 데이터를 대상 파일로로드하기 위한 원하는 형식으로 변환하는 것입니다. 이는 데이터 정리, 누락된 값 처리 및 데이터 유형 변환을 포함할 수 있습니다.\n\n![image](/TIL/assets/img/2024-07-09-Hands-onSimpleETLProjectwithPython_5.png)\n\n# 단계 4: 데이터 로드\n\n마지막 단계는 변환된 데이터를 대상 파일로로드하는 것입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Hands-on Simple ETL Project with Python](/TIL/assets/img/2024-07-09-Hands-onSimpleETLProjectwithPython_6.png)\n\n# 결론:\n\n이 프로젝트의 주요 목표는 간단한 ETL 파이프라인을 만들고 자동화하는 실용적인 가이드를 제공하는 것입니다. 이를 통해 이 프로젝트는 데이터 엔지니어링 스킬을 향상시키는 실용적인 방법을 제공하는 데 기대합니다.\n\n하지만 여기서 모험이 끝나는 건 아닙니다. 데이터는 다양한 분석 목적으로 사용될 수 있으며 사용자 행동에 대한 가치 있는 통찰을 제공합니다.\n","ogImage":{"url":"/assets/img/2024-07-09-Hands-onSimpleETLProjectwithPython_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-Hands-onSimpleETLProjectwithPython_0.png","tag":["Tech"],"readingTime":3},{"title":"Leetcode 200 섬의 개수 완벽 정복 가이드","description":"","date":"2024-07-09 09:07","slug":"2024-07-09-PerfectingLeetcode200NumberofIslands","content":"\nLeetCode의 \"섬의 개수\" 문제는 '1' (육지)과 '0' (물)로 구성된 m x n 그리드가 포함되어 있습니다. 이 문제는 그리드 내의 섬의 개수를 결정하는 것입니다. 여기서 섬은 수평 또는 수직으로 연결된 '1'의 그룹으로 정의되며, 물 ('0')로 완전히 둘러싸여 있습니다.\n\n<img src=\"/TIL/assets/img/2024-07-09-PerfectingLeetcode200NumberofIslands_0.png\" />\n\n예를 들어, 예제 1에서는 총 3개의 섬이 있고, 예제 2에서는 하나의 섬이 있습니다. 중요한 점은 '1'들이 수평 또는 수직 연결을 통해서만 다른 '1'들에 연결될 수 있다는 것입니다.\n\n## 그래서, 이 문제에 적합한 알고리즘은 무엇일까요?\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 문제는 그리드를 탐색하고 인접한 노드들을 체계적으로 탐색해야 하기 때문에 BFS가 가장 효율적인 알고리즘입니다. 그리드나 그래프 구조에서 연결된 구성 요소를 탐색하고 식별할 수 있는 능력은 이 작업에 잘 어울립니다.\n\n## BFS가 그리드에서 섬을 발견하는 방식을 시각화해 봅시다!\n\n- 알고리즘은 각 셀을 탐색하면서 그리드 안의 행과 열을 하나씩 탐색합니다.\n- 방문하지 않은 '1'로 표시된 셀을 탐색하기 위해 BFS를 사용합니다. 작업을 최적화하고 중복 방문을 피하기 위해 '방문함' 집합을 사용하여 이미 탐색한 노드를 추적합니다.\n- BFS는 방문해야 할 다음 노드를 유지하기 위해 큐도 필요합니다.\n\n![그림](/TIL/assets/img/2024-07-09-PerfectingLeetcode200NumberofIslands_1.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 셀 [0, 0]에서 탐사를 시작합니다. '1'이 포함되어 있기 때문에 섬의 일부로 간주되어 'visited' 세트에 추가됩니다. 이제 [0, 0]에서 4가지 방향으로 이동할 수 있습니다: [0, 1], [1, 0], [-1, 0], [0, -1]. 그리드를 벗어나지 않도록 하기 위해 [1, 0]과 [0, 1]만 남습니다. 이 두 셀은 현재 탐색 중인 동일한 섬의 일부라는 것을 나타내는 '1'입니다. 따라서 이러한 셀을 큐에 추가하여 다음에 방문합니다. (그림 1)\n- 다음으로 [1, 0]을 pop하고 visited 세트에 추가합니다. [1, 0]에서 4방향으로 갈 수 있습니다: [0, 0], [1, -1], [1, 1], [2, 0]. 그리드를 벗어나지 않기 때문에 [1, -1]을 버립니다. [0, 0]은 이미 방문했으므로 방문을 스킵합니다. [2, 0]은 '0'이므로 물이므로 방문할 필요가 없습니다. 방문되지 않은 [1, 1]은 '1'이므로 큐에 추가합니다. (그림 2)\n- '1'을 보면 새로운 셀을 큐에 추가하면서 계속해서 큐에서 셀을 탐색합니다. 현재 조사 중인 섬에 더 이상 탐색할 '1'이 없을 때까지 큐는 활성 상태를 유지합니다. 해당 섬을 완전히 탐색하면 그 섬에 대한 BFS가 중지됩니다. 한 섬을 완전히 탐사한 후에는 그리드에서 추가적인 섬이 있는지 검색합니다. (그림 3 및 그림 4)\n\n![그림](/TIL/assets/img/2024-07-09-PerfectingLeetcode200NumberofIslands_2.png)\n\n- [2, 2] 셀의 경우 주변에 계속 탐색할 '1'이 없습니다. 이것은 다른 섬의 발견을 나타냅니다. 이 시점에서 큐가 비어 있으므로 다음 BFS 이터레이션으로 넘어갑니다.\n\n![그림](/TIL/assets/img/2024-07-09-PerfectingLeetcode200NumberofIslands_3.png)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- [3, 3]에 위치하면 [3, 4]로만 이동할 수 있습니다. 여전히 발견되지 않은 '1' 이므로 큐에 넣어줍니다.\n- [3, 4]를 팝하여 방문했다고 표시하고, 주변에 더 이상 발견되지 않은 '1'이 없기 때문에, 이 섬을 대상으로 하는 BFS 및 이후 알고리즘을 완료합니다.\n\n따라서, 총 3개의 섬을 찾았습니다.\n\n## 파이썬 구현:\n\n```js\nimport collections\n\nclass Solution(object):\n def numIslands(self, grid):\n\n  if not grid:\n   return 0\n\n  islands = 0\n  visited = set()\n  rows, cols = len(grid), len(grid[0])\n  directions = [[1, 0], [-1, 0], [0, 1], [0, -1]]\n\n  def bfs(r, c):\n   q = collections.deque()\n\n   visited.add((r, c))\n   q.append((r, c))\n\n   while q:\n    cur_r, cur_c = q.popleft()\n\n    for dr, dc in directions:\n\n     new_dr = cur_r + dr\n     new_dc = cur_c + dc\n\n     if (new_dr in range(rows) and new_dc in range(cols) and\n      grid[new_dr][new_dc] == \"1\" and (new_dr, new_dc) not in visited):\n\n      visited.add((new_dr, new_dc))\n      q.append((new_dr, new_dc))\n\n  for r in range(rows):\n   for c in range(cols):\n    if (grid[r][c] == \"1\" and\n     (r, c) not in visited):\n     bfs(r, c)\n     islands += 1\n\n  return islands\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 시간 복잡도:\n\n그래서, m x n 그리드에서, 여기서 m은 행의 수를 나타내고 n은 열의 수를 나타냅니다. 이 알고리즘은 각 셀을 정확히 한 번씩 통과합니다. 따라서, 이 알고리즘의 전체 시간 복잡도는 O(m×n)입니다.\n\n읽어 주셔서 감사합니다! 즐거운 코딩하세요!\n","ogImage":{"url":"/assets/img/2024-07-09-PerfectingLeetcode200NumberofIslands_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-PerfectingLeetcode200NumberofIslands_0.png","tag":["Tech"],"readingTime":5},{"title":"Apache Airflow와 Amazon-S3를 사용한 End-to-End ETL 파이프라인 구축 하는 방법","description":"","date":"2024-07-09 09:06","slug":"2024-07-09-End-to-EndETLPipelinewithApacheAirflowandAmazon-S3","content":"\n# 프로젝트 개요\n\n이 프로젝트는 Apache Airflow와 Amazon S3를 사용하여 end-to-end ETL (추출, 변환, 로드) 파이프라인을 개발하는 데 중점을 둡니다.\n\n이 파이프라인은 OpenWeather API에서 날씨 데이터를 검색하여 구조화된 형식으로 변환하고 S3 버킷에로드합니다. 이 프로젝트를 완료하면 희망하는 빈도로 예약된 파이프라인을 실행할 수 있는 완전히 기능하는 파이프라인을 보유하게 됩니다.\n\n# 프로젝트 구조\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 날씨 데이터 가져오기: OpenWeather API에서 날씨 데이터를 가져옵니다.\n- 날씨 데이터 변환: API에서 가져온 데이터는 JSON 형식이며, 변환 작업은 JSON 개체에서 데이터프레임을 만들고 데이터프레임을 CSV 파일로 변환하는 작업을 포함합니다.\n- S3에 데이터로드: 변환된 데이터를 S3 버킷에 저장합니다.\n\n# 사전 준비 및 사용된 도구\n\n- Apache Airflow: 워크플로우를 프로그래밍 방식으로 작성, 예약, 모니터링할 수 있는 강력하고 유연한 플랫폼입니다.\n- OpenWeather API: 여러 도시의 날씨 데이터를 제공하는 서비스입니다.\n- Amazon S3: Amazon Web Services (AWS)의 확장 가능한 객체 스토리지 서비스입니다.\n- Pandas: 데이터 조작 및 분석을 위해 사용되는 Python 라이브러리입니다.\n- Boto3: Python 개발자가 S3와 같은 Amazon 서비스를 활용하는 소프트웨어를 작성할 수 있게 해주는 AWS SDK for Python입니다.\n- DAG 파일: Apache Airflow에서 작업 및 종속성을 정의하는 작업열로서 사용되는 중요한 개념인 Directed Acyclic Graph(DAG) 파일입니다.\n\n# 구현\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- API와 연결하여 데이터를 가져오는 DAG 스크립트를 작성하세요. 데이터는 데이터프레임에 저장됩니다. DAG 코드는 이 페이지의 맨 아래에서 찾을 수 있습니다.\n- EC2 인스턴스를 생성하고 인스턴스를 시작하여 콘솔에 연결하세요. 저는 무료티어 AWS를 사용하여 이 인스턴스를 생성했습니다. 사양은 t2.micro 및 우분투 22 버전입니다.\n\n![이미지](/TIL/assets/img/2024-07-09-End-to-EndETLPipelinewithApacheAirflowandAmazon-S3_0.png)\n\n인스턴스가 실행되면 콘솔에 연결하여 다음을 설치하세요.\n\n```js\nsudo apt-get update\nsudo install python3-pip\nsudo pip install requests pandas boto3 s3fs pyarrow apache-airflow\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 한 번 설치되면, Airflow가 올바르게 설치되었는지 확인하세요. airflow 명령어를 사용하여 확인하고 초기 로그인 자격 증명을 위해 스탠드얼론 명령어를 실행하십시오. 자격 증명을 복사하여 나중에 사용하세요.\n\n```bash\nairflow\nairflow standalone\n```\n\n4. 실행 중인 인스턴스에서 보안으로 이동하여 보안 그룹에 액세스하세요. 인바운드 규칙을 편집하고 새 역할을 생성하세요. \"모든 트래픽\", \"IPv4 어디서나\"로 설정하세요.\n\n5. Airflow 서버와 스케줄러를 시작하세요.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n에어플로우 스케줄러 및 에어플로우 웹서버 - 포트 8080\n\n6. 공개 IP 주소를 복사하고 포트를 추가하세요. 예: 172.31.22.254:8080. 이로써 에어플로우 어플리케이션을 열 수 있습니다. 기본 자격 증명을 사용하여 로그인하고 마음에 드는 비밀번호로 재설정하세요.\n\n7. AWS에서 데이터를 저장할 S3 버킷을 만드세요. IAM 역할을 사용하여 권한을 조정하세요. 새 IAM 역할을 만들고 S3 및 EC2에 권한을 부여하세요.\n\n8. DAG 파일에 관련 있는 S3 버킷 이름을 추가하고 저장하세요.\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n9. 인스턴스 콘솔에서 서버를 중지하고 명령을 실행하세요. 이렇게 하면 airflow의 DAGs 폴더에 액세스할 수 있어요. 원하는 경우 DAG 파일을 추가하고 필요할 때 수정할 수 있어요.\n\n```js\nairflow\ncd airflow\nls\nsudo nano airflow.cfg\n```\n\nDAGs 폴더에서 파일 이름을 조정하세요. 수정된 버퍼를 저장하고 종료하세요.\n\n10. 파일을 저장한 후 airflow 명령을 다시 실행하고 로그인하세요. 그러면 airflow 내에서 Dag 파일을 볼 수 있어요. 보이는 형태는 이렇습니다:\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 Markdown 형식으로 변경된 테이블입니다.\n\n11. 파일을 열어서 수동으로 실행할 수 있어야 합니다. Airflow의 내장 그래프 기능을 사용하여 DAG 파일의 상태를 모니터링할 수 있습니다. 초록 테두리는 성공적인 실행을 나타냅니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n12. 실행이 성공하면 데이터가 S3 버킷에 표시됩니다.\n\n![Airflow-S3](/TIL/assets/img/2024-07-09-End-to-EndETLPipelinewithApacheAirflowandAmazon-S3_4.png)\n\nDAG 파일과 설명:\n\n```js\nfrom datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nimport requests\nimport pandas as pd\nimport boto3\nfrom io import StringIO\n\n# Configuration\nAPI_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxx'  # OpenWeather의 API 키\nCITY = 'Arizona'  # 날씨 데이터를 가져올 도시\nS3_BUCKET = 'open-weather-s3-bucket'  # 데이터가 저장될 S3 버킷 이름\nS3_KEY = 'weather_data/weather.csv'  # S3 오브젝트 키 (버킷 내 파일 경로)\n\n# DAG를 위한 기본 인수\ndefault_args = {\n    'owner': 'airflow',  # DAG 소유자\n    'depends_on_past': False,  # 작업 인스턴스는 과거 실행에 의존하지 않음\n    'start_date': datetime(2024, 7, 5),  # DAG 시작 날짜\n    'email_on_failure': False,  # 실패 시 이메일 알림 비활성화\n    'email_on_retry': False,  # 재시도 시 이메일 알림 비활성화\n    'retries': 1,  # 실패 시 재시도 횟수\n    'retry_delay': timedelta(minutes=5),  # 재시도 간의 지연\n}\n\n# 스케줄러가 없는 DAG 정의\ndag = DAG(\n    'OpenWeather_to_s3',\n    default_args=default_args,\n    description='날씨 데이터를 가져와 변환한 후 S3로 로드합니다.',\n    schedule_interval=None,  # schedule_interval을 None으로 설정하여 스케줄러 비활성화\n)\n\ndef fetch_weather_data():\n    \"\"\"OpenWeather API에서 날씨 데이터 가져오기\"\"\"\n    url = f\"http://api.openweathermap.org/data/2.5/weather?q={CITY}&appid={API_KEY}\"  # 도시와 API 키를 포함한 API 엔드포인트\n    response = requests.get(url)  # API에 GET 요청 보내기\n    data = response.json()  # 응답을 JSON으로 변환\n    return data  # 데이터 반환\n\ndef transform_weather_data(**kwargs):\n    \"\"\"가져온 날씨 데이터 변환하기\"\"\"\n    ti = kwargs['ti']  # 작업 인스턴스 가져오기\n    data = ti.xcom_pull(task_ids='fetch_weather_data')  # XCom을 사용하여 'fetch_weather_data' 작업에서 데이터 가져오기\n\n    weather = {\n        'city': data['name'],  # 도시 이름 추출\n        'temperature': data['main']['temp'],  # 온도 추출\n        'pressure': data['main']['pressure'],  # 기압 추출\n        'humidity': data['main']['humidity'],  # 습도 추출\n        'weather': data['weather'][0]['description'],  # 날씨 설명 추출\n        'wind_speed': data['wind']['speed'],  # 풍속 추출\n        'date': datetime.utcfromtimestamp(data['dt']).strftime('%Y-%m-%d %H:%M:%S')  # 타임스탬프를 읽기 가능한 날짜로 변환\n    }\n\n    df = pd.DataFrame([weather])  # 날씨 데이터를 판다스 DataFrame으로 변환\n    return df  # DataFrame 반환\n\ndef load_data_to_s3(**kwargs):\n    \"\"\"변환된 데이터를 S3 버킷에 로드하기\"\"\"\n    ti = kwargs['ti']  # 작업 인스턴스 가져오기\n    df = ti.xcom_pull(task_ids='transform_weather_data')  # XCom을 사용하여 'transform_weather_data' 작업에서 변환된 데이터 가져오기\n\n    csv_buffer = StringIO()  # 인메모리 버퍼 생성\n    df.to_csv(csv_buffer, index=False)  # DataFrame을 CSV로 버퍼에 작성\n    print(df)  # DataFrame 출력 (선택 사항)\n\n    s3_resource = boto3.resource('s3')  # boto3 S3 리소스 생성\n    s3_resource.Object(S3_BUCKET, S3_KEY).put(Body=csv_buffer.getvalue())  # CSV 데이터를 지정한 S3 버킷 및 키에 업로드\n\n# PythonOperator를 사용하여 작업 정의\nfetch_task = PythonOperator(\n    task_id='fetch_weather_data',  # 작업 ID\n    python_callable=fetch_weather_data,  # 호출 가능한 함수\n    dag=dag,  # 작업이 속한 DAG\n)\n\ntransform_task = PythonOperator(\n    task_id='transform_weather_data',  # 작업 ID\n    python_callable=transform_weather_data,  # 호출 가능한 함수\n    provide_context=True,  # 호출 가능한 함수에 컨텍스트 제공\n    dag=dag,  # 작업이 속한 DAG\n)\n\nload_task = PythonOperator(\n    task_id='load_data_to_s3',  # 작업 ID\n    python_callable=load_data_to_s3,  # 호출 가능한 함수\n    provide_context=True,  # 호출 가능한 함수에 컨텍스트 제공\n    dag=dag,  # 작업이 속한 DAG\n)\n\n# 작업 간 의존성 정의 (작업 실행 순서)\nfetch_task >> transform_task >> load_task  # 작업 실행 순서 설정: 가져오기 -> 변환 -> 로드\n```\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n설명:\n\n- Imports 및 구성: 필요한 라이브러리를 import하고 구성 변수를 설정합니다.\n- 기본 인수: DAG의 기본 인수를 정의합니다. 예를 들어, 소유자, 시작 날짜, 재시도 정책 등이 포함됩니다.\n- DAG 정의: DAG 개체를 설명과 일정 간격으로 생성합니다 (일정을 비활성화하려면 None으로 설정 가능합니다).\n- 작업 함수: 사용할 Python 함수를 작업으로 정의합니다.\n\n- fetch_weather_data: OpenWeather API에서 날씨 데이터를 가져옵니다.\n- transform_weather_data: 가져온 데이터를 Pandas DataFrame으로 변환합니다.\n- load_data_to_s3: 변환된 데이터를 S3 버킷에 로드합니다.\n\n5. 작업 생성: PythonOperator를 사용하여 정의된 함수를 호출하는 작업을 생성합니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n6. 종속성 설정: 비트 시프트 연산자를 사용하여 작업을 실행할 순서를 정의하세요.\n\n# 자료들\n","ogImage":{"url":"/assets/img/2024-07-09-End-to-EndETLPipelinewithApacheAirflowandAmazon-S3_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-End-to-EndETLPipelinewithApacheAirflowandAmazon-S3_0.png","tag":["Tech"],"readingTime":9},{"title":"훌륭한 베이즈 통계 개념 입문","description":"","date":"2024-07-09 09:05","slug":"2024-07-09-AFantasticIntroductiontotheConceptofBayesianStatistics","content":"\n저는 최근 캠브리지 대학 입학 시험지에 나온 매우 어려워 보이지만 창의적으로 표현된 문제를 발견했습니다. 처음에는 매우 복잡해 보였지만, 몇 년간 수학을 연습한 경험으로 배운 한 가지는, 당장 무슨 일을 하는지 모르는 경우에는 가지고 있는 정보들을 적도록 하는 것이 중요하다는 것입니다. 그렇게 하면 종종 해결법이 나타날 겁니다.\n\n이제 문제부터 시작해보죠. 여기 있습니다. 이런 질문을 쓰는 것은 아마 작가가 창의적으로 시도할 수 있는 소중한 기회 중 하나인 것 같아서 웃음이 나네요 😂\n\n이렇게 정보를 적어 보겠습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그 곳에 많은 정보가 제공되었기 때문에, 질문을 다루기 전에 유용한 형식으로 모두 적어 두기로 결정했습니다. 질문이 주로 넥타이와 바지의 조합과 관련이 있다고 생각해서 간단한 표가 정보를 잡아낼 수 있을 것이라고 판단하여, 바지 선택을 행으로 하는 표를 만들었습니다. 넥타이 선택을 열로 했습니다. 표의 각 셀은 바지에 따른 넥타이 선택의 확률입니다...\n","ogImage":{"url":"/assets/img/2024-07-09-AFantasticIntroductiontotheConceptofBayesianStatistics_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-AFantasticIntroductiontotheConceptofBayesianStatistics_0.png","tag":["Tech"],"readingTime":1},{"title":"당신의 삶을 안전하고, 쉬우며, 행복하게 만들어주는 7가지 유용한 Python 스크립트","description":"","date":"2024-07-09 09:04","slug":"2024-07-09-7HandyPythonScriptsThatMadeYourLifeSecurerEasierandHappier","content":"\n## 파이썬\n\n![Python](/TIL/assets/img/2024-07-09-7HandyPythonScriptsThatMadeYourLifeSecurerEasierandHappier_0.png)\n\n파이썬 프로그래밍 기술은 적절히 활용할 수 있다면 취업뿐만 아니라 삶을 더욱 효율적으로 자동화하고 간소화할 수 있습니다.\n\n우리 일상 생활과 업무에는 지루하고 반복적인 작업이 많습니다. 디지털 형태로 표현될 수 있는 작업이라면 파이썬으로 최적화할 수 있습니다. (아마도 파이썬은 현재로서는 정원 가꾸는 데는 크게 도움을 줄 수 없을 것입니다.)\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사에서는 이 목적을 위한 7가지 유용한 파이썬 스크립트를 소개합니다.\n\n# 1. 디지털 안전을 위해 강력하고 예측할 수 없는 암호 생성하기\n\n온라인 계정의 비밀번호로 여전히 생일을 사용하고 있나요?\n\n디지털 보안을 향상시키는 때입니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n하지만 강력하고 예측 불가능한 암호를 얻는 것은 쉽지 않습니다. 그래서 이 작업을 Python에 맡겨두는 것이 좋은 아이디어입니다.\n\n다음은 이 유형의 암호를 생성하는 Python 스크립트입니다:\n\n```js\n# 강력하고 예측 불가능한 암호를 생성하기 위한 Python 스크립트\n# 저자: 양 조우\nimport secrets\nimport string\n\n\ndef generate_strong_password(length=8):\n    alphabet = string.ascii_letters +…\n```\n","ogImage":{"url":"/assets/img/2024-07-09-7HandyPythonScriptsThatMadeYourLifeSecurerEasierandHappier_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-7HandyPythonScriptsThatMadeYourLifeSecurerEasierandHappier_0.png","tag":["Tech"],"readingTime":2},{"title":"2024년에 풀스택 데이터 과학자가 되는 방법","description":"","date":"2024-07-09 09:03","slug":"2024-07-09-Howwillyoubeafull-stackdatascientistin2024","content":"\n![이미지](/TIL/assets/img/2024-07-09-Howwillyoubeafull-stackdatascientistin2024_0.png)\n\n내 꿈이었던 직업은 데이터 과학자가 되는 것이었습니다. 이 끝없는 여정은 2021년 9월 7일에 시작되었습니다. 고등학교 때부터 컴퓨터 과학에 관심을 가졌습니다. 삶은 나를 산업계의 생산 엔지니어로 이끌었습니다. 경력 동안 많은 데이터 주도 비즈니스 개발 프로젝트를 수행했습니다. 코로나 시기 이후, 내 열정을 찾고 미래로 나아가기로 결심했습니다. 파이썬 프로그래밍 언어를 배우기 시작했습니다. 학습 습관을 형성하는 데 74일이 걸렸습니다. 학습을 멈추지 않았습니다. 파이썬이 데이터 과학에서 가장 인기 있는 언어임을 알아보고 목표를 데이터 과학 분야로 변경했습니다. 제 생애 13년을 제조 엔지니어로 보낸 뒤에 데이터 과학이 경력 전환에 가장 적합한 분야임을 깨달았습니다.\n\n항상 기초가 중요하다고 믿었습니다. 파이썬에 몰두했습니다. 6개월이 걸렸습니다. 동시에 Numpy, Pandas, Matplotlib, Seaborn, Scikit-learn 같은 파이썬의 인기 있는 라이브러리를 배우기 시작했습니다. 또한 데이터 과학 부트캠프에 등록했습니다. 성장 마인드셋을 채택했습니다. 가치 있는 데이터 과학 소셜 네트워크를 구축했습니다. 새로운 데이터 과학 기회를 얻을 수 있는 기술을 표현하는 자신감을 얻었습니다. 3개월 후에 데이터 관련 직무를 시작했습니다.\n\n새로운 역할을 맡은 때에도 아직 달성해야 할 목표가 있었습니다. 기대치를 높였습니다. 프로그래밍의 객체 지향 접근법을 배웠습니다. 객체 지향 프로그래밍을 잘 이해하기 위해 자바 프로그래밍 언어를 공부했고, 이 접근법을 파이썬을 사용해 데이터 과학 프로젝트에 적용했습니다. 예측 분석을 위한 파이프라인을 구축했습니다. 이를 통해 확장 가능하고 유연한 모델과 유지 보수가 쉬운 보고 도구를 구축할 수 있었습니다. 상사들로부터 매우 감명깊은 피드백을 받았습니다. 이는 제 동기부여에 도움이 되었습니다.\n\n<!-- TIL 수평 -->\n\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-4877378276818686\"\n     data-ad-slot=\"1549334788\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이번 성공 이후, 경쟁 예측 분석 도구를 해킹하기 위해 역공학을 수행했습니다. 예측 분석을 위한 클러스터링 머신 러닝 알고리즘의 나만의 버전을 만들었고, 아직 개발 중에 있습니다.\n\n이 기간 동안 GPT 시스템에 대한 혹평에 실망했습니다. GPT 시스템을 해킹할 방법을 찾기 시작했고, V자형 직원이 데이터 과학에서 더 많은 잠재력을 가지고 있다는 것을 발견했습니다. 클라우드 컴퓨팅이 미래라고 생각했고, 풀 스택 데이터 과학자가 되는 목표를 세웠습니다. 이 모델에서 데이터 과학에 대한 심도 있는 지식을 개발하고, 데이터 엔지니어링, 데이터 분석, 프로젝트 관리, 소프트웨어 엔지니어링, ML/AI 엔지니어링 및 DevOps 지식을 확장하고 싶습니다.\n\nAWS, Azure 및 GCP의 기본 클라우드 컴퓨팅 자격증 준비를 시작했습니다. Europe와 미국의 수요가 많은 기술을 찾기 위해 LinkedIn의 구인 게시판을 분석했으며, 아래 목록을 만들었습니다. 더 추가하고 싶은 항목이 있으면 댓글을 남겨주세요. 데이터 과학에 대한 열정이 계속됩니다.\n\n- Agile\n- Amazon Kinesis\n- Apache Airflow\n- Apache Cassandra\n- Apache Hadoop\n- Apache Hive\n- Apache Kafka\n- Apache Spark\n- Apheris\n- ARIMA\n- Atlassian Bitbucket\n  -AWS\n- AWS Athena\n- AWS Bedrock\n- AWS Glue\n- AWS Redshift\n- AWS S3\n- AWS SageMaker\n- Azure\n- Azure AI Services\n- Azure CosmosDB\n- Azure Data factory\n- Azure Data Lake\n- Azure Data storage\n- Azure Databricks\n- Azure HDInsight\n- Azure Machine Learning Studio\n- Azure SQL\n- Azure Stream Analytics\n- Azure Synapse Analytics\n- Bash\n- Bigquery\n- C\n- C#\n- C++\n- Catboost\n- CI/CD\n- Circle CI\n- Databricks\n- Datashield\n- DAX\n- DBT\n- Deep Learning\n- DevOps\n- Digital Signal Processing\n- Docker\n- DOMO\n- Elasticsearch\n- ETL\n- FA/FL\n- Fast Fourier Analysis\n- FastAPI\n- Feature Engineering\n- Fivetran\n- FPGA\n- GCP\n- GCP Looker\n- Git\n- GitHub\n- GitLab\n- GraphQL\n- IBM Cognos Analytics\n- Java\n- Javascript\n- Jenkins\n- Jupyter\n- Kubeflow\n- Kubernetes\n- LangChain\n- LightGBM\n- Linux\n- LLM\n- LSTM\n- Matplotlib\n- Metabase\n- Microsoft 365\n- Microsoft Language Studio\n- Microsoft SQL Server\n- MLflow\n- Monai\n- MongoDB\n- MySQL\n- NLP\n- NLTK\n- NoSQL\n- Numpy\n- Nvidia Flare\n- NWP\n- OOP\n- OpenAI API\n- OpenCL\n- Oracle\n- Pandas\n- PostgreSQL\n- Power BI\n- PySpark\n- Pytest\n- Python\n- PyTorch\n- QlikSense\n- Qlikview\n- R\n- RAG\n- Rest API\n- SAS\n- Scala\n- Scikit-learn\n- Scipy\n- Scrum\n- SDLC\n- Snowflake\n- Spacy\n- Spinnaker\n- SQL\n- SQLAlchemy\n- Streamlit\n- Tableau\n- Tensorflow\n- Tensorflow Lite\n- Time Series\n- Travis CI\n- Vector Database\n- XGBoost\n","ogImage":{"url":"/assets/img/2024-07-09-Howwillyoubeafull-stackdatascientistin2024_0.png"},"coverImage":"/TIL/assets/img/2024-07-09-Howwillyoubeafull-stackdatascientistin2024_0.png","tag":["Tech"],"readingTime":4}],"page":"33","totalPageCount":41,"totalPageGroupCount":3,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}